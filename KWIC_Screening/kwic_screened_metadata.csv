Year,pdf_name,ID,title,author,keywords,abstract,doi,bibtex
2002,nime2002_Oboe.pdf,nime2002_Oboe,Multi-instrument Virtual Keyboard -- The MIKEY Project,"Oboe, Roberto and De Poli, Giovanni","Virtual mechanisms, dynamic simulation","The design of a virtual keyboard, capable of reproducing the tactile feedback of several musical instruments is reported. The key is driven by a direct drive motor, which allows friction free operations. The force to be generated by the motor is calculated in real time by a dynamic simulator, which contains the model of mechanisms' components and constraints. Each model is tuned on the basis of measurements performed on the real system. So far, grand piano action, harpsichord and Hammond organ have been implemented successfully on the system presented here. ",10.5281/zenodo.1176452,"@inproceedings{nime2002_Oboe,
 abstract = {The design of a virtual keyboard, capable of reproducing the tactile feedback of several musical instruments is reported. The key is driven by a direct drive motor, which allows friction free operations. The force to be generated by the motor is calculated in real time by a dynamic simulator, which contains the model of mechanisms' components and constraints. Each model is tuned on the basis of measurements performed on the real system. So far, grand piano action, harpsichord and Hammond organ have been implemented successfully on the system presented here. },
 address = {Dublin, Ireland},
 author = {Oboe, Roberto and De Poli, Giovanni},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 date = {24-26 May, 2002},
 doi = {10.5281/zenodo.1176452},
 issn = {2220-4806},
 keywords = {Virtual mechanisms, dynamic simulation},
 pages = {137--142},
 title = {Multi-instrument Virtual Keyboard -- The MIKEY Project},
 url = {http://www.nime.org/proceedings/2002/nime2002_137.pdf},
 year = {2002}
}
"
2025,nime2025_61.pdf,nime2025_61,Augmentation of a Historical Harpsichord Keyboard Replica for Haptic-Enabled Interaction in Museum Exhibitions,Matthew Hamilton and Michele Ducceschi and Roberto Livi and Catalina Vicens and Andrew McPherson,,"This paper describes the design and creation of an electronically augmented replica of a historical harpsichord keyboard with a typical 17th-century Italian layout to create a digital musical instrument. The keyboard was commissioned for exhibition in a musical instrument museum to enhance the visitor experience by providing an interface to digitised versions of instruments within the collection. The replica balances the competing demands of historical authenticity, public accessibility, and preservation. It replicates the original instrument’s tactile feedback and mechanical resistance using historically informed construction techniques. Optical sensors integrated within the mechanism capture the jacks’ motion data, enabling MIDI message generation. This work situates itself within broader discussions on the role of technology in museums. A keyboard interface of this type offers an opportunity to enhance visitor interaction with musical heritage while safeguarding delicate artefacts. The paper examines the keyboard’s design principles, technical implementation, and implications, emphasising its contribution to public engagement and the long-term preservation of musical heritage.",10.5281/zenodo.15698916,"@inproceedings{nime2025_61,
 abstract = {This paper describes the design and creation of an electronically augmented replica of a historical harpsichord keyboard with a typical 17th-century Italian layout to create a digital musical instrument. The keyboard was commissioned for exhibition in a musical instrument museum to enhance the visitor experience by providing an interface to digitised versions of instruments within the collection. The replica balances the competing demands of historical authenticity, public accessibility, and preservation. It replicates the original instrument’s tactile feedback and mechanical resistance using historically informed construction techniques. Optical sensors integrated within the mechanism capture the jacks’ motion data, enabling MIDI message generation. This work situates itself within broader discussions on the role of technology in museums. A keyboard interface of this type offers an opportunity to enhance visitor interaction with musical heritage while safeguarding delicate artefacts. The paper examines the keyboard’s design principles, technical implementation, and implications, emphasising its contribution to public engagement and the long-term preservation of musical heritage.},
 address = {Canberra, Australia},
 articleno = {61},
 author = {Matthew Hamilton and Michele Ducceschi and Roberto Livi and Catalina Vicens and Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698916},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {8},
 pages = {424--431},
 title = {Augmentation of a Historical Harpsichord Keyboard Replica for Haptic-Enabled Interaction in Museum Exhibitions},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_61.pdf},
 year = {2025}
}
"
2021,nime2021_44.pdf,nime2021_44,An Infinitely Sustaining Piano Achieved Through a Soundboard-Mounted Shaker  ,"Thompson, William and Berdahl, Edgar",,"This paper outlines a demonstration of an acoustic piano augmentation that allows for infinite sustain of one or many notes. The result is a natural sounding piano sustain that lasts for an unnatural period of time. Using a tactile shaker, a contact microphone and an amplitude activated FFT-freeze Max patch, this system is easily assembled and creates an infinitely sustaining piano.",10.21428/92fbeb44.2c4879f5,"@inproceedings{nime2021_44,
 abstract = {This paper outlines a demonstration of an acoustic piano augmentation that allows for infinite sustain of one or many notes. The result is a natural sounding piano sustain that lasts for an unnatural period of time. Using a tactile shaker, a contact microphone and an amplitude activated FFT-freeze Max patch, this system is easily assembled and creates an infinitely sustaining piano.},
 address = {Shanghai, China},
 articleno = {44},
 author = {Thompson, William and Berdahl, Edgar},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.2c4879f5},
 issn = {2220-4806},
 month = {June},
 presentation-video = {https://youtu.be/YRby0VdL8Nk},
 title = {An Infinitely Sustaining Piano Achieved Through a Soundboard-Mounted Shaker  },
 url = {https://nime.pubpub.org/pub/cde9r70r},
 year = {2021}
}
"
2010,nime2010_McPherson.pdf,nime2010_McPherson,Augmenting the Acoustic Piano with Electromagnetic String Actuation and Continuous Key Position Sensing,"McPherson, Andrew and Kim, Youngmoo","Augmented instruments, piano, interfaces, electromagnetic actuation, gesture measurement","This paper presents the magnetic resonator piano, an augmented instrument enhancing the capabilities of the acoustic grand piano. Electromagnetic actuators induce the stringsto vibration, allowing each note to be continuously controlled in amplitude, frequency, and timbre without external loudspeakers. Feedback from a single pickup on thepiano soundboard allows the actuator waveforms to remainlocked in phase with the natural motion of each string. Wealso present an augmented piano keyboard which reportsthe continuous position of every key. Time and spatial resolution are sufficient to capture detailed data about keypress, release, pretouch, aftertouch, and other extended gestures. The system, which is designed with cost and setupconstraints in mind, seeks to give pianists continuous control over the musical sound of their instrument. The instrument has been used in concert performances, with theelectronically-actuated sounds blending with acoustic instruments naturally and without amplification.",10.5281/zenodo.1177849,"@inproceedings{nime2010_McPherson,
 abstract = {This paper presents the magnetic resonator piano, an augmented instrument enhancing the capabilities of the acoustic grand piano. Electromagnetic actuators induce the stringsto vibration, allowing each note to be continuously controlled in amplitude, frequency, and timbre without external loudspeakers. Feedback from a single pickup on thepiano soundboard allows the actuator waveforms to remainlocked in phase with the natural motion of each string. Wealso present an augmented piano keyboard which reportsthe continuous position of every key. Time and spatial resolution are sufficient to capture detailed data about keypress, release, pretouch, aftertouch, and other extended gestures. The system, which is designed with cost and setupconstraints in mind, seeks to give pianists continuous control over the musical sound of their instrument. The instrument has been used in concert performances, with theelectronically-actuated sounds blending with acoustic instruments naturally and without amplification.},
 address = {Sydney, Australia},
 author = {McPherson, Andrew and Kim, Youngmoo},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177849},
 issn = {2220-4806},
 keywords = {Augmented instruments, piano, interfaces, electromagnetic actuation, gesture measurement},
 pages = {217--222},
 title = {Augmenting the Acoustic Piano with Electromagnetic String Actuation and Continuous Key Position Sensing},
 url = {http://www.nime.org/proceedings/2010/nime2010_217.pdf},
 year = {2010}
}
"
2014,nime2014_pvandertorren1.pdf,nime2014_pvandertorren1,"Striso, a Compact Expressive Instrument Based on a New Isomorphic Note Layout",Piers Titus van der Torren,,"The Striso is a new expressive music instrument with an acoustic feel, which is designed to be intuitive to play and playable everywhere. The sound of every note can be precisely controlled using the direction and pressure sensitive buttons, combined with instrument motion like tilting or shaking. It works standalone, with an internal speaker and battery, and is meant as a self contained instrument with its own distinct sound, but can also be connected to a computer to control other synthesizers. The notes are arranged in an easy and systematic way, according to the new DCompose note layout that is also presented in this paper. The DCompose note layout is designed to be compact, ergonomic, easy to learn, and closely bound to the harmonic properties of the notes.",10.5281/zenodo.1178957,"@inproceedings{nime2014_pvandertorren1,
 abstract = {The Striso is a new expressive music instrument with an acoustic feel, which is designed to be intuitive to play and playable everywhere. The sound of every note can be precisely controlled using the direction and pressure sensitive buttons, combined with instrument motion like tilting or shaking. It works standalone, with an internal speaker and battery, and is meant as a self contained instrument with its own distinct sound, but can also be connected to a computer to control other synthesizers. The notes are arranged in an easy and systematic way, according to the new DCompose note layout that is also presented in this paper. The DCompose note layout is designed to be compact, ergonomic, easy to learn, and closely bound to the harmonic properties of the notes.},
 address = {London, United Kingdom},
 author = {Piers Titus van der Torren},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178957},
 issn = {2220-4806},
 month = {June},
 pages = {615--620},
 publisher = {Goldsmiths, University of London},
 title = {Striso, a Compact Expressive Instrument Based on a New Isomorphic Note Layout},
 url = {http://www.nime.org/proceedings/2014/nime2014_442.pdf},
 year = {2014}
}
"
2015,nime2015_pdahlstedt.pdf,nime2015_pdahlstedt,Mapping Strategies and Sound Engine Design for an Augmented Hybrid Piano,Palle Dahlstedt,,"Based on a combination of novel mapping techniques and carefully designed sound engines, I present an augmented hybrid piano specifically designed for improvisation. The mapping technique, originally developed for other control interfaces but here adapted to the piano keyboard, is based on a dynamic vectorization of control parameters, allowing both wild sonic exploration and minute intimate expression. The original piano sound is used as the sole sound source, subjected to processing techniques such as virtual resonance strings, dynamic buffer shuffling, and acoustic and virtual feedback. Thanks to speaker and microphone placement, the acoustic and processed sounds interact in both directions and blend into one new instrument. This also allows for unorthodox playing (knocking, plucking, shouting). Processing parameters are controlled from the keyboard playing alone, allowing intuitive control of complex processing by ear, integrating expressive musical playing with sonic exploration. The instrument is not random, but somewhat unpredictable. This feeds into the improvisation, defining a particular idiomatics of the instruments. Hence, the instrument itself is an essential part of the musical work. Performances include concerts in UK, Japan, Singapore, Australia and Sweden, in solos and ensembles, performed by several pianists. Variations of this hybrid instrument for digital keyboards are also presented.",10.5281/zenodo.1179046,"@inproceedings{nime2015_pdahlstedt,
 abstract = {Based on a combination of novel mapping techniques and carefully designed sound engines, I present an augmented hybrid piano specifically designed for improvisation. The mapping technique, originally developed for other control interfaces but here adapted to the piano keyboard, is based on a dynamic vectorization of control parameters, allowing both wild sonic exploration and minute intimate expression. The original piano sound is used as the sole sound source, subjected to processing techniques such as virtual resonance strings, dynamic buffer shuffling, and acoustic and virtual feedback. Thanks to speaker and microphone placement, the acoustic and processed sounds interact in both directions and blend into one new instrument. This also allows for unorthodox playing (knocking, plucking, shouting). Processing parameters are controlled from the keyboard playing alone, allowing intuitive control of complex processing by ear, integrating expressive musical playing with sonic exploration. The instrument is not random, but somewhat unpredictable. This feeds into the improvisation, defining a particular idiomatics of the instruments. Hence, the instrument itself is an essential part of the musical work. Performances include concerts in UK, Japan, Singapore, Australia and Sweden, in solos and ensembles, performed by several pianists. Variations of this hybrid instrument for digital keyboards are also presented.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Palle Dahlstedt},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179046},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {271--276},
 publisher = {Louisiana State University},
 title = {Mapping Strategies and Sound Engine Design for an Augmented Hybrid Piano},
 url = {http://www.nime.org/proceedings/2015/nime2015_170.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/170/0170-file1.zip},
 year = {2015}
}
"
2013,nime2013_McPherson.pdf,nime2013_McPherson,Portable Measurement and Mapping of Continuous Piano Gesture,Andrew McPherson,"Piano, keyboard, optical sensing, gesture sensing, visual feedback, mapping, magnetic resonator piano","This paper presents a portable optical measurement system for capturingcontinuous key motion on any piano. Very few concert venues have MIDI-enabledpianos, and many performers depend on the versatile but discontinued MoogPianoBar to provide MIDI from a conventional acoustic instrument. The scannerhardware presented in this paper addresses the growing need for alternativesolutions while surpassing existing systems in the level of detail measured.Continuous key position on both black and white keys is gathered at 1kHz samplerate. Software extracts traditional and novel features of keyboard touch fromeach note, which can be flexibly mapped to sound using MIDI or Open SoundControl. RGB LEDs provide rich visual feedback to assist the performer ininteracting with more complex sound mapping arrangements. An application ispresented to the magnetic resonator piano, an electromagnetically-augmentedacoustic grand piano which is performed using continuous key positionmeasurements.",10.5281/zenodo.1178610,"@inproceedings{nime2013_McPherson,
 abstract = {This paper presents a portable optical measurement system for capturingcontinuous key motion on any piano. Very few concert venues have MIDI-enabledpianos, and many performers depend on the versatile but discontinued MoogPianoBar to provide MIDI from a conventional acoustic instrument. The scannerhardware presented in this paper addresses the growing need for alternativesolutions while surpassing existing systems in the level of detail measured.Continuous key position on both black and white keys is gathered at 1kHz samplerate. Software extracts traditional and novel features of keyboard touch fromeach note, which can be flexibly mapped to sound using MIDI or Open SoundControl. RGB LEDs provide rich visual feedback to assist the performer ininteracting with more complex sound mapping arrangements. An application ispresented to the magnetic resonator piano, an electromagnetically-augmentedacoustic grand piano which is performed using continuous key positionmeasurements.},
 address = {Daejeon, Republic of Korea},
 author = {Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178610},
 issn = {2220-4806},
 keywords = {Piano, keyboard, optical sensing, gesture sensing, visual feedback, mapping, magnetic resonator piano},
 month = {May},
 pages = {152--157},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Portable Measurement and Mapping of Continuous Piano Gesture},
 url = {http://www.nime.org/proceedings/2013/nime2013_240.pdf},
 year = {2013}
}
"
2025,nime2025_6.pdf,nime2025_6,XR Musical Keyboard: An Extended Reality Keyboard with an Arbitrary Number of Keys and Pitches,Tatsunori Hirai and Jack Topliss and Thammathip Piumsomboon,,"We introduce the Extended Reality (XR) Musical Keyboard, a system allowing users to overlay a virtual keyboard onto a tabletop surface, such as a standard PC keyboard. This virtual keyboard is highly customizable: users can freely program the number of keys and their respective pitches. Modern software instruments offer advanced capabilities, including microtonal scales (pitches outside the standard 12-tone equal temperament). However, playing these instruments often remains challenging due to the lack of corresponding physical hardware. Our proposed solution addresses this gap by projecting a programmable virtual keyboard onto a tangible object within the XR space. This approach combines the software's flexibility with the tactile feedback of a physical surface, enhancing playability. Users can simplify the keyboard layout (e.g., fewer keys than a piano) or expand it beyond conventional limits to explore new expressive possibilities, particularly for microtonal music. We conducted a small pilot study (N=4) involving participants mostly inexperienced with keyboards to gather preliminary feedback on the interface's ease of use for performance.",10.5281/zenodo.15698784,"@inproceedings{nime2025_6,
 abstract = {We introduce the Extended Reality (XR) Musical Keyboard, a system allowing users to overlay a virtual keyboard onto a tabletop surface, such as a standard PC keyboard. This virtual keyboard is highly customizable: users can freely program the number of keys and their respective pitches. Modern software instruments offer advanced capabilities, including microtonal scales (pitches outside the standard 12-tone equal temperament). However, playing these instruments often remains challenging due to the lack of corresponding physical hardware. Our proposed solution addresses this gap by projecting a programmable virtual keyboard onto a tangible object within the XR space. This approach combines the software's flexibility with the tactile feedback of a physical surface, enhancing playability. Users can simplify the keyboard layout (e.g., fewer keys than a piano) or expand it beyond conventional limits to explore new expressive possibilities, particularly for microtonal music. We conducted a small pilot study (N=4) involving participants mostly inexperienced with keyboards to gather preliminary feedback on the interface's ease of use for performance.},
 address = {Canberra, Australia},
 articleno = {6},
 author = {Tatsunori Hirai and Jack Topliss and Thammathip Piumsomboon},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698784},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {6},
 pages = {40--45},
 title = {XR Musical Keyboard: An Extended Reality Keyboard with an Arbitrary Number of Keys and Pitches},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_6.pdf},
 year = {2025}
}
"
2016,nime2016_Meacham.pdf,nime2016_Meacham,The Laptop Accordion,Aidan Meacham and Sanjay Kannan and Ge Wang,,"The `Laptop Accordion' co-opts the commodity laptop
computer
to craft an expressive, whimsical accordion-like instrument.
It utilizes the opening and closing of the laptop
screen as a physical metaphor for accordion bellows, and the
laptop keyboard as musical buttonboard. Motion is tracked
using the laptop camera via optical flow and mapped to continuous
control over dynamics, while the sound is generated
in real-time. The instrument uses both skeuomorphic and
abstract onscreen graphics which further reference the core
mechanics of `squeezebox' instruments. The laptop accordion
provides several game modes, while overall offering an
unconventional aesthetic experience in music making.",10.5281/zenodo.1176078,"@inproceedings{nime2016_Meacham,
 abstract = {The `Laptop Accordion' co-opts the commodity laptop
computer
to craft an expressive, whimsical accordion-like instrument.
It utilizes the opening and closing of the laptop
screen as a physical metaphor for accordion bellows, and the
laptop keyboard as musical buttonboard. Motion is tracked
using the laptop camera via optical flow and mapped to continuous
control over dynamics, while the sound is generated
in real-time. The instrument uses both skeuomorphic and
abstract onscreen graphics which further reference the core
mechanics of `squeezebox' instruments. The laptop accordion
provides several game modes, while overall offering an
unconventional aesthetic experience in music making.},
 address = {Brisbane, Australia},
 author = {Aidan Meacham and Sanjay Kannan and Ge Wang},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176078},
 isbn = {978-1-925455-13-7},
 issn = {2220-4806},
 pages = {236--240},
 publisher = {Queensland Conservatorium Griffith University},
 title = {The Laptop Accordion},
 track = {Papers},
 url = {http://www.nime.org/proceedings/2016/nime2016_paper0047.pdf},
 year = {2016}
}
"
2013,nime2013_Park_a.pdf,nime2013_Park_a,Rainboard and Musix: Building dynamic isomorphic interfaces,Brett Park and David Gerhard,"isomorphic, mobile application, hexagon, keyboard","Since Euler's development of the Tonnetz in 1739, musicians, composers and instrument designers have been fascinated with the concept of musicalisomorphism, the idea that by arranging tones by their harmonic relationships rather than by their physical properties, the common shapes of musical constructs will appear, facilitating learning and new ways of exploring harmonic spaces. The construction of isomorphic instruments, beyond limited square isomorphisms present in many stringed instruments, has been a challenge in the past for two reasons: The first problem, that of re-arranging note actuators from their sounding elements, has been solved by digital instrument design. The second, more conceptual problem, is that only a single isomorphism can be designed for any one instrument, requiring the instrument designer (as well as composer and performer) to ""lock in"" to a single isomorphism, or to have a different instrument for each isomorphism in order to experiment. Musix (an iOS application) and Rainboard (a physical device) are two new musical instruments built to overcome this and other limitations of existing isomorphic instruments. Musix was developed to allow experimentation with a wide variety of different isomorphic layouts, to assess the advantages and disadvantages of each. The Rainboard consists of a hexagonal array of arcade buttons embedded with RGB-LEDs, which are used to indicate characteristics of the isomorphism currently in use on the Rainboard. The creation of these two instruments/experimentation platforms allows for isomorphic layouts to be explored in waysthat are not possible with existing instruments.",10.5281/zenodo.1178632,"@inproceedings{nime2013_Park_a,
 abstract = {Since Euler's development of the Tonnetz in 1739, musicians, composers and instrument designers have been fascinated with the concept of musicalisomorphism, the idea that by arranging tones by their harmonic relationships rather than by their physical properties, the common shapes of musical constructs will appear, facilitating learning and new ways of exploring harmonic spaces. The construction of isomorphic instruments, beyond limited square isomorphisms present in many stringed instruments, has been a challenge in the past for two reasons: The first problem, that of re-arranging note actuators from their sounding elements, has been solved by digital instrument design. The second, more conceptual problem, is that only a single isomorphism can be designed for any one instrument, requiring the instrument designer (as well as composer and performer) to ""lock in"" to a single isomorphism, or to have a different instrument for each isomorphism in order to experiment. Musix (an iOS application) and Rainboard (a physical device) are two new musical instruments built to overcome this and other limitations of existing isomorphic instruments. Musix was developed to allow experimentation with a wide variety of different isomorphic layouts, to assess the advantages and disadvantages of each. The Rainboard consists of a hexagonal array of arcade buttons embedded with RGB-LEDs, which are used to indicate characteristics of the isomorphism currently in use on the Rainboard. The creation of these two instruments/experimentation platforms allows for isomorphic layouts to be explored in waysthat are not possible with existing instruments.},
 address = {Daejeon, Republic of Korea},
 author = {Brett Park and David Gerhard},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178632},
 issn = {2220-4806},
 keywords = {isomorphic, mobile application, hexagon, keyboard},
 month = {May},
 pages = {319--324},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Rainboard and Musix: Building dynamic isomorphic interfaces},
 url = {http://www.nime.org/proceedings/2013/nime2013_65.pdf},
 year = {2013}
}
"
2017,nime2017_bliang.pdf,nime2017_bliang,Piano Pedaller: A Measurement System for Classification and Visualisation of Piano Pedalling Techniques,Beici Liang and György Fazekas and Andrew McPherson and Mark Sandler,,"This paper presents the results of a study of piano pedalling techniques on the sustain pedal using a newly designed measurement system named Piano Pedaller. The system is comprised of an optical sensor mounted in the piano pedal bearing block and an embedded platform for recording audio and sensor data.  This enables recording the pedalling gesture of real players and the piano sound under normal playing conditions. Using the gesture data collected from the system, the task of classifying these data by pedalling technique was undertaken using a Support Vector Machine (SVM). Results can be visualised in an audio based score following application to show pedalling together with the player's position in the score.",10.5281/zenodo.1176268,"@inproceedings{nime2017_bliang,
 abstract = {This paper presents the results of a study of piano pedalling techniques on the sustain pedal using a newly designed measurement system named Piano Pedaller. The system is comprised of an optical sensor mounted in the piano pedal bearing block and an embedded platform for recording audio and sensor data.  This enables recording the pedalling gesture of real players and the piano sound under normal playing conditions. Using the gesture data collected from the system, the task of classifying these data by pedalling technique was undertaken using a Support Vector Machine (SVM). Results can be visualised in an audio based score following application to show pedalling together with the player's position in the score.},
 address = {Copenhagen, Denmark},
 author = {Beici Liang and György Fazekas and Andrew McPherson and Mark Sandler},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176268},
 issn = {2220-4806},
 pages = {325--329},
 publisher = {Aalborg University Copenhagen},
 title = {Piano Pedaller: A Measurement System for Classification and Visualisation of Piano Pedalling Techniques},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0062.pdf},
 year = {2017}
}
"
2025,nime2025_38.pdf,nime2025_38,The Sparksichord: Practical Implementation of a Lorentz Force Electromagnetic Actuation and Feedback System,Adam Schmidt and Jeffrey Snyder and Gian Torrano Jacobs and Joseph Gascho and Joyce Chen and Andrew McPherson,,"In line with a sustained community interest in electromagnetic actuation of musical instruments, we describe practical considerations for Lorentz Force actuation in conductive strings, exemplified by the Sparksichord – an augmented harpsichord that uses Lorentz Force actuation, optical feedback, and analog circuitry to sustain vibrations of its brass strings. Electromagnetically-actuated and feedback instruments have grown increasingly popular in NIME, though most systems rely on the use of solenoid-style electromagnetic coils. By running current through the string itself, Lorentz Force actuation offers an alternate arrangement of magnets and wire that can afford new modes of interaction, a broader frequency response, and cheaper implementation.  We aim to empower practitioners with a toolbox for designing and building actuated instruments of this style and describe our specific implementation for this instrument.",10.5281/zenodo.15698857,"@inproceedings{nime2025_38,
 abstract = {In line with a sustained community interest in electromagnetic actuation of musical instruments, we describe practical considerations for Lorentz Force actuation in conductive strings, exemplified by the Sparksichord – an augmented harpsichord that uses Lorentz Force actuation, optical feedback, and analog circuitry to sustain vibrations of its brass strings. Electromagnetically-actuated and feedback instruments have grown increasingly popular in NIME, though most systems rely on the use of solenoid-style electromagnetic coils. By running current through the string itself, Lorentz Force actuation offers an alternate arrangement of magnets and wire that can afford new modes of interaction, a broader frequency response, and cheaper implementation.  We aim to empower practitioners with a toolbox for designing and building actuated instruments of this style and describe our specific implementation for this instrument.},
 address = {Canberra, Australia},
 articleno = {38},
 author = {Adam Schmidt and Jeffrey Snyder and Gian Torrano Jacobs and Joseph Gascho and Joyce Chen and Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698857},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {12},
 pages = {268--279},
 title = {The Sparksichord: Practical Implementation of a Lorentz Force Electromagnetic Actuation and Feedback System},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_38.pdf},
 year = {2025}
}
"
2008,nime2008_Hadjakos.pdf,nime2008_Hadjakos,The Elbow Piano : Sonification of Piano Playing Movements,"Hadjakos, Aristotelis and Aitenbichler, Erwin and Mühlhäuser, Max","Piano, education, sonification, feedback, gesture. ","The Elbow Piano distinguishes two types of piano touch: a touchwith movement in the elbow joint and a touch without. A playednote is first mapped to the left or right hand by visual tracking.Custom-built goniometers attached to the player's arms are usedto detect the type of touch. The two different types of touchesare sonified by different instrument sounds. This gives theplayer an increased awareness of his elbow movements, which isconsidered valuable for piano education. We have implementedthe system and evaluated it with a group of music students.",10.5281/zenodo.1179553,"@inproceedings{nime2008_Hadjakos,
 abstract = {The Elbow Piano distinguishes two types of piano touch: a touchwith movement in the elbow joint and a touch without. A playednote is first mapped to the left or right hand by visual tracking.Custom-built goniometers attached to the player's arms are usedto detect the type of touch. The two different types of touchesare sonified by different instrument sounds. This gives theplayer an increased awareness of his elbow movements, which isconsidered valuable for piano education. We have implementedthe system and evaluated it with a group of music students.},
 address = {Genoa, Italy},
 author = {Hadjakos, Aristotelis and Aitenbichler, Erwin and M\''{u}hlh\''{a}user, Max},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179553},
 issn = {2220-4806},
 keywords = {Piano, education, sonification, feedback, gesture. },
 pages = {285--288},
 title = {The Elbow Piano : Sonification of Piano Playing Movements},
 url = {http://www.nime.org/proceedings/2008/nime2008_285.pdf},
 year = {2008}
}
"
2017,nime2017_pdahlstedt.pdf,nime2017_pdahlstedt,Physical Interactions with Digital Strings --- A hybrid approach to a digital keyboard instrument,Palle Dahlstedt,,"A new hybrid approach to digital keyboard playing is presented, where the actual acoustic sounds from a digital keyboard are captured with contact microphones and applied as excitation signals to a digital model of a prepared piano, i.e., an extended wave-guide model of strings with the possibility of stopping and muting the strings at arbitrary positions. The parameters of the string model are controlled through TouchKeys multitouch sensors on each key, combined with MIDI data and acoustic signals from the digital keyboard frame, using a novel mapping.  The instrument is evaluated from a performing musician's perspective, and emerging playing techniques are discussed. Since the instrument is a hybrid acoustic-digital system with several feedback paths between the domains, it provides for expressive and dynamic playing, with qualities approaching that of an acoustic instrument, yet with new kinds of control.  The contributions are two-fold. First, the use of acoustic sounds from a physical keyboard for excitations and resonances results in a novel hybrid keyboard instrument in itself. Second, the digital model of ""inside piano"" playing, using multitouch keyboard data, allows for performance techniques going far beyond conventional keyboard playing.",10.5281/zenodo.1176191,"@inproceedings{nime2017_pdahlstedt,
 abstract = {A new hybrid approach to digital keyboard playing is presented, where the actual acoustic sounds from a digital keyboard are captured with contact microphones and applied as excitation signals to a digital model of a prepared piano, i.e., an extended wave-guide model of strings with the possibility of stopping and muting the strings at arbitrary positions. The parameters of the string model are controlled through TouchKeys multitouch sensors on each key, combined with MIDI data and acoustic signals from the digital keyboard frame, using a novel mapping.  The instrument is evaluated from a performing musician's perspective, and emerging playing techniques are discussed. Since the instrument is a hybrid acoustic-digital system with several feedback paths between the domains, it provides for expressive and dynamic playing, with qualities approaching that of an acoustic instrument, yet with new kinds of control.  The contributions are two-fold. First, the use of acoustic sounds from a physical keyboard for excitations and resonances results in a novel hybrid keyboard instrument in itself. Second, the digital model of ""inside piano"" playing, using multitouch keyboard data, allows for performance techniques going far beyond conventional keyboard playing.},
 address = {Copenhagen, Denmark},
 author = {Palle Dahlstedt},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176191},
 issn = {2220-4806},
 pages = {115--120},
 publisher = {Aalborg University Copenhagen},
 title = {Physical Interactions with Digital Strings --- A hybrid approach to a digital keyboard instrument},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0023.pdf},
 year = {2017}
}
"
2020,nime2020_19.pdf,nime2020_19,A platform for low-latency continuous keyboard sensing and sound generation,"Moro, Giulio and McPherson, Andrew",,"On several acoustic and electromechanical keyboard instruments, the produced sound is not always strictly dependent exclusively on a discrete key velocity parameter, and minute gesture details can affect the final sonic result. By contrast, subtle variations in articulation have a relatively limited effect on the sound generation when the keyboard controller uses the MIDI standard, used in the vast majority of digital keyboards. In this paper we present an embedded platform that can generate sound in response to a controller capable of sensing the continuous position of keys on a keyboard. This platform enables the creation of keyboard-based DMIs which allow for a richer set of interaction gestures than would be possible through a MIDI keyboard, which we demonstrate through two example instruments. First, in a Hammond organ emulator, the sensing device allows to recreate the nuances of the interaction with the original instrument in a way a velocity-based MIDI controller could not. Second, a nonlinear waveguide flute synthesizer is shown as an example of the expressive capabilities that a continuous-keyboard controller opens up in the creation of new keyboard-based DMIs.",10.5281/zenodo.4813253,"@inproceedings{nime2020_19,
 abstract = {On several acoustic and electromechanical keyboard instruments, the produced sound is not always strictly dependent exclusively on a discrete key velocity parameter, and minute gesture details can affect the final sonic result. By contrast, subtle variations in articulation have a relatively limited effect on the sound generation when the keyboard controller uses the MIDI standard, used in the vast majority of digital keyboards. In this paper we present an embedded platform that can generate sound in response to a controller capable of sensing the continuous position of keys on a keyboard. This platform enables the creation of keyboard-based DMIs which allow for a richer set of interaction gestures than would be possible through a MIDI keyboard, which we demonstrate through two example instruments. First, in a Hammond organ emulator, the sensing device allows to recreate the nuances of the interaction with the original instrument in a way a velocity-based MIDI controller could not. Second, a nonlinear waveguide flute synthesizer is shown as an example of the expressive capabilities that a continuous-keyboard controller opens up in the creation of new keyboard-based DMIs.},
 address = {Birmingham, UK},
 author = {Moro, Giulio and McPherson, Andrew},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813253},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {97--102},
 presentation-video = {https://youtu.be/Y137M9UoKKg},
 publisher = {Birmingham City University},
 title = {A platform for low-latency continuous keyboard sensing and sound generation},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper19.pdf},
 year = {2020}
}
"
2021,nime2021_25.pdf,nime2021_25,Global Hyperorgan: a platform for telematic musicking and research,"Harlow, Randall and Petersson, Mattias and Ek, Robert and Visi, Federico and Östersjö, Stefan",,"The Global Hyperorgan is an intercontinental, creative space for acoustic musicking. Existing pipe organs around the world are networked for real-time, geographically-distant performance, with performers utilizing instruments and other input devices to collaborate musically through the voices of the pipes in each location. A pilot study was carried out in January 2021, connecting two large pipe organs in Piteå, Sweden, and Amsterdam, the Netherlands. A quartet of performers tested the Global Hyperorgan’s capacities for telematic musicking through a series of pieces. The concept of modularity is useful when considering the artistic challenges and possibilities of the Global Hyperorgan. We observe how the modular system utilized in the pilot study afforded multiple experiences of shared instrumentality from which new, synthetic voices emerge. As a long-term technological, artistic and social research project, the Global Hyperorgan offers a platform for exploring technology, agency, voice, and intersubjectivity in hyper-acoustic telematic musicking.",10.21428/92fbeb44.d4146b2d,"@inproceedings{nime2021_25,
 abstract = {The Global Hyperorgan is an intercontinental, creative space for acoustic musicking. Existing pipe organs around the world are networked for real-time, geographically-distant performance, with performers utilizing instruments and other input devices to collaborate musically through the voices of the pipes in each location. A pilot study was carried out in January 2021, connecting two large pipe organs in Piteå, Sweden, and Amsterdam, the Netherlands. A quartet of performers tested the Global Hyperorgan’s capacities for telematic musicking through a series of pieces. The concept of modularity is useful when considering the artistic challenges and possibilities of the Global Hyperorgan. We observe how the modular system utilized in the pilot study afforded multiple experiences of shared instrumentality from which new, synthetic voices emerge. As a long-term technological, artistic and social research project, the Global Hyperorgan offers a platform for exploring technology, agency, voice, and intersubjectivity in hyper-acoustic telematic musicking.},
 address = {Shanghai, China},
 articleno = {25},
 author = {Harlow, Randall and Petersson, Mattias and Ek, Robert and Visi, Federico and Östersjö, Stefan},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.d4146b2d},
 issn = {2220-4806},
 month = {June},
 presentation-video = {https://youtu.be/t88aIXdqBWQ},
 title = {Global Hyperorgan: a platform for telematic musicking and research},
 url = {https://nime.pubpub.org/pub/a626cbqh},
 year = {2021}
}
"
2009,nime2009_Nicolls.pdf,nime2009_Nicolls,Twenty-First Century Piano,"Nicolls, Sarah","sensor, gestural, technology, performance, piano, motors, interactive ","“The reinvigoration of the role of the human body” - as John Richards recently described trends in using homemade electronics to move away from laptop performance [1] - is mirrored in an ambition of instrumentalists to interact more closely with the electronic sounds they are helping to create. For these players, there has often been a one-way street of the ‘instrument feeds MAX patch’ paradigm and arguments are made here for more complete performance feedback systems. Instrumentalists come to the question of interactivity with a whole array of gestures, sounds and associations already in place, so must choose carefully the means by which the instrumental performance is augmented. Frances-Marie Uitti [2] is a pioneer in the field, creating techniques to amplify the cellist’s innate performative gestures and in parallel developing the instrument. This paper intends to give an overview of the author’s work in developing interactivity in piano performance, mechanical augmentation of the piano and possible structural developments of the instrument to bring it into the twenty-first century.",10.5281/zenodo.1177641,"@inproceedings{nime2009_Nicolls,
 abstract = {“The reinvigoration of the role of the human body” - as John Richards recently described trends in using homemade electronics to move away from laptop performance [1] - is mirrored in an ambition of instrumentalists to interact more closely with the electronic sounds they are helping to create. For these players, there has often been a one-way street of the ‘instrument feeds MAX patch’ paradigm and arguments are made here for more complete performance feedback systems. Instrumentalists come to the question of interactivity with a whole array of gestures, sounds and associations already in place, so must choose carefully the means by which the instrumental performance is augmented. Frances-Marie Uitti [2] is a pioneer in the field, creating techniques to amplify the cellist’s innate performative gestures and in parallel developing the instrument. This paper intends to give an overview of the author’s work in developing interactivity in piano performance, mechanical augmentation of the piano and possible structural developments of the instrument to bring it into the twenty-first century.},
 address = {Pittsburgh, PA, United States},
 author = {Nicolls, Sarah},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177641},
 issn = {2220-4806},
 keywords = {sensor, gestural, technology, performance, piano, motors, interactive },
 pages = {203--206},
 title = {Twenty-First Century Piano},
 url = {http://www.nime.org/proceedings/2009/nime2009_203.pdf},
 year = {2009}
}
"
2025,nime2025_16.pdf,nime2025_16,Repurposing a Rhythm Accompaniment System for Pipe Organ Performance,Nicholas Evans and Behzad Haki and Sergi Jordà,,"This paper presents an overview of a human-machine collaborative musical performance by Raül Refree utilizing multiple MIDI-enabled pipe organs at Palau Güell, as part of the Organic concert series. Our earlier collaboration focused on live performances using drum generation systems, where generative models captured rhythmic transient structures while ignoring harmonic information. For the organ performance, we required a system capable of generating harmonic sequences in real-time, conditioned on Refree's performance. Instead of developing a comprehensive state-of-the-art model, we integrated a more traditional generative method to convert our pitch-agnostic rhythmic patterns into harmonic sequences. This paper details the development process, the creative and technical considerations behind the final performance, and a reflection on the efficacy and adaptability of the chosen methodology.",10.5281/zenodo.15698807,"@inproceedings{nime2025_16,
 abstract = {This paper presents an overview of a human-machine collaborative musical performance by Raül Refree utilizing multiple MIDI-enabled pipe organs at Palau Güell, as part of the Organic concert series. Our earlier collaboration focused on live performances using drum generation systems, where generative models captured rhythmic transient structures while ignoring harmonic information. For the organ performance, we required a system capable of generating harmonic sequences in real-time, conditioned on Refree's performance. Instead of developing a comprehensive state-of-the-art model, we integrated a more traditional generative method to convert our pitch-agnostic rhythmic patterns into harmonic sequences. This paper details the development process, the creative and technical considerations behind the final performance, and a reflection on the efficacy and adaptability of the chosen methodology.},
 address = {Canberra, Australia},
 articleno = {16},
 author = {Nicholas Evans and Behzad Haki and Sergi Jordà},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698807},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {5},
 pages = {116--120},
 title = {Repurposing a Rhythm Accompaniment System for Pipe Organ Performance},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_16.pdf},
 year = {2025}
}
"
2021,nime2021_29.pdf,nime2021_29,SoftMRP: a Software Emulation of the Magnetic Resonator Piano,"Pitkin, Jonathan",,"The Magnetic Resonator Piano (MRP) is a relatively well-established DMI which significantly expands the capabilities of the acoustic piano. This paper presents SoftMRP, a Max/MSP patch designed to emulate the physical MRP and thereby to allow rehearsal of MRP repertoire and performance techniques using any MIDI keyboard and expression pedal; it is hoped that the development of such a tool will encourage even more widespread adoption of the original instrument amongst composers and performers. This paper explains SoftMRP’s features and limitations, discussing the challenges of approximating responses which rely upon the MRP’s continuous sensing of key position, and considering ways in which the development of the emulation might feed back into the development of the original instrument, both specifically and more broadly: since it was designed by a composer, based on his experience of writing for the instrument, it offers the MRP’s designers an insight into how the instrument is conceptualised and understood by the musicians who use it.",10.21428/92fbeb44.9e7da18f,"@inproceedings{nime2021_29,
 abstract = {The Magnetic Resonator Piano (MRP) is a relatively well-established DMI which significantly expands the capabilities of the acoustic piano. This paper presents SoftMRP, a Max/MSP patch designed to emulate the physical MRP and thereby to allow rehearsal of MRP repertoire and performance techniques using any MIDI keyboard and expression pedal; it is hoped that the development of such a tool will encourage even more widespread adoption of the original instrument amongst composers and performers. This paper explains SoftMRP’s features and limitations, discussing the challenges of approximating responses which rely upon the MRP’s continuous sensing of key position, and considering ways in which the development of the emulation might feed back into the development of the original instrument, both specifically and more broadly: since it was designed by a composer, based on his experience of writing for the instrument, it offers the MRP’s designers an insight into how the instrument is conceptualised and understood by the musicians who use it.},
 address = {Shanghai, China},
 articleno = {29},
 author = {Pitkin, Jonathan},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.9e7da18f},
 issn = {2220-4806},
 month = {June},
 presentation-video = {https://youtu.be/Fw43nHVyGUg},
 title = {SoftMRP: a Software Emulation of the Magnetic Resonator Piano},
 url = {https://nime.pubpub.org/pub/m9nhdm0p},
 year = {2021}
}
"
2023,nime2023_82.pdf,nime2023_82,The Sabotaging Piano: key-to-pitch remapping as a source of new techniques in piano improvisation,Teodoro Dannemann and Nick Bryan-Kinns,,"In this paper we present the Sabotaging Piano, a prepared electronic piano that alters key-to-pitch correspondence by reassigning adjacent pitches (i.e. one semi-tone higher or lower) to each key. Performers can control how many keys to remap through an expression pedal. If the pedal is not pressed the Sabotaging Piano works as a normal piano. When fully pressed, each key is remapped one semi-tone up or down with equal probability. Each new performance (i.e. when the piano is turned on) triggers a new and unknown remapping pattern, but the specific pattern remains fixed throughout the whole performance. This aims to provide a balance of uncertain but still explorable and learnable behaviour. 
We invited three professional piano improvisers to rehearse with our piano in order to prepare a final improvisation concert. We aimed to explore how much can be rehearsed or prepared with a piano that will behave somewhat differently for each new performance. We asked pianists to document their rehearsal processes to witness the appearing of strategies or techniques with the Sabotaging Piano. 
Through analysis of the rehearsals reports and the MIDI data collected in the final concert, here we show that the three pianists not only developed different techniques with the Sabotaging Piano, but they also leveraged the particularities of it to use them as creative resources.",10.5281/zenodo.11189298,"@inproceedings{nime2023_82,
 abstract = {In this paper we present the Sabotaging Piano, a prepared electronic piano that alters key-to-pitch correspondence by reassigning adjacent pitches (i.e. one semi-tone higher or lower) to each key. Performers can control how many keys to remap through an expression pedal. If the pedal is not pressed the Sabotaging Piano works as a normal piano. When fully pressed, each key is remapped one semi-tone up or down with equal probability. Each new performance (i.e. when the piano is turned on) triggers a new and unknown remapping pattern, but the specific pattern remains fixed throughout the whole performance. This aims to provide a balance of uncertain but still explorable and learnable behaviour. 
We invited three professional piano improvisers to rehearse with our piano in order to prepare a final improvisation concert. We aimed to explore how much can be rehearsed or prepared with a piano that will behave somewhat differently for each new performance. We asked pianists to document their rehearsal processes to witness the appearing of strategies or techniques with the Sabotaging Piano. 
Through analysis of the rehearsals reports and the MIDI data collected in the final concert, here we show that the three pianists not only developed different techniques with the Sabotaging Piano, but they also leveraged the particularities of it to use them as creative resources.},
 address = {Mexico City, Mexico},
 articleno = {82},
 author = {Teodoro Dannemann and Nick Bryan-Kinns},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.11189298},
 editor = {Miguel Ortiz and Adnan Marquez-Borbon},
 issn = {2220-4806},
 month = {May},
 numpages = {5},
 pages = {574--578},
 title = {The Sabotaging Piano: key-to-pitch remapping as a source of new techniques in piano improvisation},
 track = {Work in Progress},
 url = {http://nime.org/proceedings/2023/nime2023_82.pdf},
 year = {2023}
}
"
2013,nime2013_Xiao.pdf,nime2013_Xiao,Conjuring the Recorded Pianist: A New Medium to Experience Musical Performance,Xiao Xiao and Anna Pereira and Hiroshi Ishii,"piano performance, musical expressivity, body language, recorded music, player piano, augmented reality, embodiment","The body channels rich layers of information when playing music, from intricatemanipulations of the instrument to vivid personifications of expression. Butwhen music is captured and replayed across distance and time, the performer'sbody is too often trapped behind a small screen or absent entirely.This paper introduces an interface to conjure the recorded performer bycombining the moving keys of a player piano with life-sized projection of thepianist's hands and upper body. Inspired by reflections on a lacquered grandpiano, our interface evokes the sense that the virtual pianist is playing thephysically moving keys.Through our interface, we explore the question of how to viscerally simulate aperformer's presence to create immersive experiences. We discuss designchoices, outline a space of usage scenarios and report reactions from users.",10.5281/zenodo.1178692,"@inproceedings{nime2013_Xiao,
 abstract = {The body channels rich layers of information when playing music, from intricatemanipulations of the instrument to vivid personifications of expression. Butwhen music is captured and replayed across distance and time, the performer'sbody is too often trapped behind a small screen or absent entirely.This paper introduces an interface to conjure the recorded performer bycombining the moving keys of a player piano with life-sized projection of thepianist's hands and upper body. Inspired by reflections on a lacquered grandpiano, our interface evokes the sense that the virtual pianist is playing thephysically moving keys.Through our interface, we explore the question of how to viscerally simulate aperformer's presence to create immersive experiences. We discuss designchoices, outline a space of usage scenarios and report reactions from users.},
 address = {Daejeon, Republic of Korea},
 author = {Xiao Xiao and Anna Pereira and Hiroshi Ishii},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178692},
 issn = {2220-4806},
 keywords = {piano performance, musical expressivity, body language, recorded music, player piano, augmented reality, embodiment},
 month = {May},
 pages = {7--12},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Conjuring the Recorded Pianist: A New Medium to Experience Musical Performance},
 url = {http://www.nime.org/proceedings/2013/nime2013_28.pdf},
 year = {2013}
}
"
2012,nime2012_Shear.pdf,nime2012_Shear,Further Developments in the Electromagnetically Sustained Rhodes Piano,Greg Shear and Matthew Wright,"Rhodes, piano, mechanical synthesizer, electromagnetic, sustain, feedback","The Electromagnetically Sustained Rhodes Piano is an orig-inal Rhodes Piano modified to provide control over the amplitude envelope of individual notes through aftertouch pressure. Although there are many opportunities to shape the amplitude envelope before loudspeaker amplification, they are all governed by the ever-decaying physical vibra-tions of the tone generating mechanism. A single-note proof of concept for electromagnetic control over this vibrating mechanism was presented at NIME 2011.
In the past year, virtually every aspect of the system has been improved. We use a different vibration sensor that is immune to electromagnetic interference, thus eliminat-ing troublesome feedback. For control, we both reduce cost and gain continuous position sensing throughout the entire range of key motion in addition to aftertouch pressure. Finally, the entire system now fits within the space constraints presented by the original piano, allowing it to be installed on adjacent notes.",10.5281/zenodo.1180599,"@inproceedings{nime2012_Shear,
 abstract = {The Electromagnetically Sustained Rhodes Piano is an orig-inal Rhodes Piano modified to provide control over the amplitude envelope of individual notes through aftertouch pressure. Although there are many opportunities to shape the amplitude envelope before loudspeaker amplification, they are all governed by the ever-decaying physical vibra-tions of the tone generating mechanism. A single-note proof of concept for electromagnetic control over this vibrating mechanism was presented at NIME 2011.
In the past year, virtually every aspect of the system has been improved. We use a different vibration sensor that is immune to electromagnetic interference, thus eliminat-ing troublesome feedback. For control, we both reduce cost and gain continuous position sensing throughout the entire range of key motion in addition to aftertouch pressure. Finally, the entire system now fits within the space constraints presented by the original piano, allowing it to be installed on adjacent notes.},
 address = {Ann Arbor, Michigan},
 author = {Greg Shear and Matthew Wright},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1180599},
 issn = {2220-4806},
 keywords = {Rhodes, piano, mechanical synthesizer, electromagnetic, sustain, feedback},
 publisher = {University of Michigan},
 title = {Further Developments in the Electromagnetically Sustained Rhodes Piano},
 url = {http://www.nime.org/proceedings/2012/nime2012_284.pdf},
 year = {2012}
}
"
2011,nime2011_Lamb.pdf,nime2011_Lamb,Seaboard : a New Piano Keyboard-related Interface Combining Discrete and Continuous Control,"Lamb, Roland and Robertson, Andrew","Piano keyboard-related interface, continuous and discrete control, haptic feedback, Human-Computer Interaction (HCI) ","This paper introduces the Seaboard, a new tangible musicalinstrument which aims to provide musicians with significantcapability to manipulate sound in real-time in a musicallyintuitive way. It introduces the core design features whichmake the Seaboard unique, and describes the motivationand rationale behind the design. The fundamental approachto dealing with problems associated with discrete and continuous inputs is summarized.",10.5281/zenodo.1178081,"@inproceedings{nime2011_Lamb,
 abstract = {This paper introduces the Seaboard, a new tangible musicalinstrument which aims to provide musicians with significantcapability to manipulate sound in real-time in a musicallyintuitive way. It introduces the core design features whichmake the Seaboard unique, and describes the motivationand rationale behind the design. The fundamental approachto dealing with problems associated with discrete and continuous inputs is summarized.},
 address = {Oslo, Norway},
 author = {Lamb, Roland and Robertson, Andrew},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178081},
 issn = {2220-4806},
 keywords = {Piano keyboard-related interface, continuous and discrete control, haptic feedback, Human-Computer Interaction (HCI) },
 pages = {503--506},
 title = {Seaboard : a New Piano Keyboard-related Interface Combining Discrete and Continuous Control},
 url = {http://www.nime.org/proceedings/2011/nime2011_503.pdf},
 year = {2011}
}
"
2012,nime2012_Wierenga.pdf,nime2012_Wierenga,"A New Keyboard-Based, Sensor-Augmented Instrument For Live Performance",Red Wierenga,"Gesture, controllers, Digital Musical Instrument, keyboard","In an attempt to utilize the expert pianist's technique and spare bandwidth, a new keyboard-based instrument augmented by sensors suggested by the examination of existing acoustic instruments is introduced. The complete instrument includes a keyboard, various pedals and knee levers, several bowing controllers, and breath and embouchure sensors connected to an Arduino microcontroller that sends sensor data to a laptop running Max/MSP, where custom software maps the data to synthesis algorithms. The audio is output to a digital amplifier powering a transducer mounted on a resonator box to which several of the sensors are attached. Careful sensor selection and mapping help to facilitate performance mode.",10.5281/zenodo.1178451,"@inproceedings{nime2012_Wierenga,
 abstract = {In an attempt to utilize the expert pianist's technique and spare bandwidth, a new keyboard-based instrument augmented by sensors suggested by the examination of existing acoustic instruments is introduced. The complete instrument includes a keyboard, various pedals and knee levers, several bowing controllers, and breath and embouchure sensors connected to an Arduino microcontroller that sends sensor data to a laptop running Max/MSP, where custom software maps the data to synthesis algorithms. The audio is output to a digital amplifier powering a transducer mounted on a resonator box to which several of the sensors are attached. Careful sensor selection and mapping help to facilitate performance mode.},
 address = {Ann Arbor, Michigan},
 author = {Red Wierenga},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178451},
 issn = {2220-4806},
 keywords = {Gesture, controllers, Digital Musical Instrument, keyboard},
 publisher = {University of Michigan},
 title = {A New Keyboard-Based, Sensor-Augmented Instrument For Live Performance},
 url = {http://www.nime.org/proceedings/2012/nime2012_211.pdf},
 year = {2012}
}
"
2012,nime2012_McPherson_b.pdf,nime2012_McPherson_b,Techniques and Circuits for Electromagnetic Instrument Actuation,Andrew McPherson,"augmented instruments, electromagnetic actuation, circuit design, hardware","There is growing interest in the field of augmented musical instruments, which extend traditional acoustic instruments using new sensors and actuators. Several designs use electromagnetic actuation to induce vibrations in the acoustic mechanism, manipulating the traditional sound of the in-strument without external speakers. This paper presents techniques and guidelines for the use of electromagnetic actuation in augmented instruments, including actuator design and selection, interfacing with the instrument, and cir-cuits for driving the actuators. The material in this pa-per forms the basis of the magnetic resonator piano, an electromagnetically-augmented acoustic grand piano now in its second design iteration. In addition to discussing applications to the piano, this paper aims to provide a toolbox to accelerate the design of new hybrid acoustic-electronic instruments.",10.5281/zenodo.1180533,"@inproceedings{nime2012_McPherson_b,
 abstract = {There is growing interest in the field of augmented musical instruments, which extend traditional acoustic instruments using new sensors and actuators. Several designs use electromagnetic actuation to induce vibrations in the acoustic mechanism, manipulating the traditional sound of the in-strument without external speakers. This paper presents techniques and guidelines for the use of electromagnetic actuation in augmented instruments, including actuator design and selection, interfacing with the instrument, and cir-cuits for driving the actuators. The material in this pa-per forms the basis of the magnetic resonator piano, an electromagnetically-augmented acoustic grand piano now in its second design iteration. In addition to discussing applications to the piano, this paper aims to provide a toolbox to accelerate the design of new hybrid acoustic-electronic instruments.},
 address = {Ann Arbor, Michigan},
 author = {Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1180533},
 issn = {2220-4806},
 keywords = {augmented instruments, electromagnetic actuation, circuit design, hardware},
 publisher = {University of Michigan},
 title = {Techniques and Circuits for Electromagnetic Instrument Actuation},
 url = {http://www.nime.org/proceedings/2012/nime2012_117.pdf},
 year = {2012}
}
"
2013,nime2013_Grosshauser.pdf,nime2013_Grosshauser,Finger Position and Pressure Sensing Techniques for String and Keyboard Instruments,Tobias Grosshauser and Gerhard Tröster,"Sensor, Piano, Violin, Guitar, Position, Pressure, Keyboard","Several new technologies to capture motion, gesture and forces for musical instrument players' analyses have been developed in the last years. In research and for augmented instruments one parameter is underrepresented so far. It is finger position and pressure measurement, applied by the musician while playing the musical instrument. In this paper we show a flexible linear-potentiometer and forcesensitive-resistor (FSR) based solution for position, pressure and force sensing between the contact point of the fingers and the musical instrument. A flexible matrix printed circuit board (PCB) is fixed on a piano key. We further introduce linear potentiometer based left hand finger position sensing for string instruments, integrated into a violin and a guitar finger board. Several calibration and measurement scenarios are shown. The violin sensor was evaluated with 13 music students regarding playability and robustness of the system. Main focus was a the integration of the sensors into these two traditional musical instruments as unobtrusively as possible to keep natural haptic playing sensation. The musicians playing the violin in different performance situations stated good playability and no differences in the haptic sensation while playing. The piano sensor is rated, due to interviews after testing it in a conventional keyboard quite unobtrusive, too, but still evokes a different haptic sensation.",10.5281/zenodo.1178538,"@inproceedings{nime2013_Grosshauser,
 abstract = {Several new technologies to capture motion, gesture and forces for musical instrument players' analyses have been developed in the last years. In research and for augmented instruments one parameter is underrepresented so far. It is finger position and pressure measurement, applied by the musician while playing the musical instrument. In this paper we show a flexible linear-potentiometer and forcesensitive-resistor (FSR) based solution for position, pressure and force sensing between the contact point of the fingers and the musical instrument. A flexible matrix printed circuit board (PCB) is fixed on a piano key. We further introduce linear potentiometer based left hand finger position sensing for string instruments, integrated into a violin and a guitar finger board. Several calibration and measurement scenarios are shown. The violin sensor was evaluated with 13 music students regarding playability and robustness of the system. Main focus was a the integration of the sensors into these two traditional musical instruments as unobtrusively as possible to keep natural haptic playing sensation. The musicians playing the violin in different performance situations stated good playability and no differences in the haptic sensation while playing. The piano sensor is rated, due to interviews after testing it in a conventional keyboard quite unobtrusive, too, but still evokes a different haptic sensation.},
 address = {Daejeon, Republic of Korea},
 author = {Tobias Grosshauser and Gerhard Tr{\''o}ster},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178538},
 issn = {2220-4806},
 keywords = {Sensor, Piano, Violin, Guitar, Position, Pressure, Keyboard},
 month = {May},
 pages = {479--484},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Finger Position and Pressure Sensing Techniques for String and Keyboard Instruments},
 url = {http://www.nime.org/proceedings/2013/nime2013_286.pdf},
 year = {2013}
}
"
2011,nime2011_Milne.pdf,nime2011_Milne,Hex Player --- A Virtual Musical Controller,"Milne, Andrew J. and Xamb\'{o}, Anna and Laney, Robin and Sharp, David B. and Prechtl, Anthony and Holland, Simon","generalized keyboard, isomorphic layout, multi-touch surface, tablet, musical interface design, iPad, microtonality ",,10.5281/zenodo.1178109,"@inproceedings{nime2011_Milne,
 address = {Oslo, Norway},
 author = {Milne, Andrew J. and Xamb\'{o}, Anna and Laney, Robin and Sharp, David B. and Prechtl, Anthony and Holland, Simon},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178109},
 issn = {2220-4806},
 keywords = {generalized keyboard, isomorphic layout, multi-touch surface, tablet, musical interface design, iPad, microtonality },
 pages = {244--247},
 title = {Hex Player --- A Virtual Musical Controller},
 url = {http://www.nime.org/proceedings/2011/nime2011_244.pdf},
 year = {2011}
}
"
2016,nime2016_Nash.pdf,nime2016_Nash,The 'E' in QWERTY: Musical Expression with Old Computer Interfaces,Chris Nash,,"This paper presents a development of the ubiquitous computer
keyboard to capture velocity and other continuous musical properties, in order to
support more expressive interaction with music software. Building on existing
`virtual piano' utilities, the device is designed to provide a richer
mechanism for note entry within predominantly non-realtime editing tasks, in
applications where keyboard interaction is a central component of the user
experience (score editors, sequencers, DAWs, trackers, live coding), and in which
users draw on virtuosities in both music and computing.
In the keyboard, additional hardware combines existing scan code (key press)
data with accelerometer readings to create a secondary USB device, using the same
cable but visible to software as a separate USB MIDI device aside existing USB
HID functionality. This paper presents and evaluates an initial prototype,
developed using an Arduino board and inexpensive sensors, and discusses design
considerations and test findings in musical applications, drawing on user studies
of keyboard-mediated music interaction. Without challenging more established (and
expensive) performance devices; significant benefits are demonstrated in
notation-mediated interaction, where the user's focus rests with
software.",10.5281/zenodo.1176088,"@inproceedings{nime2016_Nash,
 abstract = {This paper presents a development of the ubiquitous computer
keyboard to capture velocity and other continuous musical properties, in order to
support more expressive interaction with music software. Building on existing
`virtual piano' utilities, the device is designed to provide a richer
mechanism for note entry within predominantly non-realtime editing tasks, in
applications where keyboard interaction is a central component of the user
experience (score editors, sequencers, DAWs, trackers, live coding), and in which
users draw on virtuosities in both music and computing.
In the keyboard, additional hardware combines existing scan code (key press)
data with accelerometer readings to create a secondary USB device, using the same
cable but visible to software as a separate USB MIDI device aside existing USB
HID functionality. This paper presents and evaluates an initial prototype,
developed using an Arduino board and inexpensive sensors, and discusses design
considerations and test findings in musical applications, drawing on user studies
of keyboard-mediated music interaction. Without challenging more established (and
expensive) performance devices; significant benefits are demonstrated in
notation-mediated interaction, where the user's focus rests with
software.},
 address = {Brisbane, Australia},
 author = {Chris Nash},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176088},
 isbn = {978-1-925455-13-7},
 issn = {2220-4806},
 pages = {224--229},
 publisher = {Queensland Conservatorium Griffith University},
 title = {The 'E' in QWERTY: Musical Expression with Old Computer Interfaces},
 track = {Papers},
 url = {http://www.nime.org/proceedings/2016/nime2016_paper0045.pdf},
 year = {2016}
}
"
2012,nime2012_Brent.pdf,nime2012_Brent,The Gesturally Extended Piano,William Brent,"Augmented instruments, controllers, motion tracking, mapping","This paper introduces the Gesturally Extended Piano---an augmented instrument controller that relies on information drawn from performer motion tracking in order to control real-time audiovisual processing and synthesis. Specifically, the positions, heights, velocities, and relative distances and angles of points on the hands and forearms are followed. Technical details and installation of the tracking system are covered, as well as strategies for interpreting and mapping the resulting data in relation to synthesis parameters. Design factors surrounding mapping choices and the interrelation between mapped parameters are also considered.",10.5281/zenodo.1178219,"@inproceedings{nime2012_Brent,
 abstract = {This paper introduces the Gesturally Extended Piano---an augmented instrument controller that relies on information drawn from performer motion tracking in order to control real-time audiovisual processing and synthesis. Specifically, the positions, heights, velocities, and relative distances and angles of points on the hands and forearms are followed. Technical details and installation of the tracking system are covered, as well as strategies for interpreting and mapping the resulting data in relation to synthesis parameters. Design factors surrounding mapping choices and the interrelation between mapped parameters are also considered.},
 address = {Ann Arbor, Michigan},
 author = {William Brent},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178219},
 issn = {2220-4806},
 keywords = {Augmented instruments, controllers, motion tracking, mapping},
 publisher = {University of Michigan},
 title = {The Gesturally Extended Piano},
 url = {http://www.nime.org/proceedings/2012/nime2012_102.pdf},
 year = {2012}
}
"
2014,nime2014_avanzandt.pdf,nime2014_avanzandt,PiaF: A Tool for Augmented Piano Performance Using Gesture Variation Following,Alejandro Van Zandt-Escobar and Baptiste Caramiaux and Atau Tanaka,,"When performing a piece, a pianist's interpretation is communicated both through the sound produced and through body gestures. We present PiaF (Piano Follower), a prototype for augmenting piano performance by measuring gesture variations. We survey other augmented piano projects, several of which focus on gestural recognition, and present our prototype which uses machine learning techniques for gesture classification and estimation of gesture variations in real-time. Our implementation uses the Kinect depth sensor to track body motion in space, which is used as input data. During an initial learning phase, the system is taught a set of reference gestures, or templates. During performance, the live gesture is classified in real-time, and variations with respect to the recognized template are computed. These values can then be mapped to audio processing parameters, to control digital effects which are applied to the acoustic output of the piano in real-time. We discuss initial tests using PiaF with a pianist, as well as potential applications beyond live performance, including pedagogy and embodiment of recorded performance.",10.5281/zenodo.1178991,"@inproceedings{nime2014_avanzandt,
 abstract = {When performing a piece, a pianist's interpretation is communicated both through the sound produced and through body gestures. We present PiaF (Piano Follower), a prototype for augmenting piano performance by measuring gesture variations. We survey other augmented piano projects, several of which focus on gestural recognition, and present our prototype which uses machine learning techniques for gesture classification and estimation of gesture variations in real-time. Our implementation uses the Kinect depth sensor to track body motion in space, which is used as input data. During an initial learning phase, the system is taught a set of reference gestures, or templates. During performance, the live gesture is classified in real-time, and variations with respect to the recognized template are computed. These values can then be mapped to audio processing parameters, to control digital effects which are applied to the acoustic output of the piano in real-time. We discuss initial tests using PiaF with a pianist, as well as potential applications beyond live performance, including pedagogy and embodiment of recorded performance.},
 address = {London, United Kingdom},
 author = {Alejandro Van Zandt-Escobar and Baptiste Caramiaux and Atau Tanaka},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178991},
 issn = {2220-4806},
 month = {June},
 pages = {167--170},
 publisher = {Goldsmiths, University of London},
 title = {PiaF: A Tool for Augmented Piano Performance Using Gesture Variation Following},
 url = {http://www.nime.org/proceedings/2014/nime2014_511.pdf},
 year = {2014}
}
"
2008,nime2008_Takegawa.pdf,nime2008_Takegawa,UnitKeyboard : An Easily Configurable Compact Clavier,"Takegawa, Yoshinari and Tsukamoto, Masahiko","Portable keyboard instruments, block interface, Automatic settings ","Musical keyboard instruments have a long history, whichresulted in many kinds of keyboards (claviers) today. Sincethe hardware of conventional musical keyboards cannot bechanged, such as the number of keys, musicians have tocarry these large keyboards for playing music that requiresonly a small diapason. To solve this problem, the goal ofour study is to construct UnitKeyboard, which has only 12keys (7 white keys and 5 black keys) and connectors fordocking with other UnitKeyboards. We can build variouskinds of musical keyboard configurations by connecting oneUnitKeyboard to others, since they have automatic settingsfor multiple keyboard instruments. We discuss the usabilityof the UnitKeyboard from reviews by several amateur andprofessional pianists who used the UnitKeyboard.",10.5281/zenodo.1179635,"@inproceedings{nime2008_Takegawa,
 abstract = {Musical keyboard instruments have a long history, whichresulted in many kinds of keyboards (claviers) today. Sincethe hardware of conventional musical keyboards cannot bechanged, such as the number of keys, musicians have tocarry these large keyboards for playing music that requiresonly a small diapason. To solve this problem, the goal ofour study is to construct UnitKeyboard, which has only 12keys (7 white keys and 5 black keys) and connectors fordocking with other UnitKeyboards. We can build variouskinds of musical keyboard configurations by connecting oneUnitKeyboard to others, since they have automatic settingsfor multiple keyboard instruments. We discuss the usabilityof the UnitKeyboard from reviews by several amateur andprofessional pianists who used the UnitKeyboard.},
 address = {Genoa, Italy},
 author = {Takegawa, Yoshinari and Tsukamoto, Masahiko},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179635},
 issn = {2220-4806},
 keywords = {Portable keyboard instruments, block interface, Automatic settings },
 pages = {289--292},
 title = {UnitKeyboard : An Easily Configurable Compact Clavier},
 url = {http://www.nime.org/proceedings/2008/nime2008_289.pdf},
 year = {2008}
}
"
2010,nime2010_Hadjakos.pdf,nime2010_Hadjakos,Analysis of Piano Playing Movements Spanning Multiple Touches,"Hadjakos, Aristotelis and Mühlhäuser, Max",nime10,Awareness of playing movements can help a piano student to improve technique. We are developing a piano pedagogy application that uses sensor data of hand and arm movement and generates feedback to increase movement awareness. This paper reports on a method for analysis of piano playing movements. The method allows to judge whether an active movement in a joint has occurred during a given time interval. This time interval may include one or more touches. The problem is complicated by the fact that the mechanical interaction between the arm and piano action generates additional movements that are not under direct control of the player. The analysis method is able to ignore these movements and can therefore be used to provide useful feedback.,10.5281/zenodo.1177791,"@inproceedings{nime2010_Hadjakos,
 abstract = {Awareness of playing movements can help a piano student to improve technique. We are developing a piano pedagogy application that uses sensor data of hand and arm movement and generates feedback to increase movement awareness. This paper reports on a method for analysis of piano playing movements. The method allows to judge whether an active movement in a joint has occurred during a given time interval. This time interval may include one or more touches. The problem is complicated by the fact that the mechanical interaction between the arm and piano action generates additional movements that are not under direct control of the player. The analysis method is able to ignore these movements and can therefore be used to provide useful feedback.},
 address = {Sydney, Australia},
 author = {Hadjakos, Aristotelis and M\''{u}hlh\''{a}user, Max},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177791},
 issn = {2220-4806},
 keywords = {nime10},
 pages = {335--338},
 title = {Analysis of Piano Playing Movements Spanning Multiple Touches},
 url = {http://www.nime.org/proceedings/2010/nime2010_335.pdf},
 year = {2010}
}
"
2017,nime2017_sglickman.pdf,nime2017_sglickman,Music Everywhere --- Augmented Reality Piano Improvisation Learning System,Seth Glickman and Byunghwan Lee and Fu Yen Hsiao and Shantanu Das,,"This paper describes the design and implementation of an augmented reality (AR) piano learning tool that uses a Microsoft HoloLens and a MIDI-over-Bluetooth-enabled electric piano. The tool presents a unique visual interface&#8212;a &#8220;mirror key overlay&#8221; approach&#8212;fitted for the AR environment, and opens up the possibility of on-instrument learning experiences. The curriculum focuses on teaching improvisation in blues, rock, jazz and classical genres. Users at the piano engage with interactive lessons, watch virtual hand demonstrations, see and hear example improvisations, and play their own solos and accompaniment along with AR-projected virtual musicians. The tool aims to be entertaining yet also effective in teaching core musical concepts.",10.5281/zenodo.1176350,"@inproceedings{nime2017_sglickman,
 abstract = {This paper describes the design and implementation of an augmented reality (AR) piano learning tool that uses a Microsoft HoloLens and a MIDI-over-Bluetooth-enabled electric piano. The tool presents a unique visual interface&#8212;a &#8220;mirror key overlay&#8221; approach&#8212;fitted for the AR environment, and opens up the possibility of on-instrument learning experiences. The curriculum focuses on teaching improvisation in blues, rock, jazz and classical genres. Users at the piano engage with interactive lessons, watch virtual hand demonstrations, see and hear example improvisations, and play their own solos and accompaniment along with AR-projected virtual musicians. The tool aims to be entertaining yet also effective in teaching core musical concepts.},
 address = {Copenhagen, Denmark},
 author = {Seth Glickman and Byunghwan Lee and Fu Yen Hsiao and Shantanu Das},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176350},
 issn = {2220-4806},
 pages = {511--512},
 publisher = {Aalborg University Copenhagen},
 title = {Music Everywhere --- Augmented Reality Piano Improvisation Learning System},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0104.pdf},
 year = {2017}
}
"
2003,nime2003_Nishimoto.pdf,nime2003_Nishimoto,Why Always Versatile? Dynamically Customizable Musical Instruments Facilitate Expressive Performances,"Nishimoto, Kazushi and Oshima, Chika and Miyagawa, Yohei","Musical instruments, expression, design principle, degree of freedom, dynamic specialization","In this paper, we discuss a design principle for the musical instruments that are useful for both novices and professional musicians and that facilitate musically rich expression. We believe that the versatility of conventional musical instruments causes difficulty in performance. By dynamically specializing a musical instrument for performing a specific (genre of) piece, the musical instrument could become more useful for performing the piece and facilitates expressive performance. Based on this idea, we developed two new types of musical instruments, i.e., a ""given-melody-based musical instrument"" and a ""harmonic-function-based musical instrument"". From the experimental results using two prototypes, we demonstrate the efficiency of the design principle.",10.5281/zenodo.1176545,"@inproceedings{nime2003_Nishimoto,
 abstract = {In this paper, we discuss a design principle for the musical instruments that are useful for both novices and professional musicians and that facilitate musically rich expression. We believe that the versatility of conventional musical instruments causes difficulty in performance. By dynamically specializing a musical instrument for performing a specific (genre of) piece, the musical instrument could become more useful for performing the piece and facilitates expressive performance. Based on this idea, we developed two new types of musical instruments, i.e., a ""given-melody-based musical instrument"" and a ""harmonic-function-based musical instrument"". From the experimental results using two prototypes, we demonstrate the efficiency of the design principle.},
 address = {Montreal, Canada},
 author = {Nishimoto, Kazushi and Oshima, Chika and Miyagawa, Yohei},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 date = {22-24 May, 2003},
 doi = {10.5281/zenodo.1176545},
 issn = {2220-4806},
 keywords = {Musical instruments, expression, design principle, degree of freedom, dynamic specialization},
 pages = {164--169},
 title = {Why Always Versatile? Dynamically Customizable Musical Instruments Facilitate Expressive Performances},
 url = {http://www.nime.org/proceedings/2003/nime2003_164.pdf},
 year = {2003}
}
"
2012,nime2012_Yang.pdf,nime2012_Yang,Augmented Piano Performance using a Depth Camera,Qi Yang and Georg Essl,"NIME, piano, depth camera, musical instrument, gesture, tabletop projection","We augment the piano keyboard with a 3D gesture space using Microsoft Kinect for sensing and top-down projection for visual feedback. This interface provides multi-axial gesture controls to enable continuous adjustments to multiple acoustic parameters such as those on the typical digital synthesizers. We believe that using gesture control is more visceral and aesthetically pleasing, especially during concert performance where the visibility of the performer's action is important. Our system can also be used for other types of gesture interaction as well as for pedagogical applications.",10.5281/zenodo.1178455,"@inproceedings{nime2012_Yang,
 abstract = {We augment the piano keyboard with a 3D gesture space using Microsoft Kinect for sensing and top-down projection for visual feedback. This interface provides multi-axial gesture controls to enable continuous adjustments to multiple acoustic parameters such as those on the typical digital synthesizers. We believe that using gesture control is more visceral and aesthetically pleasing, especially during concert performance where the visibility of the performer's action is important. Our system can also be used for other types of gesture interaction as well as for pedagogical applications.},
 address = {Ann Arbor, Michigan},
 author = {Qi Yang and Georg Essl},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178455},
 issn = {2220-4806},
 keywords = {NIME, piano, depth camera, musical instrument, gesture, tabletop projection},
 publisher = {University of Michigan},
 title = {Augmented Piano Performance using a Depth Camera},
 url = {http://www.nime.org/proceedings/2012/nime2012_203.pdf},
 year = {2012}
}
"
2018,nime2018_Granger.pdf,nime2018_Granger,Evaluating LED-based interface for Lumanote composition creation tool,James Granger and Mateo Aviles and Joshua Kirby and Austin Griffin and Johnny Yoon and Raniero A. Lara-Garduno and Tracy Hammond,,"Composing music typically requires years of music theory experience and knowledge that includes but is not limited to chord progression, melody composition theory, and an understanding of whole-step/half-step passing tones among others. For that reason, certain songwriters such as singers may find a necessity to hire experienced pianists to help compose their music. In order to facilitate the process for beginner and aspiring musicians, we have developed Lumanote, a music composition tool that aids songwriters by presenting real-time suggestions on appropriate melody notes and chord progression. While a preliminary evaluation yielded favorable results for beginners, many commented on the difficulty of having to map the note suggestions displayed on the on-screen interface to the physical keyboard they were playing on. This paper presents the resulting solution: an LED-based feedback system that is designed to be directly attached to any standard MIDI keyboard. This peripheral aims to help map note suggestions directly to the physical keys of a musical keyboard. A study consisting of 22 individuals was conducted to compare the effectiveness of the new LED-based system with the existing computer interface, finding that the vast majority of users preferred the LED system. Three experienced musicians also judged and ranked the compositions, noting significant improvement in song quality when using either system, and citing comparable quality between compositions that used either interface.",10.5281/zenodo.1302557,"@inproceedings{nime2018_Granger,
 abstract = {Composing music typically requires years of music theory experience and knowledge that includes but is not limited to chord progression, melody composition theory, and an understanding of whole-step/half-step passing tones among others. For that reason, certain songwriters such as singers may find a necessity to hire experienced pianists to help compose their music. In order to facilitate the process for beginner and aspiring musicians, we have developed Lumanote, a music composition tool that aids songwriters by presenting real-time suggestions on appropriate melody notes and chord progression. While a preliminary evaluation yielded favorable results for beginners, many commented on the difficulty of having to map the note suggestions displayed on the on-screen interface to the physical keyboard they were playing on. This paper presents the resulting solution: an LED-based feedback system that is designed to be directly attached to any standard MIDI keyboard. This peripheral aims to help map note suggestions directly to the physical keys of a musical keyboard. A study consisting of 22 individuals was conducted to compare the effectiveness of the new LED-based system with the existing computer interface, finding that the vast majority of users preferred the LED system. Three experienced musicians also judged and ranked the compositions, noting significant improvement in song quality when using either system, and citing comparable quality between compositions that used either interface.},
 address = {Blacksburg, Virginia, USA},
 author = {James Granger and Mateo Aviles and Joshua Kirby and Austin Griffin and Johnny Yoon and Raniero A. Lara-Garduno and Tracy Hammond},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1302557},
 editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
 isbn = {978-1-949373-99-8},
 issn = {2220-4806},
 month = {June},
 pages = {216--221},
 publisher = {Virginia Tech},
 title = {Evaluating LED-based interface for Lumanote composition creation tool},
 url = {http://www.nime.org/proceedings/2018/nime2018_paper0048.pdf},
 year = {2018}
}
"
2015,nime2015_makbari.pdf,nime2015_makbari,claVision: Visual Automatic Piano Music Transcription,Mohammad Akbari and Howard Cheng,,"One important problem in Musical Information Retrieval is Automatic Music Transcription, which is an automated conversion process from played music to a symbolic notation such as sheet music. Since the accuracy of previous audio-based transcription systems is not satisfactory, we propose an innovative visual-based automatic music transcription system named claVision to perform piano music transcription. Instead of processing the music audio, the system performs the transcription only from the video performance captured by a camera mounted over the piano keyboard. claVision can be used as a transcription tool, but it also has other applications such as music education. The claVision software has a very high accuracy (over 95%) and a very low latency in real-time music transcription, even under different illumination conditions.",10.5281/zenodo.1179002,"@inproceedings{nime2015_makbari,
 abstract = {One important problem in Musical Information Retrieval is Automatic Music Transcription, which is an automated conversion process from played music to a symbolic notation such as sheet music. Since the accuracy of previous audio-based transcription systems is not satisfactory, we propose an innovative visual-based automatic music transcription system named claVision to perform piano music transcription. Instead of processing the music audio, the system performs the transcription only from the video performance captured by a camera mounted over the piano keyboard. claVision can be used as a transcription tool, but it also has other applications such as music education. The claVision software has a very high accuracy (over 95%) and a very low latency in real-time music transcription, even under different illumination conditions.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Mohammad Akbari and Howard Cheng},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179002},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {313--314},
 publisher = {Louisiana State University},
 title = {claVision: Visual Automatic Piano Music Transcription},
 url = {http://www.nime.org/proceedings/2015/nime2015_105.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/105/0105-file1.avi},
 year = {2015}
}
"
2011,nime2011_Shear.pdf,nime2011_Shear,The Electromagnetically Sustained Rhodes Piano,"Shear, Greg and Wright, Matthew","Rhodes, keyboard, electromagnetic, sustain, augmented instrument, feedback, aftertouch ","The Electromagnetically Sustained Rhodes Piano is an augmentation of the original instrument with additional control over the amplitude envelope of individual notes. Thisincludes slow attacks and infinite sustain while preservingthe familiar spectral qualities of this classic electromechanical piano. These additional parameters are controlled withaftertouch on the existing keyboard, extending standardpiano technique. Two sustain methods were investigated,driving the actuator first with a pure sine wave, and secondwith the output signal of the sensor. A special isolationmethod effectively decouples the sensors from the actuatorsand tames unruly feedback in the high-gain signal path.",10.5281/zenodo.1178161,"@inproceedings{nime2011_Shear,
 abstract = {The Electromagnetically Sustained Rhodes Piano is an augmentation of the original instrument with additional control over the amplitude envelope of individual notes. Thisincludes slow attacks and infinite sustain while preservingthe familiar spectral qualities of this classic electromechanical piano. These additional parameters are controlled withaftertouch on the existing keyboard, extending standardpiano technique. Two sustain methods were investigated,driving the actuator first with a pure sine wave, and secondwith the output signal of the sensor. A special isolationmethod effectively decouples the sensors from the actuatorsand tames unruly feedback in the high-gain signal path.},
 address = {Oslo, Norway},
 author = {Shear, Greg and Wright, Matthew},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178161},
 issn = {2220-4806},
 keywords = {Rhodes, keyboard, electromagnetic, sustain, augmented instrument, feedback, aftertouch },
 pages = {14--17},
 presentation-video = {http://nime.org/proceedings/2011/nime2011_Shear.mov},
 title = {The Electromagnetically Sustained Rhodes Piano},
 url = {http://www.nime.org/proceedings/2011/nime2011_014.pdf},
 year = {2011}
}
"
2008,nime2008_Grosshauser.pdf,nime2008_Grosshauser,"Low Force Pressure Measurement : Pressure Sensor Matrices for Gesture Analysis , Stiffness Recognition and Augmented Instruments","Grosshauser, Tobias","Pressure Measurement, Force, Sensor, Finger, Violin, Strings, Piano, Left Hand, Right Hand, Time Line, Cramping, Gesture and Posture Analysis. ","The described project is a new approach to use highly sensitive low force pressure sensor matrices for malposition, cramping and tension of hands and fingers, gesture and keystroke analysis and for new musical expression. In the latter, sensors are used as additional touch sensitive switches and keys. In pedagogical issues, new ways of technology enhanced teaching, self teaching and exercising are described. The used sensors are custom made in collaboration with the ReactiveS Sensorlab. ",10.5281/zenodo.1179551,"@inproceedings{nime2008_Grosshauser,
 abstract = {The described project is a new approach to use highly sensitive low force pressure sensor matrices for malposition, cramping and tension of hands and fingers, gesture and keystroke analysis and for new musical expression. In the latter, sensors are used as additional touch sensitive switches and keys. In pedagogical issues, new ways of technology enhanced teaching, self teaching and exercising are described. The used sensors are custom made in collaboration with the ReactiveS Sensorlab. },
 address = {Genoa, Italy},
 author = {Grosshauser, Tobias},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179551},
 issn = {2220-4806},
 keywords = {Pressure Measurement, Force, Sensor, Finger, Violin, Strings, Piano, Left Hand, Right Hand, Time Line, Cramping, Gesture and Posture Analysis. },
 pages = {97--102},
 title = {Low Force Pressure Measurement : Pressure Sensor Matrices for Gesture Analysis , Stiffness Recognition and Augmented Instruments},
 url = {http://www.nime.org/proceedings/2008/nime2008_097.pdf},
 year = {2008}
}
"
2011,nime2011_Snyder.pdf,nime2011_Snyder,"Snyderphonics Manta Controller, a Novel USB Touch-Controller","Snyder, Jeff","Snyderphonics, Manta, controller, USB, capacitive, touch, sensor, decoupled LED, hexagon, grid, touch slider, HID, portable, wood, live music, live video ","The Snyderphonics Manta controller is a USB touch controller for music and video. It features 48 capacitive touch sensors, arranged in a hexagonal grid, with bi-color LEDs that are programmable from the computer. The sensors send continuous data proportional to surface area touched, and a velocitydetection algorithm has been implemented to estimate attack velocity based on this touch data. In addition to these hexagonal sensors, the Manta has two high-dimension touch sliders (giving 12-bit values), and four assignable function buttons. In this paper, I outline the features of the controller, the available methods for communicating between the device and a computer, and some current uses for the controller. ",10.5281/zenodo.1178171,"@inproceedings{nime2011_Snyder,
 abstract = {The Snyderphonics Manta controller is a USB touch controller for music and video. It features 48 capacitive touch sensors, arranged in a hexagonal grid, with bi-color LEDs that are programmable from the computer. The sensors send continuous data proportional to surface area touched, and a velocitydetection algorithm has been implemented to estimate attack velocity based on this touch data. In addition to these hexagonal sensors, the Manta has two high-dimension touch sliders (giving 12-bit values), and four assignable function buttons. In this paper, I outline the features of the controller, the available methods for communicating between the device and a computer, and some current uses for the controller. },
 address = {Oslo, Norway},
 author = {Snyder, Jeff},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178171},
 issn = {2220-4806},
 keywords = {Snyderphonics, Manta, controller, USB, capacitive, touch, sensor, decoupled LED, hexagon, grid, touch slider, HID, portable, wood, live music, live video },
 pages = {413--416},
 presentation-video = {http://nime.org/proceedings/2011/nime2011_Snyder.mov},
 title = {Snyderphonics Manta Controller, a Novel {USB} Touch-Controller},
 url = {http://www.nime.org/proceedings/2011/nime2011_413.pdf},
 year = {2011}
}
"
2007,nime2007_Hollinger.pdf,nime2007_Hollinger,fMRI-Compatible Electronic Controllers,"Hollinger, Avrum and Steele, Christopher and Penhune, Virginia and Zatorre, Robert and Wanderley, Marcelo M.","Input device, MRI-compatible, fMRI, motor learning, optical sensing. ","This paper presents an electronic piano keyboard and computer mouse designed for use in a magnetic resonance imaging scanner. The interface allows neuroscientists studying motor learning of musical tasks to perform functional scans of a subject's brain while synchronizing the scanner, auditory and visual stimuli, and auditory feedback with the onset, offset, and velocity of the piano keys. The design of the initial prototype and environment-specific issues are described, as well as prior work in the field. Preliminary results are positive and were unable to show the existence of image artifacts caused by the interface. Recommendations to improve the optical assembly are provided in order to increase the robustness of the design. ",10.5281/zenodo.1177119,"@inproceedings{nime2007_Hollinger,
 abstract = {This paper presents an electronic piano keyboard and computer mouse designed for use in a magnetic resonance imaging scanner. The interface allows neuroscientists studying motor learning of musical tasks to perform functional scans of a subject's brain while synchronizing the scanner, auditory and visual stimuli, and auditory feedback with the onset, offset, and velocity of the piano keys. The design of the initial prototype and environment-specific issues are described, as well as prior work in the field. Preliminary results are positive and were unable to show the existence of image artifacts caused by the interface. Recommendations to improve the optical assembly are provided in order to increase the robustness of the design. },
 address = {New York City, NY, United States},
 author = {Hollinger, Avrum and Steele, Christopher and Penhune, Virginia and Zatorre, Robert and Wanderley, Marcelo M.},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177119},
 issn = {2220-4806},
 keywords = {Input device, MRI-compatible, fMRI, motor learning, optical sensing. },
 pages = {246--249},
 title = {fMRI-Compatible Electronic Controllers},
 url = {http://www.nime.org/proceedings/2007/nime2007_246.pdf},
 year = {2007}
}
"
2022,nime2022_12.pdf,nime2022_12,Bandoneon 2.0: an interdisciplinary project for research and development of electronic bandoneons in Argentina,"Ramos, Juan and Calcagno, Esteban and Vergara, Ramiro Oscar and Riera, Pablo and Rizza, Joaquín",,"In this article we present Bandoneon 2.0, an interdisciplinary project whose main objective is to produce electronic bandoneons in Argentina. The current prices of bandoneons and the scarcity of manufacturers are endangering the possibility of access for the new generations to one of the most emblematic instruments of the culture of this country. Therefore, we aim to create an expressive and accessible electronic bandoneon that can be used in recreational, academic and professional contexts, providing an inclusive response to the current sociocultural demand. The project also involves research on instrument acoustics and the development of specialized software and hardware tools.",10.21428/92fbeb44.c38bfb86,"@inproceedings{nime2022_12,
 abstract = {In this article we present Bandoneon 2.0, an interdisciplinary project whose main objective is to produce electronic bandoneons in Argentina. The current prices of bandoneons and the scarcity of manufacturers are endangering the possibility of access for the new generations to one of the most emblematic instruments of the culture of this country. Therefore, we aim to create an expressive and accessible electronic bandoneon that can be used in recreational, academic and professional contexts, providing an inclusive response to the current sociocultural demand. The project also involves research on instrument acoustics and the development of specialized software and hardware tools.},
 address = {Auckland, New Zealand},
 articleno = {12},
 author = {Ramos, Juan and Calcagno, Esteban and Vergara, Ramiro Oscar and Riera, Pablo and Rizza, Joaqu{\'{\i}}n},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.c38bfb86},
 editor = {Andrew McPherson and Emma Frid},
 issn = {2220-4806},
 month = {jun},
 presentation-video = {https://www.youtube.com/watch?v=5y4BbQWVNGQ},
 title = {Bandoneon 2.0: an interdisciplinary project for research and development of electronic bandoneons in Argentina},
 track = {Papers},
 url = {https://doi.org/10.21428%2F92fbeb44.c38bfb86},
 year = {2022}
}
"
2007,nime2007_Takegawa.pdf,nime2007_Takegawa,Mobile Clavier : New Music Keyboard for Flexible Key Transpose,"Takegawa, Yoshinari and Terada, Tsutomu","Portable keyboard, Additional black keys, Diapason change ","Musical performers need to show off their virtuosity for selfexpression and communicate with other people. Therefore, they are prepared to perform at any time and anywhere. However, a musical keyboard of 88 keys is too large and too heavy to carry around. When a portable keyboard that is suitable for carrying around is played over a wide range, the notes being played frequently cause the diapason of the keyboard to protrude. It is common to use Key Transpose in conventional portable keyboards, which shifts the diapason of the keyboard. However, this function creates several problems such as the feeling of discomfort from the misalignment between the keying positions and their output sounds. Therefore, the goal of our study is to construct Mobile Clavier, which enables the diapason to be changed smoothly. Mobile Clavier resolves the problems with Key Transpose by having black keys inserted between any two side-by-side white keys. This paper also discusses how effective Mobile Clavier was in an experiment conducted using professional pianists. We can play music at any time and anywhere with Mobile Clavier.",10.5281/zenodo.1177255,"@inproceedings{nime2007_Takegawa,
 abstract = {Musical performers need to show off their virtuosity for selfexpression and communicate with other people. Therefore, they are prepared to perform at any time and anywhere. However, a musical keyboard of 88 keys is too large and too heavy to carry around. When a portable keyboard that is suitable for carrying around is played over a wide range, the notes being played frequently cause the diapason of the keyboard to protrude. It is common to use Key Transpose in conventional portable keyboards, which shifts the diapason of the keyboard. However, this function creates several problems such as the feeling of discomfort from the misalignment between the keying positions and their output sounds. Therefore, the goal of our study is to construct Mobile Clavier, which enables the diapason to be changed smoothly. Mobile Clavier resolves the problems with Key Transpose by having black keys inserted between any two side-by-side white keys. This paper also discusses how effective Mobile Clavier was in an experiment conducted using professional pianists. We can play music at any time and anywhere with Mobile Clavier.},
 address = {New York City, NY, United States},
 author = {Takegawa, Yoshinari and Terada, Tsutomu},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177255},
 issn = {2220-4806},
 keywords = {Portable keyboard, Additional black keys, Diapason change },
 pages = {82--87},
 title = {Mobile Clavier : New Music Keyboard for Flexible Key Transpose},
 url = {http://www.nime.org/proceedings/2007/nime2007_082.pdf},
 year = {2007}
}
"
2014,nime2014_xxiao.pdf,nime2014_xxiao,Andante: Walking Figures on the Piano Keyboard to Visualize Musical Motion,Xiao Xiao and Basheer Tome and Hiroshi Ishii,,"We present Andante, a representation of music as animated characters walking along the piano keyboard that appear to play the physical keys with each step. Based on a view of music pedagogy that emphasizes expressive, full-body communication early in the learning process, Andante promotes an understanding of the music rooted in the body, taking advantage of walking as one of the most fundamental human rhythms. We describe three example visualizations on a preliminary prototype as well as applications extending our examples for practice feedback, improvisation and composition. Through our project, we reflect on some high level considerations for the NIME community.",10.5281/zenodo.1178987,"@inproceedings{nime2014_xxiao,
 abstract = {We present Andante, a representation of music as animated characters walking along the piano keyboard that appear to play the physical keys with each step. Based on a view of music pedagogy that emphasizes expressive, full-body communication early in the learning process, Andante promotes an understanding of the music rooted in the body, taking advantage of walking as one of the most fundamental human rhythms. We describe three example visualizations on a preliminary prototype as well as applications extending our examples for practice feedback, improvisation and composition. Through our project, we reflect on some high level considerations for the NIME community.},
 address = {London, United Kingdom},
 author = {Xiao Xiao and Basheer Tome and Hiroshi Ishii},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178987},
 issn = {2220-4806},
 month = {June},
 pages = {629--632},
 publisher = {Goldsmiths, University of London},
 title = {Andante: Walking Figures on the Piano Keyboard to Visualize Musical Motion},
 url = {http://www.nime.org/proceedings/2014/nime2014_467.pdf},
 year = {2014}
}
"
2012,nime2012_Snyder.pdf,nime2012_Snyder,The JD-1: an Implementation of a Hybrid Keyboard/Sequencer Controller for Analog Synthesizers,Jeff Snyder and Andrew McPherson,"keyboard, sequencer, analog synthesizer, capacitive touch sensing","This paper presents the JD-1, a digital controller for analog modular synthesizers. The JD-1 features a capacitive touch-sensing keyboard that responds to continuous variations in finger contact, high-accuracy polyphonic control-voltage outputs, a built-in sequencer, and digital interfaces for connection to MIDI and OSC devices. Design goals include interoperability with a wide range of synthesizers, very high-resolution pitch control, and intuitive control of the sequencer from the keyboard.",10.5281/zenodo.1178421,"@inproceedings{nime2012_Snyder,
 abstract = {This paper presents the JD-1, a digital controller for analog modular synthesizers. The JD-1 features a capacitive touch-sensing keyboard that responds to continuous variations in finger contact, high-accuracy polyphonic control-voltage outputs, a built-in sequencer, and digital interfaces for connection to MIDI and OSC devices. Design goals include interoperability with a wide range of synthesizers, very high-resolution pitch control, and intuitive control of the sequencer from the keyboard.},
 address = {Ann Arbor, Michigan},
 author = {Jeff Snyder and Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178421},
 issn = {2220-4806},
 keywords = {keyboard, sequencer, analog synthesizer, capacitive touch sensing},
 publisher = {University of Michigan},
 title = {The JD-1: an Implementation of a Hybrid Keyboard/Sequencer Controller for Analog Synthesizers},
 url = {http://www.nime.org/proceedings/2012/nime2012_187.pdf},
 year = {2012}
}
"
2012,nime2012_McPherson_a.pdf,nime2012_McPherson_a,TouchKeys: Capacitive Multi-Touch Sensing on a Physical Keyboard,Andrew McPherson,"augmented instruments, keyboard, capacitive sensing, multitouch","Capacitive touch sensing is increasingly used in musical con-trollers, particularly those based on multi-touch screen interfaces. However, in contrast to the venerable piano-style keyboard, touch screen controllers lack the tactile feedback many performers find crucial. This paper presents an augmentation system for acoustic and electronic keyboards in which multi-touch capacitive sensors are added to the surface of each key. Each key records the position of fingers on the surface, and by combining this data with MIDI note onsets and aftertouch from the host keyboard, the system functions as a multidimensional polyphonic controller for a wide variety of synthesis software. The paper will discuss general capacitive touch sensor design, keyboard-specific implementation strategies, and the development of a flexible mapping engine using OSC and MIDI.",10.5281/zenodo.1180531,"@inproceedings{nime2012_McPherson_a,
 abstract = {Capacitive touch sensing is increasingly used in musical con-trollers, particularly those based on multi-touch screen interfaces. However, in contrast to the venerable piano-style keyboard, touch screen controllers lack the tactile feedback many performers find crucial. This paper presents an augmentation system for acoustic and electronic keyboards in which multi-touch capacitive sensors are added to the surface of each key. Each key records the position of fingers on the surface, and by combining this data with MIDI note onsets and aftertouch from the host keyboard, the system functions as a multidimensional polyphonic controller for a wide variety of synthesis software. The paper will discuss general capacitive touch sensor design, keyboard-specific implementation strategies, and the development of a flexible mapping engine using OSC and MIDI.},
 address = {Ann Arbor, Michigan},
 author = {Andrew McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1180531},
 issn = {2220-4806},
 keywords = {augmented instruments, keyboard, capacitive sensing, multitouch},
 publisher = {University of Michigan},
 title = {TouchKeys: Capacitive Multi-Touch Sensing on a Physical Keyboard},
 url = {http://www.nime.org/proceedings/2012/nime2012_195.pdf},
 year = {2012}
}
"
2025,nime2025_48.pdf,nime2025_48,ViVo: Piano Learning Through Visualizing Vocalizations on a Lighted Keyboard,Maya Caren,,"Vocalization and visualization are recognized as two powerful methods for internalizing music that are effective with beginner and skilled musicians alike. Despite the well-researched benefits of each practice, integrated visualization of vocalizations for instrument learning has seen little attention in the music technology community. This paper introduces the design and implementation of ViVo, a piano learning tool that connects the embodied sense of pitch offered by vocalization with the spatial intuition provided by in situ visualization. ViVo offers two modes: a real-time mode that hears live user vocalizations to concurrently illuminate the corresponding piano keys, and a practice mode that visualizes recorded vocalizations for repeated practice. By providing an integrated system to foster and visualize vocalizations, ViVo aims to leverage the noted benefits of both practices to make learning piano more effective, intuitive, and engaging.",10.5281/zenodo.15698882,"@inproceedings{nime2025_48,
 abstract = {Vocalization and visualization are recognized as two powerful methods for internalizing music that are effective with beginner and skilled musicians alike. Despite the well-researched benefits of each practice, integrated visualization of vocalizations for instrument learning has seen little attention in the music technology community. This paper introduces the design and implementation of ViVo, a piano learning tool that connects the embodied sense of pitch offered by vocalization with the spatial intuition provided by in situ visualization. ViVo offers two modes: a real-time mode that hears live user vocalizations to concurrently illuminate the corresponding piano keys, and a practice mode that visualizes recorded vocalizations for repeated practice. By providing an integrated system to foster and visualize vocalizations, ViVo aims to leverage the noted benefits of both practices to make learning piano more effective, intuitive, and engaging.},
 address = {Canberra, Australia},
 articleno = {48},
 author = {Maya Caren},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698882},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {3},
 pages = {352--354},
 title = {ViVo: Piano Learning Through Visualizing Vocalizations on a Lighted Keyboard},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_48.pdf},
 year = {2025}
}
"
2009,nime2009_Hadjakos.pdf,nime2009_Hadjakos,Probabilistic Model of Pianists' Arm Touch Movements,"Hadjakos, Aristotelis and Aitenbichler, Erwin and Mühlhäuser, Max","Piano, arm movement, gesture, classification, augmented instrument, inertial sensing. ","Measurement of pianists' arm movement provides a signal,which is composed of controlled movements and noise. Thenoise is composed of uncontrolled movement generated bythe interaction of the arm with the piano action and measurement error. We propose a probabilistic model for armtouch movements, which allows to estimate the amount ofnoise in a joint. This estimation helps to interpret the movement signal, which is of interest for augmented piano andpiano pedagogy applications.",10.5281/zenodo.1177567,"@inproceedings{nime2009_Hadjakos,
 abstract = {Measurement of pianists' arm movement provides a signal,which is composed of controlled movements and noise. Thenoise is composed of uncontrolled movement generated bythe interaction of the arm with the piano action and measurement error. We propose a probabilistic model for armtouch movements, which allows to estimate the amount ofnoise in a joint. This estimation helps to interpret the movement signal, which is of interest for augmented piano andpiano pedagogy applications.},
 address = {Pittsburgh, PA, United States},
 author = {Hadjakos, Aristotelis and Aitenbichler, Erwin and M\''{u}hlh\''{a}user, Max},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177567},
 issn = {2220-4806},
 keywords = {Piano, arm movement, gesture, classification, augmented instrument, inertial sensing. },
 pages = {7--12},
 title = {Probabilistic Model of Pianists' Arm Touch Movements},
 url = {http://www.nime.org/proceedings/2009/nime2009_007.pdf},
 year = {2009}
}
"
2017,nime2017_iwicaksono.pdf,nime2017_iwicaksono,FabricKeyboard: Multimodal Textile Sensate Media as an Expressive and Deformable Musical Interface,Irmandy Wicaksono and Joseph Paradiso,,"This paper presents FabricKeyboard: a novel deformable keyboard interface based on a multi-modal fabric sensate surface. Multi-layer fabric sensors that detect touch, proximity, electric field, pressure, and stretch are machine-sewn in a keyboard pattern on a stretchable substrate. The result is a fabric-based musical controller that combines both the discrete controls of a keyboard and various continuous controls from the embedded fabric sensors. This enables unique tactile experiences and new interactions both with physical and non-contact gestures: physical by pressing, pulling, stretching, and twisting the keys or the fabric and non-contact by hovering and waving towards/against the keyboard and an electromagnetic source. We have also developed additional fabric-based modular interfaces such as a ribbon-controller and trackpad, allowing performers to add more expressive and continuous controls. This paper will discuss implementation strategies for our system-on-textile, fabric-based sensor developments, as well as sensor-computer interfacing and musical mapping examples of this multi-modal and expressive fabric keyboard.  ",10.5281/zenodo.1176278,"@inproceedings{nime2017_iwicaksono,
 abstract = {This paper presents FabricKeyboard: a novel deformable keyboard interface based on a multi-modal fabric sensate surface. Multi-layer fabric sensors that detect touch, proximity, electric field, pressure, and stretch are machine-sewn in a keyboard pattern on a stretchable substrate. The result is a fabric-based musical controller that combines both the discrete controls of a keyboard and various continuous controls from the embedded fabric sensors. This enables unique tactile experiences and new interactions both with physical and non-contact gestures: physical by pressing, pulling, stretching, and twisting the keys or the fabric and non-contact by hovering and waving towards/against the keyboard and an electromagnetic source. We have also developed additional fabric-based modular interfaces such as a ribbon-controller and trackpad, allowing performers to add more expressive and continuous controls. This paper will discuss implementation strategies for our system-on-textile, fabric-based sensor developments, as well as sensor-computer interfacing and musical mapping examples of this multi-modal and expressive fabric keyboard.  },
 address = {Copenhagen, Denmark},
 author = {Irmandy Wicaksono and Joseph Paradiso},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176278},
 issn = {2220-4806},
 pages = {348--353},
 publisher = {Aalborg University Copenhagen},
 title = {FabricKeyboard: Multimodal Textile Sensate Media as an Expressive and Deformable Musical Interface},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0066.pdf},
 year = {2017}
}
"
2014,nime2014_ngold.pdf,nime2014_ngold,Lessons Learned in Exploring the Leap Motion(TM) Sensor for Gesture-based Instrument Design,Jihyun Han and Nicolas Gold,,"The Leap Motion(TM) sensor offers fine-grained gesture-recognition and hand tracking. Since its release, there have been several uses of the device for instrument design, musical interaction and expression control, documented through online video. However, there has been little formal documented investigation of the potential and challenges of the platform in this context. This paper presents lessons learned from work-in-progress on the development of musical instruments and control applications using the Leap Motion(TM) sensor. Two instruments are presented: Air-Keys and Air-Pads and the potential for augmentation of a traditional keyboard is explored. The results show that the platform is promising in this context but requires various challenges, both physical and logical, to be overcome.",10.5281/zenodo.1178784,"@inproceedings{nime2014_ngold,
 abstract = {The Leap Motion(TM) sensor offers fine-grained gesture-recognition and hand tracking. Since its release, there have been several uses of the device for instrument design, musical interaction and expression control, documented through online video. However, there has been little formal documented investigation of the potential and challenges of the platform in this context. This paper presents lessons learned from work-in-progress on the development of musical instruments and control applications using the Leap Motion(TM) sensor. Two instruments are presented: Air-Keys and Air-Pads and the potential for augmentation of a traditional keyboard is explored. The results show that the platform is promising in this context but requires various challenges, both physical and logical, to be overcome.},
 address = {London, United Kingdom},
 author = {Jihyun Han and Nicolas Gold},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178784},
 issn = {2220-4806},
 month = {June},
 pages = {371--374},
 publisher = {Goldsmiths, University of London},
 title = {Lessons Learned in Exploring the Leap Motion(TM) Sensor for Gesture-based Instrument Design},
 url = {http://www.nime.org/proceedings/2014/nime2014_485.pdf},
 year = {2014}
}
"
2007,nime2007_Paine.pdf,nime2007_Paine,The Thummer Mapping Project (ThuMP),"Paine, Garth and Stevenson, Ian and Pearce, Angela","Musical Instrument Design, Mapping, Musicianship, evaluation, testing. ","This paper presents the Thummer Mapping Project (ThuMP), an industry partnership project between ThumMotion P/L and The University of Western Sydney (UWS). ThuMP sought to developing mapping strategies for new interfaces for musical expression (NIME), specifically the ThummerTM, which provides thirteen simultaneous degrees of freedom. This research presents a new approach to the mapping problem resulting from a primary design research phase and a prototype testing and evaluation phase. In order to establish an underlying design approach for the ThummerTM mapping strategies, a number of interviews were carried out with high-level acoustic instrumental performers, the majority of whom play with the Sydney Symphony Orchestra, Sydney, Australia. Mapping strategies were developed from analysis of these interviews and then evaluated in trial usability testing.",10.5281/zenodo.1177217,"@inproceedings{nime2007_Paine,
 abstract = {This paper presents the Thummer Mapping Project (ThuMP), an industry partnership project between ThumMotion P/L and The University of Western Sydney (UWS). ThuMP sought to developing mapping strategies for new interfaces for musical expression (NIME), specifically the ThummerTM, which provides thirteen simultaneous degrees of freedom. This research presents a new approach to the mapping problem resulting from a primary design research phase and a prototype testing and evaluation phase. In order to establish an underlying design approach for the ThummerTM mapping strategies, a number of interviews were carried out with high-level acoustic instrumental performers, the majority of whom play with the Sydney Symphony Orchestra, Sydney, Australia. Mapping strategies were developed from analysis of these interviews and then evaluated in trial usability testing.},
 address = {New York City, NY, United States},
 author = {Paine, Garth and Stevenson, Ian and Pearce, Angela},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177217},
 issn = {2220-4806},
 keywords = {Musical Instrument Design, Mapping, Musicianship, evaluation, testing. },
 pages = {70--77},
 title = {The Thummer Mapping Project (ThuMP)},
 url = {http://www.nime.org/proceedings/2007/nime2007_070.pdf},
 year = {2007}
}
"
2020,nime2020_62.pdf,nime2020_62,KnittedKeyboard: Digital Knitting of Electronic Textile Musical Controllers,"Wicaksono, Irmandy and Paradiso, Joseph",,"In this work, we have developed a textile-based interactive surface fabricated through digital knitting technology. Our prototype explores intarsia, interlock patterning, and a collection of functional and non-functional fibers to create a piano-pattern textile for expressive and virtuosic sonic interaction. We combined conductive, thermochromic, and composite yarns with high-flex polyester yarns to develop KnittedKeyboard with its soft physical properties and responsive sensing and display capabilities. The individual and combination of each key could simultaneously sense discrete touch, as well as continuous proximity and pressure. The KnittedKeyboard enables performers to experience fabric-based multimodal interaction as they explore the seamless texture and materiality of the electronic textile.",10.5281/zenodo.4813391,"@inproceedings{nime2020_62,
 abstract = {In this work, we have developed a textile-based interactive surface fabricated through digital knitting technology. Our prototype explores intarsia, interlock patterning, and a collection of functional and non-functional fibers to create a piano-pattern textile for expressive and virtuosic sonic interaction. We combined conductive, thermochromic, and composite yarns with high-flex polyester yarns to develop KnittedKeyboard with its soft physical properties and responsive sensing and display capabilities. The individual and combination of each key could simultaneously sense discrete touch, as well as continuous proximity and pressure. The KnittedKeyboard enables performers to experience fabric-based multimodal interaction as they explore the seamless texture and materiality of the electronic textile.},
 address = {Birmingham, UK},
 author = {Wicaksono, Irmandy and Paradiso, Joseph},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813391},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {323--326},
 publisher = {Birmingham City University},
 title = {KnittedKeyboard: Digital Knitting of Electronic Textile Musical Controllers},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper62.pdf},
 year = {2020}
}
"
2013,nime2013_Yang.pdf,nime2013_Yang,Visual Associations in Augmented Keyboard Performance,Qi Yang and Georg Essl,"Visual feedback, interaction, NIME, musical instrument, interaction, augmented keyboard, gesture, Kinect","What is the function of visuals in the design of an augmented keyboardperformance device with projection? We address this question by thinkingthrough the impact of choices made in three examples on notions of locus ofattention, visual anticipation and causal gestalt to articulate a space ofdesign choices. Visuals can emphasize and deemphasize aspects of performanceand help clarify the role input has to the performance. We suggest that thisprocess might help thinking through visual feedback design in NIMEs withrespect to the performer or the audience.",10.5281/zenodo.1178694,"@inproceedings{nime2013_Yang,
 abstract = {What is the function of visuals in the design of an augmented keyboardperformance device with projection? We address this question by thinkingthrough the impact of choices made in three examples on notions of locus ofattention, visual anticipation and causal gestalt to articulate a space ofdesign choices. Visuals can emphasize and deemphasize aspects of performanceand help clarify the role input has to the performance. We suggest that thisprocess might help thinking through visual feedback design in NIMEs withrespect to the performer or the audience.},
 address = {Daejeon, Republic of Korea},
 author = {Qi Yang and Georg Essl},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178694},
 issn = {2220-4806},
 keywords = {Visual feedback, interaction, NIME, musical instrument, interaction, augmented keyboard, gesture, Kinect},
 month = {May},
 pages = {252--255},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Visual Associations in Augmented Keyboard Performance},
 url = {http://www.nime.org/proceedings/2013/nime2013_156.pdf},
 year = {2013}
}
"
2016,nime2016_Laurenzo.pdf,nime2016_Laurenzo,"5500: performance, control, and politics",Tomas Laurenzo,,"In the period between June 2014 and June 2015, at least 5,500
immigrants died trying to reach Europe from Africa while crossing the
Mediterranean Sea.
In this paper we present 5500, a piano performance that is a part of an on-going
project that investigates the incorporation of electrical muscle stimulation
(EMS) into musical performances, with a particular interest in the political
significance of the negotiation of control that arises.
5500 consists of a performance of Beethoven's Sonata Pathétique, where the
pianist's execution is disrupted using computer-controlled electrodes
which stimulate the muscles in his or her arms causing their involuntary
contractions and affecting the final musical result.",10.5281/zenodo.1176058,"@inproceedings{nime2016_Laurenzo,
 abstract = {In the period between June 2014 and June 2015, at least 5,500
immigrants died trying to reach Europe from Africa while crossing the
Mediterranean Sea.
In this paper we present 5500, a piano performance that is a part of an on-going
project that investigates the incorporation of electrical muscle stimulation
(EMS) into musical performances, with a particular interest in the political
significance of the negotiation of control that arises.
5500 consists of a performance of Beethoven's Sonata Path\'{e}tique, where the
pianist's execution is disrupted using computer-controlled electrodes
which stimulate the muscles in his or her arms causing their involuntary
contractions and affecting the final musical result.},
 address = {Brisbane, Australia},
 author = {Tomas Laurenzo},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176058},
 isbn = {978-1-925455-13-7},
 issn = {2220-4806},
 pages = {36--40},
 publisher = {Queensland Conservatorium Griffith University},
 title = {5500: performance, control, and politics},
 track = {Papers},
 url = {http://www.nime.org/proceedings/2016/nime2016_paper0008.pdf},
 year = {2016}
}
"
2019,nime2019_Granieri.pdf,nime2019_Granieri,Reach: a keyboard-based gesture recognition system for live piano sound modulation,Niccolò Granieri and James Dooley,,"This paper presents Reach, a keyboard-based gesture recog- nition system for live piano sound modulation. Reach is a system built using the Leap Motion Orion SDK, Pure Data and a custom C++ OSC mapper1. It provides control over the sound modulation of an acoustic piano using the pi- anist's ancillary gestures. The system was developed using an iterative design pro- cess, incorporating research findings from two user studies and several case studies. The results that emerged show the potential of recognising and utilising the pianist's existing technique when designing keyboard-based DMIs, reducing the requirement to learn additional techniques.",10.5281/zenodo.3673000,"@inproceedings{nime2019_Granieri,
 abstract = {This paper presents Reach, a keyboard-based gesture recog- nition system for live piano sound modulation. Reach is a system built using the Leap Motion Orion SDK, Pure Data and a custom C++ OSC mapper1. It provides control over the sound modulation of an acoustic piano using the pi- anist's ancillary gestures. The system was developed using an iterative design pro- cess, incorporating research findings from two user studies and several case studies. The results that emerged show the potential of recognising and utilising the pianist's existing technique when designing keyboard-based DMIs, reducing the requirement to learn additional techniques.},
 address = {Porto Alegre, Brazil},
 author = {Niccolò Granieri and James Dooley},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3673000},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {375--376},
 publisher = {UFRGS},
 title = {Reach: a keyboard-based gesture recognition system for live piano sound modulation},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper072.pdf},
 year = {2019}
}
"
2007,nime2007_Gruenbaum.pdf,nime2007_Gruenbaum,The Samchillian Tip Tip Tip Cheeepeeeee : A Relativistic Keyboard Instrument,"Gruenbaum, Leon","samchillian, keyboard, MIDI controller, relative, interval, microtonal, computer keyboard, pitch, musical instrument ","Almost all traditional musical instruments have a one-to-one correspondence between a given fingering and the pitch that sounds for that fingering. The Samchillian Tip Tip Tip Cheeepeeeee does not --- it is a keyboard MIDI controller that is based on intervals rather than fixed pitches. That is, a given keypress will sound a pitch a number of steps away from the last note sounded (within the key signature and scale selected) according to the 'delta' value assigned to that key. The advantages of such a system are convenience, speed, and the ability to play difficult, unusual and/or unintended passages extemporaneously. ",10.5281/zenodo.1177103,"@inproceedings{nime2007_Gruenbaum,
 abstract = {Almost all traditional musical instruments have a one-to-one correspondence between a given fingering and the pitch that sounds for that fingering. The Samchillian Tip Tip Tip Cheeepeeeee does not --- it is a keyboard MIDI controller that is based on intervals rather than fixed pitches. That is, a given keypress will sound a pitch a number of steps away from the last note sounded (within the key signature and scale selected) according to the 'delta' value assigned to that key. The advantages of such a system are convenience, speed, and the ability to play difficult, unusual and/or unintended passages extemporaneously. },
 address = {New York City, NY, United States},
 author = {Gruenbaum, Leon},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177103},
 issn = {2220-4806},
 keywords = {samchillian, keyboard, MIDI controller, relative, interval, microtonal, computer keyboard, pitch, musical instrument },
 pages = {256--259},
 title = {The Samchillian Tip Tip Tip Cheeepeeeee : A Relativistic Keyboard Instrument},
 url = {http://www.nime.org/proceedings/2007/nime2007_256.pdf},
 year = {2007}
}
"
2004,nime2004_Miyashita.pdf,nime2004_Miyashita,Thermoscore: A New-type Musical Score with Temperature Sensation,"Miyashita, Homei and Nishimoto, Kazushi","musical score, improvisation, peltier device, chroma profile","In this paper, we propose Thermoscore, a musical score form-that dynamically alters the temperature of the instrument/player interface. We developed the first version of theThermoscore display by lining Peltier devices on piano keys.The system is controlled by MIDI notes-on messages from anMIDI sequencer, so that a composer can design songs that aresequences of temperature for each piano key. We also discussmethodologies for composing with this system, and suggesttwo approaches. The first is to make desirable keys (or otherkeys) hot. The second one uses chroma-profile, that is, a radarchart representation of the frequency of pitch notations in the-piece. By making keys of the same chroma hot in reverse proportion to the value of the chroma-profile, it is possible to-constrain the performer's improvisation and to bring the tonality space close to a certain piece.",10.5281/zenodo.1176637,"@inproceedings{nime2004_Miyashita,
 abstract = {In this paper, we propose Thermoscore, a musical score form-that dynamically alters the temperature of the instrument/player interface. We developed the first version of theThermoscore display by lining Peltier devices on piano keys.The system is controlled by MIDI notes-on messages from anMIDI sequencer, so that a composer can design songs that aresequences of temperature for each piano key. We also discussmethodologies for composing with this system, and suggesttwo approaches. The first is to make desirable keys (or otherkeys) hot. The second one uses chroma-profile, that is, a radarchart representation of the frequency of pitch notations in the-piece. By making keys of the same chroma hot in reverse proportion to the value of the chroma-profile, it is possible to-constrain the performer's improvisation and to bring the tonality space close to a certain piece.},
 address = {Hamamatsu, Japan},
 author = {Miyashita, Homei and Nishimoto, Kazushi},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176637},
 issn = {2220-4806},
 keywords = {musical score, improvisation, peltier device, chroma profile},
 pages = {104--107},
 title = {Thermoscore: A New-type Musical Score with Temperature Sensation},
 url = {http://www.nime.org/proceedings/2004/nime2004_104.pdf},
 year = {2004}
}
"
2020,nime2020_80.pdf,nime2020_80,Augmented Piano in Augmented Reality,"Santini, Giovanni ",,"Augmented instruments have been a widely explored research topic since the late 80s. The possibility to use sensors for providing an input for sound processing/synthesis units let composers and sound artist open up new ways for experimentation. Augmented Reality, by rendering virtual objects in the real world and by making those objects interactive (via some sensor-generated input), provides a new frame for this research field. In fact, the 3D visual feedback, delivering a precise indication of the spatial configuration/function of each virtual interface, can make the instrumental augmentation process more intuitive for the interpreter and more resourceful for a composer/creator: interfaces can change their behavior over time, can be reshaped, activated or deactivated. Each of these modifications can be made obvious to the performer by using strategies of visual feedback. In addition, it is possible to accurately sample space and to map it with differentiated functions. Augmenting interfaces can also be considered a visual expressive tool for the audience and designed accordingly: the performer’s point of view (or another point of view provided by an external camera) can be mirrored to a projector. This article will show some example of different designs of AR piano augmentation from the composition Studi sulla realtà nuova.",10.5281/zenodo.4813449,"@inproceedings{nime2020_80,
 abstract = {Augmented instruments have been a widely explored research topic since the late 80s. The possibility to use sensors for providing an input for sound processing/synthesis units let composers and sound artist open up new ways for experimentation. Augmented Reality, by rendering virtual objects in the real world and by making those objects interactive (via some sensor-generated input), provides a new frame for this research field. In fact, the 3D visual feedback, delivering a precise indication of the spatial configuration/function of each virtual interface, can make the instrumental augmentation process more intuitive for the interpreter and more resourceful for a composer/creator: interfaces can change their behavior over time, can be reshaped, activated or deactivated. Each of these modifications can be made obvious to the performer by using strategies of visual feedback. In addition, it is possible to accurately sample space and to map it with differentiated functions. Augmenting interfaces can also be considered a visual expressive tool for the audience and designed accordingly: the performer’s point of view (or another point of view provided by an external camera) can be mirrored to a projector. This article will show some example of different designs of AR piano augmentation from the composition Studi sulla realtà nuova.},
 address = {Birmingham, UK},
 author = {Santini, Giovanni },
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813449},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {411--415},
 presentation-video = {https://youtu.be/3HBWvKj2cqc},
 publisher = {Birmingham City University},
 title = {Augmented Piano in Augmented Reality},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper80.pdf},
 year = {2020}
}
"
2019,nime2019_VanTroyer.pdf,nime2019_VanTroyer,From Mondrian to Modular Synth: Rendering NIME using Generative Adversarial Networks,Akito Van Troyer and Rebecca Kleinberger,,"This paper explores the potential of image-to-image translation techniques in aiding the design of new hardware-based musical interfaces such as MIDI keyboard, grid-based controller, drum machine, and analog modular synthesizers. We collected an extensive image database of such interfaces and implemented image-to-image translation techniques using variants of Generative Adversarial Networks. The created models learn the mapping between input and output images using a training set of either paired or unpaired images. We qualitatively assess the visual outcomes based on three image-to-image translation models: reconstructing interfaces from edge maps, and collection style transfers based on two image sets: visuals of mosaic tile patterns and geometric abstract two-dimensional arts. This paper aims to demonstrate that synthesizing interface layouts based on image-to-image translation techniques can yield insights for researchers, musicians, music technology industrial designers, and the broader NIME community.",10.5281/zenodo.3672956,"@inproceedings{nime2019_VanTroyer,
 abstract = {This paper explores the potential of image-to-image translation techniques in aiding the design of new hardware-based musical interfaces such as MIDI keyboard, grid-based controller, drum machine, and analog modular synthesizers. We collected an extensive image database of such interfaces and implemented image-to-image translation techniques using variants of Generative Adversarial Networks. The created models learn the mapping between input and output images using a training set of either paired or unpaired images. We qualitatively assess the visual outcomes based on three image-to-image translation models: reconstructing interfaces from edge maps, and collection style transfers based on two image sets: visuals of mosaic tile patterns and geometric abstract two-dimensional arts. This paper aims to demonstrate that synthesizing interface layouts based on image-to-image translation techniques can yield insights for researchers, musicians, music technology industrial designers, and the broader NIME community.},
 address = {Porto Alegre, Brazil},
 author = {Akito Van Troyer and Rebecca Kleinberger},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672956},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {272--277},
 publisher = {UFRGS},
 title = {From Mondrian to Modular Synth: Rendering {NIME} using Generative Adversarial Networks},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper052.pdf},
 year = {2019}
}
"
2015,nime2015_spapetti.pdf,nime2015_spapetti,Multi-point vibrotactile feedback for an expressive musical interface,Stefano Papetti and Sébastien Schiesser and Martin Fröhlich,,"This paper describes the design of a hardware/software system for rendering multi-point, localized vibrotactile feedback in a multi-touch musical interface. A prototype was developed, based on the Madrona Labs Soundplane, which was chosen for it provides easy access to multi-touch data, including force, and its easily expandable layered construction. The proposed solution makes use of several piezo actuator discs, densely arranged in a honeycomb pattern on a thin PCB layer. Based on off-the-shelf components, custom amplifying and routing electronics were designed to drive each piezo element with standard audio signals. Features, as well as electronic and mechanical issues of the current prototype are discussed.",10.5281/zenodo.1179152,"@inproceedings{nime2015_spapetti,
 abstract = {This paper describes the design of a hardware/software system for rendering multi-point, localized vibrotactile feedback in a multi-touch musical interface. A prototype was developed, based on the Madrona Labs Soundplane, which was chosen for it provides easy access to multi-touch data, including force, and its easily expandable layered construction. The proposed solution makes use of several piezo actuator discs, densely arranged in a honeycomb pattern on a thin PCB layer. Based on off-the-shelf components, custom amplifying and routing electronics were designed to drive each piezo element with standard audio signals. Features, as well as electronic and mechanical issues of the current prototype are discussed.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Stefano Papetti and S\'ebastien Schiesser and Martin Fr\''ohlich},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179152},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {235--240},
 publisher = {Louisiana State University},
 title = {Multi-point vibrotactile feedback for an expressive musical interface},
 url = {http://www.nime.org/proceedings/2015/nime2015_118.pdf},
 year = {2015}
}
"
2018,nime2018_Lepri.pdf,nime2018_Lepri,"Mirroring the past, from typewriting to interactive art: an approach to the re-design of a vintage technology",Giacomo Lepri and Andrew P. McPherson,,"Obsolete and old technologies are often used in interactive art and music performance. DIY practices such as hardware hacking and circuit bending provide
effective methods to the integration of old machines into new artistic inventions. This paper presents the Cembalo Scrivano .1, an interactive audio-visual installation based on an augmented typewriter. Borrowing concepts from media archaeology studies, tangible interaction design and digital lutherie, we discuss how investigations into the historical and cultural evolution of a technology can suggest directions for the regeneration of obsolete objects. The design approach outlined focuses on the remediation of an old device and aims to evoke cultural and physical properties associated to the source object.",10.5281/zenodo.1302601,"@inproceedings{nime2018_Lepri,
 abstract = {Obsolete and old technologies are often used in interactive art and music performance. DIY practices such as hardware hacking and circuit bending provide
effective methods to the integration of old machines into new artistic inventions. This paper presents the Cembalo Scrivano .1, an interactive audio-visual installation based on an augmented typewriter. Borrowing concepts from media archaeology studies, tangible interaction design and digital lutherie, we discuss how investigations into the historical and cultural evolution of a technology can suggest directions for the regeneration of obsolete objects. The design approach outlined focuses on the remediation of an old device and aims to evoke cultural and physical properties associated to the source object.},
 address = {Blacksburg, Virginia, USA},
 author = {Giacomo Lepri and Andrew P. McPherson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1302601},
 editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
 isbn = {978-1-949373-99-8},
 issn = {2220-4806},
 month = {June},
 pages = {328--333},
 publisher = {Virginia Tech},
 title = {Mirroring the past, from typewriting to interactive art: an approach to the re-design of a vintage technology},
 url = {http://www.nime.org/proceedings/2018/nime2018_paper0069.pdf},
 year = {2018}
}
"
2008,nime2008_Barbosa.pdf,nime2008_Barbosa,Ten-Hand Piano : A Networked Music Installation,"Barbosa, Àlvaro","algorithmic composition,behavioral driven,electronic music instruments,interfaces,network music instruments,nime08,performance,public music,real-time collaborative,sound","This paper presents the latest developments of the Public Sound Objects (PSOs) system, an experimental framework to implement and test new concepts for Networked Music. The project of a Public interactive installation using the PSOs system was commissioned in 2007 by Casa da Musica, the main concert hall space in Porto. It resulted in a distributed musical structure with up to ten interactive performance terminals distributed along the Casa da Musica's hallways, collectively controlling a shared acoustic piano. The installation allows the visitors to collaborate remotely with each other, within the building, using a software interface custom developed to facilitate collaborative music practices and with no requirements in terms previous knowledge of musical performance. ",10.5281/zenodo.1179487,"@inproceedings{nime2008_Barbosa,
 abstract = {This paper presents the latest developments of the Public Sound Objects (PSOs) system, an experimental framework to implement and test new concepts for Networked Music. The project of a Public interactive installation using the PSOs system was commissioned in 2007 by Casa da Musica, the main concert hall space in Porto. It resulted in a distributed musical structure with up to ten interactive performance terminals distributed along the Casa da Musica's hallways, collectively controlling a shared acoustic piano. The installation allows the visitors to collaborate remotely with each other, within the building, using a software interface custom developed to facilitate collaborative music practices and with no requirements in terms previous knowledge of musical performance. },
 address = {Genoa, Italy},
 author = {Barbosa, \`{A}lvaro},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179487},
 issn = {2220-4806},
 keywords = {algorithmic composition,behavioral driven,electronic music instruments,interfaces,network music instruments,nime08,performance,public music,real-time collaborative,sound},
 pages = {9--12},
 title = {Ten-Hand Piano : A Networked Music Installation},
 url = {http://www.nime.org/proceedings/2008/nime2008_009.pdf},
 year = {2008}
}
"
2014,nime2014_pdahlstedt.pdf,nime2014_pdahlstedt,Circle Squared and Circle Keys Performing on and with an Unstable Live Algorithm for the Disklavier,Palle Dahlstedt,,"Two related versions of an unstable live algorithm for the Disklavier player piano are presented. The underlying generative feedback system consists of four virtual musicians, listening to each other in a circular configuration. There is no temporal form, and all parameters of the system are controlled by the performer through an intricate but direct mapping, in an attempt to combine the experienced musician's physical control of gesture and phrasing, with the structural complexities and richness of generative music. In the first version, Circle Squared, the interface is an array of pressure sensors, and the performer performs on the system without participating directly, like a puppet master. In the second version, control parameters are derived directly from playing on the same piano that performs the output of the system. Here, the performer both plays with and on the system in an intricate dance with the unpredictable output of the unstable virtual ensemble. The underlying mapping strategies are presented, together with the structure of the generative system. Experiences from a series of performances are discussed, primarily from the perspective of the improvising musician.",10.5281/zenodo.1178740,"@inproceedings{nime2014_pdahlstedt,
 abstract = {Two related versions of an unstable live algorithm for the Disklavier player piano are presented. The underlying generative feedback system consists of four virtual musicians, listening to each other in a circular configuration. There is no temporal form, and all parameters of the system are controlled by the performer through an intricate but direct mapping, in an attempt to combine the experienced musician's physical control of gesture and phrasing, with the structural complexities and richness of generative music. In the first version, Circle Squared, the interface is an array of pressure sensors, and the performer performs on the system without participating directly, like a puppet master. In the second version, control parameters are derived directly from playing on the same piano that performs the output of the system. Here, the performer both plays with and on the system in an intricate dance with the unpredictable output of the unstable virtual ensemble. The underlying mapping strategies are presented, together with the structure of the generative system. Experiences from a series of performances are discussed, primarily from the perspective of the improvising musician.},
 address = {London, United Kingdom},
 author = {Palle Dahlstedt},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178740},
 issn = {2220-4806},
 month = {June},
 pages = {114--117},
 publisher = {Goldsmiths, University of London},
 title = {Circle Squared and Circle Keys Performing on and with an Unstable Live Algorithm for the Disklavier},
 url = {http://www.nime.org/proceedings/2014/nime2014_534.pdf},
 year = {2014}
}
"
2017,nime2017_mjensen.pdf,nime2017_mjensen,A low-cost MRI compatible keyboard,Martin Snejbjerg Jensen and Ole Adrian Heggli and Patricia Alves Da Mota and Peter Vuust,,"Neuroimaging is a powerful tool to explore how and why humans engage in music. Magnetic resonance imaging (MRI) has allowed us to identify brain networks and regions implicated in a range of cognitive tasks including music perception and performance. However, MRI-scanners are noisy and cramped, presenting a challenging environment for playing an instrument. Here, we present an MRI-compatible polyphonic keyboard with a materials cost of 850 USD, designed and tested for safe use in 3T (three Tesla) MRI-scanners. We describe design considerations, and prior work in the field. In addition, we provide recommendations for future designs and comment on the possibility of using the keyboard in magnetoencephalography (MEG) systems. Preliminary results indicate a comfortable playing experience with no disturbance of the imaging process.",10.5281/zenodo.1176240,"@inproceedings{nime2017_mjensen,
 abstract = {Neuroimaging is a powerful tool to explore how and why humans engage in music. Magnetic resonance imaging (MRI) has allowed us to identify brain networks and regions implicated in a range of cognitive tasks including music perception and performance. However, MRI-scanners are noisy and cramped, presenting a challenging environment for playing an instrument. Here, we present an MRI-compatible polyphonic keyboard with a materials cost of 850 USD, designed and tested for safe use in 3T (three Tesla) MRI-scanners. We describe design considerations, and prior work in the field. In addition, we provide recommendations for future designs and comment on the possibility of using the keyboard in magnetoencephalography (MEG) systems. Preliminary results indicate a comfortable playing experience with no disturbance of the imaging process.},
 address = {Copenhagen, Denmark},
 author = {Martin Snejbjerg Jensen and Ole Adrian Heggli and Patricia Alves Da Mota and Peter Vuust},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176240},
 issn = {2220-4806},
 pages = {257--260},
 publisher = {Aalborg University Copenhagen},
 title = {A low-cost MRI compatible keyboard},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0048.pdf},
 year = {2017}
}
"
2015,nime2015_byuksel.pdf,nime2015_byuksel,BRAAHMS: A Novel Adaptive Musical Interface Based on Users' Cognitive State,Beste Filiz Yuksel and Daniel Afergan and Evan Peck and Garth Griffin and Lane Harrison and Nick Chen and Remco Chang and Robert Jacob,,"We present a novel brain-computer interface (BCI) integrated with a musical instrument that adapts implicitly (with no extra effort from user) to users' changing cognitive state during musical improvisation. Most previous musical BCI systems use either a mapping of brainwaves to create audio signals or use explicit brain signals to control some aspect of the music. Such systems do not take advantage of higher level semantically meaningful brain data which could be used in adaptive systems or without detracting from the attention of the user. We present a new type of real-time BCI that assists users in musical improvisation by adapting to users' measured cognitive workload implicitly. Our system advances the state of the art in this area in three ways: 1) We demonstrate that cognitive workload can be classified in real-time while users play the piano using functional near-infrared spectroscopy. 2) We build a real-time, implicit system using this brain signal that musically adapts to what users are playing. 3) We demonstrate that users prefer this novel musical instrument over other conditions and report that they feel more creative.",10.5281/zenodo.1181418,"@inproceedings{nime2015_byuksel,
 abstract = {We present a novel brain-computer interface (BCI) integrated with a musical instrument that adapts implicitly (with no extra effort from user) to users' changing cognitive state during musical improvisation. Most previous musical BCI systems use either a mapping of brainwaves to create audio signals or use explicit brain signals to control some aspect of the music. Such systems do not take advantage of higher level semantically meaningful brain data which could be used in adaptive systems or without detracting from the attention of the user. We present a new type of real-time BCI that assists users in musical improvisation by adapting to users' measured cognitive workload implicitly. Our system advances the state of the art in this area in three ways: 1) We demonstrate that cognitive workload can be classified in real-time while users play the piano using functional near-infrared spectroscopy. 2) We build a real-time, implicit system using this brain signal that musically adapts to what users are playing. 3) We demonstrate that users prefer this novel musical instrument over other conditions and report that they feel more creative.},
 address = {Baton Rouge, Louisiana, USA},
 author = {{Beste Filiz} Yuksel and Daniel Afergan and Evan Peck and Garth Griffin and Lane Harrison and Nick Chen and Remco Chang and Robert Jacob},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1181418},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {136--139},
 publisher = {Louisiana State University},
 title = {BRAAHMS: A Novel Adaptive Musical Interface Based on Users' Cognitive State},
 url = {http://www.nime.org/proceedings/2015/nime2015_243.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/243/0243-file1.mp4},
 year = {2015}
}
"
2006,nime2006_Lehrman.pdf,nime2006_Lehrman,"A ""Ballet M\'{e}canique"" for the 21{s}t Century: Performing George Antheil's Dadaist Masterpiece with Robots","Lehrman, Paul D. and Singer, Eric","Robotics, computer control, MIDI, player pianos, mechanical music, percussion, sound effects, Dadaism. ",,10.5281/zenodo.1176961,"@inproceedings{nime2006_Lehrman,
 address = {Paris, France},
 author = {Lehrman, Paul D. and Singer, Eric},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176961},
 issn = {2220-4806},
 keywords = {Robotics, computer control, MIDI, player pianos, mechanical music, percussion, sound effects, Dadaism. },
 pages = {300--303},
 title = {A ""Ballet M\'{e}canique"" for the 21{s}t Century: Performing George Antheil's Dadaist Masterpiece with Robots},
 url = {http://www.nime.org/proceedings/2006/nime2006_300.pdf},
 year = {2006}
}
"
2008,nime2008_Macrae.pdf,nime2008_Macrae,From Toy to Tutor : Note-Scroller is a Game to Teach Music,"Macrae, Robert and Dixon, Simon","Graphical Interface, Computer Game, MIDI Display ",,10.5281/zenodo.1179593,"@inproceedings{nime2008_Macrae,
 address = {Genoa, Italy},
 author = {Macrae, Robert and Dixon, Simon},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179593},
 issn = {2220-4806},
 keywords = {Graphical Interface, Computer Game, MIDI Display },
 pages = {364--365},
 title = {From Toy to Tutor : Note-Scroller is a Game to Teach Music},
 url = {http://www.nime.org/proceedings/2008/nime2008_364.pdf},
 year = {2008}
}
"
2018,nime2018_Dewey.pdf,nime2018_Dewey,MIDI Keyboard Defined DJ Performance System,Christopher Dewey and Jonathan P. Wakefield,,This paper explores the use of the ubiquitous MIDI keyboard to control a DJ performance system. The prototype system uses a two octave keyboard with each octave controlling one audio track. Each audio track has four two-bar loops which play in synchronisation switchable by its respective octave's first four black keys. The top key of the keyboard toggles between frequency filter mode and time slicer mode. In frequency filter mode the white keys provide seven bands of latched frequency filtering. In time slicer mode the white keys plus black B flat key provide latched on/off control of eight time slices of the loop. The system was informally evaluated by nine subjects. The frequency filter mode combined with loop switching worked well with the MIDI keyboard interface. All subjects agreed that all tools had creative performance potential that could be developed by further practice.,10.5281/zenodo.1302547,"@inproceedings{nime2018_Dewey,
 abstract = {This paper explores the use of the ubiquitous MIDI keyboard to control a DJ performance system. The prototype system uses a two octave keyboard with each octave controlling one audio track. Each audio track has four two-bar loops which play in synchronisation switchable by its respective octave's first four black keys. The top key of the keyboard toggles between frequency filter mode and time slicer mode. In frequency filter mode the white keys provide seven bands of latched frequency filtering. In time slicer mode the white keys plus black B flat key provide latched on/off control of eight time slices of the loop. The system was informally evaluated by nine subjects. The frequency filter mode combined with loop switching worked well with the MIDI keyboard interface. All subjects agreed that all tools had creative performance potential that could be developed by further practice.},
 address = {Blacksburg, Virginia, USA},
 author = {Christopher Dewey and Jonathan P. Wakefield},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1302547},
 editor = {Luke Dahl, Douglas Bowman, Thomas Martin},
 isbn = {978-1-949373-99-8},
 issn = {2220-4806},
 month = {June},
 pages = {200--201},
 publisher = {Virginia Tech},
 title = {{MIDI} Keyboard Defined DJ Performance System},
 url = {http://www.nime.org/proceedings/2018/nime2018_paper0043.pdf},
 year = {2018}
}
"
2005,nime2005_Cook.pdf,nime2005_Cook,Real-Time Performance Controllers for Synthesized Singing,"Cook, Perry R.","Singing synthesis, real-time singing synthesis control. ","A wide variety of singing synthesis models and methods exist,but there are remarkably few real-time controllers for thesemodels. This paper describes a variety of devices developedover the last few years for controlling singing synthesismodels implemented in the Synthesis Toolkit in C++ (STK),Max/MSP, and ChucK. All of the controllers share somecommon features, such as air-pressure sensing for breathingand/or loudness control, means to control pitch, and methodsfor selecting and blending phonemes, diphones, and words.However, the form factors, sensors, mappings, and algorithmsvary greatly between the different controllers.",10.5281/zenodo.1176846,"@inproceedings{nime2005_Cook,
 abstract = {A wide variety of singing synthesis models and methods exist,but there are remarkably few real-time controllers for thesemodels. This paper describes a variety of devices developedover the last few years for controlling singing synthesismodels implemented in the Synthesis Toolkit in C++ (STK),Max/MSP, and ChucK. All of the controllers share somecommon features, such as air-pressure sensing for breathingand/or loudness control, means to control pitch, and methodsfor selecting and blending phonemes, diphones, and words.However, the form factors, sensors, mappings, and algorithmsvary greatly between the different controllers.},
 address = {Vancouver, BC, Canada},
 author = {Cook, Perry R.},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176846},
 issn = {2220-4806},
 keywords = {Singing synthesis, real-time singing synthesis control. },
 pages = {236--237},
 title = {Real-Time Performance Controllers for Synthesized Singing},
 url = {http://www.nime.org/proceedings/2005/nime2005_236.pdf},
 year = {2005}
}
"
2022,nime2022_42.pdf,nime2022_42,Pitch Fingering Systems and the Search for Perfection,"West, Travis",,"In the search for better designs, one tool is to specify the design problem such that globally optimal solutions can be found. I present a design process using this approach, its strengths and limitations, and its results in the form of four pitch fingering systems that are ergonomic, simple, and symmetric. In hindsight, I emphasize the subjectivity of the design process, despite its reliance on objective quantitative assessment.",10.21428/92fbeb44.d6c9dcae,"@inproceedings{nime2022_42,
 abstract = {In the search for better designs, one tool is to specify the design problem such that globally optimal solutions can be found. I present a design process using this approach, its strengths and limitations, and its results in the form of four pitch fingering systems that are ergonomic, simple, and symmetric. In hindsight, I emphasize the subjectivity of the design process, despite its reliance on objective quantitative assessment.},
 address = {Auckland, New Zealand},
 articleno = {42},
 author = {West, Travis},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.d6c9dcae},
 editor = {Andrew McPherson and Emma Frid},
 issn = {2220-4806},
 month = {jun},
 presentation-video = {https://youtu.be/4QB3sNRmK1E},
 title = {Pitch Fingering Systems and the Search for Perfection},
 track = {Papers},
 url = {https://doi.org/10.21428%2F92fbeb44.d6c9dcae},
 year = {2022}
}
"
2015,nime2015_rdannenbergc.pdf,nime2015_rdannenbergc,Duet Interaction: Learning Musicianship for Automatic Accompaniment,Guangyu Xia and Roger Dannenberg,,"Computer music systems can interact with humans at different levels, including scores, phrases, notes, beats, and gestures. However, most current systems lack basic musicianship skills. As a consequence, the results of human-computer interaction are often far less musical than the interaction between human musicians. In this paper, we explore the possibility of learning some basic music performance skills from rehearsal data. In particular, we consider the piano duet scenario where two musicians expressively interact with each other. Our work extends previous automatic accompaniment systems. We have built an artificial pianist that can automatically improve its ability to sense and coordinate with a human pianist, learning from rehearsal experience. We describe different machine learning algorithms to learn musicianship for duet interaction, explore the properties of the learned models, such as dominant features, limits of validity, and minimal training size, and claim that a more human-like interaction is achieved.",10.5281/zenodo.1179198,"@inproceedings{nime2015_rdannenbergc,
 abstract = {Computer music systems can interact with humans at different levels, including scores, phrases, notes, beats, and gestures. However, most current systems lack basic musicianship skills. As a consequence, the results of human-computer interaction are often far less musical than the interaction between human musicians. In this paper, we explore the possibility of learning some basic music performance skills from rehearsal data. In particular, we consider the piano duet scenario where two musicians expressively interact with each other. Our work extends previous automatic accompaniment systems. We have built an artificial pianist that can automatically improve its ability to sense and coordinate with a human pianist, learning from rehearsal experience. We describe different machine learning algorithms to learn musicianship for duet interaction, explore the properties of the learned models, such as dominant features, limits of validity, and minimal training size, and claim that a more human-like interaction is achieved.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Guangyu Xia and Roger Dannenberg},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179198},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {259--264},
 publisher = {Louisiana State University},
 title = {Duet Interaction: Learning Musicianship for Automatic Accompaniment},
 url = {http://www.nime.org/proceedings/2015/nime2015_202.pdf},
 year = {2015}
}
"
2007,nime2007_Ojanen.pdf,nime2007_Ojanen,Design Principles and User Interfaces of Erkki Kurenniemi's Electronic Musical Instruments of the 1960's and 1970's,"Ojanen, Mikko and Suominen, Jari and Kallio, Titti and Lassfolk, Kai","Erkki Kurenniemi, Dimi, Synthesizer, Digital electronics, User interface design ",This paper presents a line of historic electronic musical instruments designed by Erkki Kurenniemi in the 1960's and1970's. Kurenniemi's instruments were influenced by digitallogic and an experimental attitude towards user interfacedesign. The paper presents an overview of Kurenniemi'sinstruments and a detailed description of selected devices.Emphasis is put on user interface issues such as unconventional interactive real-time control and programming methods.,10.5281/zenodo.1177211,"@inproceedings{nime2007_Ojanen,
 abstract = {This paper presents a line of historic electronic musical instruments designed by Erkki Kurenniemi in the 1960's and1970's. Kurenniemi's instruments were influenced by digitallogic and an experimental attitude towards user interfacedesign. The paper presents an overview of Kurenniemi'sinstruments and a detailed description of selected devices.Emphasis is put on user interface issues such as unconventional interactive real-time control and programming methods.},
 address = {New York City, NY, United States},
 author = {Ojanen, Mikko and Suominen, Jari and Kallio, Titti and Lassfolk, Kai},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177211},
 issn = {2220-4806},
 keywords = {Erkki Kurenniemi, Dimi, Synthesizer, Digital electronics, User interface design },
 pages = {88--93},
 title = {Design Principles and User Interfaces of Erkki Kurenniemi's Electronic Musical Instruments of the 1960's and 1970's},
 url = {http://www.nime.org/proceedings/2007/nime2007_088.pdf},
 year = {2007}
}
"
2015,nime2015_mblessing.pdf,nime2015_mblessing,Textural Crossfader,Matthew Blessing and Edgar Berdahl,,"A LapBox derivative, the Textural Crossfader is a keyboard-based embedded acoustic instrument, which sits comfortably across the performer's lap and radiates sound out of integrated stereo speakers. The performer controls the sound by manipulating the keys on a pair of mini-keyboard interfaces. A unique one-to-one mapping enables the performer to precisely crossfade among a set of looped audio wave files, creating a conveniently portable system for navigating through a complex timbre space. The axes of the timbre space can be reconfigured by replacing the wave files stored in the flash memory.",10.5281/zenodo.1179032,"@inproceedings{nime2015_mblessing,
 abstract = {A LapBox derivative, the Textural Crossfader is a keyboard-based embedded acoustic instrument, which sits comfortably across the performer's lap and radiates sound out of integrated stereo speakers. The performer controls the sound by manipulating the keys on a pair of mini-keyboard interfaces. A unique one-to-one mapping enables the performer to precisely crossfade among a set of looped audio wave files, creating a conveniently portable system for navigating through a complex timbre space. The axes of the timbre space can be reconfigured by replacing the wave files stored in the flash memory.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Matthew Blessing and Edgar Berdahl},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179032},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {180--181},
 publisher = {Louisiana State University},
 title = {Textural Crossfader},
 url = {http://www.nime.org/proceedings/2015/nime2015_337.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/337/0337-file1.mp4},
 urlsuppl2 = {http://www.nime.org/proceedings/2015/337/0337-file2.mov},
 year = {2015}
}
"
2010,nime2010_Maruyama.pdf,nime2010_Maruyama,UnitInstrument : Easy Configurable Musical Instruments,"Maruyama, Yutaro and Takegawa, Yoshinari and Terada, Tsutomu and Tsukamoto, Masahiko","Musical instruments, Script language","Musical instruments have a long history, and many types of musical instruments have been created to attain ideal sound production. At the same time, various types of electronic musical instruments have been developed. Since the main purpose of conventional electronic instruments is to duplicate the shape of acoustic instruments with no change in their hardware configuration, the diapason and the performance style of each instrument is inflexible. Therefore, the goal of our study is to construct the UnitInstrument that consists of various types of musical units. A unit is constructed by simulating functional elements of conventional musical instruments, such as output timing of sound and pitch decision. Each unit has connectors for connecting other units to create various types of musical instruments. Additionally, we propose a language for easily and flexibly describing the settings of units. We evaluated the effectiveness of our proposed system by using it in actual performances.",10.5281/zenodo.1177845,"@inproceedings{nime2010_Maruyama,
 abstract = {Musical instruments have a long history, and many types of musical instruments have been created to attain ideal sound production. At the same time, various types of electronic musical instruments have been developed. Since the main purpose of conventional electronic instruments is to duplicate the shape of acoustic instruments with no change in their hardware configuration, the diapason and the performance style of each instrument is inflexible. Therefore, the goal of our study is to construct the UnitInstrument that consists of various types of musical units. A unit is constructed by simulating functional elements of conventional musical instruments, such as output timing of sound and pitch decision. Each unit has connectors for connecting other units to create various types of musical instruments. Additionally, we propose a language for easily and flexibly describing the settings of units. We evaluated the effectiveness of our proposed system by using it in actual performances.},
 address = {Sydney, Australia},
 author = {Maruyama, Yutaro and Takegawa, Yoshinari and Terada, Tsutomu and Tsukamoto, Masahiko},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177845},
 issn = {2220-4806},
 keywords = {Musical instruments, Script language},
 pages = {7--12},
 title = {UnitInstrument : Easy Configurable Musical Instruments},
 url = {http://www.nime.org/proceedings/2010/nime2010_007.pdf},
 year = {2010}
}
"
2015,nime2015_kyamamoto.pdf,nime2015_kyamamoto,LiVo: Sing a Song with a Vowel Keyboard,Kazuhiko Yamamoto and Takeo Igarashi,,"We propose a novel user interface that enables control of a singing voice synthesizer at a live improvisational performance. The user first registers the lyrics of a song with the system before performance, and the system builds a probabilistic model that models the possible jumps within the lyrics. During performance, the user simultaneously inputs the lyrics of a song with the left hand using a vowel keyboard and the melodies with the right hand using a standard musical keyboard. Our system searches for a portion of the registered lyrics whose vowel sequence matches the current user input using the probabilistic model, and sends the matched lyrics to the singing voice synthesizer. The vowel input keys are mapped onto a standard musical keyboard, enabling experienced keyboard players to learn the system from a standard musical score. We examine the feasibility of the system through a series of evaluations and user studies. ",10.5281/zenodo.1181414,"@inproceedings{nime2015_kyamamoto,
 abstract = {We propose a novel user interface that enables control of a singing voice synthesizer at a live improvisational performance. The user first registers the lyrics of a song with the system before performance, and the system builds a probabilistic model that models the possible jumps within the lyrics. During performance, the user simultaneously inputs the lyrics of a song with the left hand using a vowel keyboard and the melodies with the right hand using a standard musical keyboard. Our system searches for a portion of the registered lyrics whose vowel sequence matches the current user input using the probabilistic model, and sends the matched lyrics to the singing voice synthesizer. The vowel input keys are mapped onto a standard musical keyboard, enabling experienced keyboard players to learn the system from a standard musical score. We examine the feasibility of the system through a series of evaluations and user studies. },
 address = {Baton Rouge, Louisiana, USA},
 author = {Kazuhiko Yamamoto and Takeo Igarashi},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1181414},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {205--208},
 publisher = {Louisiana State University},
 title = {LiVo: Sing a Song with a Vowel Keyboard},
 url = {http://www.nime.org/proceedings/2015/nime2015_120.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/120/0120-file1.mp4},
 year = {2015}
}
"
2020,nime2020_118.pdf,nime2020_118,The KeyWI: An Expressive and Accessible Electronic Wind Instrument,"Caren, Matthew and Michon, Romain and Wright, Matthew",,"This paper presents the KeyWI, an electronic wind instrument design based on the melodica that both improves upon limitations in current systems and is general and powerful enough to support a variety of applications. Four opportunities for growth are identified in current electronic wind instrument systems, which then are used as focuses in the development and evaluation of the instrument. The instrument features a breath pressure sensor with a large dynamic range, a keyboard that allows for polyphonic pitch selection, and a completely integrated construction. Sound synthesis is performed with Faust code compiled to the Bela Mini, which offers low-latency audio and a simple yet powerful development workflow. In order to be as accessible and versatile as possible, the hardware and software is entirely open-source, and fabrication requires only common maker tools.",10.5281/zenodo.4813218,"@inproceedings{nime2020_118,
 abstract = {This paper presents the KeyWI, an electronic wind instrument design based on the melodica that both improves upon limitations in current systems and is general and powerful enough to support a variety of applications. Four opportunities for growth are identified in current electronic wind instrument systems, which then are used as focuses in the development and evaluation of the instrument. The instrument features a breath pressure sensor with a large dynamic range, a keyboard that allows for polyphonic pitch selection, and a completely integrated construction. Sound synthesis is performed with Faust code compiled to the Bela Mini, which offers low-latency audio and a simple yet powerful development workflow. In order to be as accessible and versatile as possible, the hardware and software is entirely open-source, and fabrication requires only common maker tools.},
 address = {Birmingham, UK},
 author = {Caren, Matthew and Michon, Romain and Wright, Matthew},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813218},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {605--608},
 publisher = {Birmingham City University},
 title = {The KeyWI: An Expressive and Accessible Electronic Wind Instrument},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper118.pdf},
 year = {2020}
}
"
2023,nime2023_23.pdf,nime2023_23,An embedded wavetable synthesizer for the electronic bandoneon with parameter mappings based on acoustical measurements,Juan M Ramos and Pablo Riera and Esteban Calcagno,,"The bandoneon is a free-reed instrument of great cultural value that is currently struggling to ensure its conservation as heritage, mainly due to its complex constitution, the lack of sufficient manufacturers to satisfy the demand, and the high sales prices that this entails. Our research group has been working on the task of revitalizing the instrument from a modern perspective, carrying out musical and scientific research for the creation of an accessible electronic bandoneon. As the next step in this endeavor, we present a method for synthesizing the bandoneon sound using multiple wavetable interpolation, and parameter mappings based on acoustic measurements. We discuss a method for capturing and selecting the wavetables, the implementation on an embedded platform (Bela Mini), and the trade-offs between realistic sound and computational efficiency. The synthesizer runs in real-time and has a polyphony of approximately 12 voices, allowing for an autonomously sounding electronic instrument.",10.5281/zenodo.11189144,"@inproceedings{nime2023_23,
 abstract = {The bandoneon is a free-reed instrument of great cultural value that is currently struggling to ensure its conservation as heritage, mainly due to its complex constitution, the lack of sufficient manufacturers to satisfy the demand, and the high sales prices that this entails. Our research group has been working on the task of revitalizing the instrument from a modern perspective, carrying out musical and scientific research for the creation of an accessible electronic bandoneon. As the next step in this endeavor, we present a method for synthesizing the bandoneon sound using multiple wavetable interpolation, and parameter mappings based on acoustic measurements. We discuss a method for capturing and selecting the wavetables, the implementation on an embedded platform (Bela Mini), and the trade-offs between realistic sound and computational efficiency. The synthesizer runs in real-time and has a polyphony of approximately 12 voices, allowing for an autonomously sounding electronic instrument.},
 address = {Mexico City, Mexico},
 articleno = {23},
 author = {Juan M Ramos and Pablo Riera and Esteban Calcagno},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.11189144},
 editor = {Miguel Ortiz and Adnan Marquez-Borbon},
 issn = {2220-4806},
 month = {May},
 numpages = {7},
 pages = {167--173},
 title = {An embedded wavetable synthesizer for the electronic bandoneon with parameter mappings based on acoustical measurements},
 track = {Papers},
 url = {http://nime.org/proceedings/2023/nime2023_23.pdf},
 year = {2023}
}
"
2010,nime2010_Essl_a.pdf,nime2010_Essl_a,Designing Mobile Musical Instruments and Environments with urMus,"Essl, Georg and Müller, Alexander","Mobile music making, meta-environment, design, mapping, user interface",We discuss how the environment urMus was designed to allow creation of mobile musical instruments on multi-touch smartphones. The design of a mobile musical instrument consists of connecting sensory capabilities to output modalities through various means of processing. We describe how the default mapping interface was designed which allows to set up such a pipeline and how visual and interactive multi-touch UIs for musical instruments can be designed within the system. ,10.5281/zenodo.1177759,"@inproceedings{nime2010_Essl_a,
 abstract = {We discuss how the environment urMus was designed to allow creation of mobile musical instruments on multi-touch smartphones. The design of a mobile musical instrument consists of connecting sensory capabilities to output modalities through various means of processing. We describe how the default mapping interface was designed which allows to set up such a pipeline and how visual and interactive multi-touch UIs for musical instruments can be designed within the system. },
 address = {Sydney, Australia},
 author = {Essl, Georg and M\''{u}ller, Alexander},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177759},
 issn = {2220-4806},
 keywords = {Mobile music making, meta-environment, design, mapping, user interface},
 pages = {76--81},
 title = {Designing Mobile Musical Instruments and Environments with urMus},
 url = {http://www.nime.org/proceedings/2010/nime2010_076.pdf},
 year = {2010}
}
"
2013,nime2013_BenAsher.pdf,nime2013_BenAsher,Toward an Emotionally Intelligent Piano: Real-Time Emotion Detection and Performer Feedback via Kinesthetic Sensing in Piano Performance,Matan Ben-Asher and Colby Leider,"Motion Sensors, IMUs, Expressive Piano Performance, Machine Learning, Computer Music, Music and Emotion","A system is presented for detecting common gestures, musical intentions andemotions of pianists in real-time using only kinesthetic data retrieved bywireless motion sensors. The algorithm can detect common Western musicalstructures such as chords, arpeggios, scales, and trills as well as musicallyintended emotions: cheerful, mournful, vigorous, dreamy, lyrical, and humorouscompletely and solely based on low-sample-rate motion sensor data. Thealgorithm can be trained per performer in real-time or can work based onprevious training sets. The system maps the emotions to a color set andpresents them as a flowing emotional spectrum on the background of a pianoroll. This acts as a feedback mechanism for emotional expression as well as aninteractive display of the music. The system was trained and tested on a numberof pianists and it classified structures and emotions with promising results ofup to 92% accuracy.",10.5281/zenodo.1178474,"@inproceedings{nime2013_BenAsher,
 abstract = {A system is presented for detecting common gestures, musical intentions andemotions of pianists in real-time using only kinesthetic data retrieved bywireless motion sensors. The algorithm can detect common Western musicalstructures such as chords, arpeggios, scales, and trills as well as musicallyintended emotions: cheerful, mournful, vigorous, dreamy, lyrical, and humorouscompletely and solely based on low-sample-rate motion sensor data. Thealgorithm can be trained per performer in real-time or can work based onprevious training sets. The system maps the emotions to a color set andpresents them as a flowing emotional spectrum on the background of a pianoroll. This acts as a feedback mechanism for emotional expression as well as aninteractive display of the music. The system was trained and tested on a numberof pianists and it classified structures and emotions with promising results ofup to 92\% accuracy.},
 address = {Daejeon, Republic of Korea},
 author = {Matan Ben-Asher and Colby Leider},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178474},
 issn = {2220-4806},
 keywords = {Motion Sensors, IMUs, Expressive Piano Performance, Machine Learning, Computer Music, Music and Emotion},
 month = {May},
 pages = {21--24},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Toward an Emotionally Intelligent Piano: Real-Time Emotion Detection and Performer Feedback via Kinesthetic Sensing in Piano Performance},
 url = {http://www.nime.org/proceedings/2013/nime2013_48.pdf},
 year = {2013}
}
"
2017,nime2017_mkallionpaa.pdf,nime2017_mkallionpaa,Composing and Realising a Game-like Performance for Disklavier and Electronics,Maria Kallionpää and Chris Greenhalgh and Adrian Hazzard and David M. Weigl and Kevin R. Page and Steve Benford,,"&#8220;Climb!&#8221; is a musical composition that combines the ideas of a classical virtuoso piece and a computer game. We present a case study of the composition process and realization of &#8220;Climb!&#8221;, written for Disklavier and a digital interactive engine, which was co-developed together with the musical score. Specifically, the engine combines a system for recognising and responding to musical trigger phrases along with a dynamic digital score renderer. This tool chain allows for the composer's original scoring to include notational elements such as trigger phrases to be automatically extracted to auto-configure the engine for live performance. We reflect holistically on the development process to date and highlight the emerging challenges and opportunities. For example, this includes the potential for further developing the workflow around the scoring process and the ways in which support for musical triggers has shaped the compositional approach.",10.5281/zenodo.1176318,"@inproceedings{nime2017_mkallionpaa,
 abstract = {&#8220;Climb!&#8221; is a musical composition that combines the ideas of a classical virtuoso piece and a computer game. We present a case study of the composition process and realization of &#8220;Climb!&#8221;, written for Disklavier and a digital interactive engine, which was co-developed together with the musical score. Specifically, the engine combines a system for recognising and responding to musical trigger phrases along with a dynamic digital score renderer. This tool chain allows for the composer's original scoring to include notational elements such as trigger phrases to be automatically extracted to auto-configure the engine for live performance. We reflect holistically on the development process to date and highlight the emerging challenges and opportunities. For example, this includes the potential for further developing the workflow around the scoring process and the ways in which support for musical triggers has shaped the compositional approach.},
 address = {Copenhagen, Denmark},
 author = {Maria Kallionpää and Chris Greenhalgh and Adrian Hazzard and David M. Weigl and Kevin R. Page and Steve Benford},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176318},
 issn = {2220-4806},
 pages = {464--469},
 publisher = {Aalborg University Copenhagen},
 title = {Composing and Realising a Game-like Performance for Disklavier and Electronics},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0088.pdf},
 year = {2017}
}
"
2009,nime2009_Havryliv.pdf,nime2009_Havryliv,Haptic Carillon -- Analysis & Design of the Carillon Mechanism,"Havryliv, Mark and Naghdy, Fazel and Schiemer, Greg and Hurd, Timothy","Haptics, force-feedback, mechanical analysis. ","The carillon is one of the few instruments that elicit sophisticated haptic interaction from amateur and professional players alike. Like the piano keyboard, the velocity of a player's impact on each carillon key, or baton, affects the quality of the resultant tone; unlike the piano, each carillon baton returns a different forcefeedback. Force-feedback varies widely from one baton to the next across the entire range of the instrument and with further idiosyncratic variation from one instrument to another. This makes the carillon an ideal candidate for haptic simulation. The application of synthesized forcefeedback based on an analysis of forces operating in a typical carillon mechanism offers a blueprint for the design of an electronic practice clavier and with it the solution to a problem that has vexed carillonists for centuries, namely the inability to rehearse repertoire in private. This paper will focus on design and implementation of a haptic carillon clavier derived from an analysis of the Australian National Carillon in Canberra. ",10.5281/zenodo.1177569,"@inproceedings{nime2009_Havryliv,
 abstract = {The carillon is one of the few instruments that elicit sophisticated haptic interaction from amateur and professional players alike. Like the piano keyboard, the velocity of a player's impact on each carillon key, or baton, affects the quality of the resultant tone; unlike the piano, each carillon baton returns a different forcefeedback. Force-feedback varies widely from one baton to the next across the entire range of the instrument and with further idiosyncratic variation from one instrument to another. This makes the carillon an ideal candidate for haptic simulation. The application of synthesized forcefeedback based on an analysis of forces operating in a typical carillon mechanism offers a blueprint for the design of an electronic practice clavier and with it the solution to a problem that has vexed carillonists for centuries, namely the inability to rehearse repertoire in private. This paper will focus on design and implementation of a haptic carillon clavier derived from an analysis of the Australian National Carillon in Canberra. },
 address = {Pittsburgh, PA, United States},
 author = {Havryliv, Mark and Naghdy, Fazel and Schiemer, Greg and Hurd, Timothy},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177569},
 issn = {2220-4806},
 keywords = {Haptics, force-feedback, mechanical analysis. },
 pages = {187--192},
 title = {Haptic Carillon -- Analysis \& Design of the Carillon Mechanism},
 url = {http://www.nime.org/proceedings/2009/nime2009_187.pdf},
 year = {2009}
}
"
2012,nime2012_Makelberge.pdf,nime2012_Makelberge,Perfect Take: Experience design and new interfaces for musical expression,Nicolas Makelberge and Álvaro Barbosa and André Perrotta and Luís Sarmento Ferreira,"NIME, Networked Music, MIDI, Disklavier, music collaboration, creativity","''Perfect Take'' is a public installation out of networked acoustic instruments that let composers from all over the world exhibit their MIDI-works by means of the Internet. The primary aim of this system is to offer composers a way to have works exhibited and recorded in venues and with technologies not accessible to him/her under normal circumstances. The Secondary aim of this research is to highlight experience design as a complement to interaction design, and a shift of focus from functionality of a specific gestural controller, towards the environments, events and processes that they are part of.",10.5281/zenodo.1178339,"@inproceedings{nime2012_Makelberge,
 abstract = {''Perfect Take'' is a public installation out of networked acoustic instruments that let composers from all over the world exhibit their MIDI-works by means of the Internet. The primary aim of this system is to offer composers a way to have works exhibited and recorded in venues and with technologies not accessible to him/her under normal circumstances. The Secondary aim of this research is to highlight experience design as a complement to interaction design, and a shift of focus from functionality of a specific gestural controller, towards the environments, events and processes that they are part of.},
 address = {Ann Arbor, Michigan},
 author = {Nicolas Makelberge and {\'A}lvaro Barbosa and Andr{\'e} Perrotta and Lu{\'i}s Sarmento Ferreira},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178339},
 issn = {2220-4806},
 keywords = {NIME, Networked Music, MIDI, Disklavier, music collaboration, creativity},
 publisher = {University of Michigan},
 title = {Perfect Take: Experience design and new interfaces for musical expression},
 url = {http://www.nime.org/proceedings/2012/nime2012_208.pdf},
 year = {2012}
}
"
2020,nime2020_125.pdf,nime2020_125,BachDuet: A Deep Learning System for Human-Machine Counterpoint Improvisation,"Benetatos, Christodoulos and VanderStel, Joseph and Duan, Zhiyao",,"During theBaroque period, improvisation was a key element of music performance and education. Great musicians, such as J.S. Bach, were better known as improvisers than composers. Today,  however,  there  is  a  lack  of  improvisation culture in classical music performance and education; classical musicians either are not trained to improvise, or cannot find other people to improvise with.  Motivated by this observation,  we  develop BachDuet,  a  system  that  enables real-time counterpoint improvisation between a human anda machine.  This system uses a recurrent neural network toprocess the human musician’s monophonic performance ona MIDI keyboard and generates the machine’s monophonic performance in real time. We  develop a GUI to visualize the generated music content and to facilitate this interaction. We  conduct  user  studies  with  13  musically  trained users  and  show  the  feasibility  of  two-party  duet  counterpoint improvisation and the effectiveness of BachDuet for this purpose.  We also conduct listening tests with 48 participants and show that they cannot tell the difference between duets generated by human-machine improvisation using BachDuet and those generated by human-human improvisation.  Objective evaluation is also conducted to assess the degree to which these improvisations adhere to common rules of counterpoint, showing promising results.",10.5281/zenodo.4813234,"@inproceedings{nime2020_125,
 abstract = {During theBaroque period, improvisation was a key element of music performance and education. Great musicians, such as J.S. Bach, were better known as improvisers than composers. Today,  however,  there  is  a  lack  of  improvisation culture in classical music performance and education; classical musicians either are not trained to improvise, or cannot find other people to improvise with.  Motivated by this observation,  we  develop BachDuet,  a  system  that  enables real-time counterpoint improvisation between a human anda machine.  This system uses a recurrent neural network toprocess the human musician’s monophonic performance ona MIDI keyboard and generates the machine’s monophonic performance in real time. We  develop a GUI to visualize the generated music content and to facilitate this interaction. We  conduct  user  studies  with  13  musically  trained users  and  show  the  feasibility  of  two-party  duet  counterpoint improvisation and the effectiveness of BachDuet for this purpose.  We also conduct listening tests with 48 participants and show that they cannot tell the difference between duets generated by human-machine improvisation using BachDuet and those generated by human-human improvisation.  Objective evaluation is also conducted to assess the degree to which these improvisations adhere to common rules of counterpoint, showing promising results.},
 address = {Birmingham, UK},
 author = {Benetatos, Christodoulos and VanderStel, Joseph and Duan, Zhiyao},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813234},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {635--640},
 presentation-video = {https://youtu.be/wFGW0QzuPPk},
 publisher = {Birmingham City University},
 title = {BachDuet: A Deep Learning System for Human-Machine Counterpoint Improvisation},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper125.pdf},
 year = {2020}
}
"
2025,nime2025_57.pdf,nime2025_57,Towards the Continuous Harmonium: Replicating the Continuous Keyboard,Travis West and Ninad Puranik and Gary Scavone and Marcelo Wanderley,,"In our effort to develop an augmented harmonium to enable the performance of continuous pitch ornamentation while preserving typical harmonium gestures, we have replicated the continuous keyboard presented by McPherson et al. in prior work. We present 1) our adaptations to the design of the sensing system, 2) our preliminary novel mapping design, and 3) a report on our replication process.",10.5281/zenodo.15699652,"@inproceedings{nime2025_57,
 abstract = {In our effort to develop an augmented harmonium to enable the performance of continuous pitch ornamentation while preserving typical harmonium gestures, we have replicated the continuous keyboard presented by McPherson et al. in prior work. We present 1) our adaptations to the design of the sensing system, 2) our preliminary novel mapping design, and 3) a report on our replication process.},
 address = {Canberra, Australia},
 articleno = {57},
 author = {Travis West and Ninad Puranik and Gary Scavone and Marcelo Wanderley},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15699652},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {4},
 pages = {406--409},
 presentation-video = {https://youtu.be/iFCblP3tDxk},
 title = {Towards the Continuous Harmonium: Replicating the Continuous Keyboard},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_57.pdf},
 urlsuppl1 = {http://nime.org/proceedings/2025/nime2025_57_file01.mp4},
 year = {2025}
}
"
2012,nime2012_Kapur.pdf,nime2012_Kapur,"Kritaanjali: A Robotic Harmonium for Performance, Pedogogy and Research",Ajay Kapur and Jim Murphy and Dale Carnegie,"Musical Robotics, pedagogy, North Indian Classical Music, augmented instruments","In this paper, we introduce Kritaanjli, a robotic harmo-nium. Details concerning the design, construction, and use of Kritaanjli are discussed. After an examination of related work, quantitative research concerning the hardware chosen in the construction of the instrument is shown, as is a thor-ough exposition of the design process and use of CAD/CAM techniques in the design lifecycle of the instrument. Addi-tionally, avenues for future work and compositional prac-tices are focused upon, with particular emphasis placed on human/robot interaction, pedagogical techniques afforded by the robotic instrument, and compositional avenues made accessible through the use of Kritaanjli.",10.5281/zenodo.1178299,"@inproceedings{nime2012_Kapur,
 abstract = {In this paper, we introduce Kritaanjli, a robotic harmo-nium. Details concerning the design, construction, and use of Kritaanjli are discussed. After an examination of related work, quantitative research concerning the hardware chosen in the construction of the instrument is shown, as is a thor-ough exposition of the design process and use of CAD/CAM techniques in the design lifecycle of the instrument. Addi-tionally, avenues for future work and compositional prac-tices are focused upon, with particular emphasis placed on human/robot interaction, pedagogical techniques afforded by the robotic instrument, and compositional avenues made accessible through the use of Kritaanjli.},
 address = {Ann Arbor, Michigan},
 author = {Ajay Kapur and Jim Murphy and Dale Carnegie},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178299},
 issn = {2220-4806},
 keywords = {Musical Robotics, pedagogy, North Indian Classical Music, augmented instruments},
 publisher = {University of Michigan},
 title = {Kritaanjali: A Robotic Harmonium for Performance, Pedogogy and Research},
 url = {http://www.nime.org/proceedings/2012/nime2012_99.pdf},
 year = {2012}
}
"
2014,nime2014_slui.pdf,nime2014_slui,A Real Time Common Chord Progression Guide on the Smartphone for Jamming Pop Song on the Music Keyboard,Simon Lui,,"Pop music jamming on the keyboard requires massive music knowledge. Musician needs to understand and memorize the behavior of each chord in different keys. However, most simple pop music follows a common chord progression pattern. This pattern applies to most simple pop music on all the 12 keys. We designed an app that can reduce the difficulty of music jamming on the keyboard by using this pattern. The app displays the current chord in the Roman numeral and suggests the expected next chord in an easy to understand way on a smartphone. This work investigates into the human computer interaction perspective of music performance. We use a smartphone app as a bridge, which assists musician to react faster in music jamming by transforming the complex music knowledge into a simple, unified and easy to understand format. Experiment result shows that this app can help the non-keyboardist musician to learn pop music jamming. It also shows that the app is useful to assist keyboardist in making key transpose and playing music in the key with many sharps and flats. We will use the same interface design to guide user on playing other chord progressions such as the jazz chord progression.",10.5281/zenodo.1178855,"@inproceedings{nime2014_slui,
 abstract = {Pop music jamming on the keyboard requires massive music knowledge. Musician needs to understand and memorize the behavior of each chord in different keys. However, most simple pop music follows a common chord progression pattern. This pattern applies to most simple pop music on all the 12 keys. We designed an app that can reduce the difficulty of music jamming on the keyboard by using this pattern. The app displays the current chord in the Roman numeral and suggests the expected next chord in an easy to understand way on a smartphone. This work investigates into the human computer interaction perspective of music performance. We use a smartphone app as a bridge, which assists musician to react faster in music jamming by transforming the complex music knowledge into a simple, unified and easy to understand format. Experiment result shows that this app can help the non-keyboardist musician to learn pop music jamming. It also shows that the app is useful to assist keyboardist in making key transpose and playing music in the key with many sharps and flats. We will use the same interface design to guide user on playing other chord progressions such as the jazz chord progression.},
 address = {London, United Kingdom},
 author = {Simon Lui},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178855},
 issn = {2220-4806},
 month = {June},
 pages = {98--101},
 publisher = {Goldsmiths, University of London},
 title = {A Real Time Common Chord Progression Guide on the Smartphone for Jamming Pop Song on the Music Keyboard},
 url = {http://www.nime.org/proceedings/2014/nime2014_275.pdf},
 year = {2014}
}
"
2019,nime2019_deSouzaNunes.pdf,nime2019_deSouzaNunes,SIBILIM: A low-cost customizable wireless musical interface,Helena de Souza Nunes and Federico Visi and Lydia Helena Wohl Coelho and Rodrigo Schramm,,"This paper presents the SIBILIM, a low-cost musical interface composed of a resonance box made of cardboard containing customised push buttons that interact with a smartphone through its video camera. Each button can be mapped to a set of MIDI notes or control parameters. The sound is generated through synthesis or sample playback and can be amplified with the help of a transducer, which excites the resonance box. An essential contribution of this interface is the possibility of reconfiguration of the buttons layout without the need to hard rewire the system since it uses only the smartphone built-in camera. This features allow for quick instrument customisation for different use cases,
such as low cost projects for schools or instrument building  workshops. Our case study used the Sibilim for music education, where it was designed to develop the conscious of music perception and to stimulate creativity through exercises of short tonal musical compositions. We conducted a study with a group of twelve participants in an experimental workshop to verify its validity.",10.5281/zenodo.3672850,"@inproceedings{nime2019_deSouzaNunes,
 abstract = {This paper presents the SIBILIM, a low-cost musical interface composed of a resonance box made of cardboard containing customised push buttons that interact with a smartphone through its video camera. Each button can be mapped to a set of MIDI notes or control parameters. The sound is generated through synthesis or sample playback and can be amplified with the help of a transducer, which excites the resonance box. An essential contribution of this interface is the possibility of reconfiguration of the buttons layout without the need to hard rewire the system since it uses only the smartphone built-in camera. This features allow for quick instrument customisation for different use cases,
such as low cost projects for schools or instrument building  workshops. Our case study used the Sibilim for music education, where it was designed to develop the conscious of music perception and to stimulate creativity through exercises of short tonal musical compositions. We conducted a study with a group of twelve participants in an experimental workshop to verify its validity.},
 address = {Porto Alegre, Brazil},
 author = {Helena de Souza Nunes and Federico Visi and Lydia Helena Wohl Coelho and Rodrigo Schramm},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672850},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {15--20},
 publisher = {UFRGS},
 title = {SIBILIM: A low-cost customizable wireless musical interface},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper004.pdf},
 year = {2019}
}
"
2015,nime2015_ndalessandro.pdf,nime2015_ndalessandro,AirPiano: A Multi-Touch Keyboard with Hovering Control,Nicolas d'Alessandro and Joëlle Tilmanne and Ambroise Moreau and Antonin Puleo,,"In this paper, we describe the prototyping of two musical interfaces that use the LeapMotion camera in conjunction with two different touch surfaces: a Wacom tablet and a transparent PVC sheet. In the Wacom use case, the camera is between the hand and the surface. In the PVC use case, the camera is under the transparent sheet and tracks the hand through it. The aim of this research is to explore hovering motion surrounding the touch interaction on the surface and include properties of such motion in the musical interaction. We present our unifying software, called AirPiano, that discretises the 3D space into 'keys' and proposes several mapping strategies with the available dimensions. These control dimensions are mapped onto a modified HandSketch sound engine that achieves multitimbral pitch-synchronous point cloud granulation.",10.5281/zenodo.1181434,"@inproceedings{nime2015_ndalessandro,
 abstract = {In this paper, we describe the prototyping of two musical interfaces that use the LeapMotion camera in conjunction with two different touch surfaces: a Wacom tablet and a transparent PVC sheet. In the Wacom use case, the camera is between the hand and the surface. In the PVC use case, the camera is under the transparent sheet and tracks the hand through it. The aim of this research is to explore hovering motion surrounding the touch interaction on the surface and include properties of such motion in the musical interaction. We present our unifying software, called AirPiano, that discretises the 3D space into 'keys' and proposes several mapping strategies with the available dimensions. These control dimensions are mapped onto a modified HandSketch sound engine that achieves multitimbral pitch-synchronous point cloud granulation.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Nicolas d'Alessandro and Jo\''elle Tilmanne and Ambroise Moreau and Antonin Puleo},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1181434},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {255--258},
 publisher = {Louisiana State University},
 title = {AirPiano: A Multi-Touch Keyboard with Hovering Control},
 url = {http://www.nime.org/proceedings/2015/nime2015_261.pdf},
 year = {2015}
}
"
2025,nime2025_78.pdf,nime2025_78,AR Matchmaking: The Compatibility of Musical Instruments with an AR Interface,Hyunkyung Shin and Henrik von Coler,,"Augmented Reality (AR) interfaces offer new possibilities for musical expression by extending the capabilities of acoustic, electronic, and electroacoustic instruments. This study investigates the usability of the ARCube, an AR-based spatial audio controller, with twelve distinct musical instruments played by experienced musicians. We identify usability challenges specific to certain instruments, particularly for two-handed playing, as well as issues related to gesture recognition and cube stability. Our analysis shows that interaction patterns, such as cube placement, sound effect usage, and gesture strategies, vary significantly between instruments. These differences are driven by the physical form of the instruments, the required playing techniques, and user expectations for control and responsiveness. Based on these insights, we suggest directions for developing adaptable AR interfaces that better accommodate diverse instruments and support broader integration of AR technologies into musical practice. ",10.5281/zenodo.15698952,"@inproceedings{nime2025_78,
 abstract = {Augmented Reality (AR) interfaces offer new possibilities for musical expression by extending the capabilities of acoustic, electronic, and electroacoustic instruments. This study investigates the usability of the ARCube, an AR-based spatial audio controller, with twelve distinct musical instruments played by experienced musicians. We identify usability challenges specific to certain instruments, particularly for two-handed playing, as well as issues related to gesture recognition and cube stability. Our analysis shows that interaction patterns, such as cube placement, sound effect usage, and gesture strategies, vary significantly between instruments. These differences are driven by the physical form of the instruments, the required playing techniques, and user expectations for control and responsiveness. Based on these insights, we suggest directions for developing adaptable AR interfaces that better accommodate diverse instruments and support broader integration of AR technologies into musical practice. },
 address = {Canberra, Australia},
 articleno = {78},
 author = {Hyunkyung Shin and Henrik von Coler},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698952},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {8},
 pages = {537--544},
 title = {AR Matchmaking: The Compatibility of Musical Instruments with an AR Interface},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_78.pdf},
 year = {2025}
}
"
2019,nime2019_Dahlstedt.pdf,nime2019_Dahlstedt,Taming and Tickling the Beast --- Multi-Touch Keyboard as Interface for a Physically Modelled Interconnected Resonating Super-Harp,Palle Dahlstedt,,"Libration Perturbed is a performance and an improvisation instrument, originally composed and designed for a multi-speaker dome. The performer controls a bank of 64 virtual inter-connected resonating strings, with individual and direct control of tuning and resonance characteristics through a multitouch-enhanced klavier interface (TouchKeys). It is a hybrid acoustic-electronic instrument, as all string vibrations originate from physical vibrations in the klavier and its casing, captured through contact microphones. In addition, there are gestural strings, called ropes, excited by performed musical gestures. All strings and ropes are connected, and inter-resonate together as a ”super-harp”, internally and through the performance space. With strong resonance, strings may go into chaotic motion or emergent quasi-periodic patterns, but custom adaptive leveling mechanisms keep loudness under the musician's control at all times. The hybrid digital/acoustic approach and the enhanced keyboard provide for an expressive and very physical interaction, and a strong multi-channel immersive experience. The paper describes the aesthetic choices behind the design of the system, as well as the technical implementation, and – primarily – the interaction design, as it emerges from mapping, sound design, physical modeling and integration of the acoustic, the gestural, and the virtual. The work is evaluated based on the experiences from a series of performances.",10.5281/zenodo.3672862,"@inproceedings{nime2019_Dahlstedt,
 abstract = {Libration Perturbed is a performance and an improvisation instrument, originally composed and designed for a multi-speaker dome. The performer controls a bank of 64 virtual inter-connected resonating strings, with individual and direct control of tuning and resonance characteristics through a multitouch-enhanced klavier interface (TouchKeys). It is a hybrid acoustic-electronic instrument, as all string vibrations originate from physical vibrations in the klavier and its casing, captured through contact microphones. In addition, there are gestural strings, called ropes, excited by performed musical gestures. All strings and ropes are connected, and inter-resonate together as a ”super-harp”, internally and through the performance space. With strong resonance, strings may go into chaotic motion or emergent quasi-periodic patterns, but custom adaptive leveling mechanisms keep loudness under the musician's control at all times. The hybrid digital/acoustic approach and the enhanced keyboard provide for an expressive and very physical interaction, and a strong multi-channel immersive experience. The paper describes the aesthetic choices behind the design of the system, as well as the technical implementation, and – primarily – the interaction design, as it emerges from mapping, sound design, physical modeling and integration of the acoustic, the gestural, and the virtual. The work is evaluated based on the experiences from a series of performances.},
 address = {Porto Alegre, Brazil},
 author = {Palle Dahlstedt},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672862},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {47--52},
 publisher = {UFRGS},
 title = {Taming and Tickling the Beast --- Multi-Touch Keyboard as Interface for a Physically Modelled Interconnected Resonating Super-Harp},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper010.pdf},
 year = {2019}
}
"
2013,nime2013_Walther.pdf,nime2013_Walther,Rocking the Keys with a Multi-Touch Interface,Thomas Walther and Damir Ismailović and Bernd Brügge,"multi-touch, mobile, keyboard, interface","Although multi-touch user interfaces have become a widespread form of humancomputer interaction in many technical areas, they haven't found their way intolive performances of musicians and keyboarders yet. In this paper, we present anovel multi-touch interface method aimed at professional keyboard players. Themethod, which is inspired by computer trackpads, allows controlling up to tencontinuous parameters of a keyboard with one hand, without requiring the userto look at the touch area --- a significant improvement over traditional keyboardinput controls. We discuss optimizations needed to make our interface reliable,and show in an evaluation with four keyboarders of different skill level thatthis method is both intuitive and powerful, and allows users to more quicklyalter the sound of their keyboard than they could with current input solutions.",10.5281/zenodo.1178684,"@inproceedings{nime2013_Walther,
 abstract = {Although multi-touch user interfaces have become a widespread form of humancomputer interaction in many technical areas, they haven't found their way intolive performances of musicians and keyboarders yet. In this paper, we present anovel multi-touch interface method aimed at professional keyboard players. Themethod, which is inspired by computer trackpads, allows controlling up to tencontinuous parameters of a keyboard with one hand, without requiring the userto look at the touch area --- a significant improvement over traditional keyboardinput controls. We discuss optimizations needed to make our interface reliable,and show in an evaluation with four keyboarders of different skill level thatthis method is both intuitive and powerful, and allows users to more quicklyalter the sound of their keyboard than they could with current input solutions.},
 address = {Daejeon, Republic of Korea},
 author = {Thomas Walther and Damir Ismailovi{\'c} and Bernd Br{\''u}gge},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178684},
 issn = {2220-4806},
 keywords = {multi-touch, mobile, keyboard, interface},
 month = {May},
 pages = {98--101},
 publisher = {Graduate School of Culture Technology, KAIST},
 title = {Rocking the Keys with a Multi-Touch Interface},
 url = {http://www.nime.org/proceedings/2013/nime2013_275.pdf},
 year = {2013}
}
"
2007,nime2007_Francois.pdf,nime2007_Francois,Visual Feedback in Performer-Machine Interaction for Musical Improvisation,"François, Alexandre R. and Chew, Elaine and Thurmond, Dennis","Performer-machine interaction, visualization design, machine improvisation ","This paper describes the design of Mimi, a multi-modal interactive musical improvisation system that explores the potential and powerful impact of visual feedback in performermachine interaction. Mimi is a performer-centric tool designed for use in performance and teaching. Its key andnovel component is its visual interface, designed to providethe performer with instantaneous and continuous information on the state of the system. For human improvisation,in which context and planning are paramount, the relevantstate of the system extends to the near future and recentpast. Mimi's visual interface allows for a peculiar blendof raw reflex typically associated with improvisation, andpreparation and timing more closely affiliated with scorebased reading. Mimi is not only an effective improvisationpartner, it has also proven itself to be an invaluable platformthrough which to interrogate the mental models necessaryfor successful improvisation.",10.5281/zenodo.1177091,"@inproceedings{nime2007_Francois,
 abstract = {This paper describes the design of Mimi, a multi-modal interactive musical improvisation system that explores the potential and powerful impact of visual feedback in performermachine interaction. Mimi is a performer-centric tool designed for use in performance and teaching. Its key andnovel component is its visual interface, designed to providethe performer with instantaneous and continuous information on the state of the system. For human improvisation,in which context and planning are paramount, the relevantstate of the system extends to the near future and recentpast. Mimi's visual interface allows for a peculiar blendof raw reflex typically associated with improvisation, andpreparation and timing more closely affiliated with scorebased reading. Mimi is not only an effective improvisationpartner, it has also proven itself to be an invaluable platformthrough which to interrogate the mental models necessaryfor successful improvisation.},
 address = {New York City, NY, United States},
 author = {Fran\c{c}ois, Alexandre R. and Chew, Elaine and Thurmond, Dennis},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177091},
 issn = {2220-4806},
 keywords = {Performer-machine interaction, visualization design, machine improvisation },
 pages = {277--280},
 title = {Visual Feedback in Performer-Machine Interaction for Musical Improvisation},
 url = {http://www.nime.org/proceedings/2007/nime2007_277.pdf},
 year = {2007}
}
"
2010,nime2010_Essl_b.pdf,nime2010_Essl_b,Use the Force (or something) --- Pressure and Pressure --- Like Input for Mobile Music Performance,"Essl, Georg and Rohs, Michael and Kratz, Sven","Force, impact, pressure, multi-touch, mobile phone, mobile music making.","Impact force is an important dimension for percussive musical instruments such as the piano. We explore three possible mechanisms how to get impact forces on mobile multi-touch devices: using built-in accelerometers, the pressure sensing capability of Android phones, and external force sensing resistors. We find that accelerometers are difficult to control for this purpose. Android's pressure sensing shows some promise, especially when combined with augmented playing technique. Force sensing resistors can offer good dynamic resolution but this technology is not currently offered in commodity devices and proper coupling of the sensor with the applied impact is difficult. ",10.5281/zenodo.1177761,"@inproceedings{nime2010_Essl_b,
 abstract = {Impact force is an important dimension for percussive musical instruments such as the piano. We explore three possible mechanisms how to get impact forces on mobile multi-touch devices: using built-in accelerometers, the pressure sensing capability of Android phones, and external force sensing resistors. We find that accelerometers are difficult to control for this purpose. Android's pressure sensing shows some promise, especially when combined with augmented playing technique. Force sensing resistors can offer good dynamic resolution but this technology is not currently offered in commodity devices and proper coupling of the sensor with the applied impact is difficult. },
 address = {Sydney, Australia},
 author = {Essl, Georg and Rohs, Michael and Kratz, Sven},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177761},
 issn = {2220-4806},
 keywords = {Force, impact, pressure, multi-touch, mobile phone, mobile music making.},
 pages = {182--185},
 title = {Use the Force (or something) --- Pressure and Pressure --- Like Input for Mobile Music Performance},
 url = {http://www.nime.org/proceedings/2010/nime2010_182.pdf},
 year = {2010}
}
"
2012,nime2012_Freed.pdf,nime2012_Freed,The Fingerphone: a Case Study of Sustainable Instrument Redesign,Adrian Freed,"Stylophone, Conductive Paper, Pressure Sensing, Touch Sensing, Capacitive Sensing, Plurifunctionality, Fingerphone, Sustainable Design","The Fingerphone, a reworking of the Stylophone in conductive paper, is presented as an example of new design approaches for sustainability and playability of electronic musical instruments.",10.5281/zenodo.1178253,"@inproceedings{nime2012_Freed,
 abstract = {The Fingerphone, a reworking of the Stylophone in conductive paper, is presented as an example of new design approaches for sustainability and playability of electronic musical instruments.},
 address = {Ann Arbor, Michigan},
 author = {Adrian Freed},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178253},
 issn = {2220-4806},
 keywords = {Stylophone, Conductive Paper, Pressure Sensing, Touch Sensing, Capacitive Sensing, Plurifunctionality, Fingerphone, Sustainable Design},
 publisher = {University of Michigan},
 title = {The Fingerphone: a Case Study of Sustainable Instrument Redesign},
 url = {http://www.nime.org/proceedings/2012/nime2012_264.pdf},
 year = {2012}
}
"
2019,nime2019_Lu.pdf,nime2019_Lu,Collaborative Musical Performances with Automatic Harp Based on Image Recognition and Force Sensing Resistors,Yupu Lu and Yijie Wu and Shijie Zhu,,"In this paper, collaborative performance is defined as the performance of the piano by the performer and accompanied by an automatic harp. The automatic harp can play music based on the electronic score and change its speed according to the speed of the performer. We built a 32-channel automatic harp and designed a layered modular framework integrating both hardware and software, for experimental real-time control protocols. Considering that MIDI keyboard lacking information of force (acceleration) and fingering detection, both of which are important for expression, we designed force-sensor glove and achieved basic image recognition. They are used to accurately detect speed, force (corresponding to velocity in MIDI) and pitch when a performer plays the piano.",10.5281/zenodo.3672846,"@inproceedings{nime2019_Lu,
 abstract = {In this paper, collaborative performance is defined as the performance of the piano by the performer and accompanied by an automatic harp. The automatic harp can play music based on the electronic score and change its speed according to the speed of the performer. We built a 32-channel automatic harp and designed a layered modular framework integrating both hardware and software, for experimental real-time control protocols. Considering that MIDI keyboard lacking information of force (acceleration) and fingering detection, both of which are important for expression, we designed force-sensor glove and achieved basic image recognition. They are used to accurately detect speed, force (corresponding to velocity in MIDI) and pitch when a performer plays the piano.},
 address = {Porto Alegre, Brazil},
 author = {Yupu Lu and Yijie Wu and Shijie Zhu},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672846},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {7--8},
 publisher = {UFRGS},
 title = {Collaborative Musical Performances with Automatic Harp Based on Image Recognition and Force Sensing Resistors},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper002.pdf},
 year = {2019}
}
"
2016,nime2016_Volioti.pdf,nime2016_Volioti,x2Gesture: how machines could learn expressive gesture variations of expert musicians,Christina Volioti and Sotiris Manitsaris and Eleni Katsouli and Athanasios Manitsaris,,"There is a growing interest in `unlocking' the motor
skills of expert musicians. Motivated by this need, the main objective of this
paper is to present a new way of modeling expressive gesture variations in
musical performance. For this purpose, the 3D gesture recognition engine
`x2Gesture' (eXpert eXpressive Gesture) has been developed, inspired
by the Gesture Variation Follower, which is initially designed and developed at
IRCAM in Paris and then extended at Goldsmiths College in London. x2Gesture
supports both learning of musical gestures and live performing, through gesture
sonification, as a unified user experience. The deeper understanding of the
expressive gestural variations permits to define the confidence bounds of the
expert's gestures, which are used during the decoding phase of the
recognition. The first experiments show promising results in terms of recognition
accuracy and temporal alignment between template and performed gesture, which
leads to a better fluidity and immediacy and thus gesture sonification. ",10.5281/zenodo.1176137,"@inproceedings{nime2016_Volioti,
 abstract = {There is a growing interest in `unlocking' the motor
skills of expert musicians. Motivated by this need, the main objective of this
paper is to present a new way of modeling expressive gesture variations in
musical performance. For this purpose, the 3D gesture recognition engine
`x2Gesture' (eXpert eXpressive Gesture) has been developed, inspired
by the Gesture Variation Follower, which is initially designed and developed at
IRCAM in Paris and then extended at Goldsmiths College in London. x2Gesture
supports both learning of musical gestures and live performing, through gesture
sonification, as a unified user experience. The deeper understanding of the
expressive gestural variations permits to define the confidence bounds of the
expert's gestures, which are used during the decoding phase of the
recognition. The first experiments show promising results in terms of recognition
accuracy and temporal alignment between template and performed gesture, which
leads to a better fluidity and immediacy and thus gesture sonification. },
 address = {Brisbane, Australia},
 author = {Christina Volioti and Sotiris Manitsaris and Eleni Katsouli and Athanasios Manitsaris},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176137},
 isbn = {978-1-925455-13-7},
 issn = {2220-4806},
 pages = {310--315},
 publisher = {Queensland Conservatorium Griffith University},
 title = {x2Gesture: how machines could learn expressive gesture variations of expert musicians},
 track = {Papers},
 url = {http://www.nime.org/proceedings/2016/nime2016_paper0061.pdf},
 year = {2016}
}
"
2015,nime2015_ckorda.pdf,nime2015_ckorda,ChordEase: A MIDI remapper for intuitive performance of non-modal music,Chris Korda,,"Improvising to non-modal chord progressions such as those found in jazz necessitates switching between the different scales implied by each chord. This work attempted to simplify improvisation by delegating the process of switching scales to a computer. An open-source software MIDI remapper called ChordEase was developed that dynamically alters the pitch of notes, in order to fit them to the chord scales of a predetermined song. ChordEase modifies the behavior of ordinary MIDI instruments, giving them new interfaces that permit non-modal music to be approached as if it were modal. Multiple instruments can be remapped simultaneously, using a variety of mapping functions, each optimized for a particular musical role. Harmonization and orchestration can also be automated. By facilitating the selection of scale tones, ChordEase enables performers to focus on other aspects of improvisation, and thus creates new possibilities for musical expression.",10.5281/zenodo.1179110,"@inproceedings{nime2015_ckorda,
 abstract = {Improvising to non-modal chord progressions such as those found in jazz necessitates switching between the different scales implied by each chord. This work attempted to simplify improvisation by delegating the process of switching scales to a computer. An open-source software MIDI remapper called ChordEase was developed that dynamically alters the pitch of notes, in order to fit them to the chord scales of a predetermined song. ChordEase modifies the behavior of ordinary MIDI instruments, giving them new interfaces that permit non-modal music to be approached as if it were modal. Multiple instruments can be remapped simultaneously, using a variety of mapping functions, each optimized for a particular musical role. Harmonization and orchestration can also be automated. By facilitating the selection of scale tones, ChordEase enables performers to focus on other aspects of improvisation, and thus creates new possibilities for musical expression.},
 address = {Baton Rouge, Louisiana, USA},
 author = {Chris Korda},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1179110},
 editor = {Edgar Berdahl and Jesse Allison},
 issn = {2220-4806},
 month = {May},
 pages = {322--324},
 publisher = {Louisiana State University},
 title = {ChordEase: A {MIDI} remapper for intuitive performance of non-modal music},
 url = {http://www.nime.org/proceedings/2015/nime2015_103.pdf},
 urlsuppl1 = {http://www.nime.org/proceedings/2015/103/0103-file1.avi},
 urlsuppl2 = {http://www.nime.org/proceedings/2015/103/0103-file2.avi},
 year = {2015}
}
"
2017,nime2017_jbender.pdf,nime2017_jbender,Song Kernel --- Explorations in Intuitive Use of Harmony,Juan Bender and Gabriel Lecup and Sergio Fernandez,,"Song Kernel is a chord-and-note harmonizing musical input interface applicable to electronic instruments in both hardware and software format. It enables to play chords and melodies while visualizing harmonic functions of chords within a scale of western music in one single static pattern.  It provides amateur musicians, as well as people with no experience in playing music, a graphic and intuitive way to play songs, manage harmonic structures and identify composition patterns.  ",10.5281/zenodo.1176352,"@inproceedings{nime2017_jbender,
 abstract = {Song Kernel is a chord-and-note harmonizing musical input interface applicable to electronic instruments in both hardware and software format. It enables to play chords and melodies while visualizing harmonic functions of chords within a scale of western music in one single static pattern.  It provides amateur musicians, as well as people with no experience in playing music, a graphic and intuitive way to play songs, manage harmonic structures and identify composition patterns.  },
 address = {Copenhagen, Denmark},
 author = {Juan Bender and Gabriel Lecup and Sergio Fernandez},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176352},
 issn = {2220-4806},
 pages = {513--514},
 publisher = {Aalborg University Copenhagen},
 title = {Song Kernel --- Explorations in Intuitive Use of Harmony},
 url = {http://www.nime.org/proceedings/2017/nime2017_paper0105.pdf},
 year = {2017}
}
"
2025,nime2025_93.pdf,nime2025_93,Melia: An Expressive Harmonizer at the Limits of AI,Matthew Caren and Joshua Bennett,,"We present Melia, a digital harmonizer instrument that explores how common failure modes of machine learning and artificial intelligence (ML/AI) systems can be used in expressive and musical ways. The instrument is anchored by an audio-to-audio neural network trained on a hand-curated dataset to perform pitch-shifting and dynamic filtering. Biased training data and poor out-of-distribution generalization are deliberately leveraged as musical devices and sources of instrument-defining idiosyncrasies. Melia features a custom hardware interface with a MIDI keyboard that polyphonically allocates instances of the model to harmonize live audio input, as well as controls that manipulate model parameters and various audio effects in real-time. This paper presents an overview of related work, the instrument itself, and a discussion of how audio-to-audio AI models might fit into the long-standing tradition of musicians, artists, and instrument-makers finding inspiration in a medium's shortcomings.",10.5281/zenodo.15698990,"@inproceedings{nime2025_93,
 abstract = {We present Melia, a digital harmonizer instrument that explores how common failure modes of machine learning and artificial intelligence (ML/AI) systems can be used in expressive and musical ways. The instrument is anchored by an audio-to-audio neural network trained on a hand-curated dataset to perform pitch-shifting and dynamic filtering. Biased training data and poor out-of-distribution generalization are deliberately leveraged as musical devices and sources of instrument-defining idiosyncrasies. Melia features a custom hardware interface with a MIDI keyboard that polyphonically allocates instances of the model to harmonize live audio input, as well as controls that manipulate model parameters and various audio effects in real-time. This paper presents an overview of related work, the instrument itself, and a discussion of how audio-to-audio AI models might fit into the long-standing tradition of musicians, artists, and instrument-makers finding inspiration in a medium's shortcomings.},
 address = {Canberra, Australia},
 articleno = {93},
 author = {Matthew Caren and Joshua Bennett},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.15698990},
 editor = {Doga Cavdir and Florent Berthaut},
 issn = {2220-4806},
 month = {June},
 numpages = {3},
 pages = {632--634},
 title = {Melia: An Expressive Harmonizer at the Limits of AI},
 track = {Paper},
 url = {http://nime.org/proceedings/2025/nime2025_93.pdf},
 year = {2025}
}
"
2010,nime2010_Woldecke.pdf,nime2010_Woldecke,ANTracks 2.0 --- Generative Music on Multiple Multitouch Devices Categories and Subject Descriptors,"Wöldecke, Björn and Geiger, Christian and Reckter, Holger and Schulz, Florian","Generative music, mobile interfaces, multitouch interaction",In this paper we describe work in progress on generative music generation on multi-touch devices. Our goal is to create a musical application framework for multiple casual users that use state of the art multitouch devices. We choose the metaphor of ants moving on a hexagonal grid to interact with a pitch pattern. The set of devices used includes a custom built multitouch table and a number of iPhones to jointly create musical expressions.,10.5281/zenodo.1177921,"@inproceedings{nime2010_Woldecke,
 abstract = {In this paper we describe work in progress on generative music generation on multi-touch devices. Our goal is to create a musical application framework for multiple casual users that use state of the art multitouch devices. We choose the metaphor of ants moving on a hexagonal grid to interact with a pitch pattern. The set of devices used includes a custom built multitouch table and a number of iPhones to jointly create musical expressions.},
 address = {Sydney, Australia},
 author = {W\''{o}ldecke, Bj\''{o}rn and Geiger, Christian and Reckter, Holger and Schulz, Florian},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1177921},
 issn = {2220-4806},
 keywords = {Generative music, mobile interfaces, multitouch interaction},
 pages = {348--351},
 title = {ANTracks 2.0 --- Generative Music on Multiple Multitouch Devices Categories and Subject Descriptors},
 url = {http://www.nime.org/proceedings/2010/nime2010_348.pdf},
 year = {2010}
}
"
2005,nime2005_Taylor.pdf,nime2005_Taylor,Using Music to Interact with a Virtual Character,"Taylor, Robyn and Torres, Daniel and Boulanger, Pierre","Music, synthetic characters, advanced man-machine interfaces, virtual reality, behavioural systems, interaction techniques, visualization, immersive entertainment, artistic in- stallations ","We present a real-time system which allows musicians tointeract with synthetic virtual characters as they perform.Using Max/MSP to parameterize keyboard and vocal input, meaningful features (pitch, amplitude, chord information, and vocal timbre) are extracted from live performancein real-time. These extracted musical features are thenmapped to character behaviour in such a way that the musician's performance elicits a response from the virtual character. The system uses the ANIMUS framework to generatebelievable character expressions. Experimental results arepresented for simple characters.",10.5281/zenodo.1176826,"@inproceedings{nime2005_Taylor,
 abstract = {We present a real-time system which allows musicians tointeract with synthetic virtual characters as they perform.Using Max/MSP to parameterize keyboard and vocal input, meaningful features (pitch, amplitude, chord information, and vocal timbre) are extracted from live performancein real-time. These extracted musical features are thenmapped to character behaviour in such a way that the musician's performance elicits a response from the virtual character. The system uses the ANIMUS framework to generatebelievable character expressions. Experimental results arepresented for simple characters.},
 address = {Vancouver, BC, Canada},
 author = {Taylor, Robyn and Torres, Daniel and Boulanger, Pierre},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176826},
 issn = {2220-4806},
 keywords = {Music, synthetic characters, advanced man-machine interfaces, virtual reality, behavioural systems, interaction techniques, visualization, immersive entertainment, artistic in- stallations },
 pages = {220--223},
 title = {Using Music to Interact with a Virtual Character},
 url = {http://www.nime.org/proceedings/2005/nime2005_220.pdf},
 year = {2005}
}
"
2019,nime2019_Almeida.pdf,nime2019_Almeida,"AMIGO: An Assistive Musical Instrument to Engage, Create and Learn Music",Isabela Corintha Almeida and Giordano Cabral and Professor Gilberto Bernardes Almeida,,"We present AMIGO, a real-time computer music system that assists novice users in the composition process through guided musical improvisation. The system consists of 1) a computational analysis-generation algorithm, which not only formalizes musical principles from examples, but also guides the user in selecting note sequences; 2) a MIDI keyboard controller with an integrated LED stripe, which provides visual feedback to the user; and 3) a real-time music notation, which displays the generated output. Ultimately, AMIGO allows the intuitive creation of new musical structures and the acquisition of Western music formalisms, such as musical notation.",10.5281/zenodo.3672910,"@inproceedings{nime2019_Almeida,
 abstract = {We present AMIGO, a real-time computer music system that assists novice users in the composition process through guided musical improvisation. The system consists of 1) a computational analysis-generation algorithm, which not only formalizes musical principles from examples, but also guides the user in selecting note sequences; 2) a MIDI keyboard controller with an integrated LED stripe, which provides visual feedback to the user; and 3) a real-time music notation, which displays the generated output. Ultimately, AMIGO allows the intuitive creation of new musical structures and the acquisition of Western music formalisms, such as musical notation.},
 address = {Porto Alegre, Brazil},
 author = {Isabela Corintha Almeida and Giordano Cabral and Professor Gilberto Bernardes Almeida},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672910},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {168--169},
 publisher = {UFRGS},
 title = {{AMIGO}: An Assistive Musical Instrument to Engage, Create and Learn Music},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper033.pdf},
 year = {2019}
}
"
2005,nime2005_Eaton.pdf,nime2005_Eaton,Multiple-Touch-Sensitive Keyboard,"Eaton, John and Moog, Robert","Multiple touch sensitive, MTS, keyboard, key sensor design, upgrading to present-day computers ","In this presentation, we discuss and demonstrate a multiple touch sensitive (MTS) keyboard developed by Robert Moog for John Eaton. Each key of the keyboard is equipped with sensors that detect the three-dimensional position of the performer's finger. The presentation includes some of Eaton's performances for certain earlier prototypes as well as this keyboard. ",10.5281/zenodo.1176735,"@inproceedings{nime2005_Eaton,
 abstract = {In this presentation, we discuss and demonstrate a multiple touch sensitive (MTS) keyboard developed by Robert Moog for John Eaton. Each key of the keyboard is equipped with sensors that detect the three-dimensional position of the performer's finger. The presentation includes some of Eaton's performances for certain earlier prototypes as well as this keyboard. },
 address = {Vancouver, BC, Canada},
 author = {Eaton, John and Moog, Robert},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176735},
 issn = {2220-4806},
 keywords = {Multiple touch sensitive, MTS, keyboard, key sensor design, upgrading to present-day computers },
 pages = {258--259},
 title = {Multiple-Touch-Sensitive Keyboard},
 url = {http://www.nime.org/proceedings/2005/nime2005_258.pdf},
 year = {2005}
}
"
2004,nime2004_Ishida.pdf,nime2004_Ishida,ism: Improvisation Supporting System based on Melody Correction,"Ishida, Katsuhisa and Kitahara, Tetsuro and Takeda, Masayuki","Improvisation support, jam session, melody correction, N-gram model, melody modeling, musical instrument","In this paper, we describe a novel improvisation supporting system based on correcting musically unnatural melodies. Since improvisation is the musical performance style that involves creating melodies while playing, it is not easy even for the people who can play musical instruments. However, previous studies have not dealt with improvisation support for the people who can play musical instruments but cannot improvise. In this study, to support such players' improvisation, we propose a novel improvisation supporting system called ism, which corrects musically unnatural melodies automatically. The main issue in realizing this system is how to detect notes to be corrected (i.e., musically unnatural or inappropriate). We propose a method for detecting notes to be corrected based on the N-gram model. This method first calculates N-gram probabilities of played notes, and then judges notes with low N-gram probabilities to be corrected. Experimental results show that the N-gram-based melody correction and the proposed system are useful for supporting improvisation.",10.5281/zenodo.1176617,"@inproceedings{nime2004_Ishida,
 abstract = {In this paper, we describe a novel improvisation supporting system based on correcting musically unnatural melodies. Since improvisation is the musical performance style that involves creating melodies while playing, it is not easy even for the people who can play musical instruments. However, previous studies have not dealt with improvisation support for the people who can play musical instruments but cannot improvise. In this study, to support such players' improvisation, we propose a novel improvisation supporting system called ism, which corrects musically unnatural melodies automatically. The main issue in realizing this system is how to detect notes to be corrected (i.e., musically unnatural or inappropriate). We propose a method for detecting notes to be corrected based on the N-gram model. This method first calculates N-gram probabilities of played notes, and then judges notes with low N-gram probabilities to be corrected. Experimental results show that the N-gram-based melody correction and the proposed system are useful for supporting improvisation.},
 address = {Hamamatsu, Japan},
 author = {Ishida, Katsuhisa and Kitahara, Tetsuro and Takeda, Masayuki},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176617},
 issn = {2220-4806},
 keywords = {Improvisation support, jam session, melody correction, N-gram model, melody modeling, musical instrument},
 pages = {177--180},
 title = {ism: Improvisation Supporting System based on Melody Correction},
 url = {http://www.nime.org/proceedings/2004/nime2004_177.pdf},
 year = {2004}
}
"
2004,nime2004_Talmudi.pdf,nime2004_Talmudi,The Decentralized Pianola: Evolving Mechanical Music Instruments using a Genetic Algorithm,"Talmudi, Assaf K.",,"This paper presents computer experiments concerning the decentralized pianola, a hypothetical mechanical music instrument, whose large-scale musical behavior is the result of local physical interactions between simple elements.Traditional mechanical music instruments like the pianola and the music box rely for their operation on the separation between a sequential memory unit and an execution unit. In a decentralized mechanical instrument, musical memory is an emergent global property of the system, undistinguishable from the execution process. Such a machine is botha score andan instrument. The paper starts by discussing the difference between sequential memory systems and systems exhibiting emergent decentralized musical behavior. Next, the use of particle system simulation for exploring virtual decentralized instruments is demonstrated, and the architecture for a simple decentralized instrument is outlined. The paper continues by describing the use of a genetic algorithm for evolving decentralized instruments that reproduce a given musical behavior.",10.5281/zenodo.1176675,"@inproceedings{nime2004_Talmudi,
 abstract = {This paper presents computer experiments concerning the decentralized pianola, a hypothetical mechanical music instrument, whose large-scale musical behavior is the result of local physical interactions between simple elements.Traditional mechanical music instruments like the pianola and the music box rely for their operation on the separation between a sequential memory unit and an execution unit. In a decentralized mechanical instrument, musical memory is an emergent global property of the system, undistinguishable from the execution process. Such a machine is botha score andan instrument. The paper starts by discussing the difference between sequential memory systems and systems exhibiting emergent decentralized musical behavior. Next, the use of particle system simulation for exploring virtual decentralized instruments is demonstrated, and the architecture for a simple decentralized instrument is outlined. The paper continues by describing the use of a genetic algorithm for evolving decentralized instruments that reproduce a given musical behavior.},
 address = {Hamamatsu, Japan},
 author = {Talmudi, Assaf K.},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1176675},
 issn = {2220-4806},
 pages = {43--46},
 title = {The Decentralized Pianola: Evolving Mechanical Music Instruments using a Genetic Algorithm},
 url = {http://www.nime.org/proceedings/2004/nime2004_043.pdf},
 year = {2004}
}
"
