Thermal Music: Exploring Sensation of Temperature as a
Performance Parameter
Jeff Snyder
Princeton University
310 Woolworth Center
Princeton, NJ
josnyder@princeton.edu
Forrest Meggers
Princeton University
310 Woolworth Center
Princeton, NJ
fmeggers@princeton.edu
Davis Polito
Princeton University
310 Woolworth Center
Princeton, NJ
ldp9443@princeton.edu
Genyuan Hu
Princeton University
310 Woolworth Center
Princeton, NJ
gh5336@princeton.edu
ABSTRACT
Thermal Music is a project to explore the possibilities of
coordinating control of temperature sensation with control
of sound and light. Unlike convective heating technologies
that change the temperature of the air around us, radia-
tive heating works by directly heating the surface of our
skin via infrared. The technology is widely used in portable
heaters in outdoor dining areas of restaurants. One inter-
esting advantage of radiative heating is that if the source
of infrared radiation is shaded by a thermally reflective sur-
face, the change in perceived temperature by a person near
the heater is very rapid. We worked to create a system
that could quickly control robotic shades in front of a radia-
tive heater to synchronize changes in perceived temperature
with music and light. We also explored the inverse, using
thermal camera input as a control method for audio, and
presented both of these techniques at a “Thermal Music”
concert at Princeton University in October of 2023.
Author Keywords
thermal, sensation, music, temperature, robotics
CCS Concepts
•Applied computing → Sound and music computing; Per-
forming arts;
1. INTRODUCTION
In 2018, Forrest Meggers and Jeff Snyder had a conversa-
tion about the potential of controlling an audience’s sense of
temperature as a performance parameter. Meggers, a pro-
fessor of environmental engineering, believed it should be
possible to do so quickly enough to make rhythmic effects
perceptible through temperature alone. The idea of using
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’24, 4–6 September, Utrecht, The Netherlands.
Figure 1: Audience members experience the thermal output
portion of the Thermal Music concert
temperature as an element of a performance, coupled with
sound and light, was interesting to Snyder for its artistic
potential. A grant from Princeton University’s CreativeX
initiative supported the development of the concept into a
working prototype, and led to a public concert/installation
event in 2023 in collaboration with the Princeton Laptop
Orchestra (PLOrk). While the concept of controlled ther-
mal output was the origin of the idea, once an event was
planned, thermal sensing and input were also considered as
additional aspects of the “Thermal Music” presentation. At
the event, PLOrk presented two pieces using thermal input
sensing, and three pieces using the thermal output control
technology we developed.
2. THERMAL OUTPUT CONTROL MECH-
ANISM
It appears that there is very little research into thermal
output for performance purposes. One interesting project
is Thermoscore[4], which uses peltier junctions to heat pi-
ano keys for interaction with a performer, but it isn’t in-
tended for the audience to experience. Outside of perfor-
mance experiences, there is a body of research aimed toward
simulating the sensation of temperature in virtual reality
environments, from projects that use actual heat to an in-
triguing project that uses chemicals to trick the body into
perceiving an altered temperature[1]. There is also an in-
teresting PhD thesis by Moesgen that focuses on designing
thermal experiences, exploring aesthetic dimensions of the
temperature experience as well as technological[5]. Based
Figure 2: Building the mechanism in the lab
on Meggers’ experience, we decided to use a radiant heat-
ing source, shuttered with a robotic louver. We designed a
mechanism that would be mounted to a commercially avail-
able heating unit by Infratech, so that the only part we
needed to solve was the louver design and the opening and
closing of the louver. We considered many options, rang-
ing from a single flap to a “venetian blinds” style array, and
settled on a design with two horizontal flaps made of alu-
minum, one on the top and one on the bottom, which open
by rotating away from the center of the unit (Figure 1).
Two flaps meant stress on the motor from the weight of the
metal would be less than it would with one flap, and it still
allowed us to move the metal flaps entirely out of the way
of the heat source, which a “venetian blinds” option would
have prevented. Each flap is driven by a NEMA23-sized
stepper motor positioned to one side of the unit, powered
by a 24V supply. We chose parallel-wired stepper motors
to maintain torque during high velocity movement, since
stall torque was much less important to the application.
The flaps are each connected to the custom-built aluminum
frame by a piano hinge, and to the motor shaft by a bracket
(Figure 2).
We felt that the effect would be more dramatic and un-
usual if we could control heat coming from multiple direc-
tions, so we built three units, and positioned them left, cen-
ter, and right of the audience (Figure 3). For cost reasons,
we used smaller heaters for the side units and a larger heater
for the center.
The power needs of the radiant heaters themselves were
high, as the large heater required its own 30Amp circuit of
210VAC, and the smaller heaters each required a 20Amp
circuit at 240VAC. This restricted the possible venue op-
tions significantly, but the Embodied Computation Lab in
the architecture department at our university had an out-
door space that could support those power needs, and could
serve as an ideal venue for the event.
The heating effect is most dramatic if the ambient tem-
perature is low, creating more contrast. However, it is also
more effective if the audience has more exposed skin to heat.
This meant that, in the climate where the performance was
happening, a time frame of fall or spring performance was a
reasonable compromise to have brisk temperatures without
all the audience members being too bundled up.
The motors were controlled by microcontrollers which re-
ceived MIDI commands from a computer nearby. We used
a Teensy 4.0 for each heater mechanism, since it was espe-
cially simple to set them up to appear as a USB MIDI de-
Figure 3: Audience members experiencing the Thermal Mu-
sic concert
vice. We developed a protocol of MIDI-to-movement map-
ping that used note-ons to send open and close commands,
and CC values to change parameters like speed of motion,
acceleration curvature, and how far the flaps should move
when given an “open” command. We also allowed for direct
control of the position of the flaps via CC values, although
that option sacrifices some of the elegance of acceleration
profiles for immediacy, and therefore can result in somewhat
jerky movement. The Teensy microcontroller sent pulse sig-
nals to a stepper motor driver, which controlled the stepper
motors. Limit switches were affixed to positions on the alu-
minum frame to sense when the flaps reached fully open
or fully closed positions, as this was necessary to compen-
sate for skipped steps when moving the flaps quickly, and
to avoid damage to the motors.
Figure 4: Left-view drawing of the heat output device com-
posed of (a) a parabolic reflective surface, (b) quartz infrared
heating elements, and (c) motorized and rotatable aluminum
flaps.
3. THERMAL INPUT CONTROL
Since we knew we wanted to build a concert/installation ex-
perience around the theme of “Thermal Music”, we decided
that we should also explore the potential of using thermal
sensing input to control sound.
Unlike the thermal output concept, using thermal camera
Figure 5: Front-view drawing of the thermal output device showing the placement of (a) an upper aluminum flap, (b) an upper
piano hinge, (c) upper limit switches, (d) an upper motor, (e) a lower aluminum flap, (f) a lower piano hinge, (g) lower limit
switches, (h) lower motor.
Figure 6: Top-view drawing of the setup using three thermal output devices.
Figure 7: Thermodynamics by PLOrk, using a thermal cam-
era pointed at a large bucket of water as a sonfication source
data as input for creating sound has more precedent. Ignor-
ing the thermal nature of the image, there is a large body
of research that explores using camera tracking or image
sensing as a control input for sound, and a long precedent
of interactive systems like David Rokeby’s Very Nervous
System[8] or STEIM’s BigEye. Roger Dannenberg has an
excellent overview of his experience in the field[2]. Because
this field has been well explored, there were several useful
tools available to us once we had the video signal, and the
two pieces we developed were built using video detection
objects that are available in Max/MSP (such as Pelletier’s
cv.jit library1) and TouchDesigner2. When the thermal na-
ture of the image is considered, there is also some precedent,
as infrared is a relatively common sensor input, used in ob-
ject detection, distance sensing, and other purposes.
We began the exploration by borrowing a high quality
thermal camera (which still only means 320X480 pixels) and
testing out actions and objects to see what created inter-
esting results. Some things that stood out in our experi-
ments were ice cubes (which showed up as dark spots and
left painterly tracks as we moved them around a surface),
candles (which give an interesting glow), and water of differ-
ent temperatures mixing together (which gives a marbled,
slowly changing response). Composer Juri Seo composed
a piece, “S` eance”3, around the ice cubes and candles, cre-
ating an occult ritual that tasked performers with moving
ice cubes and candles on a Oujia-like surface. PLOrk as a
group composed a second piece around the swirling water,
“Thermodynamics”4, with video artist Moad Musbahi using
TouchDesigner to divide the image into concentric circles,
and using the brightness of the pixels in each circle to con-
trol the spectrum of each sound performer.
4. CONCLUSIONS
While the thermal input control lent itself easily for live
performance, the thermal output mechanism felt less well
suited to live control, as there is a latency in the mini-
mum time that it takes for the flaps to physically open and
close. Davis Polito composed one piece for live performance,
“reH3AT’r”, using the thermal output mechanism, in which
he controlled audio which was being sensed to control the
1https://jmpelletier.com/cvjit/
2https://derivative.ca/UserGuide/TouchDesigner
3https://youtu.be/2jFV17qOjq8
4https://youtu.be/J3FRbs4VbvU
Figure 8: S´ eance by Juri Seo
flaps, and also utilized feedback by adding contact micro-
phones to the flaps themselves and mixing them into the
audio as a rhythmic element. Jeff Snyder and Ian Accetta
wrote pieces, “FireTongues” and “Nightshift”, respectively,
that worked more as installations, with audio playback syn-
chronized to thermal output mechanism motion and DMX-
controlled lighting.5
Limitations in how many audience members could experi-
ence the thermal effects at one time led to our organization
of the event as more installation-like, where 5 or 6 audi-
ence members crowded around the mechanisms at a time
to experience the pieces. Audience reactions were very fa-
vorable, but a formal user study has not yet been done on
how people respond to the thermal output mechanism. The
thermal output portion of the event was unquestionably the
most unusual and novel experience of the evening.
The thermal input control pieces were successful, and al-
lowed for a more standard performance situation, where the
entire crowd could experience them at once (with the ther-
mal camera image being presented on a large monitor).
5. FUTURE WORK
The development and first performance of the Thermal Mu-
sic project offer an interplay between thermal and auditory
perceptions, suggesting a potential for experience enrich-
ment using the integration of sensory modalities. Future
improvement can look into heat output modulation with a
better response rate by enhancing structural stability and
increasing motor torque. In the meantime, the performance
may also benefit from or even facilitate a better understand-
ing of the variability of the performance’s reception among
different demographics, such as the elderly with decreased
thermal perception capacity[3]. Further, by quantifying
heat output, the thermal music devices provide opportu-
nities for empirical studies on the sensorial and emotional
enhancement functionality of the thermal stimuli previously
5https://youtu.be/gNly7xbN0Xk
explored by Salminen et al[6]. and Tewell et al[7].
6. ETHICS STATEMENT
This project was undertaken within the standards of the
NIME ethical code of conduct. A formal user study was
not conducted as part of this research, so no ethical issues
relating to study subjects were encountered. Surprisingly,
nobody even accidentally burned themselves, except with a
soldering iron.
7. REFERENCES
[1] J. Brooks, S. Nagels, and P. Lopes. Trigeminal-based
temperature illusions. In Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems,
CHI ’20, page 1–12, New York, NY, USA, 2020.
Association for Computing Machinery.
[2] R. B. Dannenberg. Interactive visual music: A personal
perspective. Computer Music Journal, 29(4):25–35,
2005.
[3] S. Guergova and A. Dufour. Thermal sensitivity in the
elderly: A review. Ageing Research Reviews,
10(1):80–92, 2011. Cell Motility and Ageing.
[4] H. Miyashita and K. Nishimoto. Thermoscore: A
new-type musical score with temperature sensation.
pages 104–107, 01 2004.
[5] T. Moesgen. Understanding and designing thermal
experiences. In Proceedings of the Eighteenth
International Conference on Tangible, Embedded, and
Embodied Interaction, TEI ’24, New York, NY, USA,
2024. Association for Computing Machinery.
[6] K. Salminen, V. Surakka, J. Raisamo, J. Lylykangas,
J. Pystynen, R. Raisamo, K. M ¨akel¨a, and
T. Ahmaniemi. Emotional responses to thermal
stimuli. In Proceedings of the 13th International
Conference on Multimodal Interfaces, ICMI ’11, page
193–196, New York, NY, USA, 2011. Association for
Computing Machinery.
[7] J. Tewell, J. Bird, and G. R. Buchanan. The heat is
on: A temperature display for conveying affective
feedback. In Proceedings of the 2017 CHI Conference
on Human Factors in Computing Systems, CHI ’17,
page 1756–1767, New York, NY, USA, 2017.
Association for Computing Machinery.
[8] T. Winkler. Creating interactive dance with the very
nervous system. 1997.