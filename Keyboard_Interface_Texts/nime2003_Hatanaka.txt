Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-77
Ergonomic Design of A Portable Musical Instrument
Motohide Hatanaka
Center for Design Research, Department of Mechanical Engineering Design Division
Building 560, 424 Panama Mall, Stanford University
Stanford, California 94305, USA
+1-650-723-3286
motohat@cdr.stanford.edu
ABSTRACT
Ah andheld electronic musical instrument, named the Bento-
Box, was developed. The motivation was to develop an
instrument which one can easily carry around and play in
moments of free time, for example when ridingpublic
transportation or during short breaks at work. The device was
designedt oe nable quick learning by having various scales
programmed for different styles of music, and also be
expressive by having hand controlled timbral effects which
can be manipulated while playing. Design analysis and
iteration lead to a compact and ergonomic device. This paper
focuses on the ergonomic design process of the hardware.
Keywords
MIDI controller, electronic musical instrument, musical
instrument design, ergonomics, playability, human computer
interface.
1. INTRODUCTION
The busym odern lifestyle providesf ew opportunities for
music lovers to perform. However, people do have many short
intervals of free time during which they can potentially play
musical instruments. Fore xample,m anyp eoples pend time
less actively when riding or waiting for public transpor tation
for commuting. It would be a boon for busy music lovers if
there were a musical instrument that they could easily carry
around and play anytime anywhere without disturbing others,
just like a portable audio device such as the Sony Walkman
[10]. For instance, a harmonica is a very portable instrument
but it can disturb others if played in public. On the other hand,
an electronic keyboard can beplayed and heard through a
headphone so as not to disturb people, but it is awkward to
carry around and it may also irritate su rrounding people
because of its size. What would be ideal instead is a compact
portable silent musical instrumentw ith electric s ound output
(see Figure 1).
TheB ento-Box wasd esigneda nd built as ac lass project for
ac ourse on human computer inte raction (HCI) theory and
practice at Stanford University [11]. Basics of HCI theory as
well as electronics and computer sound generation were
taught, and students were given approximately a month to
build musical instruments of their own interest in groups of
two or three.
2. CO NCEPT
2.1 Project Goal, Design Criteria, and
Functional Requirements
The general goal of the project was to develop a device that
contains maximum musical expressiveness in a limited size
while assuring ease and comfort of performance. Some criteria
were established to limit certain properties of the device for
the user and the people around the performer. Functional
requirementsw erea lsoi dentif iedt oa ssu re satisfactory
performance for the user.
Figure 1. Compact quiet musical instrument for playing in
public places
The device had to be portable both in terms of size and
mass. The design team aimed for a size that can be held with
two hands brought fairly close together and with a mass that
can be supported comfortably for at least half an hour. The size
constraints also result in a unit that the user can easily carry
around, hence the name of the device Bento-Box (bento is a
Japanese word for packed lunch). The performer’s range of
motion also had to be small enough not to disturb the
surrounding people in crowded public transportation where
people are seated shoulder to shoulder. So the device was
designed to be played without having to move shoulders but
only hands, wrists, and forearms. Furthermore, the instrument
alsoh ad to be quiet duringp erformance. Hence, quiet input
devices, such as buttons without clicking noise, were sele cted
to minimize noise generation.
The design team decided that they wanted an instrument
that can play melody with at least two octaves of tone range for
sufficient musical expression. They also agreed on having at
least two timbral effects to control. Other functions were added
to the device as required or desired as the design evolved.
2.2 De sign Strategy
The design takes full advantage of the fact that this is an
electronic instrument. An acoustic musical instrument may
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-78
have structurald esignc onstraints that may result in poor
ergonomics. In contrast, electronic instruments have much
more freedom in structurald esigns ince thes ound usu ally
does not depend on the physical properties of the device.
Hence, here, the instrument was designed prioritizing
ergonomics, while also assuring high expressiveness. Such a
design can be done through a combined analysis of the tasks,
hardware charact eristic so fi nput dev ices, and human
ergonomics (see Figure 2).
Figure 2. Design approach involves the analyses of task,
hardware characteristics, and human ergonomics
Many compact handheld and hand-worn musical devices
take advantageo fb eing free from physical constraints seen in
acoustic instruments. The hardware designs often differ greatly
from one to another because of the intended application. The
Hands used by Waisvisz is a pair of rather sophisticated hand-
worn MIDI-controllers with nu merous sensors that allows
expr essi ve perfo rman ce [12] .A family of hand-held
instruments developed recently by Weinberg and
collaborators generally have simple hardware that are easy to
operate and comfortable to hold, probably considering use by
children, and their applications have broad goals such as
enabling collaboration among performers [13-15]. Since we
were developing an instrumentf or an entirely news etting,
design inspiration were sought not only from such existing
musical devices but also other electronic devices used in
similar settings such as mobile phones and portable video
games like the Nintendo Gameboy [7]. However, the greatest
source of ideas were various type so fb r ainstorming exercises
highlighted by building quick mockups and playing with
them, acting out as if they were real instruments.
2.3 Init ial Design
The initial concept was to have a spherical device that had
touch sensors, such as buttons or force sensitive resistor (FSR)
pads, on the surface for basic melody and chord performance.
There were also to be several effects controlled by twisting and
squeezing the device (see Figure 3).
In order to maximize the playability and s ound range of the
instrument on the limited space of the instrument, a scale
(style) selection slider was to be installed. Notes in the
selected scale and key are assigned to the melody performing
sensors (see Figure 4). This assumes that the performer only
needs to play notes that are in the scale. Hence, having a sensor
(or a part of a sensor) assigned to an off-scale note would be a
waste of space. This has an advantage, especially for beginner
musicians trying to improvise, in that the performer will not
produce a note that is terribly dissonant.
Figure 3. Controlling effect parameters by twisting and
squeezing the instrument was one of the earliest ideas.
Figure 4. By changing scale settings, the instrument limits
itself to produce only the notes that are in the specified scale.
3. HARDWARE DESIGN
3.1 Sha pe Determination
The hardware design went through er gonomics analysis and
testing using mockups to maximize playability and
expressiveness. The usefulness of prototyping in early stages
is discussed in a book on product design by Kelley [5]. Three
mockups were built using rigid urethane foam. One was
cylindrical, with tapered ends, 90mm diameter and115mm
length, and the other two were rectangular, one being narrow
(80mmx150mm x55mm thick) and the other being almost
square in its front profile (150mmx150mmx55mm) (see Figure
5).
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-79
Figure 5. Foam mockups for initial instrument design. The
glove is placed for size reference.
For the cylindrical shape, it was discovered that the hands
conform too nicely to wrap around it such that it left the
fingers with little freedom to move (see Figure 6).
Figure 6. Having no free space between the instrument and
the fingers limits the freedom of finger motion.
Then arrowr ectangle relied on the fingers and thumb for
supporting the instrument. As a consequence, both of the
thumbs as well as two fingers from each hand had to stay on
the instrument for stable support. This greatly inhibited their
freedom for performance (see Figure 7).
The square shape was selected at the end as its wide shape
allowed for the user’s palms to support the instrument wit hout
hindering the dexterity of thumbs and fingers (see Figure 8).
Ther esulto ft he experiment shows that round shape does not
necessarily make a device ergonomic. Various ways of
grasping are listed andd escribed in books by Cutkosky [3]
and MacKenzie and Iberall [6].
3.2 Sensor Selection and Layout
Controlling a timbral effect parameter by twisting the
instrument was one of the featured ideas of the design.
Twisting and bending are motions that could be easily applied
by the performer’s wrists. Therefore, making use of that motion
was perfectly suited to represent our ergonomics consideration
approach for expressiveness maximization. The pos itioning of
the twisting pivot was also experimented and determined
using the foam mockups. The pivot was first positioned at the
center of the device, which worked fine for the cylindrical
shape. However, having the pivot at the center of the
rectangular mockups required large motions of the forearms,
which could lead to elbow motions that disturb surrounding
people. The problem was solved by shifting the pivot toward
the wrists.
Figure 7. In a grip using fingertips, thumbs and some fingers
must always remain on the instrument to support it.
Figure 8. Palms are used to support the instrument, leaving
the thumbs and fingers free to move.
Anothere xpression parameterw as to be controlled with the
squeezing force between the two halves of the instrument. The
twist and squeeze sensors were integrated in one unit. The
rotary potentiometer for sensing the twist was suspended on a
linear slider that allows it to translate in the direction par allel
to its rotating axis. An FSR was installed behind the
potentiometer via a rubber cushion to sense the squeeze.
Design of other input devices was done by analyses and
matching of the task, device characteristics, and human
ergonomics all together. Predicted interaction frequency as
well as ther equireds ignal output (continuous or discrete)
were listed out for various control parameters (see Table). For
example, melody pitch changes are required much more
frequently than scale change. Properties of various input
devices such as the output signal types and the time required
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-80
to manipulate them were also listed. The list was used to
identifyt he potentialc ouplings of control parameters and
sensors.
Table 1. Body parts, control parameters, and sensors were
matched by analyzing their characteristics.
Final selection and physical la yout of these input devices
on the instrument were done through an experiment to move
thumbs and fingers in every possible way on the foam
mockup. The objective was to discover how to extract
maximum expressiveness out of the hands. The range and
speed of motiona sw ella sf orce andc ontrol involved were
analysed. Level of comfort was another factor that was tested.
The layout determination alsoc onsidered maintaining e nough
comfortable room for the thumbs and fingers to rest. It is worth
keeping in mind that fingers are good at flexing and extending
but they are not so finely controllable nor forceful at
abduction or adduction, especially when they are bent.There
are also slight but noteworthy differences in the dexterity
among the four fingers. The index finger, for example, has
much more independence in motion compared to the other
three fingers. Meanwhile, a thumb can exhibit a variety of
complex motions unrivaled by fingers. Such facts about hands
can also be obtained from literature by, for example, Kaplan [4]
and Wilson [16], but the effectiveness of mockup
experimentation cannot be completely replaced by reading
only. However, while experiments can reveal what one can do,
literature on ergonomics such as [1] by Cacha can provide
more information about what is good or bad for the hands in
long term ergonomics so that injuries can be prevented.
Here ares omee xamples fromt he resulting design. There are
twos liders positionedd iagonally on the thumb side of the
device.T heya re assignedf or keya nd chord selection. Another
slider is placed lower on the device for style change, where it is
not as accessible, since it will not be used as frequently as the
two others (see Figure 9). The chord/key/style settings change
only when an activation button is pressed. This allows the user
to control the sliders during performance in preparation for a
future change without interfering the ongoing performance.
The right fingers do the melodic performance by pressing
buttons (see Figure 10). Fingers are good for selecting and
pressing buttons. They are also quite capable of varying
pressure on each finger if needed. Fingers on the left hand were
used to trigger effects-selection toggle switches.
4. SYSTEM CONFIGURATION
Sensor information from the Bento-Box wasc ollected by an
Atmel ATMega 163 microcontroller and was sent to a desktop
computer as MIDI data. Pd [8] was employed to process the
data and generate sound with plugins created from Synthesis
ToolKit (STK) physical models [2]. C++ plugins were also
employed to ease signal processing (see Figure 11).
Figure 9. The Bento-Box (150mmx150mmx45mm, 526g)
Frequently used controllers are ergonomically placed.
Figure 10. Noiseless buttons for playing melody.
Figure 11. System configuration
5. S ETUP ALTERATION
Once the entire setup was built according to the in itial
design, some alterations were made in the assignment of
sensors to effect parameters after some experimentation.
Certain sensors turned out to be ergonomically difficult to
use. Some modes of control were avoided because they were
confusing for the user. Furthermore, less-used functions were
replaced by more desired functions for a richer musical
experience.
5.1 Init ial Setup
The initial setup was as follows (please refer to Figures 12
and 13). There were two rows of eight buttons each for the right
fingers, each assigned to individual notes. The note assigned
to these buttons changed depending on the style and key
setups, which were selected by sliders operated by the right
thumb. Thes tyle slider was located lower than the key slider,
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-81
which was positioned diagonally at the top of the back right
side (Back refers to the thumb side of the instrument, which
faces toward theu ser). Therei sa chords election slider, which
wasp lanned to automatically accompany the melody
performed, on the left back side symmetrical to the key
selection slider. The style, key, and chord changes are only to
occur when one of the two small red activation buttons,
installed on both right and left just below the two symmetrical
sliders, are pressed. A large black button next to the activation
button for the right thumb was to be a scale-reset button which
enables the user to instantly change the note designation for
the right finger buttons toac hromatic scale. Symmetrically on
the left is an FSR for a volume effect. It was to decrease volume
as it was pressed.
Figure 12. Thumb (back) side schematic of the initial setup
On the front side,t here aref our three-waym omentaryt oggle
switches for the left fingers. Each of these were to be assigned a
sound effect, and used to select a sensor for controlling the
effect; either the twist or the squeeze sensors at the center of
the device.
Figure 13. Finger (front) side schematic of the initial setup
5.2 Altered Setup
These four toggle switches turned out to be difficult to
operate with fingers. They had to be pulled toward or pushed
away from the palm, and the latter was especially difficult. The
switches were also rather stiff. These switches were not
employed in the final setup since it was found to be very
confusing for the performer to alter the effects assigned to
various sensors. Avoiding modes like this is recommended in
HCId esigni ng eneral [9]. Thel eftf ingers can instead be used
to play notes like the right fingers by installing more buttons.
The key and chord selectors were not used during test tr ials.
Thek ey selector wasl eft unused as no key change took p lace
during performance. The chord selector was not needed since
the melody buttons, controlled by the right fingers, could play
chords. Instead of the initially intended applications, these
two sliders were assigned to control more effect parameters.
As the result of the above changes, the two activation
buttons were no longer necessary. Furthermore, the s cale-reset
button and the volume effect controller were never used. These
input devices were not used in the final setup.
6. FINDINGS AND FUTURE
IMPROVEMENTS
Future improvements are suggested from the experience of
playing with the finalized setup. The musical setup,
employing the style selection slider and numerous effect
controls, was quite a success. Generally, more feedback is ideal
in both physical and visual forms. Some mechanical
improvement is also required for comfort and robustness. In
addition, device-specific f unctional consideration would
improve the quality of performing experience. Furthermore,
there is the engineering task to make it a real portable device.
6.1 Feedback
Visual information feedback is necessary to show the style
and key setup as well as any other parameters that may need
indication. (Although the key control was eliminated in the
final setup, it would still be a necessary function.) This would
simply require a small LCD on the backside of the instrument.
Force feedback would be useful in some of the continuous
effect controls. Passive feedback by springs might be
sufficient for the application. Such a system can also help
bring the effect control back to the neutral position.
The importance of tactile feedback was confirmed when
operating the note buttons on the blind side of the instrument.
For example, it would be very difficult to locate buttons if
they were all flat. Alternatively, hand location with respect to
thei nstrumentm ay be realized by placing an indexing feature
where the palm touches the instrument.
6.2 Mechanical improvement
The twisting pivot, which connected the right and left
halves of thei nstrument, hada robustness concern. It was a
rotary potentiometer and was not necessarily designed to bear
load. A load isolation mechanism must be introduced to
improve the structural reliability of the instrument.
The square Plexiglas construction is uncomfortable to hold.
The material and the fabrication method constrained the
instrument surfaces to be designed flat. Three-dimensional
freeform manufacturing capability would greatly increase
design freedom and the resulting ergonomics.
Sliders alsoh ad some usability problems. There was
frictional resistance making the operation difficult when fast
control was desired. The linear motion was also not very
ergonomic for the thumbs. Instead, a curved pressure-sensitive
touch-pad would be a nice replacement as there would be
virtually no frictional resistance upon operation. It can also
make better use of the dexterity of thumbs by added sensing
dimensions: two- dimensional coordinates and vertical
pressure.
6.3 Device- Specific Development
Currently, the various sound effects are arbitrarily assigned
to thes ensors on thei nstrument. As ar esult, the physical
motion of the performer does not correlate with the resu lting
effects in any intuitive way. Hence, custom developed effects
that relate intuitively to the physical actions are desired. For
example, sound may be ”twisted” or “squeezed” by skillful
multi-speaker output system.
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-82
6.4 Sta nd-alone
Here, the system required three separate components; the
Bento-Box as the controller, a micro controller for data
acquisition, and a desktop computer for sound generation. It
would be desirable to integrate all of it so that everything will
be enclosed in a Bento-Box size package for true portability.
7. CO NCLUSION
Ap rototype for a portable h andheld elect ronic musical
instrument was successfully built. Its unique style selection
capability allows the user to easily perform a variety of styles
of music, which would otherwise have been difficult to learn.
The initial motivation was to create a personal instrument to
beheard onlyb yt he performer.H owever,t he resulting
instrument, with a rich capability to control various
interesting sound effects, is fit for performing out loud along
with other musicians. The design was done with mockup
iterations and functional and ergonomic analyses, and has led
to many interesting findings. The experimentation with the
completed setup has inspired further improvements.
8. ACKNOWLEDGMENTS
Iw ould like to thank my project teammates Seth Nickell and
Katia Zarrillo for the collaboration, the class teaching team
(Professors Bill Verplank and Max Mathews, TA’s Michael
Gurevich and Wendy Ju)f or giving me the opportunity, and
ProfessorM ark Cutkosky and WestonG riffinf or support in
writing.
9. REFE RENCES
[1] Cacha, C.A. Ergonomics and Safety in Hand Tool Design.
CRC Press LCC, Florida, 1999.
[2] Cook, P.R. Synthesis ToolKit Algorithms and
Instruments.
http://www.cs.princeton.edu/~prc/STKAlgorithms.html
[3] Cutkosky, M.R. Robotic Grasping and Fine Manipulation.
Kluwer Academic Publishers, Massachusetts, 1985.
[4] Kaplan, E.G. Functional and Surgical Anatomy of the
Hand. J. B. Lippincott Company, Philadelphia and
Montreal, 1965.
[5] Kelley, T., and Littman, J. The Art of Innovation.
Doubleday, New York, 2001.
[6] MacKenzie, C.L. and Iberall, T. The Grasping Hand.
Elsevier Science B.V., Amsterdam, 1994.
[7] Nintendo Gameboy. http://www.gameboy.com/
[8] Puckette, M. Pd download site.
http://crca.ucsd.edu/~msp/software.html
[9] Raskin, J. The Humane Interface: New Directions for
Designing Interactive Systems. Addison-Wesley,
Massachusetts, 2000.
[10] Sony Walkman. http://www.sony.net/Products/walkman/
[11] Verplank, B., Sapp, C., and Mathews, M. A Course on
Controllers. Proceedings of NIME (Seattle, Washington,
USA April 2001)
[12] Waisvisz, M. “The hands, a set of remote midi-
controllers,'' in Proc. Int. Computer Music Conf.
(ICMC'85), pp. 313-318, 1985
[13] Weinberg, G., Lackner, T., and Jay, J. "The Musical
Fireflies - Learning About Mathematical Patterns in Music
Through Expression and Play".Proceedings of XII
Colloquium on Musical Informatics 2000 . A'quila Italy.
[14] Weinberg, G., Orth M., and Russo P. "The Embroidered
Musical Ball: A Squeezable Instrument for Expressive
Performance," Proceedings of CHI 2000. The Hague: ACM
Press.
[15] Weinberg, G., Aimi, R., and Jennings, K. "The Beatbug
Network – A Rhythmic System for Interdependent Group
Collaboration." Proceedings of NIME 2002. Dublin: MLE.
[16] Wilson, Frank R. The Hand: how its use shapes the brain,
language, and human culture. Pantheon Books, New York,
1998.