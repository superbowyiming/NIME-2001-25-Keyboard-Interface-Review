Tangible Scores: Shaping the Inherent Instrument Score
Enrique Tomás
Interface Culture Lab
Kunstuniversität Linz
Kollegiumgasse 2,4010 Linz, Austria
Enrique.Tomas@ufg.at
Martin Kaltenbrunner
Interface Culture Lab
Kunstuniversität Linz
Kollegiumgasse 2,4010 Linz, Austria
Martin.Kaltenbrunner@ufg.at
ABSTRACT
Tangible Scores are a new paradigm for musical instrument
design with a physical conﬁguration inspired by graphic
scores. In this paper we will focus on the design aspects
of this new interface as well as on some of the related tech-
nical details. Creating an intuitive, modular and expres-
sive instrument for textural music was the primary driving
force. Following these criteria, we literally incorporated a
musical score onto the surface of the instrument as a way
of continuously controlling several parameters of the sound
synthesis. Tangible Scores are played with both hands and
they can adopt multiple physical forms. Complex and ex-
pressive sound textures can be easily played over a variety
of timbres, enabling precise control in a natural manner.
Keywords
NIME, Scores, Notation, Composition, Tangible Interface,
Acoustic Interface.
1. INTRODUCTION
During the development process of a new digital instrument
it is necessary to deﬁne an a priori set of musical applica-
tions and practices where performers can use it. This will
determine many characteristics of the musical interface e.g.
its gestural vocabulary, functionalities, ergonomics, visual
aspect, etc.
Many NIMEs are not limited to a particular musical prac-
tice although some types of music will be more diﬃcult to be
played than others. For example, playing a classical music
piece with a Reactable [10] can be quite tedious indepen-
dently from the diﬃculty of the score. Other NIMEs are
designed to constrain the playable musical elements at mul-
tiple levels. Max Mathews’ Radio Baton [14] uses a com-
plementary program called Conductor to automatize the
selection of notes on a predeﬁned score. Laurie Spiegel’s
Music Mouse [7] allowed only to interact with the ranges
of change on the selection of frequencies. In both cases,
the instruments require a predeﬁned musical score. There-
fore a NIME designer often also tends to develop a notation
system for the new digital instrument and its performance
practice.
Frequently we see performers who don’t use scores be-
cause they prefer to improvise the composition during the
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’14,June 30 – July 03, 2014, Goldsmiths, University of London, UK.
Copyright remains with the author(s).
very moment of a performance, interacting with the instru-
ment and usually following some prior musical plan. For
Chadabe [5] this practice transforms the act of composi-
tion into an interactive process that depends deeply on the
system response. In these cases, the musical result can be
completely diﬀerent at every instance of a performance.
In this diversity of approaches to the problem of compos-
ing for new digital instruments, the traditional relations be-
tween composer, composition and performer are mediated
by thecomposed nature of the instrument. In this paper
we describe ﬁrst the inherent compositional aspects of our
digital instruments and their inﬂuence on the musical prac-
tice. Later, we extend the concept ofinherent scoreto the
physical layer of the interface, proposing a new family of
instruments calledTangible Scores.
Figure 1: Playing a Tangible Score.
2. INHERENT INSTRUMENT SCORE
2.1 Composers and Digital Instruments
Composing for digital music instruments can be quite chal-
lenging. The decoupling between interface and the synthe-
sized sound inﬂuences the whole process of composition.
During the age of traditional acoustic musical instruments,
the role of a composer was the encoding of musical ideas into
standard musical notations. Reading those scores, players
were able to decode the notation into physical movements,
allowing the same music to be played with diﬀerent instru-
ments. But after the conception of electronic musical in-
struments, a composition often was not ﬁnished until the
relation between sound and gesture was deﬁned. And the
deﬁnition of that relation can become a very complex pro-
cess.
For the comprehension of this problem it is important to
understand the origins of our contemporary practice with
digital instruments. Nowadays composers are generally used
to deal with gesture-based music. Many compositions after
Proceedings of the International Conference on New Interfaces for Musical Expression
609
the 50s and 60s were increasingly understood as describing
gestural information for the performer, rather than being
notations of pitch organized in time [13]. We can say that
during this period, the traditional notation system lost its
predominant position since it was not able to embrace and
reﬂect the new ideas of composers. The same problem later
applied to the case of the more recent graphic scores, which
often provided a rather subjective musical notation system.
A graphic score is often generated from the need of a no-
tation of sonic-facts that the performer will recreate in his
imagination, an approach that anticipates the process of
composing for electronic musical instruments.
But notably the last revolution in transforming the role
of a score was achieved through the use of electronic cir-
cuits in musical language. Alvin Lucier [12] explains how
within many of the works produced by the Sonic Arts Union
”there were no scores to follow; the scores were inherent in
the circuitry”. Lucier describes the suppression of notation
in its traditional form, where printed symbolic or graphic
scores leave the stage to a new kind ofinherent score. Cir-
cuits are conﬁgured in a speciﬁc way for their artistic use,
containing enough structural elements to be used in a mu-
sical situation. The role of the composer, at an equidistant
point among designers, composers and performers, starts
with the conﬁguration of the technical system behind the
actual instrument. Performing became the creative explo-
ration in freedom of the musical aﬀordances, musical reac-
tions or acoustic relations to the physical space performed,
without the need of any kind of musical notation. It is im-
portant to remark that this historical moment is a bridge
between the old traditional vision of the composer, and a
new role that is more connected to the current practices
with electronic instruments.
Now some decades later, our study ﬁeld stays at the
continuation of the cultural and technical evolution of all
those pioneering works, developing a variety of alternative
approaches [4] to composition, notation and performance.
In the following section we discuss two compositional ap-
proaches for electronic musical instruments.
2.2 Composed & Self-Composed Instruments
The concept of an inherent score is important for under-
standing the mediated relationship between composers, per-
formers and their instruments. In this section we introduce
the phenomenological approach on performing with them.
Twelve years ago Schnell and Battier introduced the con-
cept of composed instruments[17]. This term serves to ex-
plain that our digital instruments equally ”carry the notion
of an instrument as that of a score”, in the sense of de-
termining various aspects of a musical work itself. During
the technical implementation of the instrument we often in-
corporate many ideas of composition into the programmed
system.
In 1966, during the ”Nine Evenings of Experiments in
Art and Technology” the ﬁrst composition of David Tudor
was performed, marking his transition from a performer of
many of John Cage’s works to his new role of a composer. It
was the premiere of Bandoneon!, a combine of programmed
audio circuits, moving loudspeakers, TV images, and light-
ing, all controlled through the live sound of a bandoneon
played by Tudor. From the program notes we read that
Bandoneon! uses no compositional means, since it ”com-
poses itself out of its own composite instrumental nature”.
Kuivilar [11] asserts that we were in fact facing a new way
of understanding instrumentality. In these self-composed
instruments, Tudor acts as the interpreter and performer of
a composition that composes itself out of these constituent
parts. Or using Lucier’s arguments, the composition is cre-
ated from the inherent scoresthat can be found in the struc-
tural elements of a particular electronic conﬁguration. This
concept carries an extraordinary rendition: the acceptance
that an electronic instrument is an entity that can display
itself without the need of a composer or a composition.
Tudor’s aesthetic of ”composing inside electronics” antici-
pated the concepts found withing the contemporary practice
of circuit bending, DIY builders and sound hackers. But
more importantly, he founded the principles of a new musi-
cal practice that was continued up to the contemporary use
of digital instruments and interfaces. Like in Bandoneon!,
we should understand our contemporary digital music in-
struments as a more or less complex set of circuitry, soft-
ware, logics and spatial relationships, exposing an inherent
score that conﬁgures its nature, the source of inspiration for
performing with them.
John Fulleman, a frequent collaborator of John Cage, at-
tributes Tudor an ”ability to assert just enough control over
the equipment to get through a concert”. The same method-
ology of composition can be advised to the composers of
digital instruments. Navigating along the ﬁeld of charac-
teristics one could read from the instrument, not only as
a mere catalog of potentials or aﬀordances, but as an in-
herent score, that deﬁnes the sonic and musical possibilities
that can be chosen by a performer every moment when it is
played in real time.
Cook’s principle [6] about musical controller design ”bet-
ter to make a piece, not an instrument”, reinforces this vi-
sion of composing inherent scores. According to this, the
design of a new instrument should be starting with a com-
position in mind. But just like in any traditional composi-
tion, many cultural, personal and idiosyncratic elements of
the builder’s personality impregnate each digital instrument
design. Or as it is explained by Wanderley [22], if a com-
poser decides to build or take part in the design of a certain
instrument, the vocabulary of gestures of an instrument is
often created with a subjective artistic reason in mind.
3. TANGIBLE SCORES
3.1 A Physical Layer for Musical Notation
Inspired by the mediated relation between musician, instru-
ment and musical performance, we decided to design a new
instrument that emphasizes the inherent scores. Hence our
objective was the extension of the concept of inherent score
and creating a new digital instrument that could incorpo-
rate some kind of musical notation within its very physical
conﬁguration. Our ﬁnal goal is to study if we could con-
duct the way an instrument is played by adding a score to
its physical layer, in addition to the overall aﬀordances and
functionalities that it oﬀers. As a proof of concept we de-
cided to build a tangible instrument that we called Tangible
Score.
We deﬁne a tangible score as the physical layer that is
incorporated into the conﬁguration of a digital instrument
with the intention of conducting the tactile gestures and
movements. A composer could then conceive a musical idea
and incorporate it to the instrument body encoding it in
a physical manner. A performer can explore the tangible
score and navigate through its materials as another element
of the inherent score that it contains. A tangible score de-
termines only the gestural constraints and as such does not
deﬁne any sonic results. Therefore equally as a traditional
score, it encodes a musical intention and delegates the de-
coding part to other agents. A tangible score can make use
of any material and can extend to two- or three-dimensional
artifacts.
In a tangible score the musical composition and its repre-
Proceedings of the International Conference on New Interfaces for Musical Expression
610
sentation is integrated into the instrument at the physical
layer. Making use of a physical score we can:
• Represent a compositional idea or a musical process
to inspire or conduct a musical performance. As it is
incorporated physically within the body of the instru-
ment, a performer can be intimately inspired, con-
ducted or constrained without looking at any other
score.
• Deﬁne the gestures through the aﬀordances of the in-
strument as a physical object. The instrumentalist
will approach the performance in diﬀerent ways de-
pending on the physical conﬁguration of the instru-
ment.
• Modulate and design the control signal that feeds the
sound synthesis. The tactile activity will be used as
the expressive input for sound synthesis. The material
qualities of the interface will deﬁne and modulate this
ﬂow of information.
On a technical level a tangible score can make use of
diﬀerent processes for the analysis of gestural behaviors of
a performer. Although in our current implementation we
took the approach of acoustic analysis of the gestural impact
on the instruments surface, other additional or alternative
techniques, such as computer vision, capacitive sensing and
further sensing modalities may be incorporated.
3.2 Graphic Scores
During the process of ﬁnding a physical design language for
a tangible score we got inspired by graphic scores. Graphic
scores appeared in the musical avant-garde as a way to re-
lease composers from the constraints of writing their music
using the notation of a traditional score. Consequently the
representation of a musical idea opened to the personal and
subjective selection of graphic ﬁgures that inspire new and
imaginative ways of interpretation.
In the world of improvisation, graphic scores are often
used for structuring the evolution of the performance. They
are also useful for the analysis of electroacoustic music and
as a parallel notation for composers. We can thus consider
that graphic scores are living in the same musical environ-
ment as our new interfaces for musical expression. Graphic
scores are useful when traditional notation fails, like com-
plex or novel musical ideas including indetermination or ex-
treme parameterization of the musical variables.
The importance of graphic scores is that we can some-
times have a closer approach to the original ideas or aes-
thetic intentions, although other representations are as well
possible like using texts and symbols or even electronic cir-
cuits, as we have seen in previous sections. Graphic scores
have been traditionally hand written or painted by their
composers so we can extract valuable information about
the work, just like from traditional music manuscripts. It is
interesting to note that graphic scores can adopt any form
and any dimension, although historically almost all of them
have been published on paper, in an inexplicable concep-
tual analogy to the traditional format of the score. We had
to wait until the advent of digital interfaces to see musi-
cal notations that can be interactive, dynamic, fragmented
or non linear. Examples include the animated scores of
Miyashita [15] or the Reactable’s physical sound program-
ming environment, and few three-dimensional scores such
as in Berghaus [2].
With the aim of exploring and creatively extending the
ﬁeld of graphic scores, we decided to use them extensively
in our ﬁrst conceptual experiments towards tangible scores.
Although our current implementations are therefore physi-
cal representations of graphic scores, this approach has to
be understood as the further evolution of one possible score
concept into the physical domain. Future implementations
may extend to the idea of sculptural scores.
4. PHYSICAL EMBODIMENT
One of the core features within the genre of Tangible User
Interfaces is the embodiment of digital information within
physical artifacts, which can be shaped through the direct
manipulation of the interactive object itself [9]. Our design
approach for Tangible Scores borrows several concepts from
this ﬁeld and merges them with ideas from Graphic Scores
and musical instrument design. As Verplank [21] has sug-
gested an inverse relationship between Piaget’s development
psychology and the history of human computer interaction,
we can equally observe a similar development in the history
of musical score systems.
While a traditional score deﬁnes a highly symbolic no-
tation language for the description of a musical system, a
contemporary graphic score relies mainly on an iconic lan-
guage that couples a rather versatile visual representation
language with an according musical expression.
Therefore the analogy of a Tangible Score or a physical
representation of a musical piece and performance practice
seems to provide an appropriate method for an embodied
musical encoding. This uniﬁcation of score and instrument
provides the representation and control within a single mu-
sical artifact, fully concentrating the performer’s attention
on the interaction with the musical composition in a physi-
cal form.
5. DESIGN ASPECTS
In order to facilitate the design process, we have established
some prior constraints to our deﬁnition of Tangible Scores.
• Diversity. A Tangible Score design should promote a
diversity of forms and materials. There is no unique
identity for Tangible Scores and they can be designed
in any color, form and material.
• Replicability. A Tangible Score should be easy to
share, copy and replicate, transform or adapt. This
suggests the use of rapid prototyping technologies such
as 3D printers, CNC machines or Laser Cutters.
• Modularity. Traditional scores are modular, in order
to allow to use them in parts. Tangible Scores should
oﬀer the possibility of being extended or reduced.
• Embodiment. The musical idea should be embodied
into the instrument as its physical representation It
should be deﬁned through its materiality but not af-
fected by the used technology.
• Discrete and Continuous Control. Our instrument
should incorporate the qualities of an acoustic instru-
ment, with discrete and continuous dimensions.
• Intimate Expression. The instrument design should
promote an expressive performance, allowing a big dy-
namic range of gestures, from subtle tactile interac-
tions to more energetic behaviors.
6. THE TANGIBLE SCORE INSTRUMENT
For the initial implementations of Tangible Scores we de-
cided to create some ad-hoc surfaces and two-dimensional
forms that could function as interfaces for tangible interac-
tion and incorporate a physical score in its conﬁguration.
Proceedings of the International Conference on New Interfaces for Musical Expression
611
This ﬁrst set of instruments should be the proof of concept
of our hypothesis of the physical representation of musical
scores.
We chose wood as material since it is easy to manipulate
and aﬀordable, and is more importantly used commonly for
the design of many acoustic instruments.
Figure 2: Engraved score used as a acoustic inter-
face
Our ﬁrst idea was the incorporation of a graphical design,
therefore we were using a laser cutter to engrave graphic
scores into the surface of the wood. This also allows the
systematic production and easy replication of our designs.
For interfacing to the synthesis layer we decided to inter-
pret these surfaces as tangible acoustic interfaces. The tan-
gible interaction with the tactile footprint of the engraved
score will produce vibrations on the surface that can be
acquired through contact microphones. The variety of pro-
duced sounds provides an enormous vocabulary of signals
that can be used for the direct sound synthesis and for ex-
tracting information that can be used for discrete or con-
tinuous control.
According to Crevoisser [16] tangible acoustic interfaces
have the characteristic of recovering a clear correspondence
between a physical gesture and the sound response produced
by it. It is as well possible to conceive the interface accord-
ing to a desired gesture instead of adapting the gesture to
a given interface.
6.1 Sound Synthesis
After evaluating diﬀerent types of synthesis, we decided
to implement Corpus Based Concatenative Synthesis [18]
(CBCS), since our objective was to facilitate creative mu-
sical expression. When CBCS is applied to a live input
signal, it creates a very intimate relationship between the
physical gesture created and the sonic gesture perceived.
As Tanaka explained in [1] for the design of sonic aﬀor-
dances for new digital instruments, it is important to con-
sider the tendency by audiences to describe sound produc-
tion in terms of causality.
CBCS is a type of granular synthesis with the goal of im-
itating an input signal. Generally CBCS involves two pro-
cesses. First the mathematical classiﬁcation of a database
of samples, extracting speciﬁc descriptors during small win-
dows of time or grains. The objective of this ﬁrst step is
building what it is known as the space of sound character-
istics, a comparative representation of descriptor values in
the database. Second, for creating the synthesized sound,
an input signal is analyzed with the same procedure and the
grains of the corpus with similar descriptors are selected and
concatenated. Usually there are multiple grains matching
the input signal and the user deﬁnes the maximum number
of audio snippets to be used in the synthesis.
The interest of using concatenative synthesis in digital
music instruments was explained and discussed by Schwarz
[19]. Playing a CBCS instrument consists in navigating
along the space of descriptors, or in other words, projecting
the input data on the multidimensional space of the descrip-
tors. In theory, it is possible to pick single or multiple grains
and play them back for creating diﬀerent sonic gestures.
Schwarz introduced a taxonomy of controllers for concate-
native synthesis: positional control, audio driven or multi-
fader controllers. The ﬁrst and third categories show a dis-
connection between physical gesture and sonic response. On
the contrary, live audio control appears as a more natural
way of creating sound gestures. As it is discussed in [16] us-
ing a live sound signal as input ”the ﬁnal objective seems to
be the re-encounter of the acoustic energy of an excited sur-
face with the synthesized sound generated”. In other words,
we can assume causal eﬀects between tangible interaction
and sound produced.
According to the online concatenative synthesis survey
[20] we see that CBCS in combination with live input has
not been explored enough. This motivates our present use
of concatenative synthesis for the design of tangible acoustic
interfaces, in particular after the promising results obtained
in combination with acoustic interfaces [16] and scratch in-
put [8].
6.2 An Engraved Graphic Score as Controller
Engraving the graphic score on the surface of a wooden
panel, was inﬂuenced by artistic wood-carving techniques,
known as xilography, where an image is carved into the
surface of a wooden block. In our case this accomplishes
the following feature set:
• It provides a direct representation of a musical score.
• It inﬂuences the quality of the input sound that feeds
the synthesis. Tactile interaction on dedicated parts of
the engraved surface produces diﬀerent sounds and re-
inforces speciﬁc components of the control signal spec-
trum.
• It conducts and constrains the gestures of the player.
Performers follow intuitively the visual contours of the
engraved forms.
Therefore, the engraved score is designed to have an acous-
tic impact. It will determine the sound signal used in the
concatenative synthesis. For example, if we scratch an en-
graved parallel line pattern, it will create a vibration with a
component that depends on the distance between the lines.
As shown in Figures 3 and 4, the engraved notches deﬁne
diﬀerent spectral envelopes of the signal for diﬀerent parts
of the surface. Thus, we can think of our engraved tangi-
ble score as a kind of complex Idiophone. Since it is played
with our hands, these scratches and ﬁnger attacks are gener-
ally imperceptible outside of the material but can be easily
acquired with contact microphones. We decided to make
an exhaustive analysis of the sound signals produced in the
wooden material. The ﬁrst observation is the spectrum for
each of the wooden pieces, was always centered around the
same frequency, the actual resonant frequency of that par-
ticular piece of wood.
From another point of view, the spectral components are
quite diverse, and diﬀerent envelopes are easily observed.
Therefore, in our synthesis we were going to listen always
textures with grains centered in the same frequency, con-
straint that should be considered for the musical practice.
Proceedings of the International Conference on New Interfaces for Musical Expression
612
Figure 3: Engraved areas analyzed
Diﬀerent solutions can be worked out, like using the rest of
the spectrum to create spectral music or developing mech-
anisms for shifting the frequency detected.
With a standard laser cutter we were able to create sur-
face patterns with depths ranging from microns to 1mm.
Once the ﬁrst scores were engraved, we discovered that the
physical gestures over the surface were naturally induced by
the visual design that we had drawn and cut. After infor-
mally testing these engraved designs with several lab mem-
bers, we noticed that almost all had a tendency to follow
the printed design, through exploration with their ﬁnger-
tips. Although it needs to be studied more accurately in
the future, our design triggered a kind of tangible attrac-
tion, which indicates an additional layer of tactile informa-
tion apart from its visual content.
6.3 Technical Implementation
Our ﬁrst series of instruments were built using 30x20 cm
ﬂat plywood panels with an attached piezo microphone. A
preampliﬁer improved the audio signal sampled at 48KHz
by an RME Fireface UCX. We programmed the system on
a 2.3 GHz MacMini running OS X 10.8.5. After considering
various CBCS implementations, we decided to use William
Brent’s library timbreID [3] for Pure Data (PD).
An important consideration with concatenative synthesis
is the selection of the mathematical descriptor for the anal-
ysis. As Harrison explains in [8], natural gestures such as a
ﬁngernail dragged on a surface produce a speciﬁc spectral
proﬁle, while percussive gestures also contain signiﬁcant in-
formation in a lower part of the spectrum. After analyzing
the spectral components of multiple gestures, we decided
to use the descriptor Mel Frequency Cepstral Coeﬃcients
(MFCC), which represents the spectral envelope of the live
input signal through a bank of ﬁlters distributed along the
spectrum. In particular we decided to use a version called
Bark Frequency Cepstral Coeﬃcients through the PD ob-
ject bfcc∼ where the separation among the bank of ﬁlters is
the Bark weighting parameter. Since it emphasizes the low
frequency components, it achieves a better discrimination
of percussive gestures.
As a starting point we engraved a series of seven designs:
four generative based on parallel lines and another three
graphic scores composed by one of the authors. We soon
discovered that the sonic relation between the live input sig-
nal and its result is highly mediated by the selection of the
sound corpus. Thus, some negotiation was needed between
Figure 4: Frequency analysis for each of the areas
the database of samples and the engraved design, which
also indicates a future investigation on alternative surface
materials.
In a ﬁnal design step we decided to include additional
samples into our database, in order to reﬂect speciﬁc sound
gestures that were not responding as expected in the initial
synthesis experiments.
6.4 Performance Aspects
After having implemented a CBCS for our Tangible Scores
we obtained the following subjective conclusions:
• In terms of expression, the produced sonic gestures
are recognizable and suggest a causal relationship to
the tactile input gestures. The instrument reacts to
very subtle interactions, which makes the performance
process very expressive and intimate.
• The sensation of playing was generally ﬂuid. Latency
is not an issue, since we chose an adequate buﬀer value
of 32 samples. No glitches or dropouts were observed,
the CPU was not used above 65 percent.
Those results show how using concatenative synthesis in
combination with physical scores, is a promising way of cre-
ating expressive instruments. The main constraint of the
acoustic nature of the interface is that the spectrum of the
control signal is usually centered around the resonance fre-
quency of the used material. Therefore we have assumed
this sound characteristic, creating performances and compo-
sitions of spectral music, making use of the multiple param-
eters that concatenative synthesis oﬀers to modulate sound,
such as the range of the used corpus and the grain size.
6.5 Tangible Scores as a Discrete Controller
After having implemented Tangible Scores as an instrument
for concatenative synthesis, we decided to complement its
features using the same interface as a discrete controller.
The objective was extracting speciﬁc information contained
in the sound input for interpreting it as discrete parameters.
We decided to implement some simple machine learning
system, with the objective of recognizing six percussive tim-
bres in real time. For that we also used the timbreID library
for Pure Data implementing the same descriptor, the Bark-
frequency Cepstrum with an audio window of 2048 samples.
The PD object bfcc∼outputs a vector with 47 spectral com-
ponents but only the ﬁrst 20 were analyzed after noticing
that our percussive gestures did not contain diﬀerentiable
components above the spectral middle.
Proceedings of the International Conference on New Interfaces for Musical Expression
613
The process of selecting six candidates for robust recog-
nition was more diﬃcult than expected. Initially six diﬀer-
ent percussive hand gestures were chosen through listening,
and the system was trained playing the same gesture twenty
times. The extracted descriptors were later clustered in 6
sets. After testing the trained system only 40 percent were
really robustly recognized. Therefore, we recorded around
20 diﬀerent percussive gestures that were analyzed with the
bark descriptor. From this process we extracted another
six candidates with signiﬁcant diﬀerences to all the others.
Finally after another similar training process, the rate of
recognition was higher than 90
As every engraved score reacts sonically diﬀerent to the
same physical gesture, we cannot interpolate our results to
other surfaces. This fact makes the process of training the
system quite tedious and indicates the need of a more sys-
tematic procedure.
7. EV ALUATION IN LIVE PERFORMANCE
The ﬁrst evaluation in a concert situation took place at the
Linux Audio Conference 2013 in Graz. The performance,
called ”with intent to defraud” was an homage to Aaron
Swartz. It was an improvisation for two performers of the
ensemble Endphase, one playing a Tangible Score.
Therefore, we prepared an instrument with a speciﬁc de-
sign: an engraved text with a part of Aaron Swartz’s in-
dictment. The sound corpora for the synthesis were three
recordings of English native speakers reading Swartz’s in-
dictment. The system was trained to recognize four per-
cussive gestures that were used for changing parameters of
the synthesis. Those recognized values were sent via Open-
SoundControl (OSC) to the second performer, driving the
algorithms in charge of creating a sonic counterpoint to the
Tangible Score interface. All the sounds were spatialized in
a studio equipped with an ambisonics dome of 24 speakers.
In this concert situation, playing the Tangible Score in-
strument was very intuitive, oﬀering many expressive possi-
bilities. The intimate connection between gesture and sound
inspired the musical ﬂow during the performance. It was
quite easy to achieve a large dynamic range, from delicate
grains to loud and dense textures. The rate of recognition
of discrete gestures decreased to around 70 percent during
the concert because the on-stage situation inﬂuenced the
performer, who was not able to exactly repeat the trained
gestures. Nevertheless the false detections didn’t disturb
the musical plan, since we prepared the improvisation for
embracing that anticipated situation.
8. CONCLUSIONS & FUTURE RESEARCH
We have studied the mediated relation between composers
and new digital instruments, proposing methodologies of
work and approaches to the issues of composing for them.
We have built a ﬁrst series of instruments based on en-
graved designs and explained the possibilities of using these
surfaces as acoustic interfaces. We have explored the per-
spectives that these intuitive, modular and expressive in-
struments can provide in combination with concatenative
synthesis and machine learning. After having implemented
and evaluated the instrument in a concert situation, several
research questions emerged:
• What are the aesthetic, cultural and musical implica-
tions of using sculptural objects as scores?
• Which materials and shapes are most suitable for the
design of Tangible Score instruments?
• Which other sensor and synthesis technologies can be
used for the technical realization of Tangible Scores?
9. REFERENCES
[1] A. Altavilla, B. Caramiaux, A. Tanaka, ”Towards
Gestural Sonic Aﬀordances”. Proceedings of New
Interfaces for Musical Expression, pp. 61-64, 2013.
[2] M. Berghaus, ”Some Ideas for Three-Dimensional
Musical Scores”, Leonardo Music Journal Volume 21,
pp. 7-8, 2011
[3] W. Brent, ”A Timbre Analysis And Classiﬁcation
Toolkit For Pure Data”, International Computer
Music Conference Proceedings, 2010.
[4] M. Burtner, ”Composing for the (dis)Embodied
ensemble: notational systems in (dis)Appearances”,
Proc. of NIME Conference, Singapore, 2003.
[5] J. Chadabe, ”Interactive Composing”, Computer
Music Journal, VIII:1, 1984. Republished in Curtis
Roads, ed., The Music Machine. MIT Press, 1989.
[6] P. Cook ”Principles for Designing Computer Music
Controllers”, ACM SIGCHI New Interfaces for
Musical Expression (NIME) Workshop, Seattle, 2001.
[7] Gagne, C. ”Interview with Laurie Spiegel”. In
Soundpieces 2: Interviews With American Composers.
The Scarecrow Press, Inc. N.J., pp. 295-333. 1993.
[8] C. Harrison, S. E. Hudson, ”Scratch Input: Creating
Large, Inexpensive, Unpowered and Mobile ﬁnger
Input Surfaces”. Proceedings UIST ’08. ACM, 2008.
[9] H. Ishii, B. Ullmer, ”Tangible bits: towards seamless
interfaces between people, bits and atoms”.
Proceedings of CHI’97 ACM SIGCHI, 1997.
[10] S. Jord` a, M. Kaltenbrunner, G. Geiger, R. Bencina,
”The reacTable”, Proceedings of the International
Computer Music Conference, 2005.
[11] R. Kuivila, ”Open Sources: Words, Circuits, and the
Notation/Realization Relation in the Music of David
Tudor”, Presented at the Getty Research Institute
Symposium, ”The Art of David Tudor”, 2001.
[12] A. Lucier, ”Origins of a Form: Acoustic Exploration,
Science and Incessancy”. Leonardo Music Journal 8,
pp. 5-11, 1998.
[13] T. Magnusson, The musical score: the system and the
interpreter In: Proceedings of ISEA, 2011.
[14] M. Mathews, ”The Radio Baton and Conductor
program, or: Pith, the most important and least
expressive part of music”, Computer Music Journal,
15:4, 37-46, 1991.
[15] H. Miyashita. Graphic Score Animation for Two
Pianos, Feb. 28th, 2003. Toyama shimin plaza, Japan.
[16] P. Polotti, A. Crevoisier, ”Acoustic Localization of
Tactile Interactions for the Development of Novel
Tangible Interfaces”, Proc. of the 8th Int. Conference
on Digital Audio Eﬀects (DAFX-05), 2005.
[17] N. Schnell, M. Battier, Introducing Composed
Instruments: Technical and Musicological
Implications, Proceedings of NIME, 2002.
[18] D. Schwarz, ”Concatenative Sound Synthesis: The
Early Years”, Journal of New Music Research, Mars
2006, Vol. 35, p.3-22, 2006.
[19] D. Schwarz, ”The Sound Space as Musical Instrument:
Playing Corpus-Based Concatenative Synthesis”, New
Interfaces for Musical Expression (NIME), 2012.
[20] D. Schwarz, ”Corpus-Based Sound Synthesis Survey”,
IRCAM IMTR website, http://imtr.ircam.fr/imtr/
[21] B. Verplank, ”Interaction Design Sketchbook”, online
publication 2009.
[22] M. M. Wanderley and N. Orio. ”Evaluation of input
devices for musical expression: Borrowing tools from
HCI”. Computer Music Journal, 62-76, 2002.
Proceedings of the International Conference on New Interfaces for Musical Expression
614