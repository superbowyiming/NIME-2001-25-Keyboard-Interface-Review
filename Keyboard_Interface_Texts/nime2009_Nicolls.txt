Twenty-first Century Piano 
 
 
Sarah Nicolls 
Brunel University 
Kingston Lane 
Uxbridge, UK 
sarah.nicolls@brunel.ac.uk
Abstract 
“The reinvigoration of the role of the human body” - as 
John Richards recently described trends in using 
homemade electronics to move away from laptop 
performance [1] - is mirrored in an ambition of 
instrumentalists to interact more closely with the electronic 
sounds they are helping to create. For these players, there 
has often been  a one -way street of the ‘instrument feeds 
MAX patch’ paradigm and arguments are made here for 
more complete performance feedback systems.  
Instrumentalists come to the question of interactivity with 
a whole array of gestures, sounds and associations alrea dy 
in place, so must choose carefully the means by which the 
instrumental performance is augmented.    Frances -Marie 
Uitti [2] is a pioneer in the field, creating techniques to 
amplify the cellist’s innate performative gestures and in 
parallel developing t he instrument.  This paper intends to 
give an overview of the author’s work in developing 
interactivity in piano performance, mechanical 
augmentation of the piano and possible structural 
developments of the instrument to bring it into the twenty -
first century. 
Keywords: sensor, gestural, technology, performance, 
piano, motors, interactive  
1. Introduction 
There is currently much interest in how the piano might 
move forward in time.  From practitioners such as Andrea 
Neumann [3] (see end picture 1) ,  - who brought the inside 
of the pia no out with the help of piano builder Bernd 
Bittman - through to piano builders such as Pierre Malbos 
with his Piano Baschet  (see end picture 3) , artists are 
attacking the cumbersome and revered nature of the 
instrument, whilst wishing to retain something of the 
renown beauty or mechanics of the instrument.  
My own research works in several directions at once: 
separate strands that can be explored, each with its own 
context and history of research but able to be brought 
together
 
into
 
one
 
overall
 
project.
  
An
 
example
 
from
 
each
 
strand is given here, with a brief description of their 
application in making more technologically integrated 
piano performances. 
The first area of investigation is sensor technology 
(movement, light and now bio -sensors) in live 
performance.  Secondly, augmenting the mechanics of the 
piano is briefly discussed with the addition of motors 
directly to the instrument and finally, why and how a 
possible re -structuring of the piano might be pursued, to 
better enable playing of the entire inst rument using well -
established contemporary techniques.   
2. Performative feedback 
The point at which acoustic instrumental performance 
meets technology throws up many questions.  We are all 
familiar with traditional instrumental paradigms – I play 
this, you h ear this.  By adding electronic sound, this 
relationship is immediately complicated.  I play this, you 
hear this but also that – which may or may not reinforce 
what was played acoustically.  In live electronics, a 
performer’s interaction with a computer has often been one 
of feeding the computer – the familiar instrument into 
MAX/MSP patch and electronic sound out of the speakers 
approach.  Emmerson [4], Harris [5] and Rebelo [6] have 
all written eloquently on this subject.  
This one-way street is not only limited but also creates 
separation of acoustic and electronic, producing potentially 
conflicting directions of the sources of sound.  Of course, 
the performer can respond to what the computer does to 
their playing: adjusting dynamics, articulation, even t empo 
but the fact that the response is pre -programmed means 
these adjustments have limited power in really changing 
the resulting response.   
The use of MIDI pianos has attempted to make this 
street two -way and back in the 80s Phillippe Manoury’s 
Pluton [7 ] addressed this issue with success.  So how can 
we take this two -way street further: to create a circular 
system where the piano feeds the processing and in return, 
the processing feeds the pianist’s physical gesture – by 
allowing the processed sounds to be manipulated by the 
pianist, for example through the use of sensors .  The point 
here is that pre -composed responses can still be written but 
the final interpretative moment and subtlety rests with the 
instrumentalist: ‘Prospero -like, the individual perfo rmer 
might in practice control all aspects of the piece from the 
largest to the smallest, both local and field’ [4].  This 
vision works on the traditional instrument paradigm, 
proved over hundreds of years to be a powerful 
communicative mechanism and it wa s with these thoughts 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies 
are not made o r distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists 
requires prior specific permission and/or a fee.  
NIME09, June 3-6, 2009, Pittsburgh, PA 
Copyright remains with the author(s).  
NIME 2009203
that I began to look at developing the pianist’s 
‘performance environment’. Although I have 
commissioned several pieces considering this 1 here I have 
limited my examples to those that use sensor technology.  
3. Sensor work 
The first examp le given here is a piece by Jonathan Green 
[8], using light sensors inside the instrument and a webcam 
on the side of the keyboard (see Figure 1). 
 
Figure 1. Piano & Lamp set -up 
Using a lamp clipped to the instrument, the pianist first 
interacts with the webcam by gesturing towards and away 
from, into and out of its field of vision.  This activates the 
webcam to trigger pre -recorded samples.  Later, the lamp 
is picked up by the pianist and used to light up the inside 
of the piano to activate two light sens ors placed inside. 
This theatrical treatment of the instrument, which 
acknowledges and explored the inside of the piano so 
imaginatively, gives the instrumental performer the chance 
for a similar relationship with the computer sounds as with 
their instrume nt – tactile, gestural, physically immediately 
responsive. What is dramatically communicative is the 
relationship of light, gesture and sound and the very real -
time responsiveness of the system.  
The second piece by Green referenced here was part of 
an AHRC-funded project 2 into extending the repertoire for 
piano and live electronics.  This piece 3 used accelerometers 
on each hand (o ther sensors such as a flex sensor on the 
right elbow and a compass 3D sensor, which read position 
relating to a calibrated point  were rejected as too complex 
for the amount of time available) with the research 
question being ‘how can we meaningfully map pianistic 
gesture to processing?’.  We established a research method 
to collect data: making films of my playing specific 
notated gestures on the piano whilst wearing the sensors.  
In this way, visual and sensor information data was 
captured in a measurable way, to allow notational and 
gestural events to be compared.  
The aim here was to create total harmony between 
pianistic gesture,  sound and resulting electronic sound so 
                                                             
1 For example pieces by Larry Goves, Pierre Alexandre Tremblay  
2 Other commissions from Professor Richard Barrett, Professor 
Michael Clarke, Reader Michael Edwards, Larry Goves  
3 Green. J. Into Movement (2008) Available from the composer  
the system was kept simple: the accelerometers were 
controlling the pitch bend of the live sound produced at 
that exact moment.  The result was an instinctive and 
intuitive system mapped to innate pianistic gestures , which 
were simply amplified to create more ‘effect’.  However, it 
was also discovered that the gestures were so innate that 
audiences often found it hard to perceive how the sensors 
affected the sound. 
3.1  Hat sensors 
The next sensor investigations were  therefore deliberately 
made much more obvious.  The example here is given 
from work  with a group of programmers 4 from the Centre 
for Digital Music research centre at Queen Mary’s, 
University of London [9] (the research was hosted by 
PianoLab - an accumula tive research space enabling easier 
access to pianos and computer technology in one working 
space). 
After discussion, it was decided to place the sensors in a 
hat, as this would enable both independence of pianistic 
gesture from processing control and also  add an element 
that could be used to explain more theatrically what was 
being heard – the relationship between live piano and 
computer processing. 
The sensor used was the icube Gforce 3D-3 v1.1, which 
‘senses dynamic acceleration (or deceleration) and 
inclination (tilt, ie. acceleration due to gravitation) in three 
dimensions simultaneously’5.  The precise position data 
from the sensor allowed  detailed control through tilting the 
head at different angles, following trajectories and making 
sudden movements to create acceleration data.  As a device 
for a pianist it worked well – leaving all other elements of 
the pianists’ technique untouched but displaying the 
interactivity to the audience by the most visible, perhaps 
most demonstrative part of the body.  We worked to map 
the processing so the sounds were communicatively 
embodied in character or range by the gestures.  
3.2 Bio-sensors 
Taking the idea of physically entwining processing control 
and piano playing, the next example is of work with 
another icube sensor,  the bio-flex 50 v1.1 .  The question 
here is: how much is it really possible to use muscles to 
enact two different yet inseparable control functions?  
With the webcam and the hat, the pianism and processing 
control can be separated; conversely, with the 
accelerometers placed on the hands, the gestures of piano 
and computer control are innately linked.  The bio -sensors 
give a new challenge: the muscle movements needed to 
give data to the sensors are almost anti -pianistic – to get 
                                                             
4 Adam Stark, Andrew Robertson, Kur t Jacobsen, Samer 
Abdallah; commissioned by Nick Bryan -Kinns 
5 Infusion systems, Accessed 10 April 2009 
<http://infusionsystems.com/catalog/product_info.php/products
_id/157>  
204
the strongest readings, Prof essor Atau Tanaka 6 has already 
discovered over several years that they require tension 
either extending certain digits or an almost 90 degree 
flexing back of the hand (see figure 2). Researching this 
with Tanaka, initial studies were made into whether note s 
on the piano could be activated in a subtle enough way 
whilst also activating the sensors. The findings so far, are  
  
Figure 2. Atau Tanaka demonstrates the bio -sensors  
that the system becomes a kind of conversation between 
the pianistic movements and  the sensor -related ones, with 
this poetic relationship giving the impression of an almost 
breath-like quality to the playing.  
4. Augmenting the instrument 
Whilst examining methods of interaction with electronic 
sound, parallel investigations were made to exa mine 
possible augmentations of the mechanics of the piano.  
This was for two reasons: if the resulting sound was being 
amplified by electronic responses, why not make these 
electronic responses also control acoustic results and 
secondly, if we were looking  at augmenting the pianist’s 
control of processing, why not also attempt to augment the 
direct playing of the instrument.   
Motors were chosen as easily controllable electronic 
devices and starting with small motors, t he initial phase of 
this work was unde rtaken with Will Scrimshaw 7 who 
wired an Arduino board to nine normal DC motors and one 
gearhead motor (see figure 3).  The motors were initially 
programmed in Supercollider to run only in pre -set 
routines and also to respond to a live FFT analysis of the 
piano. The effect of the latter produced interesting results, 
creating a perpetually self -playing system: quickly 
accumulative – motors hearing their assigned frequencies 
constantly firing – an interesting application was found 
using two pianos: by using t he sound of one piano as a 
remote control (sending microphone information to the 
computer) we could activate the motors playing another 
piano.  
Pursuing more exact control by the performer, with 
the team from Queen Mary’s, more precise control 
functions - such as start, stop and speed control - were  
                                                             
6 Chair of Digital Media and Director of Culture Lab, a research 
centre at Newcastle University, UK  
7 A PhD student at Culture Lab, Newcastle University  
 
Figure 3. DC motors in the piano.  
established using a standard MIDI interface.  Extensive  
work on scales of predictability previously undertaken by 
Samer Abdallah was also used to create a library of 
rhythmic patterns for the motors.   A bank of a total of 
ninety-nine patterns thus allowed the performer to move 
through a quite extensive score, with increasing levels of 
unpredictability built in 8.  
5. Re-structuring the Piano 
Playing inside the piano has been notated from the early 
twentieth century with early famous examples being In a 
Nutshell ( 1916) by Grainger  and  Aeolian Harp  and The 
Banshee (1923, 1925) by Henry Cowell.  Despite the quite 
frequent call by composers since - and especially currently 
- for pianists to access the inside of the instrument in some 
way whilst playing (Crumb, Kagel, Orff, Takemitsu, 
Wolfgang Mitterer, Richard Barrett to name only a few), 
the physical discomfort and logistical difficulties of this 
has not been significantly challenged by commercial piano 
makers.  The problems begin with the obvious discomfort 
of standing up and leaning inside the instrument and 
extend to more subtle issues such as trying to pedal, 
maintaining any kind of pianistic r elationship with the 
keyboard (ie with one’s arm at the correct angle), being 
unable to still read the music from the stand in its intended 
position.  Further layers of this problem are that technically 
it is difficult to reach very far into the instrument  and even 
more importantly perhaps, the complete disassociation for 
the audience from the playing – as if the pianist is 
‘disappearing under the bonnet of a car’9.    
Thinking about how best to tackle the main issue of 
wanting to access both the strings an d the keyboard at the 
same time, my research led to deciding to up -end the piano 
(see Figure 4), and in doing so, reverting to an old piano 
shape such as the Giraffe piano.  The issues mainly 
concern having to revert to having to use an upright piano 
action – seemingly a step backwards – and also 
understanding the acoustic changes.  Initially it seems that 
the instrument actually projects more effectively, as the 
                                                             
8 A paper written by the team from the Centre for Digital Music 
and Sarah Nicolls has recently been  submitted to the Leonardo 
Music Journal: ‘Who’s in charge? Interaction in Performance’. 
9 A comment made to me after a concert.  
205
soundboard is directly facing the audience.  What is key – 
and crucially different to existing upright pianos - is that 
the strings are above the keyboard, allowing easy access.  
From an interactivity perspective, advantages are the 
audience being able to see gestures clearly and the gestures 
to be unhindered by logistical issues. Being able to acces s 
the keys and strings at once opens up the potential for the 
development of existing techniques and for a new gamut of 
techniques with string- and key- play interaction. 
 
Figure 4. Newly structured instrument  
6. Future developments: PianoLab 
Designed as an accumulative research space, the PianoLab 
will run for set periods of time (minimum one month) in 
different countries before hopefully finding a long -term 
home.  The very nature of the immobility of pianos is one 
of the driving forces for researching new o ptions of 
structural design but meanwhile, pianos remain huge 
unwieldy pieces of furniture.  The PianoLab resource 
provides an invaluable space where instruments and 
programmers can co -exist research with real -time 
investigative methods.  A comparable mode l is Uitti’s 
Augmenting the Cello project, hosted at CNMAT in 2006 
[10].   It is also the accumulative nature of the space that is 
crucial – each development is there to be further explored 
by the next collaborator, thus creating a fertile research 
framework.  This has already been proved by several 
phases of the lab, creating a sense of momentum. In my 
next research project we will also build a professionally 
regulated piano on the same structural lines, also 
incorporating MIDI elements.  
7. Acknowledgments 
Thus research has been funded by various bodies in the 
UK: the Arts and Humanities Research Council, the Brunel 
Research Innovation and Enterprise Fund and the Artist in 
Residence commission from the Centre for Digital Music, 
funded by the Engineering and Ph ysical Sciences Research 
Council. 
References 
[1] Richards, J. “Getting the hands dirty”, Leonardo Music 
Journal , vol. 18, pp. 7-8, 2008. 
[2] Frances-Marie Uitti, Accessed 15 Jan 2009, 
<http://www.uitti.org/> 
[3] Andrea Neumann,1 5 Jan 2009, 
<http://www.japanimprov.com/profiles/aneumann/>  
[4] Emmerson, S. ‘Local/field’: Towards a Typology of Live  
Electroacoustic Music”, in Proc. of the International 
Computer Music Conference: The Human Touch (ICMC), 
1994, pp. 31-34.   
[5] Harris, Y. (2006 ). Inside -out Instrument. Contemporary 
Music Review Vol. 25, No. 1/2, February/April 2006,  pp. 
151 – 162 
[6] Rebelo, P. “Haptic Sensation and Instrumental 
Transgression”, Contemporary Music Review 25:1/2, 
(Feb/Apr 2006), pp. 27 – 35 
[7] Philippe Manoury, 15 Jan 20 09, <music.ucsd.edu/faculty/>  
[8] Green. J. Piece for Piano & Lamp  (2005) Available from 
the composer, currently based at the Centre for Life 
Sciences, Cambridge 
[9] Commission for (re)Actor (BigDog Interactive) given by 
the Centre for Digital Music at Queen Mary’ s, Univ. of 
London <http://www.elec.qmul.ac.uk/digitalmusic/ > 
[10] Zbyszyński M. “Augmenting the Cello” (Freed, Adrian, 
Francis-Marie Uitti, and Michael Zbyszy ński: NIME Paris 
2006)
 
   
    
     
  
End pictures: 1. Andrea Neumann with her ‘inside piano’;  2. Piano Baschet-Malbos by Pierre Malbos ;  3. Kathy Hinde’s 
installation piano, using motors synced with projections;   4. Neo -Bechstein (piano made in the 1930s): close -up of pick ups 
206