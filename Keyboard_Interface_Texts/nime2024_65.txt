Challenges and Prospects in Remote Cross-cultural
Musical Interface Design
Tim-Tarek Grund
Dept. of Music Acoustics
mdw – Universit¨at f¨ur Musik
und darstellende Kunst Wien
Vienna, Austria
grund@mdw.ac.at
Luong Hue Trinh
Independent Artist
Accra/Paris/Hanoi,
Ghana/France/Vietnam
huetrinh.luong@gmail.com
Alex Hofmann
Dept. of Music Acoustics
mdw – Universit¨at f¨ur Musik
und darstellende Kunst Wien
Vienna, Austria
hofmann-alex@mdw.ac.at
ABSTRACT
Roles in the context of live-electronic music performance are
often overlapping. We used a cross-cultural collaboration
between a Vietnamese live-electronic composer-performer
and a German instrument maker to study the development
of roles. We followed the approach of building a digital mu-
sic instrument inspired by existing acoustic instruments and
conducted a case study with the task of developing a gran-
ular effect sample player, the Grain Bau, inspired by the
Vietnamese monochord zither đàn Bầu. We analyzed the
milestones, tasks and remote collaboration strategies and
assessedthedepthofparticipation.Wefoundthatin-person
collaborative work tended to dissolve role definitions, while
remote working emphasised them. We examine our strate-
gies for remote working and discuss the influence of gender
on our role development.
Author Keywords
Gestural repertoire, Practice-based research, Collaboration,
Roles, Vietnamese instruments, Granular synthesis, Novel
controllers
CCS Concepts
•Human-centered computing → Collaborative and social
computing; •Applied computing→ Sound and music com-
puting; Performing arts;
1. INTRODUCTION
In the context of live-electronic music performance, respon-
sibilities and activities of roles are often overlapping. This
conflation of roles is in contrast to Western art music, where
a clearer distinction between composer, performer, and in-
strument maker exists [9]. This is of particular interest to
researchers: Fiebrink [6] uses the term "composers" for in-
strument makers in order to address that instrument devel-
opmentormappingareprocesses,thatgiveshapetomusical
ideas. Emerson and Egermann interviewed performers, that
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’24, 4–6 September, Utrecht, The Netherlands.
build their own digital music instruments (DMI) [4].
In the field of DMI several approaches for gestural input
of instruments have been proposed, drawing from embodied
cognition [5], acousmatic music practice [11], and physical
modeling [2]. Another approach, that has been utilised in
various DMIs, is drawing inspiration from existing gestural
repertoire of acoustic instruments [1, 10, 12]. Modeling the
full extent of possible motion as well as some of the un-
derlying physical affordances of the instrument serves two
purposes: On one hand it allows for skill transfer from the
source instrument, on the other hand it implies a strong
communicative ability. Findings from the field of embodied
cognition imply that listeners are able to assess performer
skill based on the causal relationship between action and
sound production [3, 9].
Following this approach, we present the process of de-
veloping the Grain Bau, a granular effect sample player,
whose gestural input is inspired by the action repertoire of
the Vietnamese monochord zither đàn Bầu (Figure 1). The
Grain Bau setup consists of a gestural interface (Figure 2),
an auxiliary device, as well as a graphical user interface,
that contains the sound production code, written in Pure
Data (PD). It has been developed in a collaborative effort
between an instrument maker (the first author) and a Viet-
namese composer-performer (the second author). Over the
course of several months, there is a collaborative effort with
thegoalofperformingacompositionwrittenforanewDMI.
Tasks and milestones of this project are recorded and ana-
lyzed towards identifying roles and causes for role changes.
To better understand the extent of the collaboration, we as-
sess the depth of participation of individual working phases
using the participation framework proposed in [8]. Further-
more, we reflect on challenges and prospects during the re-
mote cross-cultural collaborative process.
2. CASE STUDY
As a case study, we initiated a collaboration between a Viet-
namesecomposer-performerandanGermaninstrumentma-
ker with the goal of developing a DMI and performing a
composition with it in a concert. The project lasted from
a kick-off meeting in April 2023 to a concert performance
in October 2023. The result of this collaborative effort is
the Grain Bau, the score for the composition, and a con-
cert performance. The duration of this case study has been
divided into four main work phases outlined in Figure 3.
2.1 Planning
During the first week-long in-person visit of the second au-
thor to our lab, the groundwork for the case study was laid
out. In a brainstorming session, a variety of ideas for a DMI
were discussed, as well as thoughts about remote collabo-
Figure 1: The đàn Bầu, a Vietnamese monochord zither. Its
gestural repertoire serves as the foundation for our DMI.
Figure 2: The gestural interface of the Grain Bau is inspired
by the đàn Bầu. On the top right: A close-up of the cart with
distance sensor, fader potentiometer, and capacitive copper
plate is shown.
ration. We assigned the role definition of a composer and
performer to the second author and the instrument maker
role to the first author, who has permanent access to the
music acoustics lab at mdw.
One of the options discussed was building or augment-
ing a traditional Vietnamese instrument, such as the đàn
Tranh or the đàn Bầu. Potential designs of the signal path
and sound FX (e.g. reverb, randomization) were discussed.
Of importance for the development of the DMI were the
option of including a granular effect section, a front panel
with control elements, and a bending bar to control a pitch
transformation.
Due to the limitations of working remotely over some
partsofthecollaboration,itwasdecidedtodevelopagraph-
ical user interface (GUI) alongside the physical gestural in-
terface so that progress could be evaluated without having
the physical interface present. PD was designated as the
platform for sound synthesis and GUI design. During this
phase we also acquired a đàn Bầu and talked to Ngô Trà
My, an expert đàn Bầu performer, to gain insight into the
instrument tradition and to learn basic playing technique.
2.2 Prototyping
The prototyping phase was completely remote due to the
touring schedule of the second author. It started with ex-
periments in feedback synthesis. During this phase, a ma-
jor shift towards alternative sound production occurred. It
was recognized that for a successful remote collaboration
the sound production method needed to be contained in-
the-box. Feedback synthesis was impractical, since feedback
instruments require interfacing points in the form of micro-
phones/pickups and speakers/exciters. Thus it was decided
to focus on sample-based granular synthesis instead, since
a granular effect section was already planned for the pro-
cessing of the feedback instrument. It also opened up the
possibility of using recordings of the đàn Bầu as material
for the sound production ensuring the ability to still incor-
porate the original instrument’s sound.
At this point, the setup of the DMI consisted only of the
gestural interface and the GUI in PD. The gestural inter-
face (shown in Figure 2) is the part of the DMI, that is
based on the gestural repertoire of the đàn Bầu. The đàn
Bầu (in Figure 1) is a monochord zither, whose single string
is tied to a loop and hooked on a bending rod on one end.
Traditionally, it is played by plucking the overtones with a
pluck, while the other hand controls string tension using the
bending rod in order to allow for pitches outsides the har-
monic series and ornamentation. The overtones are excited
by resting the plucking hand the string and plucking from
below by moving the whole arm upwards. The designed ges-
tural interface emulates these gestures. Erdem et al. classify
sound-producing actions into excitation actions and modifi-
cation actions [5]. The Grain Bau delegates excitation tasks
to the right hand: When moving the fader on top of the cart
(shown in the top right in Figure 2) across a threshold (a
virtual string to be plucked), a looped sample playback is
triggered. A distance sensor measures the position of the
cart. The sample playback starts from a playback position
relative to the distance of the cart to the left end. The left
handisassignedtomodifyingthepitchbybendingthepitch
rod, which is captured using a rotary potentiometer with a
built in spring.
2.3 Polishing
Thepolishingphasewascharacterizedbyfrequentexchanges
of PD patches, feedback and feature requests between first
andsecondauthor.Fourmaindevelopmentswere:1)Adding
sustaining and looping functionality for sample playback;
2) inclusion of a MIDI keyboard as an auxiliary device into
the formal setup; 3) a remote-playable version of the DMI;
4) change of performer role.
Previously, the DMI would play sounds with a fixed du-
ration once plucked (one-shot). However, the possibility of
continuing the sound was requested in order to explore in-
teresting parts of the samples once encountered. This led to
the implementation of a sustaining feature (referenced as
"hold"in Table 1 and in the composer-performer’s notes in
Figure5).Wheneverthepluckinghandrestsonthecart,the
sustain is triggered, which draws further inspiration from
the plucking motion of the đàn Bầu. A looping mechanism
was implemented to allow layering of different samples.
During the mapping process it became evident that cer-
tainparametersneededtobechangedquicklytofindsample
positions with satisfying sonic responses. This led to a map-
ping on an auxiliary device (Arturia MiniLab Mk II). Knobs
were mapped to synthesis parameters and keys to switching
between samples and starting or stopping the loop function.
In the beginning of the planning phase, when different DMI
ideas were discussed, the notion of having a dedicated con-
trol panel for sound parameters was evaluated highly by
2.2 Prototyping  
(2)
2.3 Polishing  
(3)
2.4 Practice & Perform 
(4)
Kickoff Meeting 
14.04.2023
First Prototype 
19.05.2023
Zoom Meeting 
16.08.2023
Second in-
person meeting 
14.09.2023
Concert 
13.10.2023
APR MAY JUN JUL AUG SEP OCT
2.1 Planning 
 (4)
In-person 
Remote
Switch from Feedback to 
granular synthesis 
27.07.2023
Switch of 
performer role
Figure 3: Timeline of the collaboration with important milestones (top) and relevant working phases (bottom) of the case
study. The numbers below the working phases refer to mean ratings by first and second author of the depth of participation
according to the participation framework in [8].
the second author. Later, the exploration of synthesis pos-
sibilities became an even more important part of the DMI’s
character, when turning knobs was extensively tested as a
performance technique. It was decided to merge gestural
interface, GUI and auxiliary device into one setup.
Since the first and second author were not situated in
the same country, a method had to be devised, that al-
lowed for testing features without access to the gestural in-
terface. It was decided to use a MIDI keyboard controller as
a substitute, since these controllers are highly standardized,
available, and often come with built-in pitch bend interface
elements.
Also due to the remote collaboration process, the sec-
ond author only had limited access to the gestural inter-
face. While the remote MIDI keyboard version was intended
to allow an assessment of the synthesis process, it did not
properly translate the gestural repertoire of the gestural in-
terface. This made it difficult for the composer-performer
to accustom herself to the DMI, in contrast to the instru-
ment maker, who continuously attuned to, evaluated, and
adjusted it. Therefore, we changed the role assignment of
the performer from the second author to the first author
one month before the concert.
2.3.1 Playing technique & sound material
Thesecondin-personvisitalsofallswithinthisphase.Itwas
mainlyconcernedwithtestingplayingtechniquesandsound
material. In the beginning, different samples were grouped
together by the instrument maker and the composer. Over
the course of the stay, these were tested, and processing
decisions were made: which samples would be included or
removed from the list, which were deemed too homogeneous
and subsequently merged together and which ones need fur-
ther editing. Initially, the selection of sounds was driven by
the intention of establishing a structural framework for the
composition. This framework aimed to showcase the DMI’s
capabilities, progressing from simpler effects and techniques
to more intricate ones, encompassing both single and com-
plex sounds. However, a shift in perspective occurred during
the second in-person meeting following numerous tests. The
revised approach prioritized the identification and inclusion
of the most expressive sound characters. This shift was mo-
tivated by the recognition that a DMI should not solely
emphasize roughness, powerfulness, and loudness. Instead,
it should also embrace qualities of delicacy, smoothness, and
softness. Consequently, some sounds underwent refinement,
involving cutting and merging with others to broaden the
overall sonic landscape.
Figure 4: The Grain Bau gestural interface and auxiliary
device played by the first author during the premiere of
"How can I be tender?"© Stephan Polzer, modified by the
first author.
Some of the explored techniques focused on controlling
the pitch playback using the pitch rod mechanism. Glis-
sando,vibratoandornamentalmotionswereexamined.Tech-
niques for interacting with looped material were also inves-
tigated. Since looped material did not require further input
on the gestural interface, techniques for interacting with
the knobs on the auxiliary device were tested. One example
of this is the simultaneous control of loop grain size and
loop reverb by gliding with the hands and arms alongside
one of the sides of the knob in order to turn them faster
than with regular finger-turning. Notes on the interplay of
techniques and sound material can be found in Figure 5,
alongside commentary on which samples should be further
processed.
2.3.2 Final implementation
The final setup for the Grain Bau consists of three ele-
ments: A custom-built gestural interface, an auxiliary stan-
dard MIDI device with keys/buttons and faders/knobs, and
a GUI in PD. PD patches, sound material, and supplemen-
tary material can be found on Github[7]. A picture of the
Grain Bau during performance is shown in Figure 4. A map-
ping of control elements to synthesis parameters is shown
in Table 1.
Gestural Interface
Name Input Description
Pluck
Fader
poten-
tiometer
Fader mounted on top of the cart.
When crossing threshold, a note is
sent with a velocity according to
the speed. Velocity controls grain
size.
Pitch
rod
Rotary
poten-
tiometer
Stick mounted on a rotary poten-
tiometer with a spring. Transposes
one octave down or up.
Hold
Capaci-
tive
plate
When held, blocks "note off" and
"pitch bend" messages to last
played voice. When released, sends
a "note off" to all voices.
Distance Distance
sensor
Measures the distance from cart to
end and controls the sample play-
back position.
Auxiliary Interface
Name Input Description
Vol
Loop Knob Controls volume of loop section.
Grain
Loop Knob Controls grain size of loop section.
Rev
Amount Knob Controls amount of reverb
D/W
Loop Knob Controls dry-wet reverb mix of
loop section.
D/W
Direct Knob Controls dry-wet reverb mix of di-
rect signal.
Stereo
Diff. Knob
Controls size of random values
added to grain size of left and right
channel
Pitch
range Knob Controls range of pitch rod.
Rand
grain
size
Knob Controls size of random values
added to grain size.
Rand
grain
pos
Knob Controls size of random values
added to grain position.
Loop Key Starts/stops Loop.
Table 1: Mapping of input control elements to synthesis
parameters.
In addition to the interface elements presented above, the
final implementation of the gestural interface includes a ca-
pacitive copper area (shown in top right in Figure 2), that
is used for detecting, whether a hand is resting on it. If a
hand is detected, the last played sample is sustained until
the hand is lifted off the copper area.
In the beginning, the use of an auxiliary device was em-
ployed to accommodate the need for remote collaboration
tools and for fine-tuning synthesis parameters. In its final
implementation, the auxiliary device handles changing sam-
ples, controlling the looping process, and adjusting FX pa-
rameters. However, the remote collaboration aspect was al-
ways maintained, so it is possible to play the Grain Bau
without the physical gestural interface.
The GUI patch was realized in PD and contains the map-
ping and sound synthesis code. Sensor data are displayed,
such as the position of the cart along the rail in reference
to the sample playback position. The GUI also displays the
sample waveform and parameter states for orientation.
Figure 5: Screenshot of composer’s notes on sound material,
playing technique and further processing.
Figure 6: The first page of the composition "How can I be
tender?", written by the second author for this project.
© Stephan Polzer
2.4 Practice & Perform
During this phase, which started remotely, most of the ac-
tivities related to concert preparations. Based on the com-
ments provided in Figure 5, a new sound bank was created
by the second author, reducing the number of samples down
to12. A firstversionofthescorefor theconcert composition
was presented, the score was then reworked several times
(see final score in Figure 6). One week before the concert,
the third in-person meeting started, where the score was ex-
plained. In a trial-and-error fashion, the composition called
"How can I be tender?" was played by the first author with
feedback on the artistic vision by the second author. Notes
were taken on the score, which influenced later iterations.
A meta-document containing waveform representations of
each sound material was created by the first author, where
the important parts in each sample were marked in order to
have a fixed reference point for practicing. The collabora-
tion concluded with a concert at Klangtheater/Future Art
Lab, mdw1 in October 2023.
1A video of the performance is shown here:
https://www.youtube.com/watch?v=JkPikiA5B68
3. REFLECTIONS AND TAKEA WAYS
Inthispaperwepresentedacross-culturalremotecollabora-
tive artistic research process to develop a new DMI, a score
and a live-electronic music performance. We have three key
takeaways: 1) remote working was challenging as it tended
to emphasise role definitions; 2) inaccessibility of the full
DMI hindered remote collaboration; 3) in-person collabora-
tive work tended to dissolve role definitions and supported
co-creativity and participation.
West and Leung [12] reported on roles of collaboration
during later stages of the development of a DMI based on
a traditional instrument, describing their cooperation as a
"collaboration between a technically competent artist [...]
and an artistically competent technician [...]." This collab-
orative setup strongly resembles the authors’ working ar-
rangement. In our case, it even invites us to reflect on gen-
der roles during the development of DMIs: Although in-
person working allowed us to steer away from traditional
stakeholder definitions, background and especially remote
working considerations led us to fall back into traditional
gender roles of assigning the (technical) development of the
DMI to the male author and the artistic role of composing
to the female author.
An unexpected event was the change of assignment of
the performer role from the composer to the instrument
maker. We believe availability of access to and experience
with the gestural interface was an important factor. We re-
alized that the option of a remote keyboard version of the
DMI was not adopted by the composer. While it could pro-
vide insight into the synthesis process, it ultimately failed
in providing an embodied access to the sound material. Fu-
ture work might therefore focus on creating multiple copies
of a travel-size version of the gestural interface in order to
support remote collaboration.
In a post-collaboration inquiry both the first and the sec-
ond author rated the participation depth for the individual
phases. Results show that the given ratings were identical
for both authors. We observed a trend of larger participa-
tion depth ratings (≥ 3) during in-person visits (see Fig. 3).
In-personvisitsweredefinedbyjointdecision-making,while
the main mode of remote collaboration phases was consulta-
tive. During in-person meetings, we observed collaborative
efforts on tasks, that could be ascribed to the performer
role (scrutinizing performance techniques) as well as the
composer role (choosing and discussing potential sound ma-
terial). This suggests that role definitions are fluid, which is
in line with considerations about the DMI building process
as a compositional task [6].
In the planning phases we had the opportunity to talk
to an expert đàn Bầu musician about the instrument and
its role in Vietnamese culture. We emphasize that we do
not see the Grain Bau as a ’modernization’ of the đàn Bầu.
Armitage et al. [1] see instrument development based on
historical and cultural instruments as an entry point to be-
comingestablishedinalocalsetting.WehopethatthisDMI
can serve as a starting point for discussions with perform-
ers and the community about places for culturally inspired
instruments. In [1], the development of a DMI as a research
probe into social dynamics was presented. They utilized the
instrument as a lens with which they could examine their
researchmethodology.Inasimilarcontextweregardourde-
velopment of the Grain Bau as a window, that sheds light
on cross-cultural collaborative practices in the field.
4. ACKNOWLEDGMENTS
This research was funded in whole by the Austrian Science
Fund (FWF) [10.55776/AR743]. For open access purposes,
the author has applied a CC BY public copyright license to
any author accepted manuscript version arising from this
submission. We would like to thank Ngô Trà My for an
introduction to the đàn Bầu and helpful instructions.
5. AUTHORS’ CONTRIBUTIONS
TTG wrote the code, built the gestural interface, and wrote
the paper. TTG and LHT wrote section 2.3.1 together. AH
supervised the research. The authors read and approved the
final manuscript.
6. ETHICAL STANDARDS
This project adheres to the standards of the NIME Princi-
ples & Code of Practice on Ethical Research. Project files
for the Grain Bau are released as open source.
7. REFERENCES
[1] J. Armitage, T. Magnusson, V. Shepardson, and
H. Ulfarsson. The proto-langspil: Launching an
icelandic nime research lab with the help of a
marginalised instrument. In NIME, 2022.
[2] R. DuPlessis. A virtual instrument for physics-based
musical gesture: Chon. In NIME, 2022.
[3] G. Emerson and H. Egermann. Gesture-sound
causality from the audience’s perspective:
Investigating the aesthetic experience of performances
with digital musical instruments. Psychology of
Aesthetics, Creativity, and the Arts, 12(1):96, 2018.
[4] G. Emerson and H. Egermann. Exploring the
motivations for building new digital musical
instruments. Musicae scientiae, 24(3):313–329, 2020.
[5] C. Erdem, Q. Lan, J. Fuhrer, C. P. Martin,
J. Tørresen, and A. R. Jensenius. Towards playing in
the’air’: Modeling motion-sound energy relationships
in electric guitar performance using deep neural
networks. In Proceedings of the SMC Conferences,
pages 177–184. Axea sas/SMC Network, 2020.
[6] R. Fiebrink. Machine learning as meta-instrument:
Human-machine partnerships shaping expressive
instrumental creation. Musical Instruments in the
21st Century: Identities, Configurations, Practices,
pages 137–151, 2017.
[7] T.-T. Grund. Grain bau, Apr. 2024. Zenodo. (code:
https://github.com/grundton/grain_bau/tree/main).
https://doi.org/10.5281/zenodo.10992539.
[8] M. K. Harder, G. Burford, and E. Hoover. What is
participation? design leads the way to a
cross-disciplinary framework. Design Issues,
29(4):41–57, 2013.
[9] A. R. Jensenius. Sound actions: conceptualizing
musical instruments. MIT Press, 2022.
[10] J. Ramos, E. R. Calcagno, R. o. Vergara, P. Riera,
and J. Rizza. Bandoneon 2.0: an interdisciplinary
project for research and development of electronic
bandoneons in Argentina. In NIME, 2022.
[11] E. Tomás, T. Gorbach, H. Tellio˘ glu, and
M. Kaltenbrunner. Embodied Gestures: Sculpting
Energy-Motion Models into Musical Interfaces. In
NIME, 2021.
[12] T. West and K. Leung. Early prototypes and artistic
practice with the mubone. In NIME, 2022.