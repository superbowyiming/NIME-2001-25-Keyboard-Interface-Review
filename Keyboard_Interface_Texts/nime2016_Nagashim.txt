Multi Rubbing Tactile Instrument
ɹ Yoichi Nagashima 
Shizuoka University of Art and Culture
2-1-1, Chuo, Naka-ku, Hamamatsu,
Shizuoka, JAPAN 430-8533
 nagasm@suac.ac.jp
ɹ
ABSTRACT
This  is a report of a novel tactile musical instrument. This instrument 
is called "Multi Rubbing Tactile Instrument (MRTI2015)", using ten 
pieces of "PAW  sensor produced by  the RT corporation". Previous 
research was focused on "untouchable" instruments, but this 
approach is fully tactile - "rub" and "touch". The ten PAW sensors are 
assigned on the surface of  the egg-like plastic case to fit the ten 
fingers grasping the instrument. The controller is mbed 
(NucleoF401RE), and it communicates with the host PC via high 
speed serial (115200bps) by  an MIDI-like protocol. Inside the egg-
like plastic case, this instrument has eight blue-LEDs which are 
controlled by the host in order to display the grasping nuances. The 
prototype of this instrument contains  realtime visualizing  system 
with  chaotic graphics by Open-GL. I will report on the principle of 
the sensor, and details about realizing the new system. 
Author Keywords
Tactile, touch, rubbing, mbed
ACM Classification
H.5.2 [Information Interfaces and Presentation] User Interfaces– 
Haptic I/O, H.5.5 [Information Interfaces and Presentation] Sound 
and Music Computing.
1.INTRODUCTION
The author has  long  been  working  in Computer Music and Media 
Arts - composition, performance, and developing new instruments 
[1]. In 2010-2011, the author developed a new musical  instruments 
focusing on the concept of "untouchable" like multi-channel 
Theremin [2]. In contrast, this is a new approach with an emphasis on 
the opposite point of view; touching, treating and rubbing heavily 
with  fingers. As previous research shows, it is  well known  that 
human interaction is sensitive and critical with hands, especially 
fingers [3].
2.PAW SENSOR
The "RT corporation" in Japan released the "P AW sensor" in 2014. 
The "P AW sensor"  (fig.1-left) is a small PCB (size 21.5mm * 
25.0mm, weight 1.5g) with a big cylinder of urethane foam on it.
   
Fig. 1 PAW sensor (left) and low pressure case (right).
On the PCB connector (6 pins) there is  a very simple signal 
assignment; GND, +3.3V power, two inputs  for control of LED1/
LED2, and two voltage outputs of Phototransistors Photo1/Photo2. 
Fig.1-right shows the P AW sensor with low pressure. The density of 
the Urethane Foam is low, so the light of LED strongly reaches the 
Phototransistor. Thus  the output  voltage of the Photo  transistor is 
higher.
     
Fig. 2 High pressure case (left) and the virtual coordinates (right).
Fig.2-left  shows the PAW sensor in  the case of higher pressure. The 
density of the Urethane Foam is higher, so the LED light weakly 
reaches the Phototransistor. Thus the output voltage of  the Photo 
transistor is lower. Fig.2-right shows the virtual coordinates 
system of the PAW sensor. Area22(ch1) is the output voltage of 
the Photo2 when LED2 is ON, Area21(ch2) is the output 
voltage of the Photo1 when LED2 is ON, Area21(ch3) is the 
output voltage of the Photo1 when LED1 is ON, and 
Area12(ch4) is the output voltage of  the Photo1 when LED1 is 
ON. LED1 and LED2 are controlled time sharing - each ON 
time is 250us with 250us intervals for the setup/recovery time. 
So, the CPU will repeat these loops; "LED1 On, LED2 Off" - 
"both LED off" - "LED2 On, LED1 Off"  - "both LED off" 
each with 250us.
3.THE 1ST PROTOTYPE
At first, I produced a prototype system of the P AW sensor with mbed 
- NucleoF401RE board. Figure 3 shows the system  which is 
connected to a PAW sensor, and mbed-USB is connected to the host.
 
Fig. 3 The 1st prototype system of the PAW sensor.
After I completed the first experiment with the P AW sensor, I started 
to consider developing a new musical instrument. I gave this first 
prototype system [4] to a student in my seminar to produce her new 
installation work using this new technology. After checking both  the 
demonstration Y ouTube movie and my sample Max patch, my 
student  Mao Miyamoto started to  consider the theme of her new 
installation work. The concept was "sexual touch/rub generates 
sexual voices". Because she had mastered my lecture "sound design", 
she started recording/sampling her voices with many styles of  sexy 
situations at first. She was in  the drama club  in high school, so she 
could act out many situations.
168
Fig. 4 Mao Miyamoto demonstrates her system.
She prepared many sound files of  her voice with many nuances  while 
acting with PAW sensor in many styles, the system changes the 
mixing  balance of volumes  and playback speeds with Max/MAP 
"groove~" object. Figure 4 shows the demonstration by Ms. 
Miyamoto [5]. In spite of the initial concept of "sexual impression", 
the final voices generated from the system  seems "pretty" or "cute", if 
anything. This is the result of her own characteristics and  cannot  be 
helped..
4.THE MAIN APPROACH
In  parallel with her project, my project for the PAW sensor was also 
started. My first impression was  that I did want to use 10  "PAW 
sensors" for the ten fingers. If all sensors are placed on  the same 
plane like a keyboard, the style of musical performance seems 
unnatural, because all finger tips must not move like a piano or 
organ. A cube or mechanical  shape is also  unnatural for fingers/hands 
to grasp. Finally I found an egg-shaped plastic container (Fig.5-left).
 
Fig. 5 The egg-shaped container (left) and MRTI2015 (right).
From a human palm  shape, I disposed the sensor corresponding to 
the thumb on  the front  side, and placed sensors corresponding to  the 
remaining  four fingers vertically on the other side. I named the 
instrument "MRTI2015" which means - Multi Rubbing Tactile 
Instrument (Fig.5-right). The egg-shaped plastic container was a 
good  size to contain the NucleoF401RE. However the USB-
mounting (uploading) part had to be cut in the end. The egg-shaped 
plastic container was  transparent, so I had  an idea to contain the 
LED-based display inside the container. The eight blue LEDs  did not 
face the outside directly. They faced the reflecting plate affixed onto 
the PCB.
5.SOUND SYNTHESIS
The output protocol from the NucleoF401RE serial port 
(speed=112500bps) is very simple, with mapping from  the outputs of 
PAW  sensors  to  MIDI  control  change message. Thus, all method of 
signal synthesis and graphic synthesis depends on the Max/MSP/
jitter programming.
Fig. 6 The main Max7 patch of  MRTI2015.
Figure 6  shows  the entire screenshot of the host of MRTI2015, the 
patch of Max7. The NucleoF401RE has a maximum 16 channels of 
A/D inputs. On the other hand, the total number of the output  voltage 
of  10 pieces of  P AW sensors is 40 channels maximum. The thumb, 
index finger and middle finger have a richer degree of freedom, but 
the ring finger and little finger's movement in conjunction with each 
other, and their degree of  freedom are less. So I assigned the 
information of  fingers to A/D channels; 4 channels to both "thumb 
and index finger and middle finger" (total 12 channels), and 1 
channel  to  each  ring finger and little finger. Impressed by the 1st 
experiment using the PAW sensor, I decided to apply the "formant 
synthesis" based sound generating system for the MRTI2015. The 
system has four sound synthesis modules (4 voices), and the input 
information is  scaled and assigned  to the parameters for the "formant 
synthesis" function which is programmed within the "gen~" object.
6.VISUALIZATION
For this new instrument featuring the nuances of 10 fingers, I also 
decided to generate realtime graphics not using existing images or 
movies. I have been performing many original works of computer 
music as interactive multimedia arts, and  I know well that the 
"relation and synchronicity" between the visual part  and the musical 
part is very important for the audience. In the main patch of Figure 6, 
some outputs from the PAW sensors are connected to  the realtime 
CG  synthesizing block in jitter. I checked and arranged from the 
jitter-examples folder of Max, and finally programmed using  a 
fractal/chaotic algorithm to generate 2-D grayscale realtime graphics. 
Figure 7 shows the example of changing images with slight changes 
of one parameter "depth" [6-7].
   
Fig. 7 Example of realtime CG.
7.FUTURE WORKS
Just  now, the development of MRTI2015 has  finished in hardware 
and in firmware. However, the system  has great possibility to 
become an effective musical instrument with  the development  of the 
host  program by  "Max". With many experiments in  my  lab  and at 
experimental demonstrations, I got many ideas and good advice to 
develop the final stage of this project. I intend to compose a new 
work for my Europe-Russia Tour in the summer  of 2016.
8.CONCLUSIONS
This  is a report of  a novel  tactile musical  instrument called "Multi 
Rubbing  Tactile Instrument (MRTI2015)", using ten pieces of  "PAW 
sensor produced by the RT corporation". I reported the principle of 
the sensor, details about realizing the new system, and sound and 
graphics in order to create new media-arts performances.
9.REFERENCES
[1] http://nagasm.org
[2] Yoichi Nagashima, Untouchable Instrument "Peller-Min", 
Proceedings of International Conference on New Interfaces for  
Musical Expression, NIME, 2010.
[3] Dan Overholt, “The Fingers” – A Tribute to “The Hands”, , 
Proceedings of ICMC2009, International Computer Music 
Association, 2009. http://quod.lib.umich.edu/i/icmc/
bbp2372.2009.076/
[4] http://www.youtube.com/watch?v=n7K7x0_2dD8
[5] http://www.youtube.com/watch?v=8rwjmhaiNzs
[6] http://www.youtube.com/watch?v=Pju887HEJ7M
[7] http://www.youtube.com/watch?v=2SD84alrN1A
169