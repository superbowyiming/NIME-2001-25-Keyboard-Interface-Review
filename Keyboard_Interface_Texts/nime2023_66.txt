The BioSynth—an affective biofeedback device grounded 
in feminist thought  
  
Erin Gee 
Centre for Interdisciplinary 
Research in Music Media and 
Technology (CIRMMT) 
Université de Montréal  
erin.gee@umontreal.ca 
 
 
 
 
 
ABSTRACT 
This paper presents the BioSynth, an affective biofeedback 
device for generating electronic music developed over a decade 
as part of a research -creation practic e. The BioSynth has 
facilitated the research and creation of work involving 
performers from a variety of ages and professional experiences, 
enriching diversity of knowledge regarding emotional 
performance, production, and differences between perceived and 
felt emotion within  biofeedback art , extending emotional 
quantification techniques to notions of emotional performance 
technique, emotional labor, and what feminist Alva Gotby calls 
emotional reproduction. 
The design of the BioSynth privileges relational and real-world 
interactions as well as feminist thought. This feminist inquiry has 
led to the development of alternatives to traditional frameworks 
for biofeedback music that rely on  metaphors of musical 
instrumentation.   
 This article is divided into three sections: hardware, software, 
and wetware. The hardware section describes the BioSynth 
through its design, which privileges ease-of-use for non-expert 
users. The software section describes mapping considerations 
based on feminist principles of measuring the emotional subject 
only against itself. Finally, in the wetware section I describe a 
feminist-inspired a pproach to emotional performance that 
embraces artificiality, irony, play, pleasure, and performance in 
biofeedback art, implying novel models for composer -
instrument-performer relations.  
 
Author Keywords 
biofeedback music, affective computing, research-creation, feminism 
 
CCS Concepts 
• Applied computing → Arts and humanities → Sound and music 
computing; • Applied computing → Arts and humanities → Media 
arts; • Human-centered computing → Human computer interaction 
(HCI) → Interaction devices  
 
1. INTRODUCTION: RESEARCH-
CREATION AND LIVED EXPERIENCE 
Scenario 1: On stage, the lights come up on the Hamilton 
Children’s choir, seven c hildren aged between seven and 
fourteen years old, each standing beside a box on a music stand 
with blinking lights and cables connected to their hands (Figure 
1). The children stare ahead at the audience as undulating sine 
tones wash over the performance space: harmonic overtones 
fade in and out, punctuated by gentle staccato pulses. A soloist 
approaches a microphone and starts singing her personal story 
of immigrating to Canada a few years ago: she feels happiness, 
fear, excitement, anxiety, which she expresses in her own words. 
The young choir listens to her voice. The pulses we hear are the 
collective beating of their hearts: rhythmic frames for 
appreciating the sounds of their collective skin conductivity as 
moments of stress or emotional intensity ebb and flow through 
the palms of their skin, shaping the overall expression of a 
shared emotional voice through sound. The girl has finished. 
Quietly, slowly, she returns to her place in the choir. The 
conductor raises the baton to cue an entrance: the whole choir’s 
skin conductance rises in anticipation. The sonic drones dance 
in a lively response, and the singers open their mouths, ready to 
sing their first entrance together. 
 
 
 
 
 
Scenario 2: Actress Laurence Dauphinais is experiencing a 
regular morning routin e during pandemic lockdown in the 
Summer of 2020. As she sits with her coffee to read the news, she 
suddenly realizes that she has once again fallen into grips of 
melancholy at the state of the world. Careful to not waste the 
moment, she gets up from her morning coffee to a chair near the 
TV where she has installed the device. She sits down, puts her 
palm into the hand rest, adjusts the oxygen tube under her nose, 
and sets her foot on the foot pedal. She switches the device and 
turns the knob until the words “SAD MODE” appear on the tiny 
blue screen. She pushes a button to begin recording her 
physiological state. Leaning into the feeling, within a few 
minutes she begins to cry. In this moment of intensity, she presses 
down on the foot pedal. A marker is set within the data to indicate 
that this is a special moment of intensity. After a few minutes the 
feeling passes: she selects “END RECORDING” and goes back 
to checking her email. Every day she contributes recordings of 
her happiness, sadness, fear, and anger  as they arrive, slowly 
building up a dataset of her own emotional physiology within the 
rhythms of her own lived experience, one that will then be used 
to train a deep neural network to represent the range of emotions 
she feeds it. 
 
The scenarios above d escribe first-person encounters with the 
BioSynth, a device for measurement of physiological markers of 
emotion through cardiac activity, respiration, and skin 
conductance that I have been developing as part of my research-
creation in electroacoustic music composition and media art for 
at least ten years. Each creation has demanded different 
affordances of the device: for instance, while the first scenario 
Figure 1. Song of Seven (2016) Performed by members of 
the Hamilton Children’s Choir. 
 
. 
 
 
required that the device be suitable for real -time processing of 
emotional data, it also had to be easy enough for children to get 
in and out of the sensor devices when they got up to approach a 
microphone on stage, and also rugged enough that they wouldn’t 
break the devices during inevitable horseplay and fidgeting that 
occurred during rehearsals. In the second scenario, the BioSynth 
is not a performance instrument, but a way of bringing a research 
environment to the everyday life of a  collaborator slowly 
building her own “emotional database.”  
 I develop the BioSynth from an interdisciplinary position at 
the intersection of music composition; emotional physiology; 
instrumentation; mapping; and feminist and queer theory 
emerging from musicology and performance art, through 
artworks that function discursively with one another in an 
interrelational process d escribed by Springgay and Truman as 
thinking-doing-performing [1].  
  Each project has allowed me to fruitfully problematize my 
research, to develop specific technological affordances of the 
device, and to work with different publics. Because research -
creation centers the personal experiences and reflections of the 
artist within the creation process through methods such as auto-
ethnography [2], it is a natural ally to feminist methods that 
articulate lived and social experience within knowledge systems 
[3], [4].  
 The importance of developing awareness of and support for 
such work within the music technology community has been 
highlighted by Hayes and Marquez -Borbon as an antidote to 
“audio-technical” framing of research within narrow fields of 
inquiry [5], whi ch Gurevich said could be addressed through 
increased attention and engagement with what he calls 
methodologies of creative practice research [6]. This being said, 
humanities researchers Chapman and Sawchuck note that 
quantitative methods within the research-creation framework 
still tend to be taken more seriously than qualitative methods 
within the academic community, so research -creation in itself 
cannot be credited as an “easy fix” to longstanding diversity 
issues in electronic music and instrument design [7], nor should 
quantitative methods be seen as antithetical to the goals of 
equity, diversity and inclusion embraced by many STEM 
researchers today.  
1.1 Background Context 
Significant research into emotional biofeedback music through 
non-invasive wearable sensors has been conducted by Winters & 
Wanderley [8]. Some of the earliest documented research into 
biofeedback conducted by composers David Rosenboom and 
Richard Teitelbaum could be considered as emotional in nature, 
such as Teitelbaum’s use of biosensors in his 1969 piece In Tune, 
which amplified the brain signals of female performers as they 
reacted to the public broadcast of themselves moaning sexually 
and performing sexual acts with one another [9]. While what 
Teitelbaum described as a “psychosexual” experiment remains 
innovative in many ways, it also naively reproduced gender 
stereotypes by staging young women performers emoting at the 
service of male composers as a  sexual spectacle for public 
consumption. It is conspicuous for example that these particular 
feminine (homo)sexual bodies are present in the official histories 
of biofeedback art, while the many biofeedback performance 
artworks of American composer Ruth Anderson (who happened 
to also be lesbian) are missing from biofeedback music history 
altogether [10], [11]. Renowned electroacoustic composer Barry 
Truax observed in 1993 that in his experience, sexuality was 
rarely addressed as an aesthetic topic in electroa coustic music, 
and moreover felt that the conspicuous avoidance of masculine 
sexuality (whether heterosexual or homosexual), could be 
attributed to the homogenously male social environment of 
electroacoustic music [12]. Reading Teitelbaum’s only 
“psychosexual” artwork through the lens of Truax, the 
instrumentation of female bodies in this biofeedback work can 
be read as a strategic means represent “sex” while avoiding the 
representation of male sexuality altogether, thus staging female 
homosexuality for the tastes of heterosexual men.  
 The fact that emotion has been historically instrumentalized 
in biofeedback music both through contemporary metaphors of 
clinical scientific research, and through the instrumentalization 
of emotional, female, and sexual bodie s in various points of 
biofeedback music history, is worthy of special mention in the 
context of this article because of how it unconsciously 
reproduces unjust hierarchical relationships in electronic music 
through binary tropes, namely the logical and dis embodied 
masculinity that thinks in contrast to an emotional and sexualized 
femininity that performs [13]. 
2. HARDWARE 
Ideally, low-cost, open-source devices would create a means for 
people from all walks of life to access and control affective and 
biological data. To support artistic work that creates narratives 
for biofeedback art beyond the scope of what Truax described in 
2003 as a homogeneously straight male academic culture, we 
need a device that is accessible in the first place. Existing devices 
on the market suitable for affective biofeedback music include 
the BITalino, at $800USD [14], or the Emotibit, an open-source 
hardware system that costs $400USD [15]. In comparison, the 
BioSynth is a non-commercial open-source and DIY project that 
costs around $200USD in parts but requires assembly that is 
beyond the scope of non-experts. 
 
 
 
 
2.1 Design Considerations 
To privilege the investigation of social connections between 
multiple users, the hardware of the BioSynth (Figure 2) is 
centered on affordability, material robustness, and a user -
interface that makes collaboration between artists and non-expert 
users easie r. Hardware and software alike are detailed at the 
BioSynth’s GitHub page [16].  
 While the use of an idiosyncratic or fragile device is 
permissible within research environments that allow for one-on-
one contact with expert users, this approach demands con stant 
expert presence. For example, the expert user must be present to 
install the sensors on the bodies of users, to initialize start-up or 
Figure 2. Interior view of BioSynth Device 
 
. 
 
 
shutdown routines, to monitor their use, and particularly to repair 
the devices should they become damaged. While t hese 
constraints are acceptable in research environments, this 
approach is unsustainable when devices are called to withstand 
non-expert use in a loosely supervised art gallery, or when many 
users need to be hooked up to electronic devices within a 
relatively short period of time, such as a sound check or 
rehearsal.  
 During the development of Song of Seven (2016/2022), one 
of the pieces that I described in the opening of this article, I 
realized that the aesthetics of the device itself had the power to 
affect the openness that the children had to working with the 
devices, which largely affected their attitudes to performing with 
them in rehearsal. For example, one child asked me if the sensors 
could hurt her and seemed hesitant to touch the sensors when 
they were first turned on. Another mentioned that the box looked 
like a toy and started to mash the buttons excitedly, making 
sounds like lasers being fired. Yet another complained that her 
Velcro strap kept on falling off, growing increasingly 
exasperated each time I had to take her sensor to a back room 
and perform a quick repair. 
 I based my design decisions around these comments from 
non-expert users (musicians, singers, actors, children, art gallery 
visitors). Many comments revealed that first -time users  were 
nervous about being witnessed in public using the technological 
devices incorrectly, and therefore being judged by their peers: 
they also often expressed anxiety about inadvertently damaging 
a fragile DIY device. The anxiety that a DIY device might 
malfunction or harm them might have been increased due to the 
intimate, wearable nature of biosensors. According to a literature 
review conducted by industrial design scholars Fayazi and 
Frankel, attention and knowledge of social and emotional 
relationships in regards to the design of wearable devices is still 
lacking, and these design elements can have a wide range of 
social impacts [17]. In developing several artistic works, I have 
found that improving the aesthetics of the device to make it more 
comfortable, friendly, and durable in nature were not merely 
cosmetic choices, but made collaborations smoother, as the 
materiality of the device can make a user feel more at ease and 
receptive to new human computer interfaces.  
 To maximize familiar elements, the BioSynth features cables 
that would be familiar to non-expert users (USB-A and USB-C). 
While the USB -C cables for powering and programming the 
device via serial port are compatible with industry USB 
standards [18], I also use USB-A cables in non-standard ways by 
reappropriating them for use with custom sensors. Although it is 
generally less desirable to use USB cables in non-standard ways, 
USB-A cables are great for the biosensor designs because they 
are lightweight, unintimidating to non experts, and are ea sy to 
detach in case a user accidentally walks away from the device 
while wired. Additionally, many USB cables are shielded, an 
essential feature for delicate electrical signals obtained from the 
body. 
 
2.2 Implementation and Features 
 The BioSynth features three non-invasive wearable sensors: 
1. The heart rate and amplitude sensor  
2. Two skin conductance sensors 
3. Respiration sensor 
The heart rate and amplitude sensor  is an affordable and 
commercially available and open -source photoplethysmograph 
device called a Pulse Sensor [19]. It has a small form-factor, ease 
of use, and effectiveness at capturing the heart signal in 
meaningful ways. The heart sensor is recessed into a 3D printed 
hand-rest to shield its light -based function from noisy light 
sources like spotlights or flashing projection scre ens, and to 
protect the device itself. 
 
The skin conductance sensor  (Figure 3) consists of two 
aluminum electrodes buffered through an op amp. All processing 
on this signal is performed in software. Skin conductance probes 
are aluminum greenhouse screws, slightly raised off the surface 
of the 3D print, providing extra reassurance to users that their 
fingers are in the right spot. This sensor has been tested in a 
scientific study regarding the conductive properties of 
experimental polymer materials [20]. 
 
 
 
 
A 3D printed hand -rest brings the heart and skin conductance 
sensors together and mitigates the kinds of cable twisting that 
destroys a DIY device over time. The hand rest is intuitive: one 
simply rests their hand on the device. There is no cheap feeling 
Velcro band, nor a fabric glove of dubious cleanliness to tolerate. 
The entire device can be sterilized with wipes, ideal for a 
contagion-conscious context.   
  
The respiration sensor (worn on a performer’s face in Figure 5) 
has gone through several designs, including masks and belts 
worn around the chest. I settled on a thermistor nestled into a 
modified oxygen tube for several reasons. Oxygen tubing is 
lightweight and comfortable on the skin, and I rarely encounter 
someone who doesn’t intuitively know how to put the tube onto 
their own face. Masks and bands can rarely accommodate every 
possible body that might encounter the device, and making an 
interface that you trust the user to adjust themselves is a d icey 
proposition at best. A thermistor is cheap, and although its signal 
obtained is still a compromise compared to other methods, it 
works surprisingly well. Finally, the tube can be safely and 
thoroughly sterilized by non-expert users with sterile pads. 
2.3 Visual Sensor Feedback, Text-screen Interface 
Graphic cut outs on the device are backlit by colored LEDs used 
to confirm signal fidelity: the brightness of each led is directly 
mapped to each sensors’ normalized signals (Figure 4). For 
example, if the red heart icon does not flash the recognizable 
Figure 3. Sketches for design of 3D-printed skin 
conductance enclosures 
 
. 
 
 
rhythms of a heartbeat, it might signal a problem with the sensor 
hardware, a problem with finger placement, or calibration.  
Small trimpots are located below the icons and can be accessed 
with a screwdriver to calibrate the sensors to individual users, 
using the illumination of the LED icons as a visual reference. 
This option is immediate and efficient in a performance situation 
where multiple users might need to be calibrated on the fly. 
The LCD text screen can display an alphanumeric identifier upon 
start up, or direct the user to scroll to a specific mapping strategy 
during a performance via the rotary selector. This bottom -up 
approach to show control entrusts humans to learn a few cues 
rather than relying on automation, which also makes for more 
flexible rehearsals. 
 
 
 
 
 
2.4 Wired, serial communication and audio outputs 
While the advantages of wireless communication are many, there 
are compelling reasons to stay plugged in.  
 When working with many devices, it is desirable to eliminate 
elements that can malfunction during setup. To facilitate an 
independent, “computer -free” experience, I chose the Teensy 
microcontroller for its capability to sonify the data directly 
through its onboard digital -analog converter [21], making the 
devices truly “plug and play.” 
 In music presentation contexts, one might have as little as a 
one hour “soundcheck” to verify sound, lighting, and electronics: 
if something malfunctions, the show must go on. Furthermore, 
when working with professional choirs or musicians who are 
paid by the hour and have limited availability, one cannot afford 
to delay a rehearsal to hunch over a laptop configuring the 
system for the venue’s router. Finally, if you want to give one of 
these devices to a collaborator to work with at home, wireless 
setup can pose an additional barrier if the wireless setu p and 
configuration ever fails, not to mention that one will still need to 
go an extra length to configure a router. 
2.5 Modular/Scalable 
The hardware and software of the BioSynth are scalable and 
modular, facilitating easier setup and programming for multiple 
users. Using conventional 3A / 5V USB power adapters, four 
BioSynth units can be daisy -chained from either side of the 
device and share a single power source, enhancing flexibility 
during setup (Figure 4). 
3. SOFTWARE 
3.1 Methods inspired by feminist thought 
While some may approach biofeedback music as a means to 
“instrumentalize” the (unconscious) body into specific 
emotional states in the service of electronic music, I argue that 
the metaphor of musical instrumentation is only one of many 
structural possibilities for emotional biofeedback, and perhaps 
one that is frus tratingly self-contradictory when one considers 
the challenge of both “being” a body and also “controlling” the 
body.  
 Regarding emotional physiology, this approach might also 
be incorrect or impossible from the outset. Based on a broad 
literature review, scientist Sylvia Kreibig observed that although 
there is clearly a relationship between autonomic nervous system 
activity and emotional experience, that no strict rules about 
emotional valence had been determined based on a broad public 
in a wide variety of environmental settings [22]. Even if 
relationships between physiological expression and emotional 
experience have become increasingly clear in recent years, 
models remain contested. Those wishing to instrumentalize 
emotion through the development of musical instrument benefit 
from isolating convenient scientific metaphors and models that 
are clear-cut, such as Russell’s circumplex model of affect from 
1980 [23]. There are several shortcomings to this approach: 
namely that older models such as Russell’s do not account for 
difference (such as gender). Furthermore, clear -cut models of 
emotion are the ones most likely to be exclusionary, relying on 
narrow definitions that limit cultural references, and as 
psychologists Nielsen et al. argued in 2017, are built upon small 
samples of experience confined to homogenous groups of 
Western, educated, industrially-rich and democratic populations 
[24].   
 The use of clear -cut models suits the needs of musical 
instrumentation, which demand predictable outputs from given 
inputs, and the ability to master the instrument. This artistic 
vulgarization of affective physiology risks “settling” the topic of 
emotion in misleading ways: first by appropriating science’s 
voice of authority, secondly by using the emotive power of music 
itself to confirm the success of the instrument through 
emotionally leading/manipulative mapping. Feminist 
musicologist Susan McClary notes that music is political 
because it gives emotion to us as though it were already our own 
[25]. Whose emotion is i t, that can be mapped easily between 
four poles on a circular grid in Max/MSP, and is being 
proclaimed as universal? 
 Scientist Elizabeth Feldman -Barrett (whose doctoral 
research was supervised by aforementioned scientist J. A. 
Russell) notes that emotion is highly contextual and subjective, 
and indeed that what one might consider to be the 
phenomenological feeling of a specific emotion might not only 
change from situation to situation, but that it might also change 
over time during the course of one’s life [26].  Following Barrett, 
if emotional categories are based contingently on broad 
linguistic concepts and menta l projections that co -construct 
one’s phenomenological experience (psychophysiological 
sensation), it is difficult to treat emotion within the body as 
something akin to a musical instrument, even with expert use.  
 What this means is that even if one found  a performer who 
was able to cry on cue, this wouldn’t guarantee that the 
physiological data obtained from this emotional outburst would 
correspond to a universal set of rules that could be 
instrumentalized.  
 Given this situation, artists, musicians, and composers need 
not despair: we don’t need to give up affective biofeedback, but 
rather, develop interesting ways to create music  beyond the 
metaphor of musical instrumentation. For example, we could 
Figure 4. Several BioSynth devices connected in a 
modular fashion to share their power supply.  
 
. 
 
 
explore what sociologist Benjamin Haber described as a qu eer 
algorithmic sorting, an algorithm that would continually adapt 
and change its methods, learning and re-learning arbitrarily with 
the goal of always drawing new conclusions about the subject, 
resulting in a forever unstable categorization [27]. This approach 
contradicts the use of algorithms trained on large -scale 
“emotional databases” that amalgamate large groups of users to 
create a fictional algorithmic subject that every user is measured 
against. This normative process in the service of musical 
instrumentation repeats what was one of the original complaints 
of feminist philosopher Simone de Beauvoir against the field of 
phenomenology as based upon an imagined universal category 
[28]. For this reason, I do very little interpretation of the 
emotional data beyond measuring the intensities of physiological 
signals against the subject themselves. 
 Reflecting the need to “read” emotional experience only 
through the individual and their body, I have found 
computationally frugal combinations of adaptive high and low-
pass filters enacted through exponential moving average 
algorithms to be useful. Although these processes are very 
simple, they satisfy my intellectual curiosity to voice emotion 
through feminist principles of only measuring bodies against 
themselves, and not measuring them against universal standards 
or norms for emotional experience or performance. Rather than 
providing absolute values, such as the heart rate’s BPM, my 
BioData library uses low-pass filtering and min-max scaling to 
provide standardized values between 0.0 and 1.0. While simple, 
this approach can represent a subject’s physiological markers of 
emotions in a way that is expressive and subjective rather than 
normative and objective.  
 Thus far, my mapping strategies have also been very simple. 
I make the audio signals as transparent as possible, sometimes 
using layering or masking for aural clarity. While explicit one -
to-one mappings are not particularly sophisticated, complexity 
emerges through a group’s psychological and social relationship 
to their body in conversation with other bodies. My avoidance of 
more virtuosic mapping (ideal for a solo performer) recalls 
technological historian Arnold Pacey’s critiques of “virtuosity 
values”, where engineers develop cutting -edge improvements 
for technology out of their own joy and thrill of engineering, 
perhaps overlooking approaches that would demand more 
mundane but practical solutions in response to material needs of 
the everyday world [29].  
 
4. WETWARE 
4.1 Performance and Composition Methods 
A feminist approach to biofeedback technology use s 
performance and composition to interrogate metaphors of 
musical instrumentation that serve to treat emotion as a resource 
that is extracted as data from a user’s body. This feminist critique 
can provide meaningful social and political expansions of 
musical experience. For example, feminist musicologist Suzanne 
Cusick has critiqued the division of mind and body in Western 
musical tradition, whereupon composers are traditionally 
considered as the “minds” in dominant power relationships to the 
“bodies” of th e performers, who are subservient to the 
composer’s creative vision  [30]. In a different paper, Cusick 
explains that these power relationships exist at the intersection 
of pleasure, intimacy and power in music, and that music’s 
emotional power seduces the l istener into hetero -normative 
power binaries such as mind over matter, reason over emotion, 
conscious over unconscious mind in their unconscious 
experience of music itself. By reinterpreting these metaphors of 
instrumentation of the body in order to instrumentalize emotion 
itself through reason and technology, I consider the articulation 
of performance technique and emotional wetware as crucial to a 
feminist model for biofeedback music, one that moves towards 
what Cusick might call a lesbian experience of m usic based on 
queer mind-body relationships [31].  
 Following these principles of thought, I have moved away 
from treating the physiological signals of the emotional body as 
sets of data that can be “instrumentalized” in a strict sense.  What 
if instead of demonstrating emotion as a universal and 
transparent concept bound to a singular conscious and sovereign 
subject, I could make music that demonstrates affect through its 
elements that are socially constructed as “non -dominating”, 
“non-power” and to construct musical experiences that allow 
people experience music and emotion as 'a flow of power in both 
directions'[31]? Instead of instrumentalizing emotion as a 
subjective experience that is bound to an individual’s body, how 
does one use music to illustrate emotion as an amorphous 
substance experienced between multiple unruly and sometimes 
contradictory users?  
 Returning to the ideas of McClary, the link between music 
and emotion can be seen as something that is falsely naturalized, 
that music has the power to artificially heighten or invokes 
emotion “as tho ugh it were already our own” [25]. McClary’s 
observations echo those of scientist Elizabeth Feldman-Barrett: 
that emotion is not a naïve, natural, nor universal unconscious 
reaction to emotional stimuli that can be easily mapped or 
instrumentalized from subject to subject: furthermore, emotions 
might indeed not even be “our own.” The idea that one might be 
deceptive in their emotions themselves was explored very early 
on in emotion detection technology, as it was found that 
physiological markers of deceptio n are very poor —as the “lie 
detector” polygraph test, which uses many physiological 
markers, has poor reproducibility  [32]. Eschewing emotional 
performance via instrumentation, one could work from 
emotional performance via feminist notions of emotional 
manipulation (see Jennifer Doyle’s defense of the artist as 
prostitute or femme fatale) [33], emotional reproduction linked 
to pink -collar labor [34], clinical methods for psychosomatic  
emotional induction [35], or even following the work of 
humanities researcher Daniel Pettmann who considers emotion 
itself as a technology [36]. An important aspect of my practice is 
to apply these concepts to wetware, or the body itself, 
introducing performance techniques as a more explicit part of the 
interface, to compose the physiological markers of emotion in an 
intentionally non -naturalistic way. The consideration of this 
wetware introduces novel structural possibilities for composition 
and performance, including but not limited to strategies of  
Instrumentalization, Empathetic resonance, and Psychosomatic 
Body Hacking. 
4.1.1 Instrumentalization 
As explored in my earliest works for affective biosensors, one 
might instrumentalize the body like any instrumentalist would: 
manipulating emotional sentiment in timed intervals to achieve 
variance in emotional data. In 2013 I worked with method actors 
to explore these possibilities while developing the robotic 
installation Swarming Emotional Pianos [37]. I learned that even 
in a group of expert performers, the physiological activation of 
specific emotion without external cues is difficult or sometimes 
impossible, and indeed this emotional activation is a specialized 
technical skill. Furthermore, the emotional data obtained by each 
performer was not only inconsistent from subject to subject, but 
sometimes even inconsistent with th e subject themselves from 
session to session, reflective of how perceived and felt emotion 
might differ based on environmental factors such as heat, 
humidity, or time of day.  
Artists can critically engage with instrumental approaches by 
creating work tha t highlights their unreliable nature: for 
example, through my emotional -control interface in VR work  
Project H.E.A.R.T. (Holographic Empathy Attack Robotics 
Team) with Alex M. Lee in 2018 [38], users are challenged to 
create spikes of non -specific emotional arousal as a means of 
moving forward in a satirical war simulator. The absurdity of the 
narrative highlights the unreliability of emotional measurement, 
emotional control, violence and labor in a VR “militainment” 
context. The work is also a comment on t he contradictory shift 
of VR technologies from their use to train soldiers for war, 
towards claims that VR might “amplify” the voices afflicted by 
war during the late 2010s [39]. 
4.1.2 Empathetic resonance 
In my choral work Song of Seven (2016) I used the BioSynth to 
sonify the em otional data of singers as they improvise sung 
memories of their childhood where they felt strong emotions. 
This strategy makes use of narrative to inspire empathy in other 
performers wearing BioSynths through psychological 
projection, and also the ability  of music to increase feelings of 
social bonding and empathy  [40]. The use of empathetic 
resonance to structure affective physiology in biofeedback music 
need not be limited to in-person interaction, as it might involve 
empathetic resonance with narratives of those not present, either 
due to distance or time, or the use of a fictional account to invoke 
emotion, such as those in films or a spoken narrative, which 
might extend empathy to non -human subjects. Key to my 
approach is to reject attempts at emotional purity and to embrace 
inevitable affective contamination “beyond the score” due to 
performance jitters, annoyance at a coughing audience member, 
or how collective emotion speaks among bodies in social ways 
when physiological mapping is transparent. 
 
 
 
4.1.3 Psychosomatic Body-Hacking 
Recently I have developed work for biosensors around method 
acting techniques, guided meditation and hypnosis -inspired 
scripts to structure and invoke affective response, profiting from 
vocal delivery and sonic treatment techniques that manufacture 
intimacy and haptics. Many of these methods are derived from 
the social media -driven practice of Autonomous Sensory 
Meridian Response (ASMR), which has been linked reliably to 
physiological markers of emotion through scientific study [41]. 
I have taken advantage of p erformance methods known as 
“triggers” to structure physiological behavior in biofeedback 
music work both in the networked biofeedback performance  
Presence (2020, with Jen Kutler) and more recently in my large-
scale solo work for vocalist, fixed electroaco ustic part and 
biofeedback performers  Affect Flo w (2022) (Figure 5). A 
complete description of these techniques would be beyond the 
scope of this paper, but the importance of this approach is in how 
it consciously articulates emotion as a technique rather than as a 
natural resource to be extracted and instrumentalized by 
technology. Think of the emotional techniques developed 
through the lived experience of pink -collar workers, feminized 
family members who have refined methods for what Alva Gotby 
calls emot ional reproduction —manufacturing positive feeling 
[34]. Humanities researcher Sarah Ahmad says emotions are 
political because of how they stabilize and support normative 
flows of political power in frictionless ways [42]. By 
denaturalizing emotion and pointing to affect as a technological 
practice (merely confirmed by the measurement processes of 
biofeedback devices), we might free ourselves from tired 
binaries of masculine logic/thought and feminine 
intuition/emotion. An affective biofeedback informed by 
feminist and queer thought leans into how lines between logic, 
emotion, nature, culture, masculinity and femininity can be 
productively and pleasurably blurred. 
5. CONCLUSION 
The BioSynth is a research tool for enacting new relationships 
between composer -performer-music that embraces play, 
performance, and co-constructed phenomenological experience 
in an affordable and frugal manner. Biofeedback music is still a 
relatively undeveloped field which has yet to fully benefit from 
the embodied knowledge systems of feminist and queer thought. 
Opening the accessibility of emotional monitoring te chnology 
also necessitates the opening of conceptual assumptions within 
the field . By focusing on unconscious sensory processing, 
human-centric, psychosomatic, and social aspects of 
biofeedback music, concepts such as emotion can be 
denaturalized and interrogated in novel ways through research-
creation and performance.  
6. ETHICAL STANDARDS 
 
The BioSynth was developed during several research 
residencies, in particular the Algorithms that Matter Residency 
at IEM Graz (2018) and the Locus Sonus residency at 
ESSAIX/Université de Marseilles (2019). At various stages  of 
the research of this instrument, my work has been supported by 
the Social Sciences and Humanities Research Council of 
Canada, Canada Council for the Arts and the Conseil des Arts de 
Montreal. This research has ethics approval 2022-2178: 
CERAH-2022-032-D 
 
7. REFERENCES 
 
[1] S. Springgay and S. E. Truman, “On the Need for Methods 
Beyond Proceduralism: Speculative Middles, (In)Tensions, 
and Response -Ability in Research,” Qualitative Inquiry, 
vol. 24, no. 3, pp. 203 –214, Mar. 2018, doi: 
10.1177/1077800417704464. 
[2] E. Barrett and B. Bolt, Eds., Practice as Research: 
Approaches to Creative Arts Enquiry. London: I.B. Tauris, 
2010. 
[3] P. H. Collins, Black Feminist Thought: Knowledge, 
Consciousness, and the Politics of Empowerment . 
Psychology Press, 2000. 
[4] S. Harding and K. Norberg, “New Feminist Approaches to 
Social Science Methodologies: An                     Introduction,” 
Signs: Journal of Women in Culture and Society , vol. 30, 
no. 4, pp. 2009–2015, Jun. 2005, doi: 10.1086/428420. 
[5] L. Hayes and A. Marquez -Borbon, “Nuanced and 
Interrelated Mediations and Exigencies (NIME): 
Addressing the Prevailing Political and Epistemological 
Crises,” Proceedings of the International Conference on 
New Interfaces for Musical Expression, 2020 , Dec. 2020, 
Accessed: Mar. 09, 2022. [Online]. Available: 
http://arxiv.org/abs/2012.00923 
[6] M. Gurevich, “Diversity in NIME Research Practices,” 
Leonardo, vol. 49, no. 1 , pp. 80 –81, Feb. 2016, doi: 
10.1162/LEON_a_01120. 
Figure 5. Performance of Affect Flow (2022), ISEA 2022 
 
. 
 
 
[7] O. Chapman, “Research -Creation: Intervention, Analysis 
and ‘Family Resemblances,’” Canadian Journal of 
Communication, vol. 37, no. 1, Art. no. 1, 2012, doi: 
10.22230/cjc.2012v37n1a2489. 
[8] R. M. Winte rs and M. M. Wanderley, “Sonification of 
Emotion: Strategies and results from the intersection with 
music,” Organised Sound, vol. 19, no. 1, pp. 60 –69, Apr. 
2014, doi: 10.1017/S1355771813000411. 
[9] D. Rosenboom, Biofeedback and the Arts - Results of Early 
Experiments. Vancouver: Aesthetic Research Center, 1976. 
[10] A. Lockwood, “Hearing a Person —Remembering Ruth 
Anderson (1928 -2019),” NewMusicBox, Dec. 19, 2019. 
Accessed: Mar. 22, 2021. [Online]. Available: 
https://nmbx.newmusicusa.org/hearing-a-person-
remembering-ruth-anderson-1928-2019/ 
[11] S. Smith, “Ruth Anderson, Pioneering Electronic 
Composer, Dies at 91,” The New York Times , Dec. 18, 
2019. Accessed: Mar. 30, 2023. [Online]. Available: 
https://www.nytimes.com/2019/12/18/arts/music/ruth-
anderson-dead.html 
[12] B. Truax, “Homoeroticism and electroacoustic music: 
absence and personal voice,” Org. Sound, vol. 8, no. 1, pp. 
117–124, Apr. 2003, doi: 10.1017/S1355771803001134. 
[13] D. S. Sofer, Sex Sounds: Vectors of Difference in Electronic 
Music. 2022. doi: 10.7551/mitpress/12089.001.0001. 
[14] “BITalino,” PLUX Biosignals . 
https://www.pluxbiosignals.com/collections/bitalino 
(accessed Feb. 01, 2023). 
[15] bloginfo('author’)?><?php, “EmotiBit.com,” EmotiBit. 
https://www.emotibit.com/ (accessed Feb. 01, 2023). 
[16] E. Gee, “BioData.” Dec. 09, 2022. Accessed: Feb. 01, 
2023. [Online]. Available: 
https://github.com/eringee/BioData 
[17] N. Fayazi and L. Frankel, “Creating Emotional Attachment 
with Assistive Wearables,” in HCI International 2020 - 
Late Breaking Papers: Multimodality and Intelligence, C. 
Stephanidis, M. Kurosu, H. Degen, and L. Reinerman -
Jones, Eds., in Lecture Notes in Computer Science. Cham: 
Springer International Publishing, 2020, pp. 73 –88. doi: 
10.1007/978-3-030-60117-1_6. 
[18] J. Axelson, USB Complete: The Developer’s Guide, Fifth 
Edition, Fifth edition. Madison, WI: Lakeview Research, 
2015. 
[19] “Open Hardware,” World Famous Electronics llc.  
https://pulsesensor.com/pages/open-hardware (accessed 
Feb. 01, 2023). 
[20] J. Hagler et al. , “Flexible a nd stretchable printed 
conducting polymer devices for electrodermal activity 
measurements,” Flex. Print. Electron. , vol. 7, no. 1, p. 
014008, Feb. 2022, doi: 10.1088/2058-8585/ac4d0f. 
[21] “PJRC: Electronic Projects.” https://www.pjrc.com/ 
(accessed Feb. 11, 2023). 
[22] S. Kreibig, “Autonomic Nervous System Activity in 
Emotion: A Review,” Biological psychology, vol. 84, pp. 
394–421, Apr. 2010, doi: 
10.1016/j.biopsycho.2010.03.010. 
[23] J. A. Russell, “A circumplex model of affect,” Journal of 
Personality and Social Psychology, vol. 39, no. 6, Art. no. 
6, Dec. 1980, doi: 10.1037/h0077714. 
[24] M. Nielsen, D. Haun, J. Kärtner, and C. H. Legare, “The 
persistent sampling bias in developmental psychology: A 
call to action,” Journal of Experimental Child Psychology, 
vol. 162, pp. 31–38, 2017. 
[25] S. McClary, Feminine Endings: Music, Gender and 
Sexuality. Minneapolis: University of Minnesota Press, 
1991. 
[26] L. F. Barrett, How Emotions Are Made: The Secret Life of 
the Brain, Illustrated édition. Boston New York: H arper 
Paperbacks, 2018. 
[27] B. Haber, “The Queer Ontology of Digital Method,” WSQ: 
Women’s Studies Quarterly, vol. 44, no. 3, pp. 150 –169, 
2016, doi: 10.1353/wsq.2016.0040. 
[28] S. D. Beauvoir, The Second Sex , 1st edition. New York: 
Vintage, 2011. 
[29] A. Pacey, The Culture of Technology. MIT Press, 1985. 
[30] S. G. Cusick, “Feminist Theory, Music Theory, and the 
Mind/Body Problem,” Perspectives of New Music, vol. 32, 
no. 1, pp. 8–27, 1994, doi: 10.2307/833149. 
[31] S. G. Cusick, “ On a Lesbian Relationship with Music: A 
Serious Effort Not to Think Straight,” in Queering the 
pitch: the new gay and lesbian musicology , New York ; 
Routledge, 1994, pp. 67–83. 
[32] The Polygraph and Lie Detection . Washington, D.C.: 
National Academies Press, 2003. doi: 10.17226/10420. 
[33] J. Doyle, “The rhetoric of prostitution,” in Sublime 
Economy: On the intersection of art and economics , 
Routledge, 2010. 
[34] A. Gotby, “A capitalism of feeling: emotional 
reproduction, work and gender,” Autonomy, 2021. 
https://autonomy.work/portfolio/gotby-emotional-repro/ 
(accessed Jul. 03, 2021). 
[35] E. Siedlecka and T. F. Denson, “Experimental Methods for 
Inducing Basic Emotions: A Qualitative Review,” Emotion 
Review, vol. 11, no. 1, pp. 87 –97, Jan. 2019, doi: 
10.1177/1754073917749016. 
[36] D. Pettman, Love and Other Technologies: Retrofitting 
Eros for the Information Age , 3e édition. New York: 
Fordham University Press, 2006. 
[37] L. Oyler, “Erin Gee Makes Feminist Robots That Respond 
to Human Emotion,” Vice, Dec. 16, 2014. 
https://www.vice.com/en/article/evggjm/erin-gee-makes-
feminist-robots-that-respond-to-human-emotion (accessed 
Feb. 01, 2023). 
[38] E. Gee, A. M. Lee, and S. Audry, “Playing with Emotions : 
Biosignal-based Control in Virtual Reality Game Project 
H.E.A.R.T.,” in ISEA Conference 2020: Montreal, 
Canada, Montreal, Oct. 2020, p. 4 pages. 
[39] K. Hamilton, “Voyeur Reality,” The New Inquiry, Feb. 23, 
2017. https://thenewinquiry.com/voyeur-reality/ (accessed 
Mar. 29, 2023). 
[40] J. Stupacher, J. Mikkelsen, and P. Vuust, “Higher empathy 
is associated with stronger social bonding when moving 
together with music,” Psychology of Music, vol. 50, no. 5, 
pp. 1511 –1526, Sep. 2022, doi: 
10.1177/03057356211050681. 
[41] G. L. Poerio, E. Blakey, T. J. Hostler, and T. Veltri, “More 
than a feeling: Autonomous sensory meridian response 
(ASMR) is characterized by reliable changes in affect and 
physiology,” PLoS ONE, vol. 13, no. 6, p. e0196645, Jun. 
2018, doi: 10.1371/journal.pone.0196645. 
[42] S. Ahmed, The Cultural Politics o f Emotion. Routledge, 
2013. 
 
 