VOICON: An Interactive Gestural Microphone For Vocal
Performance
Y ongki Park
Music and Audio Research
Group, GSCST
Seoul National University
Seoul, Korea
yongkipark@snu.ac.kr
Hoon Heo
Music and Audio Research
Group, GSCST
Seoul National University
Seoul, Korea
cubist04@snu.ac.kr
Kyogu Lee
Music and Audio Research
Group, GSCST
Seoul National University
Seoul, Korea
kglee@snu.ac.kr
ABSTRACT
This paper describes an interactive gestural microphone for
vocal performance named Voicon. Voicon is a non-invasive
and gesture-sensitive microphone which allows vocal per-
formers to use natural gestures to create vocal augmenta-
tions and modiﬁcations by using embedded sensors in a mi-
crophone. Through vocal augmentation and modulation,
the performers can easily generate desired amount of the
vibrato and achieve wider vocal range. These vocal en-
hancements will deliberately enrich the vocal performance
both in its expressiveness and the dynamics. Using Voicon,
singers can generate additional vibrato, control the pitch
and activate customizable vocal eﬀect by simple and intu-
itive gestures in live and recording context.
Keywords
Gesture, Microphone, Vocal Performance, Performance In-
terface
1. INTRODUCTION
Vocal performance is one of the most processed music sig-
nals. In contemporary vocal performances, the use of vocal
modiﬁcations and augmentations is very commonly found.
However, vocal performance relies heavily on the capabil-
ity of a sound engineer as the sound engineer is often in
charge of audio processing control of a performance. Vocal
performers are not given the freedom to use these capa-
bilities to augment, process, and control his/her own per-
formance. This inability of the performer to use vocal ef-
fects limits the vocal performance to be bounded within pre-
made agreements between a sound engineer and a performer
leaving no room for improvisational use of vocal modiﬁca-
tions and augmentations in live performances. Voicon is an
interactive gestural microphone for vocal performers. This
gesture-sensitive microphone lets the performers to generate
vibrato, control pitch and use customizable vocal eﬀects in
real-time with simple gestures and use of pre-programmed
sensors, giving new possibilities of performances in live and
recording context. This microphone-shaped gestural con-
troller diﬀers from previous gestural system as it does not
require performers to wear any invasive gestural sensors.
2. RELATED WORKS
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’12,May 21 – 23, 2012, University of Michigan, Ann Arbor.
Copyright remains with the author(s).
There have been previous eﬀorts to use gesture for mu-
sic control in existing literature [1][2]. This paper focuses
speciﬁcally on developing a vocal interface using gesture
controls. Vocal performers employ a wide range of ‘ges-
tures‘ during performances [3]. There are numerous wear-
able music controllers that use a variety of sensors to cap-
ture gestures for the enhancement of vocal performances.
“The Hands“ created by Michel Waisvisz incorporated small
keyboards on the hands of the player. The player can ma-
nipulate force sensors using his thumb and other sensors
are used to detect the tilt of the hands and distance be-
tween them. Waisvisz used this instrument to control a
variety of parameters to change the sound of his voice and
other sonic sources [4]. Another hand gesture based in-
strument is Laetitia Sonami‘s “Lady‘s Glove,“ developed by
Sonami and Bert Bongers. This glove uses a Hall Eﬀect
sensors on the thumb, magnets on the other four ﬁngers,
ﬂex sensors on each ﬁnger, switches on the top of the ﬁn-
gers, and ultrasonic receivers. During a vocal performance,
data from these sensors are used to control sound, light-
ing and motors [5][6]. The “Bodycoder“ system created by
Bromwich and Wilson is another gestural controller that
has been occasionally used for vocal performances. Resis-
tive sensors on the knee and elbow joints and keypad-like
switches are employed in this system. Switches are used to
trigger pre-recorded samples and select particular audio and
visual patches [7]. Elena Jessop‘s Vocal Augmentation and
Manipulation Prosthesis (VAMP) allows singers to remotely
control, modulate and transform their voices by capturing
arm gestures with an arm sleeve embedded with a variety
of sensors [8]. Donna Hewitt created the eMic [9], a mi-
crophone and a stand equipped with controls that allow a
performer to ﬁlter and process his or her voice live. A ma-
jor diﬀerence between Voicon and previous gestural vocal
controllers is that Voicon is a standalone microphone with
sensors embedded within it. Voicon does not require per-
formers to wear or use any other unnatural external sensors
keeping interaction between the performer and the device
seamless and natural.
3. MAPPING
The mapping between gestures and vocal augmentation and
modiﬁcation consists of three parts: generating vibrato,
holding note/controlling pitch and activating customizable
vocal eﬀects. The summary of the mapping between ges-
tures and functions is shown in Table 1.
3.1 Generating Vibrato
Vocal vibrato has been recognized as a prominent charac-
teristic of classical western singing for a long time [10]. Pro-
fessional singers inherently seem to develop vibrato without
thinking about it and without actively striving to acquire
it. It develops naturally as voice training proceeds success-
fully [11]. There are experimental data showing the inability
of professional opera singers to change their vibrato rate,
even when asked to do so [12].Using Voicon, both novice
and expert vocal performers can achieve and control the
desired amount of vibrato in their performance. When the
performers shake the Voicon in circular motions, vibrato is
generated. A circular motion is mapped to vibrato as it has
features that could be easily controlled such as radius and
rate of the motion. Rate of circular movement of Voicon is
proportionally mapped with the rate of vibrato whereas the
radius of circular motion is directly related with depth of
the generated vibrato. One might argue that both vertical
and horizontal motions suit better with generating vibrato.
However during an active vocal performance with a lot of
physical movement by the performer, vertical and horizon-
tal movements are bound to occur more often then regular
circular movements. Circular motion is chosen to eliminate
false generation of vibrato. Moreover, with circular move-
ment of Voicon, the performer has greater room to control
the rate and depth of vibrato as circular motions have both
vertical and horizontal movement features.
3.2 Holding Note/Controlling Pitch
The performer can hold the note/pitch he or she is singing
by grasping the Voicon while placing her thumb or any part
of the hands over force sensor 1 (FS1). When FS1 is pressed
the audio signal that is currently going into the Pure Data
patch is captured and played until the performer releases
FS1. While the note is being held, the performer can control
the pitch of his/her voice by tilting the Voicon up or down.
The degree of tilting motion is proportional to the degree
of the pitch modiﬁcation. Through the use of pitch control
the performer can sing higher or lower notes beyond his/her
vocal range. Being able to sing in a wider range of pitch
provides the performer with richer expressions. Moreover,
the performer can achieve visually engaging performances
while controlling pitch as he/she has the ability to control
his/her pitch while leaning forward and backward. Figure
1 illustrates the motions used with Voicon.
Figure 1: a)Circular motion of Voicon generates vi-
brato. b) Vocal performer can tilt the Voicon up-
ward/downard to raise/lower the pitch.
3.3 Activating Customizable Vocal Effects
A variety of vocal eﬀects are often used during live vocal
performances. When using vocal eﬀects, the timing and
intensity of the eﬀects need to be considered. Convention-
ally, a sound engineer and a vocal performer need to agree
upon both timing and intensity of the eﬀect. By giving
the performer the ability to handle vocal eﬀects freely, the
performance will become more dynamic and expressive. A
performer can activate pre-programmed vocal eﬀects by ap-
plying pressure over force sensor 2 (FS2). The intensity of
the eﬀect is proportional to the amount of pressure applied
on FS2. By establishing a co-relation between the amounts
of pressure the performer applies to Voicon and intensity of
vocal eﬀect Voicon sends, controlling vocal eﬀects through
Voicon comes very natural and intuitive to its user.
Table 1: Gesture mapping to parameters of function
Gestures Activated func-
tions
Parameters mappings of
functions
Circular
motion
Generating vi-
brato
Radius and rate of cir-
cular motion
Tilting
motion
Pitch control Angle of inclination
Applying
pressure
Activating vo-
cal eﬀect
Amount of pressure
4. TECHNICAL DETAIL
The Voicon system can be largely divided into microphone
and PC. In the microphone, a tri-axial accelerometer(TAA)
and force sensors are embedded. Obtained audio signals us-
ing the microphone are sent to a PC through Arduino Nano.
Arduino Nano is a small-sized microcontroller for open-
source electronics prototyping. The tri-axial accelerometer
is used for measuring the acceleration of the movement in
order to detect circular motions and the degree of tilting mo-
tions performed by the performer which lets the performer
control vibrato and pitch, respectively. Two force sensors
are used as activation switches for the holding note/controlling
pitch function and the customizable vocal eﬀect function.
The force sensors were used to provide the performer room
for more robust expressions of eﬀects and natural interac-
tions with the Voicon. The force sensors are in the form of
thin ﬁlm enabling it to be mounted seamlessly on the sur-
face of Voicon. This physical feature of force sensors makes
the hardware of Voicon more compact and simple. Figure
2 illustrates hardware system overview.
Figure 2: Hardware system overview.
4.1 Hardware System
Regarding its compactness and eﬃciency in real perfor-
mances, our design was based on the idea that all compo-
nents should be equipped on a single microphone body while
not deviating so far from its original appearance. As there
are enough space for the small components, installing addi-
tional components to a microphone will not aﬀect acoustical
performance of the microphone itself. Figure 3 shows the
TAA mounted on Arduino Nano. Arduino Nano was se-
lected due to its small size and it receives three kinds of
acceleration data from the TAA and also transfers the data
to a PC via a serial USB cable. Besides, the voice is inde-
pendently sent to a PC by the original microphone cable in
this prototype design. Figure 4 depicts the internal compo-
nents before the ﬁnal assembly.
Figure 3: Arduino Nano with the tri-axial ac-
celerometer.
Figure 4: The internal components of Voicon.
4.2 Software System
Sensor data such as movement, tilt angle and pressure are
received and processed by a program called Pure Data (PD)
to perform audio signal processing. PD is an open-source
real-time graphical programming environment for audio pro-
cessing. PD was chosen as a sound-processing engine of the
Voicon system as it is very ﬂexible and simple, yet, it of-
fers powerful DSP functionality. The PD patches were de-
signed to perform each functions of Voicon. Figure 5 shows
schematic diagram including the software components and
the hardware components.
4.2.1 Generating Vibrato
When the performer shakes Voicon in circular motions to
generate vibrato, the audio signal that is currently coming
into the Pure Data patch is handled by the internal acceler-
ation value of the TAA embedded in Voicon. These internal
values such as acceleration and slope are calculated consid-
ering the initial values of sensors and then calibrated. As
Voicon should not respond to the unintentional motions of
the performer, a control module is designed to prevent the
Voicon from responding to the unintended and irregular mo-
tions by applying a threshold value. In other words, vocal
vibrato is a small oscillation in two features, which are am-
plitude and frequency. It is generated using a pre-deﬁned
modulator function that generates small variations in both
features to express a natural vocal vibrato.
Figure 5: The internal components of Voicon.
4.2.2 Holding Note/ Controlling Pitch
At the instance of the activation of holding note/controlling
pitch function, the vocal input from the previous one second
is saved into a buﬀer of 44100 samples. This buﬀer is played
in a loop until FS1 is released. For the pitch control, a per-
former can assign their own musical scales and the degree
of the pitch modulation responding to degree of tilt motion
from the Voicon. Pure Data patches are programmed to
recognize the degree of tilting motion and increase or de-
crease the pitch of the performer‘s voice depending on the
corresponding pitch change of 8-step musical notes. Pitch
modulation and vibrato generation are processed through
a short time transient process to prevent Voicon from pro-
ducing unnecessary noise caused by a rapid change of au-
dio signal. Parameter mapping between tilting angle and
change in pitch is shown in Table 2.
Table 2: Tilting angle and corresponding change in
pitch
Tilting
Degree
Change
in Pithch
[semitone]
Tilting
Degree
Change
in Pitch
[semitone]
-20 -2 30 5
-0 0 40 7
-10 2 50 9
20 4 60 11
4.2.3 Vocal Effects
The performer can also choose the amount of audio eﬀects
that he/she has assigned in advance by controlling the pres-
sure applied on FS2. The assigned vocal eﬀects are added
to the original sound through the local buﬀer line. Pressure
level on the corresponding sensor, which is sent to a PC,
decides the amount of the eﬀect. In a similar way to gen-
erating vibrato, the performer should put pressure on the
sensor over a certain threshold level to avoid any unneces-
sary mishandling.
5. CONCLUSION
We have developed an interactive gestural microphone ca-
pable of generating vibrato, holding note/controlling pitch
and activating vocal eﬀects through the simple and intuitive
gestures. Voicon enriches expression of voice of the per-
formers by enabling them to manipulate their voice while
maintaining the form of standalone microphone. The de-
sign of Voicon, much similar to a conventional microphone,
makes it very approachable by the performers. All in all, an
interactive gestural microphone was developed that allows
explorable possibilities and high control level of the vocal
performance.
6. FUTURE WORK
For the future work, Voicon should be developed to give tac-
tile and visual feedback on audio augmentation and modu-
lation it has created. Although the performer will be able
to monitor the vocal eﬀects, giving additional tactile and
visual feedback apart from audio feedback will enable the
performer to control vocal eﬀects more eﬃciently. When
applying vocal eﬀects, tactile feedback should be designed
to inform the performer using mild vibrations. The inten-
sity of the vibrations should be mapped with the intensity
of the created vocal eﬀects. While controlling pitch, short
vibrations between each change of pitch can inform the per-
former with the number of pitches he/she has modulated.
Additionally, Voicon could be developed into the personal
vocal guide using pitch detection. Voicon could alarm the
performer with the tactile feedback when he/she deviates
unintentionally from the appropriate melody. [7][5][4][3]
7. REFERENCES
[1] Joseph Butch Rovan, Marcelo M. Wanderley, Shlomo
Dubnov, and Philippe Depalle. Instrumental gestural
mapping strategies as expressivity determinants in
computer music performance. In Proceedings of
KANSEI - the Technology of Emotion Workshop,
pages 3–4, 1997.
[2] Sylviane Sapir. Gestural control of digital audio
environments. Journal of New Music Research,
31(2):119–129, 2002.
[3] C. Cadoz, A. Luciani, and J. Florens. Responsive
input devices and sound synthesis by simulation of
instrumental mechanisms: The cordis system.
Computer Music Journal, 8(3):60–73, 1984. Cited By
(since 1996): 17.
[4] A. J. Bongers. Tactual display of sound properties in
electronic musical instruments. Displays,
18(3):129–133, 1998. Cited By (since 1996): 2.
[5] Bert Bongers. Physical interfaces in the electronic
arts. interaction theory and interfacing techniques for
real-time performance. In Trends in Gestural Control
of, pages 41–70, 2000.
[6] L. Sonami. ”lady’s glve”. [Web Site], 12 2008.
[7] M Bromwitch and J Wilson. A sensor suit and vocal
performance mechanism for real-time performance.
Proceedings of 1998 International Computer Music
Conference, pages 292–295, 1998.
[8] Elena Jessop. The vocal augmentation and
manipulation prosthesis (vamp): A conducting-based
gestural controller for vocal performance. In
Proceedings of the 2009 conference on New interfaces
for musical expression, NIME ’09, pages 256–259,
2009.
[9] Donna Hewitt and Ian Stevenson. E-mic: extended
mic-stand interface controller. In Proceedings of the
2003 conference on New interfaces for musical
expression, NIME ’03, pages 122–128, Singapore,
Singapore, 2003. National University of Singapore.
[10] C. E. Seashore. The Vibrato. University of Iowa, 1932.
[11] Alf Bjørklund. Analyses of soprano voices. The
Journal of the Acoustical Society of America,
33(5):575–582, 1961.
[12] J Sundberg T Shipp, R Leanderson. Some
acousticcharacteristics of vocal vibrato. J Res Sing,
1980.