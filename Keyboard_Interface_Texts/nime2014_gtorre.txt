Constraining Movement as a Basis for DMI Design and
Performance
Nicholas Ward
Digital Media and Arts Research Centre
Department of Computer Science and
Information Systems
University of Limerick
nicholas.ward@ul.ie
Giuseppe Torre
Digital Media and Arts Research Centre
Department of Computer Science and
Information Systems
University of Limerick
giuseppe.torre@ul.ie
ABSTRACT
In this paper we describe the application of a movement-
based design process for digital musical instruments (DMIs)
which led to the development of a prototype DMI named
the Twister. The development is described in two parts.
Firstly, we consider the design of the interface or physical
controller. Following this we describe the development of
a speciﬁc sonic character, mapping approach and perfor-
mance. In both these parts an explicit consideration of the
type of movement we would like the device to engender in
performance drove the design choices. By considering these
two parts separately we draw attention to two di↵erent lev-
els at which movement might be considered in the design
of DMIs; at a general level of ranges of movement in the
creation of the controller and a more speciﬁc, but still quite
open, level in the creation of the ﬁnal instrument and a
particular performance. In light of the results of this pro-
cess the limitations of existing representations of movement
within the DMI design discourse is discussed. Further, the
utility of a movement focused design approach is discussed.
Keywords
Movement-based design, gesture, DMI performance, design
1. INTRODUCTION
A central theme within the NIME literature is that of ges-
ture and the manner in which new interfaces might engage
the body in performance. Prior examination of the role of
movement in DMI design has focused on the development of
descriptive models of gesture [4], the ‘expressive’ quality of
movement [5], and the notion of musician e↵ort [20]. Where
research has explicitly considered the design of movement
it has tended to be in relation to very speciﬁc applications
that make use of open-handed gesture [13], the soniﬁcation
of dance movement [25], or to situations where the design
space is ﬁrst constrained by either a focus on some spe-
ciﬁc sensor technology or the augmentation of an existing
interaction style [6]. Although the role of the body and hu-
man movement in musical interaction has been the focus
of prior study, there has been comparatively little consid-
eration of how insights gained from this work might inform
design practice. Though many idiosyncratic approaches are
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’14,June 30 – July 03, 2014, Goldsmiths, University of London, UK.
Copyright remains with the author(s).
evident in the literature - approaches that often result in
instruments that involve the body in engaging and novel
ways - a more general movement-based design method has
not been proposed.
When playing an acoustic instrument the instrumentalist
must excite some element into vibration, and then possibly
manipulate it in some manner so as to control its vibration.
And, this excitation and manipulation is achieved through
bodily movement. Of course, the situation in the case of
DMIs di↵ers. With the replacement of a physically vibrat-
ing object (a string, membrane or column of air) with an
electronic sound engine (an electronic synthesiser or com-
puter capable of generating sound) the requirement to sup-
ply excitation energy is removed and also the manner in
which the sonic result can be manipulated expands greatly.
A synthesiser or electronic sound engine may have dozens of
individually adjustable parameters. It becomes thus a chal-
lenge for the DMI designer, to conceive a coherent model for
the requirement of bodily movement on a technology-based
instrument.
Designers of DMIs have tended to side step this challenge.
Rather than designing movement explicitly, DMI develop-
ment has more often utilised paradigms of interaction based
on established traditional artefacts, or moved through small
steps of incremental change toward new modes of interac-
tion, guided by the opportunities o↵ered by technological
development. By focusing, for example, on technological
aspects such as sensor choice, the design space can be ade-
quately constrained without the need to explicitly consider
the instrumentalist’s movement at any deeper level than an
acceptance that knobs are turned and sliders slid. And in-
deed ergonomic principals of ease-of-use and anthropomet-
rics can aid in the layout of said controls. Further, existing
instruments or electronic equipment, e.g. piano keyboards
and mixing desk consoles, can be used as familiar templates
for design.
In this paper we examined how a designer can design
for performer movement explicitly. Our interest lay in ex-
amining how a focus on movement ﬁrst and foremost might
drive the design process i.e. that all choices of material, size,
shape, sensing and sonic character would be based on the
desire to support speciﬁc movement in use. Our motivation
for this stance stems from the proposition that irrespective
of the theoretical background that prompts a greater con-
sideration of the role of the body and physicality in musical
performance - be it an embodied approach to cognition, a
dissatisfaction with the styles of movement encouraged by
existing DMIs, or a recognition of the embodied nature of
musical skill - a designer must possess an ability to design
explicitly for speciﬁc qualities of movement in order to ex-
ploit this theoretical viewpoint in design.
Proceedings of the International Conference on New Interfaces for Musical Expression
449
2. BACKGROUND
As with DMI design, product design research has focused on
the opportunities and challenges presented by the transition
from analogue mechanical control, toward the digitally me-
diated control of computation enabled devices. Electronics
and digital computation have enabled behaviour that re-
quires a rethinking of how users interact with products. As
product designers integrate this technology, new challenges
arise in terms of designing the physical engagement.
Within the ﬁeld of Human Computer Interaction (HCI)
a similar development has occurred, albeit from a di↵erent
starting point. The movement of computing from the pri-
marily PC centred paradigm toward what is termed ‘ubiq-
uitous computing’ has resulted in the need to reconsider
at many levels the manner in which human and computer
interact [24]. Much work has focused on the social and
cognitive aspects of this new paradigm. Recently a greater
interest in the role of the body and physicality has emerged.
This is evident in the development of Tangible User Inter-
face (TUI) and Tangible Interaction, approaches that have
inﬂuence on DMI and NIME design also [1]. Though sev-
eral di↵erent emphases are evident within TUI research a
common thread is, ‘the desire to design ways of physically
interacting with computers that ﬁt with our innate abili-
ties’ [3]. Though the notion of innateness is problematic
[21][19], the statement denotes the dissatisfaction that de-
veloped around traditional methods of HCI, be that the
WIMP 1 model on PCs or the prevalence of simple button
pushing on digital devices. In contrast, it emphasises the
desire to explore a much wider notion of physicality that
goes beyond these approaches.
Interestingly however, although notions of physicality, hu-
man movement and action are intrinsic to the ﬁeld of tangi-
ble interaction, there has until recently been little direct
reference to physical movement in much of the research
within this ﬁeld. By ‘direct’ we mean that few researchers
have considered movement explicitly. This may partly be
explained by the originally data centred approach of TUI
research, which focused on the physical representation of
data [22] and lead to systems which, while involving the
movement of objects, rarely considered the quality of the
movement as important.
It also arguably reﬂects the tacit nature of movement
knowledge and the di cult nature of explicitly describing
and prescribing human movement. A designer will often
ﬁnd that their tacit and embodied knowledge of movement
allows them to arrive at a solution without ever explicitly
considering the quality or type of movement that the inter-
face will require. For example, in the development of the
TUI based musical device ‘music bottles’ [9] at no point do
the developers describe the movement of the user. The act
of lifting up a small bottle, removing the cork, and placing
it back on a table is one that does not beneﬁt from a de-
tailed description of the movement. However, in making use
of this style of interaction, the designers have relied upon
their tacit knowledge of movement.
The reacTable [14] is also noteworthy in this regard. Al-
though it is presented as an example of a TUI by the authors
there is no explicit discussion of the interaction in terms of
the qualities of the user’s movement. The interface, consist-
ing of pucks and a horizontal surface, deﬁnes the range of
movement in a manner that is easily understood by users
and designers alike without a need to attempt to analyse
in any detail the movements: we have all placed an object
1In human computer interaction, WIMP stands for ‘win-
dows, icons, menus, pointer’ denoting a style of interaction
using these elements of the user interface.
on a table. In summary, the tangible interaction approach
allows for an expanded consideration of the possibilities for
the role of movement in interaction. It does not however
necessarily require the explicit consideration of the quality
or range of movement and further, does not necessarily lead
to a richer use of movement than in the case of say WIMP
based interfaces.
Figure 1: The Twister
2.1 Movement Based Design
In recent years the term ‘movement based interaction’ has
been used to describe approaches to interaction that empha-
sise the role of human movement, irrespective of whether
that emphasis stems from an embodied, enactive, tangi-
ble, aesthetic or other viewpoint. In the introduction to
the special issue of Personal and Ubiquitous Computing on
movement based interaction, the editors called on designers
to ‘think further about the role of the body, and how bod-
ily movement can and should be used in real use contexts’
[17]. A recurring theme within this ﬁeld is the idea that
in order to exploit movement within design fully a designer
needs to have an embodied understanding of movement and
that the designer needs to move. Klooster emphasises the
view that designers need to be physically engaged in the act
of movement exploration as part of the design process [15].
Essentially, they argue that ‘the designers body needs to be
educated’.
Jensen et al. [11] present several design methods based
around an approach they term ‘designing actions before
product’. The authors cite the desire to be explicit about ac-
tions before linking them to physical design solutions. Their
approach takes observation of existing examples of rich hu-
man movement from craft traditions as a starting point.
The designer then seeks to isolate qualities of the actions
that might be of interest to, or applicable to, another con-
text.
2.2 A Movement Based Design Process
A complete description of the various movement-based de-
sign approaches that have been described is beyond the
scope of this paper. However, in reviewing the work of
movement-based designers four activities can be seen to be
commonly used:
1. Observation and Analysis of existing movement
2. Exploration of Movement
3. Devising Movement
Proceedings of the International Conference on New Interfaces for Musical Expression
450
4. Product or System Actualisation
These activities fulﬁl speciﬁc requirements for movement-
based design. Observation and analysis of movement lead
to an understanding of the qualities of movement that typ-
ify a situation, and can also highlight relationships between
an existing product and the movement style that it encour-
ages. The exploration of movement exempliﬁes the embod-
ied approach to understanding movement as argued for by
Hummels and others [8]. Activities Three and Four move
directly toward design and the creation of a system or ob-
ject. The emphasis on movement is maintained by explicitly
attempting to design actions and movement before consid-
ering the product’s features. The features are then designed
to encourage or require the intended movement quality in
use.
Based on this observation we decided to explore movement-
based design of a DMI using these four activities as the basis
of the design process. In order to support the observation
and exploration activities we chose to use Laban Movement
Analysis (LMA) [7] as a framework. Our decision to use
LMA was inﬂuenced by previous work within DMI devel-
opment which explored the E↵ort and phrasing aspects of
the framework [2][23].
3. THE TWISTER
In designing the Twister we began ﬁrst by analyzing the
movement of several clips of violin and no-input-mixer per-
formance using LMA. Our focus here was on the di↵erent
qualities of movement that were displayed and how the in-
terfaces’ physical characteristics encouraged or constrained
movement qualities. From this analysis two movement qual-
ities were chosen for further exploration.
• Carving. A speciﬁc quality of movement deﬁned in
LMA as part of the Shape category. A Mode of Shape
Change that is environment motivated and molds with
the environment. It is adaptive, 3-dimensional, uses
rotary function. Both mover and environment (space,
other person, etc) are changed in Carving movement.
• Interfaces and physical boundaries:It was interesting
to note how certain interface elements set very deﬁ-
nite constraints on the useful movement whilst oth-
ers allow the limitations of the body to deﬁne the
constraints. e.g. a simple linear potentiometer with
120mm of travel versus a rotary encoder that can be
turned continuously.
Following the selection of these two qualities the ﬁrst au-
thor engaged in a physical exploration of di↵erent Shape
and carving actions using a range of di↵erent E↵orts and
scales. The hands-only approach of Jensen et al [11] was
found useful as part of this process.
This process of movement exploration, which led to the
deﬁnition of a two handed action with a range of E↵ort
variations, also generated very deﬁnite ideas as to the form
and features of the instrument. In order to encourage the
two hands to act simultaneously, the instrument needed to
be an object that was grasped and held in both hands. It
needed to allow the distance between the hands to vary
whilst keeping the palms facing each other and encouraging
the hands to rotate in opposite directions.
In order to explore the notion of challenging boundaries
it was decided that the limits of the rotational aspect of the
Carving movement should be set by the performer’s body,
and not by the interface. This suggested the rotation should
be continuous. The device was ﬁrst sketched and then a 3D
model of the prototype was created. A physical prototype
was then created in ABS plastic. Following this the metal
bearings, shaft, spring and keyways were ﬁtted.
4. TECHNICAL DESCRIPTION
The Twister interface consists of two ﬂat cylindrical discs,
each with a smaller diameter raised cylindrical section that
acts as a handle and allows it to be gripped easily. The
two discs are attached to a shaft or axle which allows one
side to rotate freely with respect to the other. One of the
discs can also slide along the axle thereby varying the dis-
tance between the two discs between 18 mm and 0 mm.
A light spring maintains the distance of 18mm between the
discs when no force is applied. The movement suggested the
physical form for the Twister, and also the main elements
of the sensing system. An optical encoder was integrated to
sense the change in angular displacement between the two
sides of the device. A short-range infra-red sensor was used
to sense the distance between the two hemispheres. These
two sensors, coupled with the physical mechanism, allow for
the combined pressing and twisting movement which char-
acterise the Carving action to be captured. Two buttons
were added as a simple way to exploit the ﬁngers of the
hand that is gripping the disc. The associated circuitry was
integrated into the handle of the device. A cable exits from
the side to carry the sensor signals to an arduino.
5. EVALUATION & REFINEMENT
A user study was carried out that explored the manner
in which naive users manipulate the device. In this study
the device was not connected to any sound generator. The
central question was whether it did in fact invite Carving
movement in use. The study showed that the interface did
naturally invite the Carving. Participants also suggested
possible sound mappings. Several unexpected actions were
suggested as possible music producing gestures. A recur-
ring suggestion was the use of tilt and also shaking as a
control parameter. Based on these suggestions a three axis
accelerometer was added to the interface to enable the de-
tection of these parameters.
6. PERFORMANCE DEVELOPMENT
The Twister was used in a live performance viewable at
http://vimeo.com/75591098. Hereafter, we o↵er a descrip-
tion of the process behind the creation of the performance.
We will do this by trying to o↵er an insight of the men-
tal processes that facilitated the development of the perfor-
mance. This analysis is, however, not strictly made by using
tools borrowed from the ﬁeld of musicology. Rather, we of-
fer a framework for the analysis that focuses on justifying
the choices made according to either technical constraints
and/or aesthetic issues.
6.1 Deﬁning Affordances and Constraints
The ﬁrst step towards the creation of the performance was
the study of the Twister interface’s characteristics. This
process was formalised in a process whereby the ﬁrst author
interviewed and guided the second through the discovery of
the instrument’s features and capabilities. The intention
here was to place the emphasis on considering action ﬁrst.
The ﬁrst author asked the second to respond to the follow-
ing:
• Please list o↵and demonstrate as many di↵erent ac-
tions that you feel the device supports.
• Please perform two fast, energetic actions
• Please perform two long slow gradual actions.
Proceedings of the International Conference on New Interfaces for Musical Expression
451
Table 1: List of a↵ordances for the Twister
Gesture Sensor
clockwise and anti-clockwise rotation optical encoder
two buttons momentary switches
shaking accelerometers
opening and closing of the discs Infrared sensor
• Please perform two actions that combine a range of
sudden and gradual movements (about 20 seconds).
Using Norman’s words this process aimed at ﬁnding‘the
perceived and actual properties of the thing, primarily those
fundamental properties that determine just how the thing
could possibly be used’: the a↵ordances [18].
However, it is important to stress that the list of the
DMI’s a↵ordances was conﬁned to those actions that were
felt would be useful for the purpose of the performance
and to which the device could respond, i.e. that could be
detected by the sensors. The list of these utilitarian af-
fordances is therefore deﬁned here by the combination of
gesture and actuators as presented in Table 1. It should
be noted that the list provided in the table includes highly
subjective a↵ordances of the Twister and that di↵erent per-
formers could have expanded or reduced the provided list.
In particular the list includes actions that are limited to a
very deﬁned section of the kinesphere surrounding the per-
former (i.e. hand movements close to the performer’s chest)
and that performers more inclined to ‘dancerly’ or open
movements could easily expand on the list o↵ered here.
6.2 Sonic Character
6.2.1 Sound Generation vs Event Controller
Before delving into the mapping problem (connecting gesture-
data to sound output), it was useful to just play with the
device while imagining possible sounds. This simple, playful
and imaginative exercise helped in answering a more seri-
ous issue: should the device control parameters of a sound
generating mechanism (e.g. a carrier frequency, modulation
frequency and so on for an FM synth) or instead focus on the
triggering of pre-recorded loops, events etc? or both? The
answer is, of course, completely subjective but it is required
in order to progress in the development of the performance.
For the purpose of the performance presented here, the de-
vice was intended to be used primarily as a controller of
events.
6.2.2 Instrument(s) sound design
Having decided that the Twister will control events, the
next step involves deciding what kind of events. Two el-
ements inﬂuenced the choice. On one hand, we have a
limited sets of actions (see Table 1). On the other hand,
the composer felt the urge to have control over multiple
sounds simultaneously in order to facilitate the creation
of a vertical/multi-layered dimension in the music perfor-
mance (multi-voicing). The compromise between these two
elements was achieved by assigning to each button a syn-
thesizer (synth 2 and 3) and a further synth (synth 1) to
the opening and closing action. The quality of the sounds
generated by these three synthesizer was inﬂuenced by the
quality of the movement that would trigger them. More
precisely the opening and closing movement suggested long
notes with amplitude curves reﬂecting the sound produced
by an accordion. Conversely, the action of pushing the two
buttons was suggesting amplitude curves of short notes as
originating from a kalimba.
Having deﬁned the amplitude shape of the sound gener-
ated by each individual synthesizer, the attention moved on
to the pitch for the notes. The constrained movements that
the device a↵orded was thought to be insu cient for the
precise trigger of several individual notes. Therefore, it was
felt that the note generating process could be left to a ran-
dom generator algorithm bounded to speciﬁc rules2. The
closing and opening movement and the buttons were then
conﬁned to the enabling of the start and stop function of
this algorithm.
6.3 Mapping
6.3.1 Creating a sound-to-gesture vocabulary
The number of useful gestures discovered represents the
starting point for the subsequent development of a musi-
cal gesture vocabulary. This vocabulary links gestures to
potential sounds by means of metaphors and it forms the
basis of what will be then used for the appropriate coding
of the mapping. The vocabulary is built by taking into ac-
count gestures but also combinations of gestures. The way
the data retrieved is manipulated enables the mapping be-
tween action and sound.
The software used for the data manipulation was MAX 6.
Sounds and e↵ects were generated and triggered in Ableton
Live. Hereafter is the list of actions described in terms of
metaphors and technical implementation & mapping.
Music Box: The continuous rotation speed of the disc
was mapped to the tempo of the random generator unit
connected to synth 1. The two discs must be in open po-
sition. The action providing this data resembles the move-
ment required to act upon a music box for which the faster
you rotate its wheel the faster the notes are played.
Accordion: The distance between the discs controls the
volume for the Ableton channel strip hosting synth 1 and
continuously receiving midi notes from the random gener-
ator unit. A close position mutes the sound. The open
position maximises the volume of the channels strip. This
open and closing movement resembled the one used to play
an accordion.
Pointillism: The two buttons control the start/stop func-
tion for the random generator units connected to synth 2
and 3 respectively. The pushed position triggered the start
command. The released position triggered the stop com-
mand. These actions helped to add to the sonic palette.
The sonic attributes of these synth are in contrast with the
slow attack notes from synth 1 and work as ‘pointillistic’
decoration to the main melody lines built by synth 1.
Voices: By default, when opening the discs the random
generator units for synth 1, 2 and 3 generate random notes
from the Cm7 chord with random velocity. When closing
the discs, it is possible to rotate the two in opposite direc-
tions. The angle of this rotation is measured and mapped to
a ﬁfth up or down every +/-15°of rotation as showed in Ta-
ble 2. Thus, the sequence closing-rotating-opening triggers
the random notes from the selected chord.
Shaking: The data retrieved from the three axis accelerom-
eter was converted to polar form and the magnitude used to
control the shaking e↵ect. The e↵ect is a combination of dis-
tortion and delay lines added in an auxiliary track in Able-
ton Live. The shaking movement controls the threshold pa-
rameter of the gate (input of the auxiliary) which opens and
2see next Section.
Proceedings of the International Conference on New Interfaces for Musical Expression
452
Figure 2: A stop-frame sequence of the carving gesture.
Table 2: Angle to Chord Mapping.
Angle Chord
0°< angle < 15° Cm7
15°< angle < 30° Gm7
30°< angle < 45° Dm7
0°< angle < -15° Fm7
-15°< angle < -30° Bbm7
closes itself according to the magnitude and thus creates a
distorted rattling e↵ect (a metaphor for the movement orig-
inating it). The mapping of the magnitude to the threshold
parameter is mediated by a physics emulator object (pmpd
library) which smoothes the oscillation between values with
a spring motion that reinforces the rattling metaphor.
Tilting: The Y axis accelerometer value was used to re-
trieve the inclination of the Twister over one axis only. This
function was enabled in order to discern in which mode the
data originating from the rotational movement of the discs
would be interpreted. The two modes were: ‘Voices’ (see
above) and ‘Carving’ (see below).
Carving: The carving movement is depicted in Figure 2
and it includes a combination of closing, tilting and rotat-
ing actions. The carving mode is enabled when the Y tilting
value is above 350°and the discs are closed. When the Y tilt-
ing is below 350°and discs are closed data is instead used for
the ‘Chord selection’. Once the tilting value is above the
given threshold, tilting data is used to control the gain of the
send faders of each synth connected to a dedicated auxiliary
track in Ableton Live. The auxiliary track include a com-
bination of delay and grain e↵ects. These e↵ects are then
controlled by a macro parameter that has been mapped to
the angle of rotation performed. The resulting sonic output
is a gradual deformation of the ongoing music which now
seems to be squeeze and crashed. Similarly the body grad-
ually contorts to force itself, and the Twister, in a carving
gesture.
6.4 Structuring and Sequencing
Each word in the previously described dictionary can be
considered as a unit with distinct characteristics. The ‘Ac-
cordion’ and ‘Pointillism’ provide a fairly large sound palette.
Their combined use allowed for the adding in complexity
and density. The ‘Shaking’ and ‘Carving’ allow for the
building of tension. The ‘Music Box’ allows for relentless-
ness. The ‘Voices’ unit allows for modulation to a di↵erent
key signature.
The performance presented in the video accompanying
this paper is improvised and it follows a ternary form ABA’.
This was possible due to the ‘Voices’ unit which allowed
to modulate to several key signatures. Sound intensity and
density followed a bell shape curve. The ‘Accordion’, ‘Music
Box’ and ‘Pointillism’ units are introduced gradually and
mixed throughout the performance. The apex of tension is
created in the central part of the performance by combining
shaking and carving.
All these units, which originated from a reasoning of the
links between action and sounds, were available to the per-
former who needs to present them in an structured man-
ner at performance time. Thus, the structure is thought in
terms of gestures and sound at the same time and it could
be scored by displacing units vertically and across the tem-
poral line (horizontal) to depict time of intervention. This
would then be a sort of graphical score or storyboard of the
kind of what illustrated , for example, in [16, p. 106-107].
7. DISCUSSION & CONCLUSION
The Twister interface was deliberately kept simple in order
for us to focus on the design process and examine whether it
was useful to target speciﬁc movement qualities as the basis
for design. Our experience suggests that this approach is
useful. The device did invite the movement quality that it
was intended to. Further, considering how the sound map-
ping might encourage certain actions was seen as a useful
starting point in the further development of the DMI.
Central to the design approach was the use of LMA as
a typology of terms that refer to speciﬁc aspects of move-
ment. LMA is but one of many di↵erent framework for
movement description. Prior work has focused on the E↵ort
and Phrasing aspects of LMA [2]. Here we found it useful to
look at the Space and Shape elements and consider how the
di↵erent types of Shaping might suggest interaction. What
is apparent from our limited exploration of LMA however
is the need to familiarise ourselves better with the nuances
of this rich and detailed approach to movement description.
Being able to refer to aspects of movement explicitly deﬁned
in a framework such as LMA, and to di↵erentiate between
various actions according to clearly deﬁned qualities is es-
sential if movement is to become a design material. The
interface described here is not what one might expect to
emerge from a movement centred design process. It does
not require large exaggerated ’dancerly’ movements. This
reﬂects our desire to explore design process and theory as
opposed to simply attempting to develop what we might
personally feel to be instruments that epitomise physicality.
The second author did not ﬁnd it necessary to refer to
LMA in deﬁning the actions that would underpin the de-
Proceedings of the International Conference on New Interfaces for Musical Expression
453
velopment of the Twister as a complete DMI. We see here
the need for several di↵erent representations of movement
at di↵erent stages of the design process. LMA is beneﬁ-
cial in the initial stages of identifying ranges of movement,
in terms of body part usage, spatial aspects etc. Within
the NIME literature musicians’ movement has tended to be
most often considered in terms of a functional taxonomy
of gesture. This description however does not fully capture
the qualities of movement. It does not describe movement
in movement terms. Our work with LMA suggests that a
shift toward describing movement in terms of how the body
actually changes, its shape, use of space, and the dynamics
of this change, might better inform design.
In any approach where the aim is to design the actions be-
fore product the designer must note that it is never possible
to fully prescribe the movement that will be evident in per-
formance. This of course is dependent upon the intentions
and preferences of the performer. However, as with Jensen
[10], we have found that an explicit focus on action is a
rich starting point for design. It forces the designer to con-
sider how the interface will require and encourage certain
movement qualities whilst constraining or prohibiting oth-
ers. Through repeated applications of a movement-based
design process we believe that a designer should develop a
clearer understanding of how to design for movement and
how design choices e↵ect possible movement. As stated ear-
lier this approach appears beneﬁcial both in the early stage
of considering the interfaces’s physical characteristics and
also in the development of action-sound coupling [12]. Here
we have attempted to add to the notion of action-sound cou-
pling by considering what we see as the preceding problem
of action-interface coupling, an area that we feel has been
somewhat neglected in the NIME literature to this point.
8. REFERENCES
[1] P. Bennett and S. O’Modhrain. The BeatBearing: a
tangible rhythm sequencer. InProceedings of
NordiCHI 2008: 5th Nordic Conference on
Computer-Human Interaction (electronic proceedings),
2008.
[2] P. Bennett, N. Ward, S. O’Modhrain, and P. Rebelo.
DAMPER: a platform for e↵ortful interface
development. InProceedings of the 7th international
conference on New interfaces for musical expression,
pages 273–276, New York, New York, 2007. ACM
Press.
[3] J. Bird. The phenomenal challenge of designing
transparent technologies.interactions,1 8 ( 6 ) : 2 0 – 2 3 ,
Nov. 2011.
[4] C. Cadoz and M. Wanderley. Gesture music.Reprint
from : Trends in Gestural Control of Music, M.M.
Wanderley and M. Battier, eds.,2 0 0 0 .
[5] A. Camurri, P. Coletta, and M. Ricchetti.
Expressiveness and physicality in interaction.Journal
of New Music Research, 29(3), Sept. 2000.
[6] N. Gillian and S. Nicolls. A gesturally controlled
improvisation system for piano. InProceedings of the
2012 International Conference on Live Interfaces:
Performance, Art, Music (LiPAM), Leeds, UK,2 0 1 2 .
[7] P. Hackney.Making Connections: Total Body
Integration Through Bartenie↵ Fundamentals.
Routledge, 1998.
[8] C. Hummels, K. C. Overbeeke, and S. Klooster. Move
to get moved: a search for methods, tools and
knowledge to design for expressive and rich
movement-based interaction.Personal Ubiquitous
Comput,1 1 ( 8 ) : 6 7 7 – 6 9 0 ,2 0 0 7 .
[9] H. Ishii, A. Mazalek, and J. Lee. Bottles as a minimal
interface to access digital information. InCHI’01
extended abstracts on Human factors in computing
systems,p a g e1 8 7 – 1 8 8 ,2 0 0 1 .
[10] M. V. Jensen. A physical approach to tangible
interaction design. InProceedings of the 1st
international conference on Tangible and embedded
interaction, pages 241–244, Baton Rouge, Louisiana,
2007. ACM.
[11] M. V. Jensen, J. Buur, and T. Djajadiningrat.
Designing the user actions in tangible interaction. In
Proceedings of the 4th decennial conference on Critical
computing: between sense and sensibility, pages 9–18,
Aarhus, Denmark, 2005. ACM.
[12] A. R. Jensenius.ACTION — SOUND. Developing
Methods and Tools to Study Music-Related Body
Movement. PhD, University of Oslo, 2007.
[13] E. N. Jessop.AG e s t u r a lM e d i aF r a m e w o r k :T o o l sf o r
Expressive Gesture Recognition and Mapping in
Rehearsal and Performance. PhD thesis,
Massachusetts Institute of Technology, May 2010.
[14] S. Jord‘ a, G. Geiger, M. Alonso, and
M. Kaltenbrunner. The reacTable exploring the
synergy between live music performance and tabletop
tangible interfaces. InConference on tangible and
embeded interaction,2 0 0 7 .
[15] S. Klooster and K. Overbeeke. Designing products as
an integral part of choreography of interaction: The
product’s form as an integral part of movement. In
DeSForM 2005: Design and Semantics of Form and
Movement,N e w c a s t l eU K ,2 0 0 5 .
[16] L. Landy.Making Music With Sounds.T a y l o r&
Francis, 2012.
[17] A. Larssen, T. Robertson, L. Loke, and J. Edwards.
Introduction to the special issue on movement-based
interaction. Personal and Ubiquitous Computing,
11(8):607–608, Dec. 2007.
[18] D. A. Norman.The Design of Everyday Things.B a s i c
Books, 2002.
[19] D. A. Norman. Natural user interfaces are not
natural. interactions, 17(3):6–10, May 2010.
[20] J. Ryan. Some remarks on musical instrument design
at STEIM.Cotemporary Music Review,6 ( 1 ) : 3–1 7 ,
1991.
[21] Tim Ingold. Beyond art and technology: The
anthropology of skill. InAnthropological perspectives
on technology, pages 17 – 31. 2001.
[22] B. Ullmer, H. Ishii, and R. Jacob. Token+constraint
systems for tangible interaction with digital
information. ACM Trans. Comput.-Hum. Interact.,
12(1):118, 81, Mar. 2005.
[23] N. Ward, K. Penﬁeld, S. O’Modhrain, and R. B.
Knapp. A study of two thereminists: Towards
movement informed instrument design. InProceedings
of the 8th international conference of new interfaces
for musical expression, pages 117–121, Genoa, 2008.
[24] M. Weiser. The computer for the 21st century.
Scientiﬁc American,2 6 5 ( 3 ) : 9 4 – 1 0 4 ,1 9 9 1 .
[25] T. Winkler. Motion-sensing music: Artistic and
technical challenges in two works for dance. In
Proceedings of the International Computer Music
Conference,1 9 9 8 .
Proceedings of the International Conference on New Interfaces for Musical Expression
454