Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-135
MidiGrid: Past, Present and Future
Andy Hunt
Media Eng. Group
Dept. Electronics
University of York
Heslington, York
YO10 5DD, U.K.
+441904 432375
adh@ohm.york.ac.uk
Ross Kirk
Media Eng. Group
Dept. Electronics
University of York
Heslington, York
YO10 5DD, U.K.
+441904 432375
ross@ohm.york.ac.uk
ABSTRACT
MidiGrid is a computer-based musical instrument, primarily
controlled with the computer mouse, which allows live
performance of MIDI-based musical material by mapping 2-
dimensional position ontom usical events. Since its
invention in 1987, it has gained a small, but enthusias tic,
band of users, and has become the primary instrument for
several people with physical disabilities. This paper reviews
its development, uses and user interface issues, and highlights
the work currently in progress for its transformation into
MediaGrid.
Keywords
Livep erformance, Computer-based musical instruments,
Human Computer Interaction for Music.
1. INTRODUCTION
The MidiGrid project was an experiment to investigate the
design of a new computer-based interface to electronic tone
generators. It was started at the University of York UK in
1987, and has been developed in stages since then [1][2][3].
MidiGrid has been used by a wide range of people (composers,
schoolchildren, and special needs teachers and their clients)
and its useh as raised several important issues relating to the
design of interactive musical systems. A summary of its key
features is now given, followed by a discussion of the issues
that arise from its use.
2. THE MIDIGRID CONCEPT
Many computer programs with mouse control exist to allow
musical information to be stored and edited on a computer,
rather like a musical word processor. These programs are often
called (sequencers, editors) as they enable people to build up
sequences of music, track by track, usually in non-real time.
In contrast MidiGrid allows users to trigger musical
material freely in real-time using the computer's mouse. As
shown below, the screen shows a grid of boxes, each of which
contains a nugget of music that is triggered as the mouse
cursor moves over it.
Hand gestures are thus converted, via the mouse, into notes,
chords and musical sequences.
The range of movement can be customised so that more or
less of the user's physical action can move the mouse cursor
around the grid. The grid can be set up in advance to consist
of any number of boxes containing any musical material
(including that played in from a keyboard).
Figure 1. Main MidiGrid performance screen (PC version)
showing sequences, single notes, and chords.
The grid can be shaded to separate different areas of notes,
for example (in figure 1, above) some areas consists of melodic
notes whilst others contain chords (denoted by more than one
dot in a grid box.
In fact, the grid can be arra nged to allow an assortment of
instrumental sounds to be present on the screen. Thus the user
can freely explore several timbres by moving the mouse to
different areas of the screen. Anything that is played on the
grid can be recorded and placed into a box of its own as a
sequence. Further recordings can be made which involve
sequences, and thus complex layers of musical material can be
rapidly constructed.
2.1 Customizing the grid for performance
Theg ridi so fau ser-definable size ands howst he musical
contents of each box by simple graphical representations of
notes and sequences. Thus the layout of the cells can be
customized for each player, performance or musical use. The
grid pattern shown in Figure 2 contains many shaded areas,
each containing sound elements on different timbres.
The player sweeps a cursor (using the computer mouse)
around the screen and notes are triggered when the mouse
buttons arep ressed. Consequently identical gestures pr oduce
identical musical results, but these gestures have to be learnt
and rehearsed by the player.
Sequence
Single Note
Chord
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-136
Figure 2. Grid pattern showing a variety of shaded areas
(Atari version), each containing a different timbre.
Thes ystem uses theM IDIp rotocolf or controlling notes on
an external synthesiser or sampler. Versions of the software
since 1990 have allowed a variety of MIDI conti nuous
controllers to be sent in response to mouse movement. The
effect of this is to permit much more subtle forms of musical
control using gestures to bend the pitch, sweep the panning
position and swell the volume, using the same gestural input
to choose and control the notes.
2.2 Extern al Control
Other MIDI instruments (e.g. electronic keyboards, drums or
wind controllers) can be used to trigger the musical material in
the boxes, so - for instance -notes on a keyboard can be used
to activate several pre-recorded sequences of music. This
feature allows MidiGrid to be ‘remote-controlled’ by any other
MIDI-compatible device. This has yielded some of its most
interesting uses over the years, as it moves the player away
from the computer terminal and allows them to concentrate on
aphysical performance interface. One of the more popular
configurations has become known as ‘Carpet-Grid’[5].
MidiCreator [6][7] is a device which converts the various
signals from electronic sensors into MIDI. Based on a music
technology student’s project, it was subsequently developed
by the York Electronics Centre, the commercial arm of York
University's Electronics Department. Assorted sensors are
available which sense Pressure, Distance, Proximity, Direction
etc. These are plugged into the front of the unit, which can be
programmedt os end out MIDI messages corresponding to
notes or chords. Thus movement is converted to music.
When ag rid of pressure sensors is placed on the floor a
'carpet-grid'i sf ormed. Each pad can trigger a note on a
specified instrumental sound. When these notes are routed
through the abovementioned MidiGrid software, entire
musical sequences can be triggered from different areas of the
floor.T hisf orms af ascinating 'floor-based' instrument which
people of moderate movement can explore. In some cases
people have driven their electric wheelchairs over it to achieve
the same effect.
2.3 MidiGr id version history
MidiGrid’s original and most fully developed platform was
the Atari ST.D uringt he 1990s a series of ports were made to
the PC platform and the most stable of these is available for a
trial download from www.midigrid.com. This vers ion does
not ha ve th ec omprehensive real-time contro ller
implementation or piano-roll editing of the Atari version, but
embodies most of the main grid-cell features for live
performance of MIDI material.
2.4 Context: Computers in Live Performance
Since the introduction of digital computing technology to
the art of music in the late 1950s, there have been several
strands of research which use the computer as a performance
instrument. Them ostc ommont hread is thea ddition of a
specifically designedc ontroli nterface. Axel Mulder [16] and
Joe Paradiso [17] each describe the various forms that these
devices tend to take – mostly in emulation of existing
acoustic gestural models, such as wind interfaces, keyboards,
guitars or conducting devices. They also note the less f amiliar
concept of the using the computer’s native interf aces
(specifically the mouse and the k eyboard) as live performance
tools.
A number of systems have been developed over the last
fifteen years for using the computer mouse as a means of
triggering andc ontrolling real- time sonic material. MidiGrid
is one such system, so is Music Mouse[4] (see section 2.4
below). Other systems which use similar paradigms include
Fleximusic [18] (allows keys totrigger sound and MIDI files),
and MousMuso [19] (mouse is used to strum virtual melodies
and harmonies). More recent systems use the concept of pre-
packaging musical material into a form ready to be triggered in
live performance, but using a specially designed physical
interface. A particular example to note is the BlockJam project
[20] which uses a graspable block-structured interface to allow
several users to trigger audio samples and algorithms in real-
time, with graphical and tactile feedback.
2.5 Musi cM o u s e
Comparisons have occasionally been made between
MidiGrid and Laurie Spiegel’s Music Mouse [4]. This is hardly
surprising since bothp ieces of software were developed (in
different continents!) at about the same time, and both allow
the user to move the mouse to make real-time musical
improvisations.
However, the programs and the concepts are quite different,
and I have discussed this with Laurie some years ago and more
recently during the production of this paper. Music Mouse
uses a level of ‘intelligence’ to provide an interactive
environment within which users can improvise using different
mouse gestures.
In contrast MidiGrid provides no interpretive intelligence;
the boxes (and the musical material contained within) are
simply triggered when the cursor passes over them or the
mouse is clicked on them. So, MusicMouse ‘joins in’your
improvisation, whereas MidiGrid simply reproduces the stored
musical material on demand. You probably have to work
harder with MidiGrid to create ac ohe rent sounding
polyphony.
Despite these differences, Music Mouse and MIDI Grid do
share something that has turned out to be far less common
among music programs than might have been expected by
either of their authors when these programs were first created.
Acore value of both is the satisfying immediacy of sound
responding directly to human movement and touch that has
been central to most successful human interfacest om usical
sound for millennia. Both programs place the computer in the
role traditionally given to musical instruments, rather than
seeing the computer as a tool for storage and editing of
materials to be played subsequently via some other
instrument[26].
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-137
3. USES OF MIDIGRID
MidiGrid has been used by a variety of people from many
walks of life. Whilst it has been used for triggering sequences
and notes in live electroacoustic performances, it seems to
have found its niche with people who benefit from the pre-
storage of musical material – yet under live performance
control. Many of theseu sers have been peoplew ith physical
disability as the mouse movement and grid layout can be
customized to suit individual gestural capacity.
3.1 Music T herapy
Music Therapy is an increasingly popular form of clinical
practice which engages client and therapist in dynamic
interaction without necessary recourse to words, by involving
the power and universality of music. Gary Ansdell, in the
book “Music for Life”[22], describes the main function of
MusicT herapy as beingf or the therapist to hear, res pond and
answer, while the client experiences being heard, being
responded to and being answered.“The aim of Creative Music
Therapy is to benefit people by giving them access to a
creative music relationship within a sustained and
dependable therapeutic context”[22].
Many of the branches of Music Therapy make use of
improvisation sessions involving both clients and therapist.
It is therefore important that the client has access to a device
which enables real-time musical interaction. Traditional
acoustic musical instruments are customarily used, but cause
problems when clients have restricted movement or weak
muscles. This is where the use of electronic-powered music
technology devices becomes important. Surprisinglylittle
work has been done to provide technology in such an
improvisational context for therapy, but Phil Ellis has been
working with the direct use sound for such purposes for a
number of years[23][24]. Fitzwilliam describes some of the
potential of electronic technology, along with several practical
reasons why technology has not been as popular with music
therapists[25]. Most of these relate to the overttechnicality
(wires, menus, programming, setting up) that seem to be
required by many electronic instruments, in contrast to the
simplicity and directness of an acoustic instrument.
In Music Therapy, MidiGrid has been used [7][8][9][10] to
allow free improvisation on a palette of sounds. The s ounds
have been pre-chosen by thet herapist to constrain them usical
material to ap articular genre, tonality or timbre set. This has
allowed access for people with limited movement to trigger
self-consistent performance material. One of the outcomes is
that where several acoustic instruments are used in the same
piece aswell, MidiGrid can be effectively ‘pre-tuned’ so that,
fore xample,i ti si nt he same tonality as the chime bars. This
enables groups of musicians to play together.
MidiGrid was built into the mobile Music Therapy van,
devisedb yM ary& Raymond Abbotson [11] and used as part
of the North Yorkshire Music Therapy centre's service in the
UK over a number of years.
Outside of clinical Music Therapy, MidiGrid has been used
on a number of occasions to allow people with limited
movement to access musical material in an immediate way.
Figure 3 shows a grid pattern that consists of a web of
individual notes which form scales (when played up and
down) and arpeggios (when played across).
Figure 3. Grid pattern containing harp notes arranged in
arpeggios and scales.
Ah arp-like sound is used, and flurries of notes can be easily
generated by gentle mouse movements. In a series of tests in
the children's centre at York District hospital, a 2 year old
blind girl with severe learning impairment moved the mouse
rapidly and even began talking to it. Therapists noted that this
was her longest recorded concentration span without one of
her regular seizures.
In a concert by the Drake Music Project [21] several people
with movement difficulties each played a MidiGrid as part of a
livep erformance with conventional (professional) mus icians
at London’s Millennium Dome. For some people, MidiGrid
has become their primary instrument, the tool that has enabled
them to contribute to the musical world.
4. INTERACTION ISSUES RAISED
Several issues have emerged from personal exper imentation
with MidiGrid and from watching others performing with it.
These issues have implications for the design of computer
instruments and of new forms of interactive human computer
interfaces in general [12].
4.1 Le arning an instrument
Players of musical instruments have always required
considerable dedication and commitment to hard work and
rehearsali no rder to learn how to play well. During the
difficult times, particularly at the start of this process, it is the
inspiration of watching an accomplished musician perform on
the instrument that provides the motivation for continuing to
practice for long periods of time.
Therefore we should assume that if a computer interface
demands more than a surface level of operation, users should
be expected to spend long periods of time learning the
dynamics of how to ‘drive’ it. Many computing interfaces are,
however, based on the assumption that users do not need to
learn it, since they navigate the menu system and interpret
accordingly each time they want to access a certain function.
4.2 Config urable Instruments
MidiGrid can be customised by the user to produce
individual grid patterns of different size and complexity,
containing whatever layout of performance material is
required. This flexibility of configuration has been
responsible for MidiGrid's successful use in schools and for
various Music Therapy situations. Teachers and therapists can
devise, restrict or expand the musical material that is available
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-138
to thee nd-user.I n doing so they form customised musical
environments where the tonality, instrumentation and
physical layout of the notes (and thus the type of hand
gestures used to play them) are defined for a particular
music/client combination.
However, there is a danger that players will never learn to
control the instrument beyond a surface level of explor ation
because the ‘goalposts are constantly being moved’. Players
of traditional acoustic instruments undergo a good deal of
configuration themselves in the process of learning to control
their instrument! Generally, if we allow system interfaces to be
continually reconfigured, we are perhaps in danger of
removing any reason for human operators to work hard at
learning to control the system interactively. We should
perhaps set up an instrument for a particular situation and then
always use that configuration with that particular situation.
After all a cymbal or a drum does not change its character from
one session to the next.
4.3 Nece ssity of graphics for musical
instrument control
One aspect of a dev eloping control intimacy shown by a
traditional instrumentalist is a decreasing reliance on visual
cues.
“Novice users of MidiGrid frequently request that material
be annotated so that they may remember the location of
materialw ithin theg rid. This is analogous to the labeling of
ap iano keyboard with the letter names of the notes on the
stave. Observation of competent pianists will quickly r eveal
that they do not even look at their fingers, let alone any
annotation which may be associated with the keys”.[3]
As users develop their mus ical performan ce ability on a
particular instrument, they rely increasingly on tactile, audio
and kinaesthetic feedback, and less on graphical information.
Therapists cannot be expected to constantly stare at a
computer screen in ordert o operate thep rogram without
breaking the concentration and eye contact that is so vital for
effective musical communication. However, there is also a
general lesson here for the designers of human-computer
interfaces in high-performance systems; graphics are a useful
wayo fp resenting information (especially to beginners) but
are not necessarily the primary channel which humans use
when they are fully accustomed to the system.
4.4 ‘Performance Mode’
When users are performing with MidiGrid there is no
‘dialogue’ between user and com puter, instead the computer
responds instantly to the user's hand movements. The
computer does not set the agenda or dictate the conversation
or insist the users select from a set of predefined options, but
instead provides an environment for creative exploration.
This is very close to the concept of ‘flow’, coined by Mihaly
Csikszentmihalyi [27], where users experience a continuous
stream of enjoyable and creative activity for its own sake.
This mode of operation is very different to the c onventional
means of communication with a computer. Traditionally the
software is there to gather data, and often does so by
dominating the interaction. Even in those situations where the
user is fully in charge of thei nteraction, it usually takes p lace
at a certain level of language ab ility (for example, the need to
read, interpret and take action on hierarchically arranged
menus).
5. THE FUTURE OF MIDIGRID
It is as trange feelingt oh avep roduced an experimental
instrument, moved on to other things, then to regularly hear
about the ‘new life’ that the instrument has in other people’s
hands. So recently, once again, we have returned to the design
table, anda re reconsidering how MidiGrid should evolve in
the 21 st century. Two major new projects are planned, and are
currently in their early stages.
5.1 MidiGrid on a PDA
Work is underway to produce a portable version of
MidiGrid that will run on a Portable Digital Assistant (PDA).
The ready availability of a touch-sensitive screen in a portable
device would enable a miniature version of MidiGrid to be
used on the move, and very easily in concert situations. We
are currently experimenting with various devices and
operating systems, and at the time of writing have a simple
grid which responds to the touch-screen. An artist’s
impression of the final product can be seen below in Figure 4.
Figure 4. Artist’s impression of MidiGrid on a PDA
5.2 MediaGrid
There is a natural progression for MidiGrid to be developed
into a device capable of allowing live performance of pre-
stored multiple media material [13]. The speed of today’s PCs
makes this perfectly feasible. What is interesting is to
speculate on its uses. Imagine a touch-screen (or a mouse-
control) on which there is a grid. As the grid is touched
imagesa ppear on as creen,o rs oundfiles play, or movie
snippets begin. Other boxes control the evolution or
transformation of the material.
Though this pro ject is in its infancy, we are excited by the
possibilities of having a simple two-dimensional mapping of
finger/hand position to animation clips, graphics, sounds, and
the original MIDI-based notes, controllers and sequences.
MidiGrid continues to be used and developed, and has
prompted a good deal of discussion and research into the role
of mapping for live performance control [14][15].
6. REFE RENCES
[1] "MIDIGRID - A new musical performance and
composition system'', A Hunt and PR Kirk Proceedings of
the Institute of Acoustics 1988
[2] "MIDIGRID - An innovative computer-based performance
and composition system", A Hunt & PR Kirk Proc.
International Computer Music Conference 1990 pp127
[3] "MidiGrid - A computer-based Musical Instrument", Andy
Hunt & Ross Kirk, Journal of the Institute of Musical
Instrument Technology, Vol. 1 June 1994 pp 3-13
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-139
[4] Laurie Spiegel’s “Music Mouse” software:
http://retiary.org/ls/programs.html
[5] "The Role of Gesture in Environmental Control", Ross
Kirk , Andy Hunt, Mark Hildred and Adrian Verity, Proc.
EuroMicro Conference 2000, vol II, pp 377-381,
Maastricht, September 2000.
[6] MidiCreator website: www.midicreator.com
[7] "Computer Music in the service of Music Therapy: The
MIDIGRID and MIDICREATOR systems'', M & R.
Abbotson, PR Kirk, AD Hunt, A Cleaton, Medical
Engineering Physics, Vol. 16, May 1994, pp. 253.
[8] "Enabling Musical Performance in Therapy: The
MIDIGRID and MIDICREATOR systems'', M & R.
Abbotson, PR Kirk, AD Hunt, A Cleaton Proc. 11th
International Congress World Federation of Occupational
Therapists, April 1994.
[9] "Technology in the service of Music Therapy'', M & R.
Abbotson, PR Kirk & AD Hunt, World Congress of Music
Therapy. July 1993
[10] "Music Therapy and Electronic Technology", Andy Hunt,
Ross Kirk, Mary Abbotson and Raymond Abbotson, Proc.
EuroMicro Conference 2000, vol II, pp 362-367,
Maastricht, September 2000.
[11] "MIDIGRID - in the Mobile Music Therapy Unit'', PR Kirk,
AD Hunt, M & R Abbotson World Congress of Music
Therapy, April 1991
[12] "Radical user interfaces for real-time control", Andy Hunt
&Ross Kirk, Proc. EuroMicro Conference 1999, vol II, pp
6-12, Milan, September 1999.
[13] "Graphical Performance Interfaces for Computer Music
Systems'', Ross Kirk, Andy Hunt. EuroGraphics HCI
conference April 1993 pp. 103
[14] Radical User Interfaces for real-time musical control,
Thesis by Andy Hunt, University of York, 2000. Available
on-line: http://www-
users.york.ac.uk/~elec18/download/adh_thesis/
[15] "The importance of parameter mapping in electronic
instrument design", Hunt, A.D., Paradis, M. & Wanderley,
M., Proc. Conf. New Instruments for Musical Expression,
Dublin, May 2002.
[16] “Virtual Musical Instruments: Accessing the Sound
Synthesis Universe as a Performer”, Axel Mulder.
Available on-line at:
www.cs.sfu.ca/~amulder/personal/vmi/BSCM1.rev.html
[17] "Electronic music interfaces: new ways to play", Joe
Paradiso, IEEE Spectrum Magazine, Vol. 34, No. 12, Dec.
1997, pp. 18-30. Available on-line at:
http://www.spectrum.ieee.org/select/1297/muse.html
[18] Fleximusic: http://www.fleximusic.com
[19] MousMuso:
http://www.busker.net/mousmuso/mm1.html
[20] BlockJam:
http://www.csl.sony.co.jp/IL/projects/blockjam/index.ht
ml
[21] Drake Music Project: www.drakemusicproject.com/
[22] Ansdell, G. ”Music for Life – Aspects of Creative Music
Therapy with adult clients”, London 1995, ISBN 1-853-
02299-3.
[23] Ellis, P. & Dowsett, R. (1987) MicroElectronics in Special
Education British Journal of Music Education 4 (1), 17-
23.
[24] Ellis, P. (1997) ‘The Music of Sound: a new approach for
children with severe and profound and multiple learning
difficulties’ (British Journal of Music Education, vol.14,
no.2) 4.
[25] Fitzwilliam, A. (1988) An Assessment of the Benefits of
Micro Technology in Music Therapy Journal of British
Music Therapy 2 (1), 24-3.
[26] Laurie Spiegel, personal correspondence with the author.
[27] Csikszentmihalyi, M., “Beyond Boredom and Anxiety:
Experiencing Flow in Work and Play (1975; reprint,
Jossey Bass Wiley; 2000 ISBN: 0787951404).