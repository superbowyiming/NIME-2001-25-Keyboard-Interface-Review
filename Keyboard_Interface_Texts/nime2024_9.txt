Co-Designing Haptic Instruments With Deaf and
Hard-of-Hearing Children
Lloyd May
Stanford University
660 Lomita Drive
Stanford, California 94305
lloyd@ccrma.stanford.edu
Rabia B. Malik
University of St. Thomas
2115 Summit Ave
St Paul, MN 55105
rabia.malik@stthomas.edu
AnnMarie Thomas
University of St. Thomas
2115 Summit Ave
St Paul, MN 55105
lapthomas@stthomas.edu
ABSTRACT
This paper explores haptic art and tactile experiences as
an independent form of artistic expression, distinct from
audio-visual (AV) technologies. Haptic technologies have
seen significant advances in gaming, virtual reality train-
ing, and as an auxiliary output in select music performance
and playback systems. However, there are currently no
stand-alone haptic music/art systems that allow for the easy
creation and distribution of haptic music/art. Despite the
convergence of haptics research and music technology, the
perspectives of the Deaf and Hard-of-Hearing (DHH) com-
munities remain underrepresented in the field of creative
haptic technology development. Recognizing the potential
of more readily available haptic art creation and sharing
systems for the Deaf and/or Disabled community, we con-
ducted a co-design workshop with 27 DHH middle school
children, focusing on their experiences with haptic vibra-
tions, creating low-fidelity prototypes for haptic art presen-
tation devices, and composing short pieces of haptic music.
Through a mixed-methods analysis of survey responses, re-
flections, and thematic analysis of the prototypes and haptic
art compositions, we gained valuable insights into the aes-
thetic possibilities and considerations for future haptic art
instruments. By elevating haptic music/art as a distinct
category of work not always subservient to auditory music,
we hope to pave the way for more inclusive and accessible
technologies in the realm of artistic expression and enrich
the experiences of diverse communities in the world of art
and creativity.
Author Keywords
Haptic Art, Inclusive Design, Deaf Haptics, Musical Haptics
CCS Concepts
•Human-centered computing →Empirical studies in accessi-
bility; Accessibility design and evaluation methods;•Applied
computing → Sound and music computing;
1. INTRODUCTION
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’24, 4–6 September, Utrecht, The Netherlands.
Musical and artistic expression are part of every day for
many, with several related research fields producing tech-
nologies to facilitate both the creation and experience of
these artistic expressions. While the majority of these ad-
vances have focused predominantly on audio-visual (AV)
technologies, there have been many recent strides in hap-
tic technologies to provide nuanced dynamic feedback while
gaming or simulate the tactile feeling of surgery in virtual
reality training [9, 12]. However, far fewer technologies ex-
ist to create and experience stand-alone haptic art 1 that
is not paired with a larger AV experience. Haptic art and
tactile experiences present a variety of aesthetic possibilities
but are notably of interest to members of the Deaf and/or
Disabled community as it provides another sensory channel
to perceive and create artistic experiences.
Within the field of haptics, there exist two major groups
of technologies, namely force haptics, which use motorized
systems to provide physical resistance or assistance while
interacting with an object, and vibrotactile (VT) haptics,
which comprises of vibrations that are felt by parts of the
body in contact with the medium, such as the sensation of
holding a mobile phone in one’s hand while it receives an in-
coming call. Given the similarity of the techniques and tech-
nologies used, VT research and artistic practice [14]. Within
the field of designing new interfaces for musical expression
(NIMEs), the perspectives of D/deaf and Hard-of-Hearing
(DHH) communities are often under-considered. In a 2019
review article on developments in accessible digital musi-
cal instruments (ADMIs), only 6% of ADMI research and
development focused on the DHH community [6]. Gunther
and O’Modhrain proposed the term “tactile composition”
referring to a “system that facilitates the composition and
perception of intricate, musically structured spatiotemporal
patterns of vibration on the surface of the body” [8]. This
was done to highlight the need to consider the somatosen-
sory system and haptic art on its own terms with its own
aesthetic possibilities as opposed to only considering it in a
support capacity, such as in the audio-to-haptic translation
of music.
In this paper we present the findings of a three-session
co-design workshop where 27 DHH children (1) reflected on
their previous experiences of haptic vibrations, (2) created a
low-fidelity prototype to artistically present VT signals, and
(3) composed several short pieces of VT art. The contribu-
tions of this work include an analysis of survey responses
and reflections, a thematic analysis of prototypes and VT
art compositions, and a list of considerations for the design
of future interfaces for VT art experiences and creation.
1Please note that we use the term haptic art as a broader
term that includes haptic, vibration, and touch-based mu-
sical experiences.
2. BACKGROUND
2.1 Vibrotactile Perception
Humans can perceive VT information through various touch,
pressure, motion, and temperature-related sensory organs
all over the body [2]. Through these various sensory organs
in and around the skin, we are generally able to perceive
VT signals that are in contact with the skin from frequen-
cies of about 0.1 Hz - 800 Hz, where 0.1-3 Hz is perceived
as kinesthetic motion, 10-70 Hz as rough or fluttering mo-
tion, and 100-800 Hz as smooth vibration [21]. In addition
the frequency of a pure sine wave signal, rapidly changing
the intensity of these signals through amplitude modulation
is an additional characteristic of VT signals that are read-
ily perceivable [22], and can effectively convey sensations of
roughness [23].
2.2 State of The Art VT Systems
Haptic feedback technology has been implemented in a vari-
ety of applications, from feedback while playing video games [5]
or the piano [13], to trying to convey semantically mean-
ingful information through emulation of established touch-
based languages used within DeafBlind communities such
as social-haptic communication or protactile [16]. While
some technologies have incorporated novel haptic technolo-
gies, many share common underlying haptic components
that are then utilized to achieve a specific effect. Regard-
less of the combination of haptic technologies used, simi-
lar considerations regarding the spectral, spatial, temporal,
and dynamic profile must be made.
Sound-to-Haptic Translation and VT Art: There are a va-
riety of solutions in which the user holds a device in their
hands or against their body to receive increased haptic in-
formation during a musical performance. The practice of
holding balloons during concerts to provide richer vibrotac-
tile feedback is not uncommon in DHH communities and
can often be seen in many Deaf studies writings [4]. Artist
and scholar Wendy Jacobs created a large-scale installation
consisting of various sub-woofers and a vibrating floor to
establish a shared tactile experience of sound among DHH
and hearing audience members [10], while David Bobier has
explored haptic and sound art through activating taut ropes
using vibrotactile drivers [1] The SoundHug2 consists of a
1-foot diameter plastic sphere that uses a mix of colored
light and haptic feedback to augment musical experiences.
Controllers and Surface Simulators: Video game controllers
and controller pads are a common entry point to haptic feed-
back for many, and there has been significant progress from
the early days of rumble-enabled controllers. The field has
progressed considerably since vibrotactile feedback was first
added to commercial game controllers in 1997 when Nin-
tendo released the Rumble Pak for the N64 controller [5].
Current commercial video game controllers have expanded
the rumble technology, from the Xbox One’s Wireless Con-
troller utilizing localized vibrotactile feedback on the back
triggers [20], to the PlayStation 5 DualSensecontroller us-
ing force-feedback in the large triggers on the back of the
controller as a form of haptic communication to players [17].
Wearables Wearable haptic feedback devices have been
employed in a variety of application areas. The HaptX
DK23 glove utilizes a combination of microfluidics and restive-
force haptics to emulate technology that emulates the hap-
tic sensation of holding an object. A variety of multi-driver
vests and shirts have been designed primarily for immersive
2https://pixiedusttech.com/soundhug/en/index.html
3https://haptx.com/dk2-release/
gaming experiences or as an augmentation to music listen-
ing, such as the SoundShirt4,Woojer Vest5, and the BHap-
tics Tactsuit6. Wearable haptic technologies have also been
used in a variety of sensory substitution research, such as
a haptic wristband that has been used to augment experi-
ences of verbal speech and showed significant improvement
in speech intelligibility [15]. While sensory substitution re-
mains an exciting application, ensuring many members are
actively involved in the design process is crucial but not
widely practiced in the field [7].
Non-contact: The Ultra Leap Stratos7 utilizes a grid of
256 ultra-sonic speakers to render contact-less haptic feed-
back on the user’s skin, provided they are within the inter-
action zone. The system tracks the position of the user and
modulates the amplitude and phase of the pressure waves
emitted by the ultra-sonic speaker array. Disney’s exper-
imental AIREAL system emitted strongly-timed, concen-
trated air vortexes which the user experienced as a feeling
of localized pressure [19].
2.3 Participatory Design with DHH Children
Participatory design (PD) is a framework for human-centered
research that engages participants to be active agents and
partners in the designing of research related artifacts or pro-
totypes rather than engaging only with end users during
the later stages of the design process [18]. These methods
are particularly effective for communities who have been
under-engaged with by prior research and may experience
additional socio-economic marginalization, such as the DHH
community, as the embodied knowledge and lived experi-
ences they have are not often included in the academy. Ko-
rte et al. highlight in the importance of establishing clear,
robust communication with young DHH children partici-
pating in PD research in their “YoungDeafDesign” frame-
work to ensure the highest degree of participation possi-
ble [11]. Both PD and YoungDeafDesign highlight the im-
portance providing structure and support while working
with co-designers, but remaining flexible to respond to their
needs, concerns, and goals, which may change throughout
the course of the study.
3. METHODS
This participatory design study occurred over three work-
shop sessions held at Metro Deaf School, a charter school
for Deaf, DeafBlind, and Hard-of-Hearing students located
in St. Paul, MN that uses American Sign Language (ASL)
as the primary language of instruction. We employed a
mixed methods approach that combined survey data, ob-
servational data, as well as the creation and analysis of
workshop artifacts in the form of VT display prototypes
as well as short exploratory VT compositions (etudes).
3.1 Participants
Participants were comprised of 27 middle school students
aged 11-14 who were enrolled at Metro Deaf School, DHH,
fluent in ASL, and students of the science class in which the
workshops took place. Due to the fixed time window of the
workshop as well as the difference in time required by dif-
ferent participants to complete the activities, not all partic-
ipants completed every part of each session. Of the 27 par-
ticipants who took place in at least one of three workshops,
4https://cutecircuit.com/soundshirt/
5https://www.woojer.com/pages/vest
6https://www.bhaptics.com/tactsuit
7https://www.ultraleap.com/haptics/
17 participants completed all parts of all three workshops.
Not all participants completed every session or survey due
to time constraints, illness, or other factors. The composi-
tion of each workshop session had the same participants as
the science class the participants would normally attend at
that same time. Additional participant demographics can
be found in Table 4
3.2 Workshop Overview
Three workshop sessions were conducted over the course of
one week. Each workshop lasted approximately 50 minutes
and took place during the science class period at Metro
Deaf School. These workshops were primarily facilitated
by Lloyd May, a hearing music technology researcher fluent
in ASL, with support provided by an experienced science
educator at Metro Deaf School, during every session. Ad-
ditional support during classes 2 and 5, as shown in 5, was
provided by trained professionals employed or contracted
by Metro Deaf School. The supports offered included one-
on-one support, particularly for the two DeafBlind partic-
ipants, an additional educator trained in accessible educa-
tion practices, as well as an ASL interpreter with experience
signing with additional clarity that has previously benefit-
ted participants in this class. Other members of the research
team who were hearing and not fluent in ASL were present
during approximately half of the workshops and assisted
with documentation and set-up.
Participants completed the survey worksheets and exit
surveys throughout the workshop session with assistance
from the facilitation team as needed. All workshop activ-
ities were conducted in ASL. Enlarged survey worksheets
printed on colored paper were prepared for the two Deaf-
Blind workshop participants.
3.2.1 Session 1: Introduction and Exploration
Introductions include who the researchers are, why they
are visiting, and what we hope to achieve together. This
was then followed by an overview of the workshop and an
ideation icebreaker activity asking participants to discuss
what superpowers they would have if they could have any
superpowers. Researchers then presented a 5-minute mini-
lecture on introduction to vibrations, which included a level-
appropriate introduction to waves and pressure and a work-
sheet activity asking participants to report three examples
of vibrations they have experienced before noting where and
when they happened as well as any emotions they remem-
ber experiencing during the vibration. The research team
then introduced the concept of VT playback to participants,
including an overview of the hardware setup and playback
software as shown in Figure 1. Additionally, participants
were provided with a Dell laptop that ran both pieces of
Max MSP standalone programs described below and out-
put the VT signals via an 1/8” stereo cable to the amplifier.
All equipment was set up and tested before participants ar-
rived for each session. Participants were invited to explore
the four vibration data types presented (brainwave, earth-
quake, train, and heartbeat), explore the placement of the
transducer on their bodies, and note their observations on
the survey worksheet. Heartbeat and train passing signals
were manually recorded using a piezo surface microphone,
the ’brainwave’ signal was a single channel of an electroen-
cephalogram (EEG) of a member of the research team at
rest, and the earthquake signal was obtained from an earth-
quake sound effect video publicly available on YouTube 8.
These signals were selected to convey a diversity of sources,
8https://www.youtube.com/watch?v=mgLBmLoL2Aw
amplitude profiles, and levels of assumed experience with
the vibrations.
3.2.2 Session 2: Display Prototype Building
The session began with an overview of the agenda for the
session, a review of the VT components, and an overview
of the various materials they would have access to during
the session. Participants were then invited to select one
of the four vibrations they experienced in session one and
build a prototype of a device to best display that specific
vibration. Participants had access to the same VT playback
interface as session 1. Upon completion of their own pro-
totype, participants were randomly paired with a partner
with a completed prototype and asked to complete a sur-
vey worksheet analyzing their partner’s display prototype.
Each participant had access to all of the materials listed in
Table 2.
3.2.3 Session 3: VT Composition
After a recap of the previous session and an overview of
the session’s agenda, the research team presented an intro-
duction to composing (i.e. placing things intentionally in
time and/or space) as well as an overview of the compo-
sition interface, as shown in Figure 2. Participants were
able to generate a continuous tone by holding the space
bar, stopping by lifting the space bar up, and adjusting the
frequency (20 - 400 Hz) and roughness (depth of 20 Hz am-
plitude modulation) using either the arrow keys or mouse
button. Four short (approximately 4 seconds) samples were
available, namely: heartbeat, rumble (constant noise), riser
(noise with an exponential increase in volume), and impact
(noise with an exponential decrease in volume). Samples
could be triggered using the corresponding numbered keys
on the keyboard or using the mouse. Multiple samples could
be triggered simultaneously and would play polyphonically
with the tone if one was being generated when the sample
was triggered. Global volume was adjusted via a slider us-
ing the mouse. Participants were able to record VT signals
by pressing the ‘R’ key on their keyboard or clicking the
large red button. This would trigger a three-second count-
down, displayed in the grey box beneath the “Timer” label,
which then transitioned into a 20-second countdown, during
which the VT signals were recorded. After the 20-second
window, the recordings became available for playback us-
ing the buttons labeled 1-3, which would each turn green
once they were associated with a recording. Only three
recordings could be recorded using this software, encourag-
ing participants to approach the recordings with a degree of
intentionality. Once all three slots were full, no more could
be recorded.
Participants were asked to select either an emotion (e.g.
anger, excitement, etc.) or a situation (e.g. petting a cat,
riding the bus, etc.) that they would like to communi-
cate through their VT compositions. Participants were then
asked to record three 20-second-long etudes 9 communicat-
ing that emotion or situation. Participants then paired up,
experienced a single VT etude selected by their partner,
and completed a survey worksheet analyzing their partner’s
etude.
3.3 Analysis
We inductively analyzed both the VT display prototypes
as well as the VT etudes through a grounded theory ap-
proach with two researchers to identify both general cate-
9Short, exploratory compositions.
Figure 1: (Left) The user interface used to control VT signal selection and playback. (Right) the (a) signal amplifier and (b)
VT transducer each participant had access to during the workshop.
Figure 2: The user interface used to compose, record, and playback VT signals.
gories and specific themes created across display prototypes
and etudes [3]. For the VT display prototype analysis, re-
searchers constructed a table of material characteristics and
design patterns (seen in Table 2), and independently ana-
lyzed each prototype to determine which of the characteris-
tics and design patterns each instrument used. The research
team then viewed the picture(s) of each of the n=24 proto-
types as well as any related observational notes in the dig-
ital sticky note software Miro. We discussed what physical
attributes and design patterns were present in each proto-
type and grouped them based on this content. Axial coding
was then performed by dividing these initial groups into
smaller, detailed, cohesive categories. This was repeated
until no smaller categories could be found, with each cate-
gory being subsequently labeled. Artifacts that prompted
disagreements between researchers were put aside and dis-
cussed again at the end of the analysis. These artifacts were
either placed into an agreed-upon category or placed into
the “Other” category.
The VT etudes were analyzed in the same fashion, with
notes in Miro containing a codename for each etude used
for grouping. Each researcher had access to a VT playback
system consisting of a Kinter MA170 18W amplifier and a
Dayton Audio DAEX 25 VT transducer. The researchers
performed gain matching before every VT etude analysis
session.
4. RESULTS
4.1 Vibrotactile Exploration
During session one, participants completed a vibration ex-
ploration activity where they used the interface and equip-
ment outlined in 3.2.1, and explored short 3-5 second ex-
cerpts of earthquake, train passing by, raw brainwave (EEG)
data, and heartbeat VT signals. Participants were encour-
aged to move the VT transducer onto various parts of their
body and note the various sensations they experienced. Par-
ticipants were asked to select their favorite VT signals and
locations, with results shown in Figure 3. Participants were
additionally asked to name which vibration they would like
to record and experience as a VT signal, the answers are
summarized in Table 1.
4.2 VT Instrument Prototypes
Participants were asked to select a signal, from the four
they explored in the previous session, to create a low-fidelity
prototype for the device they would like to use to experience
their selected VT signal using various crafting materials,
such as cardboard and fabrics, and a single VT transducer.
10 selected brainwave, 4 heartbeats, 3 train passing by, and
5 participants selected the earthquake sample. In total, 24
instruments were prototyped by 25 participants, as one pair
Figure 3: Participant’s top selection for (left) their favorite location on their body to experience the VT signals, and (right)
their favorite VT signal.
Table 1: Participant’s selection of a vibration they would like to record and experience as a VT signal.
Category # of Selections Examples
Fictional 2 Sound effects from a sci-fi movie
Non-fictional, natural 5 Car purring, rain
Personal 6 Heartbeat, brainwaves
Non-fictional, synthetic 12 The inside of a computer, airplane engine
of participants preferred to collaborate.
The frequency of design characteristics and materials used
are summarized in Table 2. The categories of materials
and design patterns used were: (1) the placement of the
driver relative to other prototype components, (2) the use
of a receptacle or container-like component that could hold
other components inside, (3) the use of free objects which
were not firmly secured and allowed to move freely or semi-
freely in response to vibration, and (4) the use of fixed,
non-receptacle objects. The prototypes are illustrated in
Figure 4
A thematic analysis was performed on these artifacts and
produced two primary themes, namely prototypes that used
materials to provide additional visual feedback of the vibra-
tions, and those that relied primarily on tactile stimulation
alone and did not contain any components that responded
to vibrations in a visible manner. Two sub-themes were
noted across prototypes grouped into these main themes,
namely the utilization of three or fewer components to cre-
ate a minimal design and others that used more components
to employ a more embellished design.
Within the group of prototypes that provided additional
visual feedback and utilized a minimal design, it was noted
that some elected for the free objects to be in direct con-
tact with the driver, leading to more noticeable free object
movement, while others preferred to have free objects rest
on another surface attached to the driver. The embellished
designs however used a variety of both free objects and ob-
jects fixed at one end that vibrated in a visible way, such as
feathers, popsicle sticks, and pipe cleaners.
The group of prototypes that relied primarily on tac-
tile stimulation alone had three types of primary texture
present, namely parchment-type texture of paper and card-
board, plush-type texture of fuzzy materials, and mixed-
textured which combined parchment, rubber, and plush-
type textures. Prototypes from all three of these texture
groups contained both minimal and embellished designs.
Notably, P16’s instrument did not make use of a driver but
was required to be physically shaken to create the partici-
pant’s desired haptic sensation.
4.3 VT Composition
Participants were asked to select an emotion and/or situa-
tion and compose three 20-second VT etudes that explored
their selected theme. Selected themes (Table 4 ranged from
the recreation of real-world experiences such as “blissfully
petting a cat” (P1) or being “surprised inside an airplane”
(P29), to involving some degree of narrative such as feel-
ing “happy in a video game, then I get killed, then I get
mad” (P16), as well as abstract concepts such as “electric-
ity” (P3), or “fear, uncertainty, a sense of foreboding” (P4).
Etudes illustrated a variety of characteristics and employed
VT compositional elements ranging from amplitude modu-
lation, to sustained tones, to repetition, to silence, as shown
in (Table 3).
17 etudes were completed by 19 participants, as two sets
of two students independently decided to work together
on the compositions. The thematic analysis resulted in
two primary themes, namely compositions that employed
largely static textures ( Textural) and those that used VT
material in a strongly rhythmic way ( Rhythmic). Within
these themes, two axes of sub-themes were identified: (1) if
the piece used the same compositional motifs/patterns for
the duration ( Constant), or if it employed multiple ( Mul-
tiple), and (2) if the piece consisted of silence for a total
of more than 50% of its duration ( Sparse) or contained
less than 50% silence ( Dense). Figure 5 displays a 0-600
Hz frequency-limited spectrogram of each participant’s pre-
ferred VT etude, grouped by both primary theme and sub-
theme.
Figure 4: Images of the 24 prototypes produced by participants, divided into primary themes (Primary Tactile, Additional
Visual Information), as well as sub-themes related to the type of texture, number of design elements used, and the relationship
between elements.
5. DISCUSSION
5.1 Exploration
As shown in figure 3, participants indicated a mix of location
preferences, including ones rarely designed for in general
VT haptic devices such as the face and head. Participants
noted that these areas were more sensitive to VT stimula-
tion and it provided a more intense experience, such as P
27 noting “it feels like... woah!” when placing the driver to
their cheek. Most participants noted broad rationale such
as it felt “nice” (P1) or “fun” (P12), some participants men-
tioned connections to previous VT haptic experiences, such
as P27, whose favorite VT location was ”in my pocket, be-
cause it is [the] place for my phone”, alluding to the familiar
experience of having a phone vibrate in their pocket. Two
participants who selected the hand as their preferred area
made a similar connection to video game controllers pro-
viding VT stimulation. While every future VT instrument
user might not want their cheeks or forehead stimulated,
allowing for these playful, exploratory engagements allowed
more participants to engage with the VT art and devices
on their own terms and lead to more varied positive inter-
actions with the technology.
The majority of participants selected the raw EEG data
as their favorite, noting it was “intense” (P27) and “buzzy
and nice” (P2). The earthquake and train VT signals pos-
sessed elements that were more easily interpreted as nar-
rative due to their connection to events that participants
have previously experienced, such as P12 noting the heart-
beat VT signal “feels the same” as their heartbeat.
The mean enjoyment rating of the exploration workshop
was 2.94/3 ( ± 0.2, N = 17), on a 1–3 scale. While there
was undoubtedly a large degree of novelty bias given the
niche nature of the technology used and the excitement that
comes with having external people visit a school classroom,
these findings support the conclusion that participants en-
joyed exploring both VT driver placement and VT signal
types. There was no clear or consistent preference among all
participants, indicating that personal choice, exploration,
and customization are important factors to consider in the
future design of VT instruments.
Figure 5: Images of spectrograms of the 17 etudes produced by participants. Each etude is 20 seconds in length. The
spectrograms are frequency-limited to only display 0-600Hz and are divided by major theme (Rhythmic or Textural), and by
sub-theme (Constant Motif or Multiple Motifs).
5.2 Personalization and Referential Signals
The variety of configurations and materials used in the pro-
totypes that did not directly impact the VT signal, such
as visual decorations, illustrates a desire for personalization
in VT instruments, with some participants even anthropo-
morphizing their prototype such as P1 referring to their
prototype as a “little buddy”. This theme of personaliza-
tion extended to some etudes, as P17 used the Morse code
embedding of their name as a point of inspiration when
constructing their very rhythmic, staccato piece.
Creating representational touchpoints through the incor-
poration of familiar signals that relate to lived experience
appeared to help some participants acclimate to the use of
VT signals in a creative way. Upon reflecting on the pro-
totype they had created to display a heartbeat signal, P3
noted the similarity to a real-world experience they had
created, reflecting that their prototype “feels like an actual
heart”, while P4’s feedback on P2’s instrument highlight the
use of materials to create a similar experience, noting that
the ”balloon amplifies [the signal and] gives the heartbeat
a real feel”. P18 noted that this representation of a heart-
beat held aesthetic symbolism, enjoying that P14’s proto-
type “gave it a heartbeat”. The signals could additionally
reference stages of a narrative, such as P18’s etude which
captures the feeling of being “happy in [a] video game, then
[getting] killed, then [getting mad].” Additionally, the abil-
ity for abstraction and composing with non-referential sig-
nals allowed users to explore varied compositional questions
that are not strictly narrative or referential. This could be
seen in, for example, P4’s choice to explore the imagined
sensation of feeling electricity or P5 expressing a feeling of
“fear, uncertainty, a sense of foreboding” in their respective
VT etudes.
5.3 Physical and Compositional Textures
Both the results of the prototype thematic analysis and
workshop notes illustrate the importance of the physical
texture of the prototype to many participants. For exam-
ple, P1 “liked the fluffy” texture of P4’s instrument. Par-
ticipants noted the textures of materials, from silky lace to
smooth paper, in their reflections on their own instrument
and their feedback on the instruments of others. However, a
clear favorite physical texture did not emerge, with a variety
of textures incorporated, as shown in Figure 4. Therefore,
having multiple physical textures available for VT instru-
ments appears highly desirable.
Aside from the tactile texture of the physical prototype,
participants used a variety of compositional textures, mean-
ing the creation of a sustained sensation as opposed to
rhythmic information, in their VT art, ranging from smooth
sustained sine tones to perceptually rough amplitude-modulated
tones. VT art and technologies are generally employed to
communicate strongly rhythmic information, however, 7 out
of 17 etudes demonstrated a clear use of compositional tex-
tures, indicating a strong desire from participants to incor-
porate abstraction and texture into their VT work.
5.4 Design Recommendations
The results of the surveys, workshop notes, and thematic
analyses were analyzed in totality to derive four design con-
siderations for the development of new VT instruments, par-
ticularly those looking to actively include DHH children in
their user base. These recommendations are:
5.4.1 Flexibility of VT Driver Placement:
One size does not appear to fit all in VT display prefer-
ences. Therefore, the flexibility to move and adjust drivers
Table 2: The number of prototypes that used each of the
available materials.
Prototype Element Number of Prototypes
Driver:
Driver outside receptacle 12
Driver inside receptacle 9
Attached to other object 5
No driver 1
Receptacle :
Box 13
Roll of tape 2
Balloon stacked on top of boxes 2
Balloon 1
Boat shaped wooden box 1
Vase 1
Two boxes stacked 1
Free Objects:
Rocks - inside receptacle 11
Sand - inside receptacle 1
Other Materials:
Pipe cleaners 8
Popsicle sticks 6
Bumper dots 4
Fluffy fabric 3
Tinsel 2
Baige foam 2
Rubber worm 2
Car wash glove 2
Feather 1
Bubblewrap 1
Craft paper 1
Lace 1
Felt fabric 1
Microfiber cloth 1
Googly Eyes 1
Table 3: The number of etudes that used the identified com-
positional strategies and elements used by the 48 etudes cre-
ated by 19 participants.
Category Characteristic Count
Arrangement Constant Motif 24
Multiple Motifs 24
Element
Riser 9
Impact 9
Heartbeat 6
Silence 18
Tone - Constant Freq. 20
Tone - Constant Freq. 11
Tone - Amplitude Modulated 19
Tone - Sub 60 Hz 9
Tone - Over 300 Hz 4
Tone - Rhythmic 17
Density Sparse 16
Dense 14
Dynamics Mix of Low & High Intensity 2
Low Intensity 4
to different parts of the body and/or to different external
objects should be considered.
5.4.2 Allow for Multiple Forms of Compositional Input:
Instruments should allow for both representations of real-
world VT signals, such as through playback of recordings,
as well as allowing for abstraction through signal and com-
positional controls.
5.4.3 Actively Encourage Personalization, Narrative, and
Decoration:
VT instruments should encourage personalization and dec-
oration through the incorporation of intuitive locations on
the objects to apply both visual decorations and materials
of varied textures.
5.4.4 Provide Options for Multi-sensory Feedback:
Visual displays of VT signals, particularly through analog
means, provide an additional entry point to VT art while
also offering a useful mode of feedback.
5.5 Limitations
The current study and workshop possessed several limita-
tions. These include time constraints imposed by the struc-
ture of fitting into a standard middle school class time of
50 minutes as well as the compressed nature of a 3-day
workshop that did not offer participants as much time to
process information and reflect on themes of the workshop
over time. As a result of this, participants did not have an
opportunity to revise or expand on the design of their proto-
types or etudes. Additionally, the composition software was
designed before the workshop based on previous VT per-
ception literature. However, additional forms of composi-
tional input and user feedback could be explored, such as se-
quencers or timeline editing, to offer additional creative pos-
sibilities aside from the current plan-then-perform/improvise
structure the current compositional system affords. A fea-
ture set with increased robustness would allow for more in-
depth review and revision would allow for a greater degree
of nuance to be uncovered in these workshops.
6. CONCLUSION AND FUTURE WORKS
We presented the methods and results of a multi-day co-
design workshop with 27 DHH children in middle school
where participants (1) reflected on their previous experi-
ences with vibrations, (2) designed and fabricated a proto-
type of a low-fidelity VT display, and (3) composed three
20-second pieces of VT art. After exploring various VT vi-
bration types and driver placement, participants indicated a
wide variety of preferred locations for the VT driver, includ-
ing the head and neck. Participants’ low-fidelity prototypes
were divided into prototypes that provided additional vi-
sual feedback regarding the VT signal (15) as well as those
that relied primarily on tactile interactions and textures (9).
The various short VT compositions that participants com-
posed were analyzed in a similar way that highlighted the
compositional theme of composing with primarily rhythmic
or textural motifs. Finally, we concluded with several de-
sign insights that could be incorporated into the design of
future VT instruments, namely: (1) flexibility of VT driver
placement, (2) allow for multiple forms of compositional in-
put, (3) actively encourage personalization and decoration,
and (4) provide options for multi-sensory feedback.
Future work includes the design and creation of a medium-
fidelity, modular, customizable prototype based on these
findings and conducting another co-design workshop. Fu-
ture workshops could include a more prolonged engagement
with a smaller group of participants in an attempt to cap-
ture additional nuanced design insights and the evolution
of co-designers perspectives over multiple engagements.
7. ETHICAL STANDARDS
This research was conducted with the approval of the inter-
nal review board (IRB) of the University of St. Thomas.
All participants were under the age of 18 and were there-
fore asked to provide written, informed assent, while each
participant’s legal guardian provided written and informed
consent. Participants were informed that their choice to
participate had no impact on their academic standings or
extra-curricular activities, was purely voluntary, and that
they could stop participating at any time with no repercus-
sions. Researchers were available to answer questions about
the assent or consent process in written or spoken English
as well as ASL.
8. REFERENCES
[1] D. Bobier. Haptic voices, 2021.
[2] S. Choi and K. J. Kuchenbecker. Vibrotactile display:
Perception, technology, and applications. Proceedings
of the IEEE, 101(9):2093–2104, 2012.
[3] J. M. Corbin and A. Strauss. Grounded theory
research: Procedures, canons, and evaluative criteria.
Qualitative sociology, 13(1):3–21, 1990.
[4] S. Crider. Re-defining music through deaf lens.
Master’s thesis. Gallaudet University, Washington,
DC, 2009.
[5] Z. Davis. Behind the screens: Shake it up, baby.
Electronic Gaming Monthly. No. 95., page 74, 1997.
[6] E. Frid. Accessible digital musical instruments—a
review of musical interfaces in inclusive music
practice. Multimodal Technologies and Interaction,
3(3):57, 2019.
[7] E. Guffey. In the wake of universal design: Mapping
the terrain. Design Issues, 37(1):76–82, 2021.
[8] E. Gunther and S. O’Modhrain. Cutaneous grooves:
Composing for the sense of touch. Journal of New
Music Research, 32(4):369–381, 2003.
[9] A. Israr, S.-C. Kim, J. Stec, and I. Poupyrev.
Surround haptics: Tactile feedback for immersive
gaming experiences. In CHI’12 Extended Abstracts on
Human Factors in Computing Systems, pages
1087–1090. ACM, 2012.
[10] W. Jacobs. Waves and Signs (The Floor). Center for
Advanced Visual Studies, MIT, 2009.
[11] J. Korte. Youngdeafdesign: Participatory design with
young deaf children. International Journal of
Child-Computer Interaction, 34:100542, 2022.
[12] A. M. Okamura. Haptic feedback in robot-assisted
minimally invasive surgery. Current opinion in
urology, 19(1):102, 2009.
[13] S. Papetti, H. J ¨arvel¨ainen, and F. Fontana. Design
and assessment of digital musical devices yielding
vibrotactile feedback. In Arts, volume 12, page 143.
MDPI, 2023.
[14] S. Papetti and C. Saitis. Musical haptics. Springer
Nature, 2018.
[15] M. V. Perrotta, T. Asgeirsdottir, and D. M.
Eagleman. Deciphering sounds through patterns of
vibration on the skin. Neuroscience, 458:77–86, 2021.
[16] M. A. Plaisier and A. M. Kappers. Emulating social
haptic communication with vibration patterns. In
2021 IEEE World Haptics Conference (WHC), pages
338–338. IEEE, 2021.
[17] P. Rubin. Exclusive: A deeper look at the playstation
5-haptics, ui facelift, and more, Aug 2019.
[18] D. Schuler and A. Namioka. Participatory design:
Principles and practices. CRC Press, 1993.
[19] R. Sodhi, I. Poupyrev, M. Glisson, and A. Israr.
Aireal: interactive tactile experiences in free air. ACM
Transactions on Graphics (TOG), 32(4):1–10, 2013.
[20] X. W. Staff. The new generation xbox controller,
June 2013.
[21] H. Z. Tan, N. I. Durlach, C. M. Reed, and W. M.
Rabinowitz. Information transmission with a
multifinger tactual display. Perception &
psychophysics, 61(6):993–1008, 1999.
[22] J. M. Weisenberger. Sensitivity to
amplitude-modulated vibrotactile signals. The
Journal of the Acoustical Society of America,
80(6):1707–1715, 1986.
[23] Y. Yoo, I. Hwang, and S. Choi. Consonance of
vibrotactile chords. IEEE transactions on haptics,
7(1):3–13, 2013.
APPENDIX
A. PARTICIPANT INFORMATION
Table 4: Demographic information of participants
PID Class ID Age Gender Selected VT Signal Etude Description Note
1 1 12 F Heartbeats Blissfully petting a cat
2 1 12 F Heartbeats Not sure, it just feels good
4 1 13 M Heartbeats Electricity
5 1 12 Genderfluid Earthquake Fear, uncertainty, a sense of foreboding
6 2 11 M Brainwave N/A
7 2 13 M Earthquake Video game, excited, ps4 or xbox one, vibrates
8 2 11 F Earthquake Happy video game DeafBlind
9 2 14 M Earthquake Cat sits feel chill, going visit, excited, my heartbeats DeafBlind
10 2 13 M Brainwave Happy video game
11 2 12 M Earthquake N/A
12 2 13 M N/A Video games, ps4 black, excited
13 2 12 F N/A Happy video game
14 2 12 F Heart Excited on a roller coaster
16 3 11 M Train Cat and chill
17 3 14 M Heart (None)
18 3 14 F Train Happy in video game, then I get killed, then I get mad
19 4 11 F Brainwaves N/A
20 4 11 F Heart N/A
21 4 13 F Brainwaves N/A
22 4 13 M Brainwaves N/A
23 4 13 F Heartbeat N/A
24 4 13 M Brainwaves N/A
26 5 13 F Train Happy in airplane
27 5 13 M Heart Excited while playing videogames
28 5 12 M Brainwaves Scared in a plane
29 5 12 M N/A Surprised inside an airplane
30 5 12 M Brainwaves (None)
Table 5: Additional information regarding the five classes groupings used in the study
Class ID No. participants Notes
1 4 Advanced class
Several participants with additional Disabilities and/or learning differences.
2 9 Two additional teaching staff and an interpreter were present
3 3
5 6
6 5