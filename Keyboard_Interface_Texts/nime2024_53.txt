Concerts of the Future: Designing an interactive musical
experience in VR
Ciaran Frame
SensiLab, Monash University
Melbourne, Australia
ciaran.frame@monash.edu
ABSTRACT
This paper examines the creation and development of Con-
certs of the Future, a Virtual Reality music experience that
bridges the gap between music listening and active partici-
pation. Collaboratively developed with a chamber ensemble
over eight months, the narrative-driven experience places
participants alongside a live ensemble, enabling them to
perform with a unique gestural instrument in a VR concert
setting regardless of musical experience. Reflecting on pre-
vious work in the VR and interactive music field, the paper
outlines key design decisions that were made in the devel-
opment of the work over a period of 8 months, including
a pilot presentation with participants. The paper discusses
the implications of stylised VR design and the use of theatri-
cal elements outside the digital environment to make music
more accessible. It highlights the potential of VR in trans-
forming the traditional roles of composer, performer, and
listener, thus expanding the scope of participatory musical
experiences.
Author Keywords
VR, musicking, Digital Musical Instruments, audience par-
ticipation
CCS Concepts
•Applied computing → Sound and music computing; Per-
forming arts;•Human-centered computing→ Participatory
design;
1. MOTIV ATION
In 2022, 91% of the population of Australia aged 15 and
over listened to recorded music, leading the National Arts
Participation Survey to conclude that music was “. . . the
most accessed, and potentially most accessible, art form. . . ”
[7] in Australia. Implied but not stated in this conclusion
was that the term ‘music’ was actually referring to music
listening. In reality, only 14% of the population of Australia
aged 15 and over played or created music [7].
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’24, 4–6 September, Utrecht, The Netherlands.
In contemporary Western music, while a vast majority of
people regularly partake in music listening, a smaller per-
centage are involved in its active creation. This distinction
between listening to music and music-making has been ex-
plored by the likes of Sessions, particularly in the context of
traditional roles, where “the composer writes, the performer
plays, and the listener claps” [17].
An excellent illustration of this lies in the activities of a
concert hall – as Small points out, audiences are“. . . excluded
from the magic world of the musicians, whose separateness
is symbolised so lucidly . . . by the division of the concert
hall into two” [19].
These observations around the social aspects of musical
form and participation suggest interesting creative material
for artists and composers to explore, discussed in the next
section.
2. RELATED WORK
2.1 Audience participation and music
Active audience participation has blossomed alongside the
evolution of Western contemporary classical and popular
music, marking a trend away from the traditional struc-
tures present in the concert hall in both audience prefer-
ence and artistic intent from composers and musicians [6].
Sloboda and Melissa observe that the activity of “attending
concerts and sitting quietly as a live performance unfolds...”
is ”...an increasingly incongruous activity in our data-rich,
fast-paced world” [18] in [20].
Musical works have a rich history of allowing participants
to play more active roles, particularly in the case of audi-
ences or non-performers. Of course, listening to music can
in itself be an ‘active role’, and can certainly amount to
audience participation in some contexts [10], so here I refer
use the term ‘audience participation’ based on Toelle and
Sloboda’s proposition that it involves some form of“creative
expression on the part of the audience member” [20].
Pauline Oliveros’Lunar Opera[15] uses audiences to shape
the structure of the work, using breathing exercises and
crowd movements to alter the sound world. Audience mem-
bers do not need to play an instrument, “...the only re-
quirements for participation are that you enjoy listening
and walking/moving with awareness”[15] – a clear compo-
sitional technique that creates a more active experience for
participants.
More recently, digital technologies have begun to change
the role of the audience even more dramatically. The grow-
ing popularity of music technology and sensor-based gestu-
ral instruments has meant that traditional musical roles and
modes of participation are more fluid and interchangeable,
particularly in the context of Digital Musical Instruments
(DMIs) [13]. Examples of audience participation in this con-
text include works that use audiences’ locations [9], posting
on Twitter [8], using mobile phones [11], or even perhaps
the act of dancing in front of a DJ set [12].
These examples illustrate a new environment for music
interaction, which Lansky says leads to an“increased poten-
tial for complex social interactions in this expanded network
where the most promising musical opportunities emerge”
[14].
2.1.1 Virtual reality and music
The use of Virtual Realities in the field of music is diverse.
Here I use the term Virtual Reality (VR) to mean an im-
mersive experience that transports the participant to a new
reality through technology like VR headsets.
There are comparisons to be made with immersive music
projects outside the headset space that use different forms
of mixed and virtual realities, such as Laurie Anderson’s
Puppet Motel [1] (an interative CD-ROM), Pauline Oliv-
eros’ Rotating Brains / Beating Heart[2] (a mixed reality
performance) and Juan Carlos Vasquez’s Ecstasy / Light /
Inertia [22] (an interactive gamified musical experience).
In terms of works that use VR headsets, there has been
significant growth in the field of music training and edu-
cation, in areas such as conducting training [5], or in pi-
ano practice [16]. Virtual Reality headsets have also been a
place for artistic exploration, particularly in the field of new
instruments and generative systems, like augmented instru-
ments [16] or entirely virtual instruments [23]. These trends
reflect Bailenson’s observations around VR as a medium
that allows for tangible experiences [4] that allow for on-
demand access to environments or contexts that may oth-
erwise not be practicable or even physically possible.
Notably, however, these VR systems have typically re-
inforced the traditional roles of composer, performer and
listener proposed by Sessions [17]. For instance, new in-
struments or training tools are typically used by performers
or those aspiring to be one. There are very few instances
where the traditional role of ‘audience member’ produces
the music themselves within VR experiences – instead the
role of audience is often reinforced from a different perspec-
tive (such as the field of view in a performance) [21].
This presents an interesting opportunity to explore the
medium of VR through an artistic lens in order to extend
the audience experience. VR is an ideal medium to explore
this kind of immersive musical participation in a safe, con-
trolled environment that might not otherwise be practical
or desirable.
A natural evolution of participatory musical experiences,
discussed in the previous section, and the opportunity for
new participatory VR works discussed in this section, forms
the basis of the new work “Concerts of the Future.”
3. CONCERTS OF THE FUTURE
Concerts of the Futureis a novel VR music experience cre-
ated to address the disparity between music listenership and
active participation in a creative way. The project leverages
wireless gestural instrument technology and high-definition
360 degree video recording to offer an immersive experience
where participants with no required previous musical ex-
perience find themselves centre-stage in a virtual concert
setting.
The work invites participants onto the concert hall stage
through a VR Headset, sitting on the stage next to per-
forming members of a real ensemble, with the ability to
play, listen and absorb music in 3D space.
Virtual Reality was chosen as the means of placing partic-
ipants in a virtual concert hall because it provided a prac-
tical platform for anyone to play with musicians on a more
intimate level. As Wang and Atherton point out, VR is
ideal for “Making things that would be impossible in the
physical world” [3] – it makes an impractical scenario (hav-
ing a chamber ensemble on call for individual experiences
of the same piece for extended periods of time) a (virtual)
reality.
3.1 Audience experience
Participants interact with the performance by sitting along-
side members of a chamber ensemble in a 3D virtual space.
The chamber ensemble, Rubiks Collective, is a real ensem-
ble based in Melbourne, Australia consisting of four players
(flute, cello, percussion and piano). The participant re-
places one of these players at random, playing their own
unique digital musical instrument, the ‘AirStick’, a wireless
gestural controller that allows for the translation of move-
ment into sound (shown in Figure 1).
Figure 1: The AirStick.
The experience commences outside of VR, in a real, phys-
ical green room where participants familiarise themselves
with the ‘AirStick’ instrument. They are shown a fake live-
feed of the concert hall they will soon enter, and given a
program that has their name in it. The program outlines
the scenario participants will be placed in:
Name is a performer based in Melbourne. This
is their first collaboration withRubiks Collective,
and their first performance on the AirSticks. The
AirSticks technology will follow their movements
throughout the piece, as arm and hand move-
ments are transformed into virtuosic musical lines.
Participants receive a knock on the door of the green
room, and are escorted to the ‘concert hall’ – an empty,
dimly-lit room filled with a piano, empty spotlit stools,
speakers, and the sounds of pre-concert chatter as if an
audience were in their seats in the darkness just beyond
the light awaiting the performance. Upon donning the VR
headset, they are transported to a similarly empty concert
hall, but the performers shuffle in to take their places and
greet their fellow participant (see figure 2).
The lights come up, and the piece begins, with participant
and ensemble playing together. Members of Rubiks provide
eye contact and smiles while playing, and the integration of
spatial audio and stereoscopic imaging enhances the realism,
culminating in a performance where participants play by
Figure 2: A participant interacts with the VR experience.
moving their arms, simulating the thrill of a live concert
performance, as seen in Figure 3.
Figure 3: A screenshot of what a participant observes within
the 360 degree experience.
3.2 Technology
The performance that the participant plays in is a previ-
ously recorded video that is played back in VR. Recordings
were made with the Nokia OZO 360 camera, recorded in full
stereoscopic takes with close microphones (seen in Figure 4).
These recordings were then rendered into a polished edit,
and audio tracks split out into individual speakers placed in
the same discrete positions where the performers sat rela-
tive to the OZO camera. Through this static speaker place-
ment, and the fact that the participant remains station-
ary throughout the VR experience, a sense of realism is
achieved by creating a spatialised sound environment that
reflects what participants are seeing in the video. This tech-
nique was chosen because the recordings were made in the
same space the VR experience takes place in, thus achieving
acoustic realism without the use of headphones.
The VR experience is run through a Oculus Rift S VR
headset, with the video content coming from a Unity run-
time file. Audio is run from a separate computer due to
operating system constraints – the Unity session runs on
Windows, and the audio session runs on MacOS. Sensor
data from the AirStick is sent to a MacBook Pro via custom
AirStick software, which translates movement into MIDI in-
formation and triggers instruments within Logic Pro. Per-
former tracks from Rubiks are also played in the Logic Pro
session, allowing for the syncing of participant and Rubiks
content. The audio computer is linked to the Unity project
through OSC, meaning that the video content from Unity,
and the audio content from Logic Pro can be triggered at
Figure 4: Recording a take with the Nokia OZO camera.
the same time. QLab is used on the audio laptop to se-
lect one of four takes, and to send a ‘Go’ trigger to both
Unity and Logic Pro when the participant is comfortable
with their headset and position.
The tech layout is shown in Figure 5.
Figure 5: The technical setup for performance.
4. DESIGN DECISIONS
Development of Concerts of the Futureoccurred over a pe-
riod eight months in collaboration with Rubiks Collective,
with two design stages and a pilot performance, all of which
involved audience participation and semi-structured inter-
views that collected feedback at each point of development.
Based on the collected feedback, we were able to integrate
several key learnings and design decisions that led to the cre-
ation of a more complete work that utilised the VR medium
to a fuller extent.
These learnings are outlined in chronological order below.
4.1 Stage 1
Stage 1 of development covered the narrative context and
early discussions around the audience experience. Early
ideas were trialled with seven participants with a mix of
musical abilities. Participants took part in semi-structured
interviews at the end of their sessions, debriefing on their
experience of the work post-experience. At the end of this
stage, a series of key design decisions were made that ad-
dressed perceived needs from the creative team that would
be taken into the next stage.
4.1.1 Storytelling
One of the most important areas of Stage 1 development
was the participant’s journey and their reason for playing.
Our creative team was keen on guiding participants, espe-
cially those unfamiliar with musical performances, in a way
that was independent of external knowledge or practice. In
this way, an audience member could simply arrive to the
performance without us knowing their level of expertise or
ability. The goal was to let the music, and more specifically
the narrative of the experience, naturally guide the partici-
pants allowing them to intuitively understand their role in
the ensemble.
This narrative immersion became central to the compo-
sition of the piece, and was a key component we grappled
with. There were various scenarios that a participant could
take part in: Would the participant step into the VR world
as a last-minute replacement for an indisposed member of
Rubiks? Or would they be recognised as themselves, dis-
tinct from the ensemble?
In attempting to create a narrative that audience could
invest in, we landed on the story that the participant was an
additional musician akin to a soloist performing their own
unique instrument alongside Rubiks. Importantly, we felt
that this soloist scenario provided a clear narrative without
creating unnecessary pressure and potential feelings of in-
adequacy around having to replace a professional musician.
Early discussions with pilot participants confirmed this
– one Stage 1 participant noted that the experience was
“...giving me the experience of being in an ensemble” and
made them “...feel welcome in the group”.
4.1.2 Simple musical structure
In creating the narrative, development turned to the con-
tent and structure of the ‘piece’ that participants would
play in. Initial discussions settled on a notated piece that
had clear structural signposts, and implied sections where
the participant was to take centre stage through the use
of strong gestures and lighting. However, the ideas piloted
with trial participants were clearly overly complicated and
didn’t seem to support our narrative and goal of making the
participant feel comfortable.
For example, the initial piece commenced with a sequence
where spotlights illuminated each player in turn, moving
in a circular pattern until the light reached the partici-
pant. When under the spotlight, Rubiks performers exe-
cuted large, expressive gestures, which were intended to be
mirrored by the participant (i.e. a sequence of turns fol-
lowed by the participant’s turn). However, this cue was
either misunderstood or perceived as overly intimidating by
most participants, with one participant saying, “...I could
see there was a pattern, but I wasn’t sure if I was a part of
that or not”, and another noting their hesitation in “...hav-
ing to do the same thing as [the performers], because I’m
not a musician.”
Three changes were made to the musical structure to en-
hance participants’ engagement and comfort:
1. Purely major mode with no accidentals: The musical
composition was anchored in the key of C major, occa-
sionally integrating elements of the Mixolydian mode.
Importantly, participants were restricted to playing
exclusively within the C major scale, without any ac-
cidentals. This decision was made to ensure harmonic
integration of the participant’s input with the rest of
the ensemble, reducing the likelihood of dissonant or
‘incorrect’ notes that might create dissonance.
2. Introduction with a flexible and quiet start, featuring
a unison note: The piece commenced with a sparse
texture, offering no definitive cues for entry, which
implied that there was no singular ‘correct’ point to
begin playing. This approach was intended to mir-
ror and validate the likely tentative initial approach
of the participants. Additionally, the inclusion of a
unison note, shared between the participant and the
performers, aimed to foster a sense of unity and be-
longing. When the participant began playing, their
note would harmonise with the rest of the ensemble,
reinforcing the feeling of community and collective ac-
tion.
3. Consistency in form and structure throughout the com-
position: The overall structure of the piece was de-
signed as a gradual crescendo of texture, akin to a ‘wall
of sound’. This consistent structure was maintained
throughout, deliberately avoiding dramatic shifts or
sudden changes. The intent behind this approach
was to create a stable and predictable musical envi-
ronment. This stability aimed to alleviate anxiety
about unexpected changes in the music, allowing par-
ticipants to feel more at ease and focused on the ex-
perience of ‘jamming’ with the professional musicians,
rather than being preoccupied with the anticipation of
what might come next.
These changes resulted in a more predictable and simple
musical structure that more participants felt comfortable
participating in, evident in one participant noting the sat-
isfaction of the unison note at the beginning, stating “...ev-
eryone was on the same pitch, and I was like, ‘I wonder
what my pitch will be’ – and then I heard the same pitch!”
4.1.3 Predictable instruments
In addition to the structure of the music played by Rubiks,
we also had to determine what the participant would play
(i.e. what sounds the AirStick would be mapped to). In
wanting the participants to experience what it might be like
to be a performer, our sonic ideas centered around the idea
that the performers would perform a virtual representation
of the instrument they were replacing in the ensemble. For
instance, if Kaylie the vibraphone player was absent, the
participant would move to trigger vibraphone sounds.
This idea was almost immediately abandoned for two rea-
sons – acoustic instruments not only have a physical reality
that we could not reproduce in the same resolution or re-
alism as the high fidelity stereoscopic video, but they also
have a ‘right’ and ‘wrong’ way of playing them. By imply-
ing that participants were playing instruments analogous to
real instruments, our fear was that preconceived notions of
these instruments, or a lack thereof, might create a more
stressful and rigid environment that participants felt like
they had to adhere to. We thus removed the idea that they
were playing ‘a flute’ or ‘a vibraphone’, and instead rein-
forced that they were playing ‘the AirStick’, complete with
its own unique soundworld that was clearly distinct from
other instruments in the ensemble.
The AirStick was instead programmed to trigger MIDI
notes. That is, instead of a strike at various points in space
triggering a single note, shaking the AirStick in varying lev-
els of intensity (what we termed AirStick ‘energy’) would
excite different musical textures, as seen in Figure 6.
Figure 6: An example mapping for the AirStick inConcerts
of the Futurebased on ‘energy’.
This concept of ‘energy’ meant the participant could trig-
ger melodic lines or uncover pre-composed musical textures,
depending on how much energy they placed into the Air-
Stick. However, Stage 1 trials with participants revealed
that our original AirStick mappings, with their large dy-
namic range and possible ability to play in a different style,
were not the right design decision.
For instance, one participant, upon testing the limits of
the mapping, played a series of dissonant, loud notes that
could be interpreted as being out of place – they noted
“Once I went really loud I was terrified of playing again
... I thought I broke it!” In attempting to increase agency
of participants, we had inadvertently increased discomfort,
creating an environment of people who Jensenius observes
“...want to engage more actively with music, but they are
afraid to ‘not be good at it.’” [13]
This became a prominent concern for participants. The
notion of ‘ruining’ the music was not rooted in vanity, but
rather in a reluctance to disrupt what they perceived as a
valuable creation reserved for the realm of professional mu-
sicians. Participants expressed a sense of intrusion, with
one participant saying it was “...not my place to play...”
in an environment dominated by professionals. This sen-
timent was further compounded by a general nervousness
experienced by many participants in the presence of these
musicians, even though they were not physically present.
Rather than act as a deterrent, this reaction highlighted
the previously mentioned palpable divide between the gen-
eral public and professional musicians, particularly in the
context of performance and active participation in music-
making. Even for those accustomed to attending arts events,
the act of holding an instrument and the prospect of per-
forming alongside professionals elicited a significant reac-
tion. This insight reinforced our conviction approach and
the importance of bridging this gap between the public and
professional musicians in the realm of interactive music ex-
periences.
Our solution was to create a far more curated instrument
mapping that built in ‘musical guard-rails’ that meant a
participant wouldn’t ever go beyond the texture or dynamic
level of what members of Rubiks were playing. We ensured
that the pitch set and rhythm were always quantised to
the music coming from the ensemble (i.e. meaning all mu-
sic was in time), and that it would be impossible to make
any “ugly sounds”. By using a combination of acoustic in-
strument samples and in-built Logic Pro X synthesisers, we
were able to trigger both previously composed MIDI lines
as well as MIDI notes quantised to the performances of per-
formers. Additionally, instead of the fixed energy scale, we
introduced a dynamic energy scale that followedRubiks per-
formers, allowing for participant agency over some dynamic
and musical content, but only within fixed bounds (seen in
Figure 7).
Figure 7: Static vs dynamic mapping for the AirStick.
4.2 Stage 2
Stage 2 of development covered the recording of final perfor-
mance videos and the addition of theatrical elements around
the VR experience itself. These recordings were trialled
in a more formal presentation context, with twelve par-
ticipants taking part in a more formal trial presentation.
Feedback was collected using the same method as Stage 1,
with semi-structured interviews post-experience. Through-
out this stage, a series of key design decisions were made
that addressed perceived needs from the creative team that
would be taken into the next stage.
4.2.1 Social cues
One of the pivotal design choices made during Stage 2 was
re-imagining the traditional seating arrangement of a cham-
ber ensemble. Instead of using the conventional single-file
layout facing the participant, we opted for a circular ar-
rangement. This ensured that the VR participant was al-
ways facing all members of Rubiks, creating an inclusive
environment that fostered continuous interaction and eye
contact (see layout in Figure 8).
Figure 8: Layouts of the experience in the venue and in VR.
This choice, while unusual for a concert, was deemed the
right choice for the immersive VR experience, because it al-
lowed for eye-contact with performers, and meant the par-
ticipant could receive more subtle continuous feedback in
the high-fidelity recordings. Pilot participants noted the
layout was warm and inviting, with one participant noting
the expressions“...puts you at ease and encourages that con-
nection.” Another participant noted “I don’t like audience
participation at the best of times ... but this didn’t feel like
that!”
4.2.2 The ’extra-VR’ experience
Having trialled the musical elements and layout of the work,
Stage 2 development focussed on the refinement of what
happened around the performance. We named these lay-
ers of theatre built around the VR headset the ‘extra-VR’
elements, after the term ‘extramusical.’ These were layers
of mise-en-sc` ene that contributed to extra realism around
the idea that audience members were participating in a real
concert experience. For instance, upon entering the venue,
pilot participants were met with a digital poster with their
head-shot on it, advertising a recital that was occurring at
their booked time slot.
Of particular note was the use of a ‘green room,’ a prelim-
inary area designed to alleviate nerves related to the play-
ing in an ensemble, and to enhance the overall realism of
the concert setting. The room reflected what performers
might often experience in a similar place – a ‘live feed’ (pre-
recorded video loop) of the concert hall, some snacks and
water, and a space to warm up. A carefully crafted script
was employed in the green room to create an ambiance that
was both welcoming and informative, without being overly
directive. This script aimed to establish basic guidelines
and expectations for participants in a gentle manner. Key
elements of this script included:
• Encouraging participants to ‘play along’ with the mu-
sicians, emphasising the collaborative nature of the
experience.
• Reassuring participants that errors were not possible,
fostering an environment free from the fear of making
mistakes.
• Introducing the AirStick and physically handing it
over to participants. Also conducting a ‘calibration’
process that, whilst not technically necessary, served
to illustrate the connection between physical move-
ment and sound production, guiding participants to
explore the instrument’s capabilities.
• Exposing participants to sounds similar, but not iden-
tical, to those in the main experience, setting auditory
expectations.
• Allowing a solitary practice duration of up to five min-
utes in the green room. This period was intended to
facilitate familiarity and comfort with the AirStick in
a stress-free setting.
Additionally, the sensitivity of the instrument was delib-
erately lowered in the green room. This adjustment was de-
signed to encourage more pronounced physical movements,
thereby slightly mitigating any potential timid playing that
might hinder sound production in the actual VR experience.
One Stage 2 participant noted that they were “...always
curious” about what went on behind the scenes of a concert
hall, and “...the extra context around the music felt like I
was part of what was going on.”
5. DISCUSSION
Two elements emerge from the above design conclusions
that may be useful as broader conclusions for the creation of
musical VR experiences that involve audience participation.
5.1 Stylised Design for VR
The development of Concerts of the Future illustrated a
pivotal shift from a realistic portrayal of performance to a
stylised representation in virtual reality. This approach not
only made the experience more accessible but also enriched
it by creating an inviting and imaginative rendition of a con-
cert hall setting. The decision to move away from a strict
representation of reality allowed for a more robust and wel-
coming concept that offered participants an ‘impression’ of
performing in a concert hall, a scenario that might not align
with the reality of professional performance but nonetheless
captured the essence of the experience.
This stylised approach proved to be crucial in reducing
performance anxiety among participants, and only came
about due to the multiple stages of testing the work with
participants in development. As musicians, we were initially
too focused on replicating our experiences of performing in
the concert hall. By focusing on the impression rather than
the exact replication of a concert setting, the experience be-
came less intimidating and more approachable. Participants
were able to immerse themselves in a world that felt both
grand and accessible, encouraging engagement without the
pressure of adhering to the strict realities of professional
music performance. The design’s success lay in its ability
to balance the grandeur of a concert hall with the comfort
of an inclusive and participatory environment.
5.2 Immersive design for VR
The project expands on immersive experience discussed in 2
by considering and integrating elements of both the partici-
pants digital and real experience. This holistic approach ex-
tended beyond the digital realm, encompassing the physical
environment and additional mise-en-sc` ene that contributed
to the overall narrative and immersion.
The incorporation of additional elements such as the green
room and digital posters along with the main VR perfor-
mance, created a fully-realised narrative. This narrative
transcended the boundaries of traditional music performance,
blending various art forms and technologies to create a cohe-
sive and immersive experience that challenges the aforemen-
tioned ‘composer, performer listener’ model. The attention
to detail in both the digital and real-world components of
the project ensured a seamless integration of all elements,
enhancing the participant’s sense of being part of a larger
artistic endeavor.
The success of this endeavor highlighted the potential of
VR and interactive technology in creating new forms of im-
mersive musical experiences.
6. CONCLUSION
This paper presented Concerts of the Futurea novel Vir-
tual Reality music experience designed to bridge the gap
between passive music listening and active music participa-
tion. By leveraging VR technology and the custom-designed
AirStick, participants without any musical background are
immersed in an interactive concert environment where they
perform alongside an ensemble.
Throughout the development process, the project evolved
to focus on stylised design that reduces participants’ anxi-
ety and enhances engagement. The experience was enriched
with extra-VR elements like a green room, creating a musi-
cal narrative that extends beyond the digital performance.
The iterative development process led to an immersive mu-
sical experience, drawing on diverse forms and technologies
to create an immersive musical experience.
The success of the Concerts of the Futurepilot program
indicates future potential, particularly in the expansion of
the format to encompass different musical formats and in-
strumentation. There is also much to be explored in a more
adaptive VR experience, in which the structure, musical
content and participant’s instrument changes live depend-
ing on musical preferences and experience.
Overall, the experience hints at the potential of VR in
transforming musical experiences, challenging traditional
roles within music and fostering a new level of audience
engagement and participation.
7. ACKNOWLEDGMENTS
Concerts of the Futurewould not have been possible with-
out Rubiks Collective, consisting of Kaylie Melville, Tamara
Kohler, Jacob Abela, Gemma Kneale and Eliza Shephard.
The project has been assisted by the Australian Govern-
ment through Creative Australia, its principal arts invest-
ment and advisory body.
8. ETHICAL STANDARDS
This project and associated research obtained full informed
consent of all participants involved through the Monash
University Human Research Ethics Committee.
9. REFERENCES
[1] L. Anderson. Puppet Motel, 1995. CD-ROM.
[2] L. Anderson, Stelarc, F. Schroeder, and Avatar
Orchestra Metaverse. Rotating Brains / Beating
Heartl, 2010.
[3] J. Atherton and G. Wang. Doing vs. being: A
philosophy of design for artful vr. Journal of New
Music Research, 49(1):35–59, 2020.
[4] J. Bailenson. Experience on Demand: What Virtual
Reality Is, How It Works, and What It Can Do. W.
W. Norton, 2018.
[5] A. Barmpoutis, R. Faris, L. Garcia, L. Gruber, J. Li,
F. Peralta, and M. Zhang. Assessing the role of
virtual reality with passive haptics in music conductor
education: A pilot study. In Virtual, Augmented and
Mixed Reality. Design and Interaction: 12th
International Conference, VAMR 2020, page 275–285,
Berlin, Heidelberg, 2020. Springer-Verlag.
[6] A. S. Brown, S. Gilbride, and J. L. Novak. Getting in
on the act: How arts groups are creating
opportunities for active participation. In Wolf Brown:
Arts Engagement Research, 2011.
[7] Creative Australia. Creating Value: Results of the
National Arts Participation Survey. Australia
Council, Sep 2023.
[8] L. Dahl, J. Herrera, and C. Wilkerson. Tweetdreams:
Making music with the audience and the world using
real-time twitter data. International Conference on
New Interfaces For Musical Expression 2011, 01 2011.
[9] J. Freeman and M. Godfrey. Creative collaboration
between audiences and musicians in flock. Digital
Creativity, 21(2):85–99, 2010.
[10] D. J. Hargreaves, J. Hargreaves, and A. C. North.
Imagination and creativity in music listening. In
Musical Imaginations, 2011.
[11] A. Hindle. Swarmed: Captive portals, mobile devices,
and audience participation in multi-user music
performance. In New Interfaces for Musical
Expression, 2013.
[12] A. Ilsar, M. Hughes, and A. Johnston. Nime or mime:
A sound-first approach to developing an audio-visual
gestural instrument. In New Interfaces for Musical
Expression, 2020.
[13] A. R. Jensenius. Sound Actions: Conceptualizing
Musical Instruments. The MIT Press, 12 2022.
[14] P. Lansky. A view from the bus: When machines
make music. Perspectives of New Music,
28(2):102–110, 1990.
[15] P. Oliveros. Lunar Opera, 2000.
[16] G. Santini. Augmented piano in augmented reality. In
New Interfaces for Musical Expression, 09 2020.
[17] R. Sessions. Musical Experience of Composer,
Performer, Listener. Princeton University Press,
1950.
[18] J. Sloboda and D. Melissa. Staying behind:
explorations in post-performance musician-audience
dialogue.. Ashgate Publishing Ltd., United Kingdom,
1st edition, 2014.
[19] C. Small. Musicking: The Meanings of Performing
and Listening. Music / Culture. Wesleyan University
Press, 1998.
[20] J. Toelle and J. A. Sloboda. The audience as artist?
the audience’s experience of participatory music.
Musicae Scientiae, 25(1):67–91, 2021.
[21] L. Turchet, R. Hamilton, and A. ¸ Camci. Music in
extended realities. IEEE Access, 9:15810–15832, 2021.
[22] J. C. Vasquez. Ecstasy / Light / Inertia, 2023. Steam
game.
[23] A. ¸ Camci, M. Vilaplana, and L. Wang. Exploring the
affordances of vr for musical interaction design with
vimes. In New Interfaces for Musical Expression,
2020.