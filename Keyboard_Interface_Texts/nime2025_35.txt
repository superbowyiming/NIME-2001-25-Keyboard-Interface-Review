EMMA: Enhancing Real-Time Musical Expression through
Electromyographic Control
João Coimbra
jpcoimbra@ua.pt
Aveiro University/INET-md
Aveiro, Portugal
jpcoimbra@ua.pt
Luís Aly
ID+, ESMAD, Polytechnic of Porto
rua D.Sancho I, 4480-876, Vila do
Conde, Portugal
luisaly@esmad.pt
Henrique Portovedo
Aveiro University/INET-md
Aveiro, Portugal
henriqueportovedo@ua.pt
Sara Carvalho
Aveiro University/INET-md
Aveiro, Portugal
scarvalho@ua.pt
Tiago Almeida Bolaños
Instituto Superior Técnico (IST)/
Instituto de Telecomunicações (IT)
Lisboa, Portugal
tiago.bolanos@lx.it.pt
Abstract
This paper presents the Electromyographic Music Avatar (EMMA),
a digital musical instrument (DMI) designed to enhance real-time
sound-based composition through gestural control. Developed as
part of a doctoral research project, EMMA combines electromyo-
graphy (EMG) and motion sensors to capture nuanced finger,
hand, and arm movements, treating each finger as an indepen-
dent instrument. This approach bridges embodied performance
with computational sound generation, enabling expressive and
intuitive interaction. The system features a glove-based design
with EMG sensors for each finger and motion detection for the
wrist and arm, allowing seamless control of musical parameters.
By addressing key challenges in DMI design, such as action-
sound immediacy and performer-instrument dynamics, EMMA
contributes to developing expressive and adaptable tools for con-
temporary music-making.
CCS Concepts
• Applied computing →Sound and music computing ; Per-
forming arts; • Information systems →Music retrieval .
Keywords
Gestural interface, physiological signals, Digital Musical Instru-
ment, Human-Computer Interaction, Composition, Performance.
1 Introduction
EMMA builds upon a rich tradition of research within the New
Interfaces for Musical Expression (NIME) community, which has
extensively explored the use of electromyography (EMG) in em-
bodied musical interaction [27, 32]. EMMA is deeply influenced
by the artistic practice of its first author. As a pianist, finger map-
ping is central to performance, but EMMA expands traditional
pianistic control, allowing each finger to convey unique musical
ideas that align with its anatomical characteristics [26].
EMMA aims to leverage the hand as an expressive musical
control interface that focuses on precise finger mapping, real-time
responsiveness, and nuanced translation of muscular activity into
sound generation and spatialization of sound.
This work is licensed under a Creative Commons Attribution 4.0 International
License.
NIME ’25, June 24–27, 2025, Canberra, Australia
© 2025 Copyright held by the owner/author(s).
2 Related Work
Since the 1980s, EMG has been used in the musical realm (for a
comprehensive review please refer to [1]) with examples such
as BioMuse [20] [31] and Body Synth [32]. More recently, custom
interfaces such as Xth Sense [11], MuMYO [25], MicroMyo [17],
EAVI EMG Board [10] and RAW [13] extend the exploration of
EMGs as an expressive musical controller. Among them, RAW,
MicroMyo, and MuMYO recur to the commercial wearable Myo
Armband [24], which detects hand-muscle and forearm muscle
activity. For the purposes of the present study, projects such as
Waisvisz’s The Hands [33], Laetitia Sonami’s Lady’s Glove [5, 14,
30] and the Mi.Mu gloves [22] intensively explored the hand as a
gestural controller leveraging its dexterity, expressive potential,
and rich biomechanical complexity to create nuanced, dynamic
interactions between movement and sound.
3 Methods and Materials
EMMA consists of two main components: a gestural controller
and a sound generation unit. The gestural controller is a finger-
less glove combined with an elastic wristband, integrating five
EMG sensors (see Section 3.5), an Inertial Measurement Unit
(IMU) for motion tracking, and a wireless communication mod-
ule. This preliminary design serves as a test bed for identifying
optimal anchor points for EMG sensors. The sound generation
unit processes the EMG data in real time and maps data to sound.
3.1 Electromyographic Sensors
Electromyography quantifies the electrical signals produced by
muscles during contractions [8]. It is utilized in various fields,
including medical research, sports science, and human-machine
interfaces. To obtain an EMG signal, two electrodes are placed
along the muscle to measure their potential differences. The
EMG signal results from the superimposed polarization waves
generated by different muscle fibers and is characterized by a
stable and relatively noise-free period when the muscle is in a
relaxed state [18].
Pregelled disposable surface electrodes are the most widely
used option for interfacing with muscles due to their affordability
and ease of handling. These electrodes have a diameter of≤1 cm
and be positioned 2 cm apart (center to center). Proper placement,
aligned with the orientation of the muscle fibers and centrally
situated over the muscle belly, is essential, especially considering
the potential muscle movement beneath the electrodes during the
analyzed motion [18]. EMMA uses the Bitalino SnapBIT-DUO;
NIME ’25, June 24–27, 2025, Canberra, Australia Coimbra et al.
Figure 1: The diagram of the Electromyographic Music
Avatar (EMMA) system illustrates the integration of elec-
tromyography (EMG) sensors and the signal processing
flow. On the left side, the image presents both dorsal and
palmar views of a hand, featuring five EMG sensor place-
ments (EMG 1–5) that capture muscle activity from var-
ious regions of the hand and forearm. The right side de-
tails the functional components of EMMA, beginning with
the performer’s motor program, which generates move-
ments detected by the sensors. The subsequent signal un-
dergoes processing through filtering, finger classification,
and sound generation, resulting in the final sound output.
A feedback loop is incorporated through an evaluation
stage, enhancing the interaction between the performer
and the instrument while refining the expressive control
of musical parameters.
however, the standard electrode size presented challenges in
identifying optimal anchor points in the hand where spatial con-
straints and anatomical variations necessitated greater precision
(see subsection 3.5).
Figures 2 and 3 depict custom terminals that aim to elimi-
nate plastic casings and minimize the spacing between electrode
snaps. Furthermore, the EMG sensor was decoupled from the
terminal, contrasting with the integrated design of the Bitalino
SnapBIT-Duo. This modification reduces the terminal’s weight
and enhances flexibility and adaptability during testing, allowing
for more precise electrode placement.
Figure 2: Bitalino EMG sensor with a UC-E6 connector
and labeled wiring connections. The annotations indicate
the signal channels, including reference (blue), ground
(red/copper), and active signals (green). The UC-E6 connec-
tor is partially stripped to expose the internal wiring for
manual soldering.
Figure 3: Custom-modified EMG sensor setup featuring a
compact electrode terminal. The stripped cable is soldered
directly to the electrode terminals. An UC-E6 connector,
with an identical cable, links the sensor to the board.
3.2 Platform
EMMA incorporates the BITalino CORE platform [7] providing
real-time data streaming capabilities along with an integrated
3.7V Li-Po battery charger. The BITalino CORE allows for a max-
imum selectable sampling rate of 1000 Hz. It features six analog
ports (comprising four 10-bit and two 6-bit ports) and four digital
ports (including two 1-bit inputs and two 1-bit outputs).
EMMA integrates an Real-time Internet of Things (R-IoT) mod-
ule directly onto the BITalino enabling wireless sensor digitiza-
tion. This arrangement ensures reliable performance through a
dedicated data transmission router. The R-IoT features a 9-axis
digital IMU sensor, which includes a 3-axis accelerometer, a 3-
axis gyroscope, and a 3-axis magnetometer allowing on-board
computation of the module’s orientation in space.
3.3 Implementation
The EMG data is transmitted using custom software developed
in Max/MSP [28]. Communication between the hardware and
software is facilitated by the BITalino Max object [ 15], which
employs the Open Sound Control protocol [ 34] to establish a
connection between the board and the software. Data is subse-
quently mapped to sound algorithms fostering sound spatializa-
tion through IMU sensing. Data processing and storage were
conducted on a MacBook Air equipped with an M3 processor
and 16GB of RAM.
The implementation of the EMMA prototype encompasses
four stages: Sensor customization: Focuses on designing and
configuring EMG sensors to effectively capture and transmit
data. Sensor anchorage: Involves identifying optimal anchor-
age points on the hand and forearm for sensor positioning.Signal
processing: Aims to develop effective methodologies for inter-
preting and transforming incoming sensor data into meaningful
control parameters. Sound mapping: Involves applying sound
synthesis techniques specifically tailored for gestural control in
real-time performance environments.
3.4 Sensor customization
Small terminals were designed for the thumb, index, and little
finger, while standard-sized terminals accommodate the middle
and ring fingers accounting for the deeper muscle configuration
EMMA: Enhancing Real-Time Musical Expression through Electromyographic Control NIME ’25, June 24–27, 2025, Canberra, Australia
in the forearm requiring more spacing between snaps as depicted
in Figure 4.
Figure 4: EMMA uses five EMG sensors with UC-E6 connec-
tors linking terminals to sensors. Terminals 1, 2, and 5 on
the hand are sized for specific anchoring, while standard
Bitalino sensors were used on the forearm.
To assess conductivity, the polymer and the hydrogel layer
were removed from the surface of the electrodes. Additional tests
were conducted without the electrodes, relying solely on the
direct conductivity of the snaps. In-house testing confirmed that
snaps alone provided adequate conductivity, which streamlined
the design and enhanced sustainability by eliminating the need
for frequent electrode replacements due to erosion.
3.5 Sensor Anchorage
In the initial phase, optimal anchor points were identified namely,
on the hand and forearm. These anatomical regions are complex,
characterized by the close interaction of various muscles, tendons,
and tissues, which often leads to signal crosstalk and complicates
signal isolation [ 3, 19, 29]. Through extensive trials, five key
points were discerned within the intrinsic muscles of the hand
(entirely contained within the hand) and the extrinsic muscles
(located in the wrist and forearm) [2, 16].
3.5.1 Intrinsic Muscles Anchorage. In the intrinsic muscles
three anchorage points were identified: (i) Thenar Muscles: Lo-
cated in the palm of the hand, just below the thumb, these muscles
form the thenar eminence (the fleshy mound at the base of the
thumb). Thenar muscles are primarily responsible for the move-
ments of the thumb, including opposition, flexion, and abduction.
(ii) Dorsal Interossei : Found between the metacarpal bones of
the hand, these muscles facilitate the movement of the fingers.
Specifically, the index sensor is anchored on the left side of the
index finger. And, (iii) Hypothenar Muscles: Situated on the ul-
nar side of the palm. Hypothenar muscles create the hypothenar
eminence responsible for movements, such as flexion, abduction,
and opposition of the little finger.
3.5.2 Extrinsic Muscles Anchorage. In the case of the extrin-
sic muscles, two anchorage points were identified for the middle
and ring fingers within the Flexor Digitorum Superficialis (FDS)
muscle. The FDS muscle allows for independent EMG activation
in adjacent regions. This anatomical feature supports the differ-
ential activation of individual finger compartments, highlighting
the specialized function of motor units in fine finger control [21],
which is particularly beneficial for tasks requiring precise proxi-
mal interphalangeal flexion, such as playing musical instruments
[4].
3.6 Fingerless glove
Figure 5 shows terminals anchored with a medical-grade band
for stability. A modular fingerless glove enhances support with a
wrist strap and fabric extensions securing the thumb, index, and
little finger. These ensure stable sensor placement, prevent adja-
cent triggering, and allow individual adjustments. A wristband
holding the circuit board reinforces sensors on the middle and
ring fingers, maintaining consistent skin contact while preserv-
ing flexibility in finger movement.
Figure 5: EMMA’s interface consists of 5 EMG sensors, a
modular fingerless glove and a wristband housing the ac-
quisition board. These components serve as mechanical
reinforcements for the terminal sensors at the skin sur-
face.
3.7 Signal Processing
EMMA processes signals in real-time, converting sensor data
into audio within milliseconds. This allows the use of standard
musical signal processing techniques, including gates, filters, and
compressors (Figure 6). Transforming EMG signals into audio en-
ables intuitive system calibration with familiar audio processing
tools.
Figure 6: A noise gate filter was utilized to suppress un-
wanted signals that fall below a specified amplitude thresh-
old, effectively reducing electrical interference and min-
imizing unintended triggers. The processed signal subse-
quently passed through a Butterworth bandpass filter (20
Hz–150 Hz), optimizing frequency capture for the selected
anchoring points. This filter could be finely adjusted for
each input like the noise gate. The signal processing chain
concluded with an audio compressor to prevent clipping.
In [9], the authors highlight that effective EMG decompo-
sition requires noise power to be no greater than half of the
signal power. Each finger is independently processed through
four stages: waveform visualization, noise gating, Butterworth
NIME ’25, June 24–27, 2025, Canberra, Australia Coimbra et al.
bandpass filtering, and compression. These components can be
fine-tuned, calibrated in real-time, and saved for future use.
The noise gate sets high and low thresholds to distinguish
EMG spikes from noise, with attack and release times adjusted
per finger. A 4th-order Butterworth bandpass filter isolates key
frequency ranges, typically 50-150 Hz [32], optimizing distinction
between fingers (in our tests, 20-85 Hz for the thumb, 20-110 Hz
for the middle finger). Finally, a compressor reduces amplitude
ranges for the five signals, improving overall signal amplitude
distinction for intrinsic and extrinsic muscle activity.
Each finger is individually calibrated for two hand poses: pi-
anistic and aerial fingering. The pianistic pose aligns with hand
positioning on a horizontal surface, compensating for key press
damping. The aerial pose functions without physical contact,
triggering audio output when finger movements exceed specific
angular thresholds.
Calibration provides two types of gestural control: Discrete
Myoelectric Control, which treats the entirety of a dynamic
gesture as a single input, resulting in one output [12]. In contrast,
Continuous Myoelectric Control interprets the full progres-
sion of a dynamic gesture (for example, the force exerted between
opposing fingers) in a manner similar to that of a sustain or ex-
pression pedal.
This process generates five distinct signal outputs that are
subsequently sonified. While sound mapping is not yet fully im-
plemented, the current emphasis is on system calibration. To
achieve this, EMMA utilizes a straightforward one-to-one audio
sample mapping (click for video) examining both aerial and pi-
anistic fingering techniques. Furthermore, the IMU unit provides
continuous control and sound manipulation. This methodology
allows us to investigate and enhance EMMA’s multimodal capa-
bilities.
4 Conclusions
Gloves interfere with tactile and proprioceptive feedback, affect-
ing natural movement. A fingerless design maintains the full
range of motion and sensory response needed for fine motor
control unlocking the hand’s expressive potential. EMMA is en-
visioned both as a timbre enhancer for instruments like the piano
and as a standalone timbre generator.
Advancements have been achieved by replacing hydrogel elec-
trodes with custom sensors and optimizing their placement on
both extrinsic and intrinsic muscles, focusing on simplicity, sig-
nal integrity, and real-time processing. Hand poses, including
pianistic and aerial fingering, broaden the expressive range and
accommodate a variety of performance contexts.
5 Future Work
Future work will investigate the integration of machine learn-
ing for a broad range gesture-based musical instructions. The
implementation of machine learning, idiomatic notation of ges-
tures [6, 23] has the potential to enhance artistic possibilities
and encourage a wide adoption of EMMA. In addition, further
studies will focus on improving the ergonomics of the finger-
less glove and wristband, as well as extending the system to the
left hand to facilitate complete bilateral finger mapping. A com-
prehensive sound mapping system will combine granular and
frequency modulation synthesis, real-time sound spatialization,
and multimodal interaction.
6 Ethics Statement
This research did not involve human participants or animals; all
directly involved individuals were members of the research team.
All software and tools used in the study were used in accordance
with the terms of their respective licenses. The methodologies
and processes adhered strictly to ethical guidelines for intellectual
property and data management, ensuring transparency, integrity,
and reproducibility throughout all phases of the research. This
research is supported by Fundação para a Ciência e Tecnologia,
I.P (FCT), grant 2022.11160.BD.
References
[1] Luís Aly, Hugo Silva, Gilberto Bernades, and Rui Penha. 2021. Appropriat-
ing biosensors as embodied control structures in interactive music systems.
Human Technology 17, 1 (2021).
[2] R Barański and A Kozupa. 2014. Hand grip-EMG muscle response. Acta
Physica Polonica A 125, 4A (2014).
[3] Nicolai A Bernstein. 1967. The co-ordination and regulation of movements.
[4] TJ Butler, SL Kilbreath, RB Gorman, and SC Gandevia. 2005. Selective recruit-
ment of single motor units in human flexor digitorum superficialis muscle
during flexion of individual fingers. The Journal of physiology 567, 1 (2005),
301–309.
[5] Joel Chadabe. [n. d.]. Electric sound: the past and promise of electronic music.
(No Title) ([n. d.]), 229–230.
[6] João Coimbra, Henrique Portovedo, and Sara Carvalho. 2024. FROM SONIC
GESTURE TO COMPOSITION: MAPPING THE PATH FOR THE PHYSICAL
COMPUTING INSTRUMENT. TENOR (2024), 73.
[7] Hugo Plácido Da Silva, José Guerreiro, André Lourenço, Ana Fred, and Raúl
Martins. 2014. BITalino: A novel hardware framework for physiological
computing. In International Conference on Physiological Computing Systems ,
Vol. 2. SciTePress, 246–253.
[8] Carlo J De Luca and Egbert J Van Dyk. 1975. Derivation of some parameters
of myoelectric signals recorded during sustained constant force isometric
contractions. Biophysical journal 15, 12 (1975), 1167–1180.
[9] A Del Vecchio, A Holobar, D Falla, F Felici, RM Enoka, and D Farina. 2020.
Tutorial: Analysis of motor unit discharge characteristics from high-density
surface EMG signals. Journal of Electromyography and Kinesiology 53 (2020),
102426.
[10] Balandino Di Donato, Atau Tanaka, Michael Zbyszynski, and Martin Klang.
2019. EAVI EMG board. (2019).
[11] Marco Donnarumma, Baptiste Caramiaux, and Atau Tanaka. 2013. Muscular
Interactions Combining EMG and MMG sensing for musical practice. (2013).
[12] Ethan Eddy, Erik J Scheme, and Scott Bateman. 2023. A framework and call to
action for the future development of EMG-based input in HCI. In Proceedings
of the 2023 CHI Conference on Human Factors in Computing Systems . 1–23.
[13] Çağrı Erdem and Alexander Refsum Jensenius. 2020. RAW: Exploring control
structures for muscle-based interaction in collective improvisation. InProceed-
ings of the International Conference on New Interfaces for Musical Expression .
477–482.
[14] Rebecca Fiebrink and Laetitia Sonami. 2020. Reflections on eight years of
instrument creation with machine learning. Proceedings of the International
Conference on New Interfaces for Musical Expression (2020).
[15] github. 2024. thalmiclabs. https://github.com/thalmiclabs
[16] Xuhui Hu, Aiguo Song, Jianzhi Wang, Hong Zeng, and Wentao Wei. 2022.
Finger movement recognition via high-density electromyography of intrinsic
and extrinsic hand muscles. Scientific Data 9, 1 (2022), 373.
[17] Alexander Refsum Jensenius, Victor Evaristo Gonzalez Sanchez, Agata Zele-
chowska, and Kari Anne Vadstensvik Bjerkestrand. 2017. Exploring the Myo
controller for sonic microinteraction. InProceedings of the International Confer-
ence on New Interfaces for Musical Expression . Aalborg University Copenhagen,
442–445.
[18] Peter Konrad. 2005. The abc of emg. A practical introduction to kinesiological
electromyography 1, 2005 (2005), 30–5.
[19] Mark L Latash. 2015. The hand: Shall we ever understand how it works?Motor
control 19, 2 (2015), 108–126.
[20] Hugh S Lusted and R Benjamin Knapp. 1988. Biomuse: Musical performance
generated by human bioelectric signals. The Journal of the Acoustical Society
of America 84, S1 (1988), S179–S179.
[21] Tara L McIsaac and Andrew J Fuglevand. 2007. Motor-unit synchrony within
and across compartments of the human flexor digitorum superficialis. Journal
of neurophysiology 97, 1 (2007), 550–556.
[22] Thomas Mitchell and Imogen Heap. 2011. Soundgrasp: A gestural interface for
the performance of live music. In Proceedings of the International Conference
on New Interfaces for Musical Expression . 465–468.
[23] Solomiya Moroz. 2020. EXTENDING NOTATION THROUGH EMBODIED
RESEARCH. (2020).
[24] Rachel Nuwer. 2013. Armband adds a twitch to gesture control.
[25] Kristian Nymoen, Mari Romarheim Haugen, and Alexander Refsum Jense-
nius. 2015. Mumyo–evaluating and exploring the myo armband for musical
interaction. (2015).
EMMA: Enhancing Real-Time Musical Expression through Electromyographic Control NIME ’25, June 24–27, 2025, Canberra, Australia
[26] William Ogle et al. 1882. Aristotle: on the parts of animals . Kegan Paul, French
& Company.
[27] Miguel A Ortiz, Niall Coghlan, Javier Jaimovich, and R Benjamin Knapp. 2011.
Biosignal-driven art: beyond biofeedback. (2011).
[28] M. PUCKETTE. 1988. The Patcher. Proceedings of the 1988 International
Computer Music Conference. San Francisco (1988). https://cir.nii.ac.jp/crid/
1573668925314493056
[29] Richard A Schmidt, Timothy D Lee, Carolee Winstein, Gabriele Wulf, and
Howard N Zelaznik. 2018. Motor control and learning: A behavioral emphasis .
Human kinetics.
[30] Laetitia Sonami. 2006. On my work. (2006).
[31] Atau Tanaka. 2009. Sensor-based musical instruments and interactive music .
na.
[32] Atau Tanaka and Miguel Ortiz. 2017. Gestural musical performance with
physiological sensors, focusing on the electromyogram. In The Routledge
companion to embodied music interaction . Routledge, 420–428.
[33] Michel Waisvisz. 1985. The hands: A set of remote midi controllers. InProceed-
ings of the International Computer Music Conference: International Computer
Music Association, 1985 .
[34] Matthew Wright, Adrian Freed, et al . 1997. Open SoundControl: A new
protocol for communicating with sound synthesizers. In ICMC.