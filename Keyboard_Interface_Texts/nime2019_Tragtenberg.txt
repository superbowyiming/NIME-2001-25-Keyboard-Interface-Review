Towards the Concept of
“Digital Dance and Music Instrument”
João Tragtenberg
Instituto SENAI de Inovação
para TICs
Rua Frei Cassimiro, 88
Recife, Brazil
joao.tragtenberg@pe.senai.br
Filipe Calegario
Instituto SENAI de Inovação
para TICs
Rua Frei Cassimiro, 88
Recife, Brazil
ﬁlipe.calegario@pe.senai.br
Giordano Cabral
CIn-UFPE
Av. Jornalista Anibal
Fernandes, s/n
Recife, Brazil
grec@cin.ufpe.br
Geber Ramalho
CIn-UFPE
Av. Jornalista Anibal
Fernandes, s/n
Recife, Brazil
glr@cin.ufpe.br
ABSTRACT
This paper discusses the creation of instruments in which
music is intentionally generated by dance. We introduce the
conceptual framework of Digital Dance and Music Instru-
ments (DDMI). Several DDMI have already been created,
but they have been developed isolatedly, and there is still a
lack of common design guidelines. Knowledge about Digital
Musical Instruments (DMIs) and Interactive Dance Systems
(IDSs) can contribute to the design of DDMI, but the for-
mer brings few contributions to the body’s expressiveness,
and the latter brings few references to an instrumental re-
lationship with music. Because of these diﬀerent premises,
the integration between both paradigms can be an ardu-
ous task for the designer of DDMI. The concept of DDMI
can also be a bridge between DMIs and IDSs, serving as
a lingua franca between both communities and facilitating
the exchange of knowledge. Finally, we analyse two exist-
ing DDMI and describe two DDMI we created during this
research. The conceptual framework has shown to be a
promising analytical tool for the design of new dance and
music instruments.
Author Keywords
digital musical instrument, interactive dance systems
CCS Concepts
•Applied computing →Sound and music comput-
ing; Performing arts; •Human-centered computing →
Interaction devices;
1. INTRODUCTION
A signiﬁcant advantage of digital technology for artistic ex-
pression is related to the unprecedented freedom of integra-
tion between diverse expressive modalities. With interfaces
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’19, June 3-6, 2019, Federal University of Rio Grande do Sul,
Porto Alegre, Brazil.
that allow the conversion of human movement into informa-
tion, it is possible that a wide variety of gesture can control
any sound, visuals, light or robotic media [5].
The ﬁeld of artistic creation with digital technology is at
least 56 years old [24] and presented considerable advances
[17]. The area of Digital Musical Instruments (DMI) has
been well delimited for a long time[26]. Unlike acoustic in-
struments, in which the equivalent energy of the gestural
control is responsible for the sound production, the DMIs
have open possibilities. The production of sound is inde-
pendent of gesture control, being only connected by digital
means. This freedom has allowed a much more full range
of gestures to control sound production. For instance, there
are DMI controlled by the positioning of several people in
space [13], by eye movement [29], by muscle tension, [18]
and by brain signals [12] to cite a few.
The area of Interactive Dance Systems (IDS) is another
that puts digital technology in service to artistic expression.
In academic literature, there has not been such a clear def-
inition of the area, referred by diﬀerent terms that vary in
broadness like Interactive Dance/Music Systems [5], Inter-
active Music/Dance/Video Systems [8], or Multimodal In-
teractive System (MIS) [9]. Other terms were used, such
as Interfaces for Dance Performances [22], Interfaces for
Dancers [27], Sensor System for Interactive Dance [1] or
Multisensory Integrated Expressive Environments [6]. Even
though there is not a consensus on the terminology, we con-
sidered all these as parts of the area of IDS. These are digital
systems used in interactive dance performances developed
to enhance the expressive possibilities of dancers with sen-
sors to capture their movements and produce sounds, visu-
als or movement through robotic actuators.
Several researchers have tackled the creation of digital
instruments for symbiotic expression of music and dance.
However, the initiatives rarely refer to one another, share
conceptual frameworks, or join eﬀorts in facing similar chal-
lenges of a broader area. To contribute in this direction,
we propose a conceptual framework for Digital Instruments
of Dance and Music (DDMI). The DDMI stand out from
the DMI for the explicit concern about body expressiveness
and present diﬀerent characteristics from the majority of
IDS given the instrumental relation with the musical pro-
duction.
89
2. INSTRUMENTALITY
The concept of what makes an object a musical instrument
has been brightly tackled by Sarah-Indriyati Hardjowirogo:
“[...] instrumentality, or simply being a musical
instrument must not be understood as a prop-
erty an object as such has or has not. Rather, it
seems to result from using something in a par-
ticular way which we think of as instrumental.
Consequently, an object is not per se a musi-
cal instrument (ontological deﬁnition) but it be-
comes a musical instrument by using it as such
(utilitarian deﬁnition) [...] the term must not be
understood as denoting a property an object per
se has or has not, but it is rather intended as a
means of capturing the instrumental potential of
a given artefact.” [15]
The “degree of instrumentality” is a dynamic quality of
an object, the result of cultural negotiation [31]. This de-
gree depends on a series of factors that characterise the
possibilities of human interaction with the artefact. The
author lists several important criteria for the instrumen-
tal potential of an artefact: Sound Production, Intention;
Purpose, Learnability; Virtuosity, Playability; Control; Im-
mediacy; Agency; Interaction, Expressivity; Eﬀort; Corpo-
reality, “Immaterial Features”; Cultural Embeddedness and
Audience Perception; Liveness.
3. ARTS INTEGRATION
Our main motivation to study the creation of DDMI is the
demand of artists who are at the intersection between music
and dance, interested in expressing themselves in both art
forms at the same time.
The integration of the arts is an ancient quest in hege-
monic Western history. The Florentine humanists of the
seventeenth century introduced the concept of opera, ref-
erencing the theatrical traditions of ancient Greece which
combined music, dance and poetry. Wagner, in the nine-
teenth century, brought the concept of uniﬁcation of the
arts (Gesamtkunstwerk) [23].
There are countless artistic traditions in which dance and
music performance are inseparable. In the Brazilian tra-
ditions of samba, forr´ o, frevo, vaner˜ ao, maracatu, cavalo
marinho, dance and music play equally important roles. In
several artistic contexts, the practice of each artist is of both
languages at the same time. Some other examples are the
various tap dance traditions (such as Fandango, Coco de
Arcoverde, American tap dancing and Irish step dancing).
The ﬂamenco dance cannot be understood without the mu-
sical handclapping, foot stomps and castanets playing.
4. DANCE AND MUSIC
Some empirical studies have been conducted to prove the
importance of body expression for musical perception. Sev-
eral studies have analysed the expressive role of gestures
that are not necessary to produce sounds [3, 11, 14]. Psy-
chological studies have also shown how the visual cues may
even have a stronger weight to the perception of musical
performances than sound, even for an audience of trained
musicians [20, 30, 32, 33]. These experiments have proved
how music is not restricted to sounds but also includes vi-
sual and bodily aspects. They also reveal the importance
of the musician’s body expression for an expressive perfor-
mance.
The seminal work of Mark Leman [21] ”Embodied Music
Cognition and Mediation Technologies” suggest a deep en-
tanglement between the motor and auditory cognitive sys-
tems. These conclusions propose a new approach to playing
music, to perceiving music1 as well to designing musical in-
struments.
In the history of dance, the modern and contemporary
movements marked a rupture with previous traditions, where
dance was subordinated to musical compositions previously
made. Martha Graham, one of the founders of modern
dance, was a choreographer who marked this break by inter-
fering in the process of musical composition, commissioning
or suggesting changes in the music pieces from her choreog-
raphy [23].
This detachment process was intensiﬁed after the inter-
action between the choreographer Merce Cunningham and
the composer John Cage, where the choreography was con-
ceived independently of the sound composition. Each had a
diﬀerent narrative, but they were presented together. The
audience had the freedom to make their connections be-
tween dance and music and could switch attention between
one and the other [23]. In Cage’s words:
“[...] in working with Merce, the ﬁrst thing we
did was to liberate the music from the necessity
to go with the dance, and to free the dance from
having to interpret the music.” John Cage [19].
This rupture was essential to consolidate dance as a lan-
guage independent of music, that is, without a hierarchical
distinction. Being able to look at both equally opens pos-
sibilities to think about new possible relationships between
them.
5. CONCEPTUAL FRAMEWORK FOR DDMI
The instrumental control of music by the dancer is not usu-
ally taken into account by the IDS researchers. On the other
hand, musicians’ body expressiveness is not frequently con-
sidered as a relevant asset for the DMI literature. It is a nat-
ural consequence from the musician’s focus on sound pro-
duction, and the dancer’s primary concern in body move-
ments. These bias, nevertheless, can generate much confu-
sion to the DDMI designer, hindering its process of ideation
and development of instruments for corporal and musical
expression.
In this paper, we present a conceptual framework explic-
itly tailored to the DDMI designer taking into consideration
aspects that are important for the DDMI architecture. This
framework was based on elements of the DMI and IDS lit-
erature and also on research about IDS or DMI that we
consider to be also DDMI.
Here is a list of some examples of DDMI that meet the
main focus of this research:
•Very Nervous System - being one of the ﬁrst IDS
developed2, it used cameras in a simple and expres-
sive way. It is an important reference of interactive
installations with an instrumental interaction [34].
•Expressive Footwear - it is a gestural interface in
the form of a shoe with 12 sensors that are intended
to capture the majority of gestural possibilities with
the feet. [28]
•Karlax3 - this instrument looks like a clarinet, but
the absence of a nozzle and several other controls allow
much greater freedom of movement as will be further
analysed on section 5 [25].
1since we do not perceive music just through sound, it is
not right to say we only “listen” to music
2A DDMI can also be an IDS
3http://www.karlax.com/
90
•Prosthetic Instruments - they are a series of phys-
ical artefacts used by dancers that can be attached
to the body or freely manipulated as will be further
analysed on section 5. [16]
This conceptual framework is intended to help in the cre-
ative process of a new DDMI. It can support the ideation
phase by deﬁning the instrument’s core aspects.
This framework can also serve as a bridge between the
areas of DMI and IDS facilitating the exchange of knowl-
edge between these communities. Nevertheless, it is not in
its scope to unify the IDS and DMI areas, but to create an
intersection of both in a reduced scope to instruments for
sound and body expression at the same time. Each of the
parent areas should have broader interests regarding inter-
faces for dance alone or just for making music.
5.1 Conceptual Framework
For the development of DDMI, aspects related to musical
production and body expression are essential. The paradigms
of DMI and IDS can provide references, but the former
presents few contributions to the corporal expressiveness,
and the latter brings few inputs on an instrumental relation
with the musical production. We, therefore, propose these
conceptual framework taking elements that we considered
relevant to the design of DDMI.
The conceptual framework of a paradigm is related to
a model that is followed by its community to design new
artefacts. It is a more general systematisation of diﬀerent
devices’ architecture that helps to consolidate an area and
to share grounding principles.
Figure 1: DMI’s Conceptual Framework Diagram
[26]
Figure 2: IDS’s Conceptual Framework Diagram
[10]
The seminal book ”New Digital Musical Instruments: Con-
trol and Interaction Beyond the Keyboard” from 2006 pro-
posed the diagram in Figure 1 [26]. It is a landmark in
the area4 and has inﬂuenced many DMI developers. A cen-
tral concept is the technical independence of the controller
4by April 2019 it had 487 citations on Google Scholar
and sound production units. The Mapping layer is maybe
the most important concept, represented in a way to stimu-
late various mappings between the controller and the sound
production unit. Another vital aspect of DMI’s instrumen-
tality is the instrument’s feedback to the player for precise
real-time control.
The best representation in the IDS literature is repre-
sented by a multi-layered conceptual framework of qualities
of movement, best represented by the diagram in Figure
2 [10] ﬁrst presented in 2001 [8] and mostly referenced in
the 2003 paper 5 [7]. An important focus is on the process-
ing of the sensor data generated by body movements into
parameters with expressive content. It is a central topic
of research in the Motion Computing community. Since the
IDS main focus is on dance technology, it is natural to focus
the framework on the body expressiveness.
Figure 3: DDMI’s Conceptual Framework Diagram
For DDMI, both frameworks are relevant but incomplete.
We propose the diagram in Figure 3 to describe the con-
ceptual framework of a DDMI. This kind of representation
was inspired by both representations above, including the
multi-layer gesture processing of the IDS and the feedback
and mapping layers of the DMI.
It is important to point out that a fundamental gestural
processing unit could be considered present in most DMI
since there is signal processing on the sensor data to deliver
relevant gestural control. The main diﬀerence in a DDMI
is that this unit is to consider the signal conditioning to
expressive gestures. In the same reasoning, and the DDMI
conceptual framework could describe IDS, but the feedback
and mapping layers are intended to give precise instrumen-
tal control over sound production.
The gestural sensing interface consists of sensors that per-
ceive information from the body. The gestural processing
unit is responsible for both the processing and interpreta-
tion of raw sensor data at diﬀerent levels of abstraction. The
mapping unit must process these qualities for the sound pro-
duction unit in order to obtain interesting gesture-sound re-
lationships. This last stage is composed of sound synthesis-
ers or electromechanical actuators (loudspeakers or robotic
instruments).
We chose to inherit the layers of feedback from the DMI
since they are beneﬁcial to build an instrumental relation-
ship. Gestural feedback is responsible for communicating to
the artist that the gesture was perceived by the instrument
and can be given by passive interface elements (such as a
click of a button or the elasticity of the instrument’s struc-
ture) as well as by active elements (such as actuators lu-
minous, mechanical or sound). The sound production feed-
back is responsible for returning information to the user
about the sound produced by the instrument and consists
mainly of the sound output of the instrument, but also can
have analogous productions to this sound with projections,
light indicators (such as VU bars) or mechanical (such as
motors that vibrate at the frequency of sound).
5by April 2019 it had 441 citations on Google Scholar
91
Beyond what the diagram can describe, it is essential for
DDMI to aﬀord sound and body expressivity. For that, it
is important for the instrument to allow precise control of
the sonic parameters as well as not to restrict much of the
body’s movements. These aﬀordances are to be taken into
account by the DDMI designer in the creation. Sometimes
it is necessary to trade-oﬀ one for another, but this choice
should be conscious.
To illustrate better how this conceptual framework helps
to understand existing DDMI and also in the development of
new DDMI we will describe how it applies to 2 instruments
cited above and two new instruments we have created.
5.2 DDMI examples
To better understand the DDMI conceptual framework, we
describe two of the instruments mentioned above, the Kar-
lax and the Prosthetic Instruments.
5.2.1 Karlax
Da Fact’s Karlax is an excellent example of a DDMI. This
instrument carries a direct instrumental inheritance [4] of a
clarinet, a traditional instrument that allows great freedom
of movement [30]. The absence of a mouthpiece and its
other aﬀordances allow a much higher body expressivity
while playing it while its many buttons and pistons allow a
precise instrumental sonic control.
The instrument is also equipped with accelerometers and
gyroscopes that output to the user the raw data as well as
the processed qualities of movement. It provides two-axis
tilting and impulsivity (abrupt translation) for the six sides
of translational movement having a multi-level gestural pro-
cessing unit recognising expressive gestures.
Its sensors are divided into two parts whose ergonomics
suggest that they are each touched by one hand. These
parts are connected by an axis of rotation that perceives
an expressive twisting gesture. There are also a set of four
intensity-sensitive pistons, ﬁve continuous keys, a joystick
and many buttons with tactile feedback that allow a vir-
tuoso instrumental control of sound parameters. All data
is sent to a wireless receiver that can be connected to a
computer via MIDI or OSC protocols.
If a musician has only the intention to use it to control
sound, it can be considered a DMI. It there is also the inten-
tion to dance while playing it, it is a good DDMI because it
aﬀords a lot of o freedom of movement by its lightness and
size.
Figure 4: DaFact’s Karlax
5.2.2 Prothetic Insturments
Other references for DDMI are the Prosthetic Instruments.
They were described as a family of interactive dance in-
struments that could be perceived as new members of the
body [16]. The instruments developed were the ”Visor”, the
”Ribs” and the ”Spine”. The concept of an instrument as a
prosthesis goes beyond merely placing sensors in the body.
The material conﬁguration of the prostheses mechanically
interacts with the body, changing the possibilities and feed-
backs from movement.
The DDMI ”Spine” was equipped with two Motion Units
with accelerometers, gyroscopes and magnetometers at the
ends of the spine. The embedded gestural processing unit
allowed an expressive read of its curvature and torsion. It
was developed to minimise obstruction of the movement
while maintaining some restrictions of some movements that
were choreographically interesting. This is a good exam-
ple of how freedom of movement is important for body ex-
pressivity but some limitations to it can also contribute to
dance.
The ”Visor” and the ”Ribs” have, in addition to an ac-
celerometer, capacitive sensors to detect touch and sliding
ﬁnger gestures. The possibility of releasing the instruments
and ﬁxing them back on the body was conceived in a way
they could be perceived either as part of the body of the
performers or as objects. The tactile feedback and ﬁnger
control allowed them to have a more instrumental relation-
ship, aﬀording more precise sound control. Some develop-
ment criteria were adopted that guaranteed the instrumen-
tality of the devices like low latency (around 5ms) and high-
resolution data to allow subtlety of control. The libmap-
per library [22] was used as a mapping unit connecting the
available gestural parameters to one or more of the custom
synthesisers parameters programmed in Max/MSP.
This work was conducted by a team of digital instrument
designers, dancers, musicians and sound designers. It is
an excellent example of how an instrument can be made
for dance and music at the same time. In this process, the
musical intentions led to choreographies and movement def-
initions led to the musical composition through the DDMI
design.
Figure 5: Prosthetic Instruments
5.3 New DDMI
We describe Giromin and TumT´ a, two DDMI developed
by the authors, and how the DDMI conceptual framework
aided their creative process.
5.3.1 Giromin
Giromin is a wireless wearable free-gestures DDMI. It was
made to be worn around the torso and on the upper arm
not to impose any movement restrictions. It was designed
to amplify the gestures of continuous musical controls on
synthesisers, usually done with knobs and sliders, still al-
lowing a precise instrumental control with a direct analog-
ical connection between what is seen and what is heard by
the audience. It was motivated by research that suggested
that the musical community in the Northeast of Brazil saw
that it was important for electronic musicians gestures to be
perceivable by the audience [2] and later used in the ”Gira”
performance.
Each wearable module was composed of an accelerometer,
gyroscope and magnetometer, which could extract move-
ment information without imposing physical restrictions. It
used a sensor fusion algorithm to extract orientation data
92
of each limb together with rotation speed and acceleration
data. The arm’s height, pointing direction and torsion and
the torso’s inclination and the whole body whirling move-
ment showed to be very expressive. The gestural process-
ing unit ran on ﬁrmware, sending the parameters wirelessly
through OSC protocol to a computer to control hardware or
software synthesisers. The range and mapping settings of
input and output data could be done on a software interface.
The conceptual framework helped the design of this in-
strument in the choice of maximum movement freedom even
though losing precision of sound control. Knowing these
limitations, we searched for interesting mapping alterna-
tives to continuous sound parameters that did not need such
precise control and had perceptible relationships with the
gestures like frequency and resonance of ﬁlters, LFOs fre-
quencies, BPM rate of arpeggiators and direct amplitude
control. The intuitive mappings with analogous sound and
gesture, like the height of the arm to the frequency of a ﬁl-
ter gave possibilities to intuitively control many parameters
that would be impossible to control by one person through
regular knob/slider interfaces.
Figure 6: Giromin
5.3.2 TumTá
TumT´ a is a wearable instrument in the form of a pair of
insoles to be placed inside the shoes. It detects heel foot
stomps and triggers samples from them. It was designed to
give new sonic possibilities to the bold foot stomping dance
of Cavalo Marinho, a tradition from the Northeast of Brazil.
It was designed with a handmade pressure sensor from
conductive foam and thread that was rugged enough to re-
ceive bold stomps. These insoles were connected through
wires to a wireless transmitter belt, that did not constrain
the dancer’s movement. The gestural processing unit was
responsible for recognizing the pressure variation instead of
the raw pressure. That parameter aﬀorded more impulsive
foot gestures, which were closer to the dance that inspired
the instrument design. Most keyboards have a similar gestu-
ral design, but the diﬀerence between this DDMI approach
was to process the sensor signal based on the gestural ex-
pressiveness, instead of just the precise sound control.
There was software that converted the input signals into
MIDI notes with velocities that depended on the foot stomps
intensities, which were mapped in Ableton Live to a sam-
pler. This DDMI was another wearable instrument that
did not restrict physically any movement, but diﬀerent than
Giromin, it gave a more precise triggering control because
of the pressure feedback it gave from the ﬂoor, allowing the
player/dancer to make fast and precise rhythms that were
both visually and musically expressive.
6. CONCLUSION
We proposed a DDMI conceptual framework with a set of
arguments, references in literature and concepts to help the
design of new instruments to make music and dance. It also
aimed to argue in the DMI are in favour of body expressive-
Figure 7: TumT´ a
ness and the IDS area on the beneﬁts of musical instrumen-
tality. This is an open proposal to be in constant evolution
by the interested communities. This framework showed to
have positive impacts on the development of two instru-
ments (Giromin and TumT´ a), giving a more precise repre-
sentation of what features a DDMI should have. We noticed
there was a trade-oﬀ between movement restrictions set by
the instrument and precision in musical control. In both
cases we opted to give a higher weight for movement free-
dom, lowering the instrument’s musical expressivity. This
was not a wrong choice, but the most signiﬁcant contribu-
tion of the DDMI framework was to make this a conscious
choice.
7. FUTURE WORK
The DDMI conceptual framework has a lot to improve by
validating it with a greater number of DDMI designers and
users. A categorisation system for DDMI can also help the
development stages of new instruments, helping to struc-
ture the knowledge from previous projects into common
challenges and possibilities. An evaluation system could
have a lot to contribute to the area as well. This way the
framework could cover the whole design process of ideation,
development and evaluation.
8. REFERENCES
[1] R. Aylward and J. A. Paradiso. Sensemble: A
Wireless, Compact, Multi-User Sensor System for
Interactive Dance. In 2016 NIME Proceedings, pages
134–139, Paris, 2006.
[2] J. Barbosa, F. Calegario, J. Tragtenberg, G. Cabral,
G. Ramalho, and M. M. Wanderley. Designing DMIs
for Popular Music in the Brazilian Northeast :
Lessons Learned. Proceedings of the International
Conference on New Interfaces for Musical Expression ,
pages 277–280, 2015.
[3] M. Broughton and C. Stevens. Music, movement and
marimba: an investigation of the role of movement
and gesture in communicating musical expression to
an audience. Psychology of Music , 37(2):137–153,
2009.
[4] F. Calegario. Probatio: Towards Diﬀerent Levels of
Mapping. Technical report, INRIA Lille, Lille, Fran¸ ca,
2016.
[5] A. Camurri. Interactive Dance/Music Systems.
Computer Music Conference ICMC , pages 45–252,
1995.
[6] A. Camurri, G. De Poli, A. Friberg, M. Leman, and
G. Volpe. The MEGA Project: Analysis and
Synthesis of Multisensory Expressive Gesture in
Performing Art Applications. Journal of New Music
Research, 34(1):5–21, mar 2005.
[7] A. Camurri, I. Lagerl ¨of, and G. Volpe. Recognizing
93
emotion from dance movement: Comparison of
spectator recognition and automated techniques.
International Journal of Human Computer Studies ,
59(1-2):213–225, 2003.
[8] A. Camurri, G. D. Poli, M. Leman, and G. Volpe. A
Multi-layered Conceptual Framework for Expressive
Gesture Applications. In Proceedings of MOSART:
Workshop on Current Directions in Computer Music ,
(1):29–34, 2001.
[9] A. Camurri and G. Volpe. Multimodal Analysis of
Expressive Gesture in Music Performance. In S. J.
and N. K., editors, Musical Robots and Interactive
Multimodal Systems. Springer Tracts in Advanced
Robotics, chapter 4, pages 47–66. Springer, Berlin,
Heidelberg, 2011.
[10] A. Camurri, G. Volpe, S. Piana, M. Mancini,
R. Niewiadomski, N. Ferrari, and C. Canepa. The
Dancer in the Eye: Towards a Multi-Layered
Computational Framework of Qualities in Movement.
Proceedings of the 3rd International Symposium on
Movement and Computing , pages 6:1–6:7, 2016.
[11] J. W. Davidson. Visual Perception of Performance
Manner in the Movements of Solo Musicians.
Psychology of Music , 21(2):103–113, 1993.
[12] J. Eaton, W. Jin, and E. Miranda. The Space
Between Us. A Live Performance with Musical Score
Generated via Emotional Levels Measured in EEG of
One Performer and an Audience Member. Proceedings
of the International Conference on New Interfaces for
Musical Expression, pages 593–596, 2014.
[13] C. Frisson, S. Dupont, J. Leroy, A. Moinet, T. Ravet,
X. Siebert, and T. Dutoit. LoopJam : turning the
dance ﬂoor into a collaborative instrumental map.
NIME 2012 Proceedings of the International
Conference on New Interfaces for Musical Expression ,
pages 278–281, 2012.
[14] D. Glowinski, N. Baron, D. Grandjean, T. Ott,
K. Shirole, K. Torres-Eliard, and M.-A. Rappaz.
Analyzing expressive styles and functions of bodily
movement in violinist performance. Proceedings of the
2014 International Workshop on Movement and
Computing - MOCO ’14 , pages 154–155, 2014.
[15] S.-I. Hardjowirogo. Instrumentality. On the
Construction of Instrumental Identity. In Musical
Instruments in the 21st Century Identities,
Conﬁgurations, Practices. Springer, Berlin, 2017.
[16] I. Hattwick, J. Malloch, and M. Wanderley. Forming
Shapes to Bodies: Design for Manufacturing in the
Prosthetic Instruments. Proceedings of the
International Conference on New Interfaces for
Musical Expression, (August 2016):443–448, 2014.
[17] A. R. Jensenius and M. J. e. Lyons. A NIME Reader,
volume 3. Springer, 2017.
[18] B. Knapp and H. Lusted. A Bioelectrical Controller
for Computer Music Applications. Computer Music
Journal, 14(1):42–47, 1990.
[19] R. Kostelanetz. Conversing with Cage . Limelight,
New York, 1988.
[20] C. Krahe, U. Hahn, and K. Whitney. Is seeing
(musical) believing? The eye versus the ear in
emotional responses to music. Psychology of Music ,
10(8), oct 2013.
[21] M. Leman. Embodied Music Cognition and Mediation
Technology. The MIT Press, Cambridge,
Massachussetts; London England, 2008.
[22] J. Malloch. A Framework and Tools for Mapping of
Digital Musical Instruments . PhD thesis, McGill
University, 2013.
[23] P. H. Mason. Music, dance and the total art work:
choreomusicology in theory and practice. Research in
Dance Education, 13(1):5–24, 2012.
[24] M. V. Mathews. The Digital Computer as a Musical
Instrument. Science, 142(3592):553–557, 1963.
[25] T. Mays and F. Faber. A Notation System for the
Karlax Controller. In 2014 NIME Proceedings, pages
553–556, London, United Kingdom, jun 2014.
Goldsmiths, University of London.
[26] E. R. Miranda and M. M. Wanderley. New Digital
Musical Instruments: Control and Interaction Beyond
the Keyboard. A-R Editions, Middleton, 2006.
[27] J. Paradiso and E. Hu. Expressive footwear for
computer-augmented dance performance. Digest of
Papers. First International Symposium on Wearable
Computers, (October):20–21, 1997.
[28] J. a. Paradiso, K. Hsiao, a. Y. Benbasat, and
Z. Teegarden. Design and implementation of
expressive footwear. IBM Systems Journal ,
39(3.4):511–529, 2000.
[29] Z. Vamvakousis and R. Ramirez. The EyeHarp: A
gaze-controlled digital musical instrument. Frontiers
in Psychology, 7(JUN):1–14, 2016.
[30] B. W. Vines, C. L. Krumhansl, M. M. Wanderley,
I. M. Dalca, and D. J. Levitin. Music to my eyes:
Cross-modal interactions in the perception of
emotions in musical performance. Cognition,
118(2):157–170, 2011.
[31] F. Visi. Methods and Technologies for the Analysis
and Interactive Use of Body Movements in
Instrumental Music Performance . PhD thesis,
Plymouth University, 2017.
[32] J. K. Vuoskoski, M. R. Thompson, E. F. Clarke, and
C. Spence. Crossmodal interactions in the perception
of expressivity in musical performance. Attention,
Perception, & Psychophysics, 76(2):591–604, 2014.
[33] A. Williamon and G. Waddell. Eye of the Beholder:
Stage Entrance Behavior and Facial Expression Aﬀect
Continuous Quality Ratings in Music Performance.
Frontiers in Psychology, 8(April):1–14, 2017.
[34] T. Winkler. Creating Interactive Dance with the Very
Nervous System. Proceedings of Connecticut College
Symposium on Arts and Technology , (April), 1997.
94