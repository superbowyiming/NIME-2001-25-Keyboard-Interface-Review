Drum Modal Feedback: Concept Design of an Augmented
Percussion Instrument
Lewis Wolstanholme
Queen Mary University of London
London, United Kingdom
l.wolstanholme@qmul.ac.uk
Jordie Shier
Queen Mary University of London
London, United Kingdom
j.m.shier@qmul.ac.uk
Rodrigo Constanzo
Royal Northern College of Music
Manchester, United Kingdom
rodrigo.constanzo@rncm.ac.uk
Andrew McPherson
Imperial College London
London, United Kingdom
andrew.mcpherson@imperial.ac.uk
Abstract
We here outline the concept design of an augmented percussion
instrument, conceived for and used as part of a variety of distinct
performances and compositions. Throughout the curation of this
project, each creative act has enabled us to contextualise, exam-
ine and reflect upon the design of this augmented instrument. In
accordance with Stolterman and Wiberg’s concept driven design
methodology, we do not present a singular instrument design,
but instead an overarching design concept alongside its develop-
mental and evaluative narrative. This augmentation centres upon
the use of a drum trigger and a tactile transducer, which when
coupled together can be used to feedback or resonate a drum. The
resultant soundworld develops upon the idiomatic sonority of a
drum, and allows for the duration and timbre of a drum strike
to be continuously manipulated and shaped throughout a per-
formance. In exploring the soundworld which results from this
approach, we have experimented with numerous configurations
of these pieces of hardware, and have also employed various
pieces of software to parametrise the sonic subtleties that this
approach engenders. Most prominently, we have developed a
bespoke piece of software which analyses the modes of a drum
prior to performance, and uses this modal analysis to shape the
overall feedback and resonance. Throughout this design process,
we have consistently been met with new creative criteria that
challenge our approach and ideas, in response to the particular-
ities of the musicians we are working alongside, as well as the
performative and aesthetic environments we are working within.
Keywords
augmented percussion instruments, concept design, practice
based reasearch
1 Introduction
It is often the case that in artistic practice, a simple concept is wo-
ven into a series of distinct projects and activities. In such cases,
the form of that concept may extend beyond just its inclusion
amongst those projects and activities, and pertain to a sentiment
of its own accord. What is at first conceived as a means to achieve
a particular, contextualised aesthetic quality, may then come to
emblematise the expression of such a quality within new and un-
folding contexts. During the preparations for a recording session,
This work is licensed under a Creative Commons Attribution 4.0 International
License.
NIME ’25, June 24–27, 2025, Canberra, Australia
©2025 Copyright held by the owner/author(s).
we had the initial conception to attach both a drum trigger and
a tactile transducer to an acoustic percussion instrument, so as
to enable this instrument’s sound to be performatively distorted
using feedback and resonance. Although previous works em-
ploying the resonant feedback of drums [5, 13, 20, 25] comprise
a significant precedent, our own explorations of this concept
have manifested into a detailed exemplification of its constituent
soundworld, engendered through a malleable and variable tech-
nological approach. In many senses this project still remains in
flux, as it serves to lay the foundation for the continued creative
application and interpretation of this concept.
Building upon Stolterman and Wiberg’s [42] concept driven
design methodology, we here outline the concept design of an
augmented percussion instrument, the development of which
centres upon our exploration of this technology amidst our cre-
ative practices. Such a concept design is comprised of two parts -
a technological concept, which constitutes the instrument’s form
and interactivity, and a sonic concept, which is the soundworld
that this instrument engenders. As such, we here examine many
of this instrument’s technological intricacies, as well as docu-
ment the musical affordances and constraints that this technology
envelops. Alongside our use of hardware devices, we have devel-
oped and experimented with a variety of software tools that have
enabled us to carve out an idiomatic and performative sound-
world, building upon the acoustic properties of the percussion
instruments we are augmenting. Our practice led design process
has provoked us to consistently reconfigure our design criteria,
and define a concept that supports the implementation of an aug-
mented percussion instrument applicable to a variety of aesthetic
contexts.
2 Design Methodology
Stolterman and Wiberg’s [42] termconcept designis used to refer
to the process through which a concept is defined, detailed and
developed. Such a concept may be grounded in tangibility, i.e
a proof of concept, but the concept itself is not necessarily a
particular artefact. In this sense, a concept is a form of abstrac-
tion [15], which can then be used in the design of more complex,
situated instantiations. To recontextualise this notion, our work
and research elucidates the concept of an augmented percus-
sion instrument, however the product of this research is not the
creation of an augmented percussion instrument in particular.
Instead, we have produced a collection of implementations and
reflections that exhibit this concept, portrayed through a series
of practical and experiential manifestations.
“ [T]he design researcher must go beyond the initial
idea and explore the unknown. Usually, this means
NIME ’25, June 24–27, 2025, Canberra, Australia Lewis Wolstanholme, Jordie Shier, Rodrigo Constanzo, and Andrew McPherson
working hands-on with materials; creating models
and prototypes; and experimenting with unusual
materials, forms, and content in the exploration of
new design spaces. Concept design is about open-
ing up and exploring new design spaces or finding
unseen parts of already known spaces. ” [42, p.110]
In curating both our research and our presentation of it, we aim
for this work to provide a foundation from which augmented
percussion instruments may be further explored, within either
research driven or practice driven contexts.
In conducting this design research, we have been consistently
driven by our artistic practices, and it has been these practice
led endeavours which shaped the formulation of our resultant
concept. We similarly present this work largely as an annotated
portfolio [2, 11], with each creative act serving to exemplify and
rationalise certain facets and constraints relating to our concept.
This style of presentation was chosen primarily due to the prac-
tice led nature of our research, for it is undoubtedly an example
of ‘research through art’ [10], and such a mode of presentation
emphasises this theme [2]. This practice led methodology also
entertains an explicit contradiction to the idea of user-centred
design, within which a design is assessed based on a functional
relationship to its users, rather than its aesthetic or artistic affor-
dances. User-centred design tends to impose subtle restrictions
surrounding the openness of a design concept, by curating not
only the design of a particular system, but also the subsistent
design of its context - “A ‘user’ is something that designers cre-
ate. ” [35, p.129] This contradiction serves to alleviate some of the
well-documented pitfalls encountered during the user-centred de-
sign of musical instruments [38]. We uphold that such adherence
to a prescribed functional relationship with a user obfuscates
the intricacies of aesthetic sentiment that may be engendered
through difficult and explorative playing techniques [32, 46] or
a misuse of said functionality altogether. And in focusing our
inquiries towards practice, we allow for the emergence [12] of
aesthetic design criteria over functional ones, and embrace fail-
ure [16] and difficulty as an integral part to our reflective and
reciprocal process.
Throughout this project, it has often felt that its discoveries
and understandings were formed naturally through the inquiries
born of a creative process. At many junctures, the questions re-
garding our concept design arose not in service of the concept
itself, but toserve the music. The benefits of resolutelyserving the
musicis that the concept in question must be able to withstand all
of the scrutiny directed towards it by those who work with com-
plete conviction and dedication towards achieving their anterior
creative pursuits. Such a framing serves to elevate the authentic-
ity of artistic practice, so as to not overshadow its motives with
an extra-musical research agenda. As such, the goal for this work
was not simply to produce technical knowledge, but to align our
epistemic inquiries with the artistic pursuits that surround them
- to simultaneously embrace “the Picasso philosophy” [10, p.5].
“The notion of simultaneity is useful here because
the most enticing design artists are utterly flexi-
ble regarding the role they play, being content to
work as designers and as artists at different times,
although not always in the role or circumstances in
which they would be expected to do so. ” [4, pp.14-
15]
Serving the musicin this sense is a contestable means of conduct-
ing academic research [10]. The challenges which arise through
aesthetic pursuits may perhaps only be relevant within those aes-
thetic contexts. The knowledge produced through such pursuits
may be esoteric or embodied [1], unspeakable once removed of
its original context. However, a particular exemplification of a
concept is always contextualised, a notion which is encapsulated
by Stolterman’s use of the termultimate particular.
“In design practice, the goal is all about creating
somethingnon-universal. It is about creating some-
thing in the world with aspecificpurpose, for a
specificsituation, for aspecificclient and user, with
specificfunctions and characteristics [ . . . ] Design
is about the unique, the particular, or even theulti-
mate particular. ” [41, p.59]
In accordance, the form of aesthetic knowledge being discussed
here is both subjective and intersubjective [24]. It is influenced
by the aesthetic sentiments of its practitioners, but it is also
shared experientially. Through successive implementations and
reflections, the knowledge which surrounds a concept’s foun-
dation - the intersubjective knowledge which can transcend a
subjective context - innately becomes clearer. And via this pro-
cess of presenting our concept, we attempt to translate some of
these aesthetic understandings into a co-constructed form that
is applicable to contexts beyond our own.
3 Practical Background
Throughout this work, we have drawn a number of references
from musicians and designers who have previously explored ad-
jacent soundworlds and instrument augmentations. Primarily,
we have paid close attention to the many designers who have
used resonance and feedback in their work [7, 21], as this sonic
idiom has become a prevalent trend amongst recent augmented
instrument designs. Where augmented percussion instruments
are concerned, many designers have demonstrated a variety of
hardware approaches towards resonance, utilising either elec-
tromagnets [3, 13, 19, 34], loudspeakers [20, 25, 29, 45, 47, 48],
or tactile transducers [5, 18]. Similarly, there are also many ex-
amples of designers creating feedback with their percussion in-
struments using traditional microphones [5, 48], contact micro-
phones [13, 20, 45] or drum triggers [25] to amplify their instru-
ment’s sound, alongside the use of audio effects to manipulate
this signal [5, 25]. Many of these designs share traits with our
own work, as our personal hardware configuration sought to
combine aspects from many of these previous approaches, whilst
simultaneously extending upon the use of performative soft-
ware surrounding this concept. In accordance with our design
methodology, many of these previous approaches afford partic-
ular functionalities and aesthetic qualities with regards to the
practitioners involved and the creative contexts within which
they were working.
Often the soundworlds produced through these methods are
extremely varied, with many of the aforementioned instruments
spanning a wide range of colours from absolute noise to ar-
ticulated and textural tones. This soundworld has a long his-
tory in modern music practice, with works by Karlheinz Stock-
hausen [40] and Tony Oxley [30] being some of the earliest works
to first demonstrate the sonic possibilities of amplified percussion.
More recently, in many of the works by Rodrigo Constanzo [5]
and Christos Michalakos [26–28], the use of augmented percus-
sion has been explored through an experimental approach to solo
percussion performance. Both Constanzo and Michalakos have
previously combined drum triggers, transducers/loudspeakers,
Drum Modal Feedback: Concept Design of an Augmented Percussion Instrument NIME ’25, June 24–27, 2025, Canberra, Australia
and a software driven approach to create resonant feedback, al-
lowing for a large breadth of sonic versatility and colour that
is evocative of numerous aesthetic sensibilities. Elsewhere, aug-
mented percussion instruments have been used in installations, as
can be seen in the work of Jeff Gregorio [13]. Here Gregorio uses
electromagnets to produce modal resonances of multiple drums
in consort. By applying this method to many concurrent drums,
Gregorio is able to curate a sonorous and textural palette that un-
folds throughout his installation. And within a more traditional
concert hall environment, resonant feedback of an orchestral bass
drum has been used extensively by the composer Michelangelo
Lupone [20], being a focal point in works such asGran Cassaand
Chant de la Matière. Here, as the augmented drum is so large, its
resonant feedback creates a dynamic dialectic between the per-
former and their instrument, as they employ various techniques
to explore and shape the instrument’s ensuing resonance.
Where non-percussive instruments are concerned, we have
also paid close attention to the colours produced by themagnetic
resonator piano[ 22], and particularly the sonic versatility that its
many performers are capable of commanding [31]. One of the
more poignant lessons we learnt from the magnetic resonator pi-
ano was its ability to leverage its performer’s pre-existing musical
strengths to produce new sonic landscapes, despite the change
in performative context they subsequently had to undergo [23].
And perhaps one of our most striking sonic references, and one
that has been repeatedly audiated and revisited throughout this
project, is the feedback sounds produced by David Torn’s aug-
mented guitar [43]. In many of his performances, Torn has utilised
the sound of feedback with a striking versatility, being capable
of creating both melodic and textural passages using his guitar
augmentation.
4 Concept Implementation
The implementation of our augmented percussion instrument
utilises both hardware and software components to create acous-
tically informed modal feedback and resonance. We here outline
the design considerations surrounding these hardware and soft-
ware components, alongside a number of variabilities amongst
them which we have encountered through our artistic practices.
These variabilities serve to demarcate the possibilities of this
instrument with regards to its functionality and aesthetic affor-
dances.
4.1 Hardware
Our hardware design consists of two principal components - a
drum trigger and a tactile transducer. Each of these components
were connected to a laptop running our software, with the drum
trigger being used as a line input, and the transducer being used
as an audio output.
Throughout the implementations discussed during this paper,
wherever possible we used Rodrigo Constanzo’sOP-Sensor[ 6]
for our drum triggers. During our development, we experimented
with a variety of alternative drum triggers, and found that the
OP-Sensor had the best audio quality when being used as a line
input due to its low noise floor and shielded internal components.
The OP-Sensor is paired with a magnetic dot placed upon the
drum skin, which it uses to detect changes in the magnetic field
whenever the membrane is in motion. Many other drum triggers
use contact microphones with a foam wedge that rests upon the
drum skin, which although works well for many other audio ap-
plications, does inhibit the natural movement of the membrane
(a) Side view of a drum, showing both drum trigger and transducer
placement.
(b) Intersection of a gong drum, showing both drum trigger and
transducer placement.
(c) Underside of a snare, showing transducer placement.
Figure 1: Diagram of the hardware setup for various drums.
itself. Due to their design, the audio captured using a drum trig-
ger is not representative of the sound one naturally perceives
when hearing a percussion instrument, however those that are
well designed exhibit a clear tonal image of a drum’s vibrating
membrane. Although using drum triggers as line inputs is not
their intended function, in this context it is advantageous to use
them over typical microphones, as they exhibit minimal latency
between the moment the drum is struck and any subsequent
audio processing that follows [17].
To create both feedback and resonance, we sent audio to a
drum using a tactile transducer which was mounted directly onto
the drum itself. Throughout this project, we have used a variety
of transducer placements, as shown in figure 1. For the best sonic
relationship between the drum trigger and transducer, the trans-
ducer should be placed on the top membrane. Placing both the
drum trigger and transducer on the top membrane may interfere
with a performer’s gestural flexibility, and so alternative place-
ments of the transducer may be advantageous. The main concern
to be aware of here is that if the drum trigger and transducer
are facing each other, they will naturally create feedback of their
own accord. As well, if the transducer is being placed directly
onto a membrane, it is important to note the resonant shapes,
or Chladni patterns, which the drum will produce when struck.
These Chladni patterns demonstrate the locations of nodes and
anti-nodes, each of which corresponds to a particular subset of
modal frequencies. Placing the transducer on an anti-node will
NIME ’25, June 24–27, 2025, Canberra, Australia Lewis Wolstanholme, Jordie Shier, Rodrigo Constanzo, and Andrew McPherson
effectively mute its corresponding modal frequencies, and so the
placement of this transducer inherently effects the instrument’s
timbre. The orientation of these Chladni patterns are dictated by
the orientation of the drum strike, and so in practice the position
of these nodes and anti-nodes will change throughout perfor-
mance. To only remove high frequency modes, the transducer
should be positioned at a skewed angle from the drummer’s
perspective, and as close to the rim as possible [50].
4.2 Software
To explore acoustically informed modal feedback and resonance,
we developed a Max patch entitleddrum-modal-feedback1, the de-
sign scheme for which is shown in figure 2. This patch is used to
perform modal analysis on a augmented percussion instrument,
so as to determine the frequency content of both a resonant filter
bank and an additive synthesiser. In the case of the resonant filter
bank, the audio input from the drum trigger is used to directly
incite modal feedback. And in the case of the additive synthesiser,
the drum trigger input is used alongside an onset detector from
theSP-Tools 2 [44] Max package to trigger an envelope generator,
which in turn independently amplifies the modes of our additive
synthesiser. When designing this patch, we exposed and experi-
mented with a multitude of parameters attached to these devices,
such as the control of modal amplitudes and the shapes of our
envelopes.
To analyse the frequency content of an augmented percus-
sion instrument, we developed an API that interfaces with the
HISSTools3 [14] Max package using Node for Max 4 and Type-
Script5. Before being able to perform with this software, a per-
former is required to analyse the frequency content of their instru-
ment. This approach was chosen to allow for an overall flexibility
between different instruments, and similarly to allow for a drum
to be reanalysed after tuning or extensive playing. Our analysis
uses an exponential sine sweep [8, 9] to create an SPL measure-
ment of a drum’s overall frequency content, which is a method of
analysis also commonly used for capturing room responses [37].
Once the SPL measurement has been captured, we use the peak
picking algorithm [36] in combination with quadratic interpola-
tion [39] to determine the precise frequencies and amplitudes of
a drum’s dominant modes. Although many methods for identi-
fying the dominant modes of an object or space exist, we chose
this approach as it is both simple and intuitive [36], and has been
shown to be the preferred method for analysing musical instru-
ments [33]. Upon completing these calculations, we then made
it possible to performatively manipulate our resultant modal in-
formation in real-time, utilising techniques such as limiting the
frequency range of active modes, as well as limiting the logarith-
mic distance between these resultant frequencies. As an example
of using such a parametrisation, one could specify that they only
want to create feedback using modes between 220Hz and 880Hz,
and that they must be separated by at least a 400 cents, which is
an equally tempered major third.
5 Creative Portfolio
We explored this concept design within a variety of artistic con-
texts throughout this project, and in doing so curated four ex-
emplary recorded performances and compositions. Each of these
1The source code for this work: https://github.com/lewiswolf/drum-modal-feedback
2SP-Tools: https://github.com/rconstanzo/sp-tools
3HISSTools: https://github.com/HISSTools/HISSTools_Impulse_Response_Toolbox
4Node for Max: https://docs.cycling74.com/nodeformax/api
5TypeScript: https://www.typescriptlang.org
Figure 2: Diagram of thedrum-modal-feedbacksoftware.
recordings situates our concept within distinct creative environ-
ments, and utilises a range of artists from a variety of musical
backgrounds to assess the sonic nuances and technological lim-
its of our concept’s design. These recordings have been made
available online, as part of a web portfolio attached to this publi-
cation.6 In recording these performances, we also documented
our immediate reflections resulting from these processes, so as
to outline our concept’s prevalent artistic constraints.
5.1 Julia Set X Barrell Jones
Julia Set is an audiovisual performance duo, co-curated by Lewis
Wolstanholme and Francis Devine [49]. Julia Set have a diverse
background performing experimental music, and often employ a
variety of contemporary approaches to both their improvisatory
and compositional endeavours. For this piece, entitledmyopic,
they collaborated with the percussionist Sam ‘Barrell’ Jones7, who
has had extensive experience performing alongside a variety of
jazz and pop artists.
myopicwas recorded live in a studio as part of a two-day
recording session. The aim of this session was primarily to write
and record various pieces of improvised music that explored live
electronics and interactive percussion performance.myopicwas
the only piece during this two-day session which employed an
augmented percussion instrument. Whilst recording this work,
the piece was performed four times, with the fourth take being
the one contained in our aforementioned composition portfolio.
In the lead up to this recording session, Sam’s only other con-
tact with augmented percussion was during a single afternoon
rehearsal.
For this performance, the group used a Roland RT-30H drum
trigger and attached a Dayton Audio DAEX25CT-4 transducer to
the underside of their snare, as portrayed in figure 1c. For their
software, the group used a simple VST delay in between the drum
trigger and transducer, as at this point in time our modal feedback
and resonance software had not yet been developed. The delay’s
feedback and delay time were controlled by Lewis using a DAW
controller, which encouraged a collaborative exploration of this
technology between Lewis and Sam. Although this was a new
soundworld for the group, many of the performative technolo-
gies previously used by Julia Set X Barrell Jones employed this
6Composition portfolio:
https://lewiswolf.github.io/drum-modal-feedback-compositions
7Sam ‘Barrell’ Jones: https://barrelljonesmusic.com
Drum Modal Feedback: Concept Design of an Augmented Percussion Instrument NIME ’25, June 24–27, 2025, Canberra, Australia
approach towards sonic collaboration - where each member’s
improvisation cyclically guides and influences the improvisation
of another.
In isolation, a delayed signal works well to create a simple yet
dynamic feedback loop using our hardware, however there are
distinct limits to the sonic colours which can arise through this
method. Often the feedback’s pitch content is determined by the
delay time, and has limited flexibility on what can be achieved
through percussive technique and parametric exploration alone.
When set to specific delay times however, it is possible to catch
and resonate a drum according to its modal frequencies, however
it is not possible to manipulate the details of this sound any
further.
5.2 Lewis Wolstanholme X Ciarán Corr
Lewis and Ciarán have been long time musical collaborators,
releasing their first piece of music together in 2018. Ciarán is a
successful performer, producer and musical director in his own
right, whose work ranges across numerous different styles and
genres. In recent years, the two have collaborated on a multitude
of studio compositions, and similarly the work that they have
presented here was created within this familiar setting.
All of the percussive material for this work was performed
by Ciarán, and recorded during a one-day session. The overall
form for this work was planned in advance, however this work
was not conceived as part of a larger project, but instead as stan-
dalone exploration of percussive feedback and resonance. During
this one-day session, the pair recorded 1-2 hours of material,
which was later cut up, arranged and fully produced. Prior to
this one-day session, Ciarán had not previously performed with
an augmented percussion instrument, but had been made aware
of its sonic potential.
For this work, both a snare drum and floor tom were aug-
mented using OP-Sensors and Dayton Audio DAEX25CT-4 trans-
ducers, arranged as shown in figure 1a. For their software, they
primarily used thedrum-modal-feedbackMax patch coupled with
a VST delay. During this session, the pair explored various facets
of these pieces of software, both in isolation and in combination.
Stylistically, the two aimed towards creating a piece of music
that explored some of the more liminal qualities of percussive
feedback through contrasting playing styles and extended tech-
niques. As with the previous Julia Set X Barrell Jones project,
Lewis controlled the various sonic parameters during this ses-
sion using a DAW controller. For each drum, Lewis controlled the
delay time, the amplitudes of both the additive synthesiser and
resonant filter bank, as well as the maximum modal frequency
these synthesisers could produce. In this context, the relation-
ship between each musician was more that of a producer and a
performer rather than a collaborative improvisation. The perfor-
mative interaction between the two was very much structured
and preplanned, allowing for specific sonorities to be captured
and explored at particular moments during the recording process.
Working in this studio context allowed for the directed explo-
ration of the augmented percussion soundworld, and enabled
the group to hone in on particular techniques and sonic out-
comes. These techniques included damping and stretching the
skin whilst the drum was feeding back, which created a sort of
tremolo effect, and experimenting with the effects of different
beaters and mallets, which allowed for a variety of more subtle
and metallic sounds to emerge. In many instances, however, the
pair found it challenging to repeatedly perform the particular
sounds they were aiming for, as a number of the parameters in
thedrum-modal-feedbackMax patch were either randomised or
remained unclear with regards to their more detailed sonic func-
tion. Often the pair were attempting to create melodic passages
of feedback, which they were marginally successful in achieving,
however they were not able to repeat the same musical gestures
with a desired degree of accuracy or predictability.
5.3 Napoleon Skywalker
Napoleon Skywalker is a Canadian electronic music duo com-
prised of Jordie Shier and percussionist Carson Gant. As indi-
viduals, Jordie has a background in experimental arts practices,
whilst Carson has experience performing alongside multiple jazz,
pop and hip-hop artists. The two have been collaborating for
over 15 years, specialising in the performance of live, experimen-
tal dance music, and have explored both highly structured and
improvisatory approaches to their compositional practice.
For this project, the duo recorded an improvisatory piece dur-
ing an afternoon session in a rehearsal studio. Although an overall
form for this work was not planned in advance, this improvisation
served as a dedicated exploration of the augmented percussion
soundworld. Prior to this session, Jordie prepared a series of para-
metric controls to structure their exploration. Carson however,
did not have any previous experience working with augmented
percussion, and so his performance was guided solely by aesthetic
intuition.
The pair used a Dayton Audio DAEX25CT-4 transducer at-
tached to the bottom of a snare, as in figure 1c. Due to unforeseen
circumstances in the lead up to this session, the pair did not have
access to a drum trigger, and so used a Shure Beta 57A as a top-
mic for the snare. The pair used a digital delay pedal preceded
by thedrum-modal-feedbackMax patch, with a variety of this
patch’s parameters being controlled by Jordie using a MIDI con-
troller. These parameters included the amplitudes of eight modal
resonators, as well as coarse control of their modal frequencies.
Prior to this experience, the pair had already explored musical
collaboration through a number of distinct means, however this
was the first time that Jordie’s artistic improvisations had such a
direct result on both Carson’s playing and overall sound. This
unfamiliar dynamic in many ways added to their creative ex-
plorations, as they had no particular expectations of what this
collaborative dynamic would achieve.
Throughout this session, the pair created an extended groove
based improvisation which explored various melodic uses of feed-
back. Due to Jordie’s use of independent amplitude controls, the
pair were able to shape the duration and loudness of each modal
resonance with great melodic flexibility. At times however, they
found the frequency results of their modal analysis limiting, and
as a result were not able to command as broad a range of sounds
as they would have liked. This issue was particularly apparent in
the lower range frequencies, which the pair found had a natural
tendency to emphasise only the very lowest dominant mode,
and not those which were close to it. Lastly, the pair felt that
the digital delay pedal that they were using was a necessity to
maintain musical and aesthetic interest throughout their perfor-
mance, both in terms of adding additional rhythmic and textural
material.
NIME ’25, June 24–27, 2025, Canberra, Australia Lewis Wolstanholme, Jordie Shier, Rodrigo Constanzo, and Andrew McPherson
5.4 Rodrigo Constanzo
Rodrigo is a performer, improviser and researcher who often
works at the intersection between instrument design, improvisa-
tion, and chaotic soundworlds. He has been active as a performer
for nearly 30 years, having worked across a variety of musical
contexts and styles. Rodrigo specialises in improvisatory per-
formance, both as a solo artist and as a collaborator, and often
searches for new ways with which to extend upon his impro-
visatory practice with respect to both technique and technology.
For this project, Rodrigo created two recordings which emerged
from his initial explorations with thedrum-modal-feedbacksoft-
ware. The aim of this process was to discern a liminal soundworld
of his own, utilising a set of interactions that he felt paired well
with our concept. In doing so, his approach maintained that the
underlying modal feedback and resonance were the focal point of
his improvisations. These recordings were made during a single
session, after first experimenting with and preparing a performa-
tive relationship with the software. Unlike the previous recording
artists, Rodrigo both played the drum and controlled the soft-
ware himself, and so this preparation period was an integral part
to his process. As well, this was not the first time that Rodrigo
had performed with an augmented percussion instrument, hav-
ing previously used a number of transducer and feedback based
effects throughout his practice.
For these recordings, Rodrigo used an OP-Sensor and a Dayton
Audio DAEX58FP transducer that was attached to the inner body
of a 20” gong drum, as shown in figure 1b. Alongside these devices,
Rodrigo also made use of a number of other drum augmentations,
as well as variety of extended techniques whilst playing. For
his software, he used thedrum-modal-feedbackMax patch using
mainly the additive synthesiser, which he extended to satisfy
his own performative style and instrumentation. Rodrigo used
SP-Tools to perform additional onset detection and sonic analysis,
which he used to parametrise his performance. Throughout his
recording, Rodrigo also made us of a set of custom designed
Max for Live plugins8 for adding distortion, delay and stuttering
effects.
Whilst recording this work, Rodrigo noted that he had diffi-
culty getting the particular sound that he wanted with regards
to lower range modal frequencies. In many senses, this issue was
twofold, as he felt that his particular hardware setup was not able
to accurately produce some of these lower range frequencies, but
also that the acoustic instrument he was using naturally produced
an overpowering amount of lower range frequencies that masked
the subtleties of his performance. In both instances, it seems as
if our design did not quite lend itself to the acoustic sound of
the gong drum, however Rodrigo did still experiment with and
perform using the gong drum’s higher frequency modal content.
In doing so, Rodrigo used the higher range modal frequencies
to create a variety of nuanced textures that complemented his
other percussive augmentations. Throughout his performance,
however, Rodrigo also remarked that he wanted to explore more
variability amongst the envelope generator used as part of the
additive synthesiser, so as to engender a more transformative
and unfolding soundworld.
6 Reflections
After completing our four artistic explorations, we have noticed
a variety trends that have emerged in relation to our concept’s
sonic qualities and the potential of our technologies. These trends
8Confetti Plugins: https://github.com/rconstanzo/confetti
have emerged naturally through our practice, despite each of
us contributing to this project through our own distinct means
and aesthetic intentions. Each of these creative endeavours has
demonstrated to us the artistic possibilities imbued within this
soundworld, and confirm many of our initial artistic aspirations
that were present when we began exploring this concept. We
here reflect upon these findings, and whilst some of these reflec-
tions have already informed our concept design, there remains a
number of aesthetic possibilities to be developed through further
exploration.
6.1 Upon the Sonic Concept
In each of the recordings presented here, it is apparent that our
treatment of drum feedback is applicable to a wide range of sonic
styles and compositional environments. From studio composition
to live improvised performances, our approach to drum feedback
can act as both a subtle addition to the overall musical texture,
and as a focal point of compositional creativity. Of particular
interest, is that although our technological concept engenders a
wide ranging soundworld, many of these compositions exhibit a
number of sonic commonalities. Long and drawn out complex
tones are a recurring feature throughout each of the four com-
positional endeavours, with each musician choosing their own
approach to explore the various colours of these tones through
their individual use of our technology. These explorations of tim-
bral colour often encouraged their respective performers to play
into these moments, or rather leave space for these moments
to occupy their own weight within the overall compositional
form. This feature was particularly noteworthy during the Julia
Set X Barrell Jones performance, which saw the structure of this
work revolve around the unique moments of sonic variability
that arose during improvisation.
In collectively reflecting upon our activities, we discovered
that some of the more colourful and melodic moments of feedback
were readily sought after during our individual compositional
processes. It should be noted that the use of feedback that Jordie
was able to capture most accurately resembled our underlying
influence of David Torn [43] and Jeff Gregorio [13]. Due to the
way that Jordie parametrised his use of the resonant filter bank,
he was able to create an unfolding cascade of resonant pitches in
response to various drum strikes throughout his piece. This sonic
device is something that Rodrigo also sought after in his work,
which can be inferred from his critique of the envelope genera-
tor used as part of our additive synthesiser. Similarly, this sonic
quality is also something that Lewis aimed towards whilst record-
ing with Ciarán Corr - a sound which he was able to achieve
through his approach to parameter control, but was not able to
exhibit with the same degree of flexibility as Jordie. Although
it is clear that all parties aesthetically sought after this sound,
its particular quality was not discussed in detail until after all
four compositions had been completed. Similarly, when reflecting
upon many of our other background influences, any moment of
perceived melodic intricacy became a strong aesthetic reference
point for us. As such, it is one of this augmented percussion
instrument’s defining qualities - that it is capable of going be-
yond the expected percussivity of a drum, and transform it into
an instrument which occupies a plethora of musical functions
within a given aesthetic context. In highlighting our prevalent
desires towards this sound, there remains a number of aesthetic
possibilities to further explore this quality through composition
and performance.
Drum Modal Feedback: Concept Design of an Augmented Percussion Instrument NIME ’25, June 24–27, 2025, Canberra, Australia
6.2 Upon the Technological Concept
During the early stages of this project, the Julia Set X Barrell
Jones recording session acted as our initial inspiration to de-
velop our approach towards modal analysis and explore more of
the timbral nuances embedded within this concept. In reflecting
upon the later three compositions, it is clear that our approach
to analysis and synthesis enabled us to curate a more diverse
soundworld than what was possible during our initial perfor-
mance. As this functionality can be employed alongside a wide
variety of percussion instruments, its application allows for a
resultant sonic consistency which can be further relied upon in
aesthetic contexts outside of the ones we have already explored.
It is clear from both Napoleon Skywalker and Rodrigo’s experi-
ences however, that to properly feedback lower range sonorities,
further tests are needed to ascertain the appropriate hardware
and software configuration to use alongside a particular drum.
One of the exciting versatilities of our technological approach
is its applicability to both solo and collaborative performance en-
vironments, which demonstrates the ability for artists to employ
this concept alongside a variety of distinct performative relation-
ships. A consistent complaint amongst the later compositions
however, touched upon the remaining difficulties in interfacing
with our modal analysis approach. Although each creative en-
deavour interfaced with this software in a unique manner, the
response from each of these activities suggests that it is not yet
immediately intuitive to actualise particular aesthetic effects. In
a similar sense, under the pressures of a performative environ-
ment, this technology is not yet reliable enough to call upon in
moments of directed aesthetic pursuit. For example, Lewis and
Jordie took similar approaches to controlling resonances with
MIDI and DAW controllers, but the effects that they were capable
of producing can be contrasted in a number of qualitative ways,
with Lewis in particular not capable of easily achieving the par-
ticular sound qualities he imagined. Additionally, all examples
of creative exploration use a delay effect as part of their setup,
with each creative endeavour arguably relying upon this effect
for its complimentary ability to produce feedback, as well as its
functional familiarity, navigability and reliability. As a result, it
seems that to fully develop our concept, further inquiries need
to be undertaken to discover a more refined interface design for
incorporating our use of modal feedback and resonance during
practice.
7 Conclusion
The concept of an augmented percussion instrument designed
around modal resonance and feedback is one that pertains to an
intricate and varied soundworld. Through our own technological
design, as well as the designs of others, it is clear that there is a
rich sonic vocabulary attributable to this concept that is appli-
cable to wide variety of aesthetic contexts. And the many sonic
facets of this concept engender a multitude of compositional and
functional possibilities within a range of performative environ-
ments. In our own design implementations, we have curated a
dedicated approach towards these sonorities, via our develop-
ment of a hardware and software architecture specifically focused
towards a responsive and flexible incorporation of modal feed-
back. By examining this concept through the lens of creative
practice, we have also outlined some of the key features of this
sonic vocabulary, as well as pointed towards ways in which they
can be further explored within future projects, in terms of both
creative realisation and design implementation. The work pre-
sented here serves to incentivise the continued application and
interpretation of this concept, as the true form of this concep-
tual knowledge only becomes more apparent through new and
unfolding contexts.
Ethical Standards
All research carried out as part of this work was conducted by
the authors, except for select musical works which were writ-
ten in collaboration with other artists. All collaborating artists
gave express permission for their work and acknowledgement
to be included in this research, and they retain all rights to their
musical and artistic products. The technological assets explicitly
developed as part of this work were designed by the authors and
have been open-sourced accordingly.
Acknowledgments
This work is supported by the Centre for Doctoral Training in
Artificial Intelligence and Music at Queen Mary University of
London, funded by UK Research and Innovation (UKRI) under
EPSRC grant EP/S022694/1. The authors would also like to thank
their musical collaborators, whose artistry is forever a source of
inspiration.
References
[1] Chiara Bassetti. 2014. The Knowing Body-in-Action in Performing Arts:
Embodiment, Experiential Transformation, and Intersubjectivity. InArtistic
Practices: Social Interactions and Cultural Dynamics, Tasos Zembylas (Ed.).
Routledge, Abingdon, UK, 91–111.
[2] John Bowers. 2012. The Logic of Annotated Portfolios: Communicating the
Value of ‘Research Through Design’. InACM Conference on Designing Inter-
active Systems (DIS). Association for Computing Machinery, Newcastle, UK,
68–77. https://doi.org/10.1145/2317956.2317968
[3] N. Cameron Britt, Jeff Snyder, and Andrew McPherson. 2012. The EMvibe: An
Electromagnetically Actuated Vibraphone. In12th International Conference
on New Interfaces for Musical Expression (NIME). Zenodo, Ann Arbor, MI.
https://doi.org/10.5281/zenodo.1178221
[4] Alex Coles. 2005.DesignArt: On Art’s Romance with Design. Tate Publishing,
London, UK.
[5] Rodrigo Constanzo. 2020. Kaizo Snare. Blogpost. https://rodrigoconstanzo.
com/2020/08/kaizo-snare
[6] Joel de Guzman. 2023. Nu Drum Sensor? Blogpost. https://www.cycfi.com/
2023/04/nu-drum-sensor
[7] Alice Eldridge, Chris Kiefer, Dan Overholt, and Halldor Ulfarsson. 2021. Self-
Resonating Vibrotactile Feedback Instruments ||: Making, Playing, Conceptual-
ising :||. In21st International Conference on New Interfaces for Musical Expression
(NIME). Shanghai, China. https://doi.org/10.21428/92fbeb44.1f29a09e
[8] Angelo Farina. 2007. Advancements in Impulse Response Measurements by
Sine Sweeps. In122nd Convention of the Audio Engineering Society Convention.
Vienna, Austria.
[9] Angelo Farina and Lamberto Tronchin. 2000. On the “Virtual” Reconstruction
of Sound Quality of Trumpets.Acta Acustica86, 4 (2000), 737–745.
[10] Christopher Frayling. 1994. Research in Art and Design.Royal College of Art
Research Papers1, 1 (1994), 1–5.
[11] Bill Gaver and John Bowers. 2012. Annotated Portfolios.Interactions19, 4
(2012), 40–49. https://doi.org/10.1145/2212877.2212889
[12] William Gaver, Peter Gall Krogh, Andy Boucher, and David Chatting. 2022.
Emergence as a Feature of Practice-Based Design Research. InACM Conference
on Designing Interactive Systems (DIS). Association for Computing Machinery,
Melbourne, Australia, 517–526. https://doi.org/10.1145/3532106.3533524
[13] Jeff Gregorio, Peter English, and Youngmoo E. Kim. 2017. Sound and Inter-
action Design of an Augmented Drum System. In12th International Audio
Mostly Conference. Association for Computing Machinery, London, UK, 1–4.
https://doi.org/10.1145/3123514.3123521
[14] Alexander Harker and Pierre Alexandre Tremblay. 2012. The HISSTools
Impulse Response Toolbox: Convolution for the Masses. In38th International
Computer Music Conference (ICMC). Michigan Publishing, Ljubljana, Slovenia,
148–155.
[15] Kristina Höök and Jonas Löwgren. 2012. Strong Concepts: Intermediate-level
Knowledge in Interaction Design Research.ACM Transactions on Computer-
Human Interaction19, 3 (2012), 1–18. https://doi.org/10.1145/2362364.2362371
[16] Noura Howell, Audrey Desjardins, and Sarah Fox. 2021. Cracks in the Success
Narrative: Rethinking Failure in Design Research through a Retrospective
Trioethnography.ACM Transactions on Computer-Human Interaction28, 6
(2021), 1–31. https://doi.org/10.1145/3462447
NIME ’25, June 24–27, 2025, Canberra, Australia Lewis Wolstanholme, Jordie Shier, Rodrigo Constanzo, and Andrew McPherson
[17] Robert H. Jack, Adib Mehrabi, Tony Stockman, and Andrew McPherson. 2018.
Action-Sound Latency and the Perceived Quality of Digital Musical Instru-
ments.Music Perception36, 1 (2018), 109–128. https://doi.org/10.1525/mp.
2018.36.1.109
[18] Marguerite Jossic, Adrien Mamou-Mani, Baptiste Chomette, David Roze,
François Ollivier, and Christophe Josserand. 2017. Modal Active Control
of Chinese Gongs.The Journal of the Acoustical Society of America141, 6
(2017), 4567–4578. https://doi.org/10.1121/1.4985108
[19] Chris Kiefer. 2024. The Nalima: A Multistable Membrane Instrument with
Integrated Excitation. In18th International Conference on Tangible, Embedded,
and Embodied Interaction (TEI). ACM, Cork, Ireland. https://doi.org/10.1145/
3623509.3635325
[20] Michelangelo Lupone and Lorenzo Seno. 2005. Gran Cassa and the Adaptive
Instrument Feed-Drum. In3rd International Symposium on Computer Music
Modeling and Retrieval (CMMR). Springer, Pisa, Italy, 149–163. https://doi.
org/10.1007/11751069_14
[21] Thor Magnusson, Chris Kiefer, and Halldor Ulfarsson. 2022. Reflexions upon
Feedback. In22nd International Conference on New Interfaces for Musical Ex-
pression (NIME). Auckland, New Zealand. https://doi.org/10.21428/92fbeb44.
aa7de712
[22] Andrew McPherson. 2010. The Magnetic Resonator Piano: Electronic Aug-
mentation of an Acoustic Grand Piano.Journal of New Music Research39, 3
(2010), 189–202. https://doi.org/10.1080/09298211003695587
[23] Andrew McPherson and Youngmoo E Kim. 2012. The Problem of the Second
Performer: Building a Community around an Augmented Piano.Computer
Music Journal36, 4 (2012), 10–27. https://doi.org/10.1162/COMJ_a_00149
[24] Maurice Merleau-Ponty. 1964.Signs. Northwestern University Press, Evanston,
IL.
[25] Christos Michalakos. 2012. The Augmented Drum Kit: An Intuitive Approach
to Live Electronic Percussion Performance. In38th International Computer
Music Conference (ICMC). Michigan Publishing, Ljubljana, Slovenia, 257–260.
[26] Christos Michalakos. 2012. Frrriction. Album. https://cmichalakos.bandcamp.
com/album/frrriction
[27] Christos Michalakos. 2013. Trrraction. InWhat Is Sound Design...?Edinburgh,
UK.
[28] Christos Michalakos. 2016. Augmented Drum Kit: Path Finder. In16th Inter-
national Conference on New Interfaces for Musical Expression (NIME). Brisbane,
Australia.
[29] Dan Overholt, Edgar Berdahl, and Robert Hamilton. 2011. Advancements
in Actuated Musical Instruments.Organised Sound16, 2 (2011), 154–165.
https://doi.org/10.1017/S1355771811000100
[30] Tony Oxley. 1971. Ichnos. Album. https://www.discogs.com/release/659887-
Tony-Oxley-Ichnos
[31] Xenia Pestova Bennett. 2020. Atomic Legacies. Album. https://diatriberecords.
bandcamp.com/album/atomic-legacies
[32] Lucy Railton and Peter Zinovieff. 2022. Memories and Transformations. In
Spectres III: Ghosts in the Machine. Shelter Press, Paris, France, 67–74.
[33] Mark Rau, Julius O. Smith III, and Jonathan S. Abel. 2022. A Comparison
of Modal Parameter Extraction Methods When Applied to Measurements of
Stringed Instruments. In10th Convention of the European Acoustics Association
(Forum Acusticum). European Acoustics Association, Turin, Italy, 2425–2431.
https://doi.org/10.61782/fa.2023.0418
[34] David Rector and Spencer Topel. 2014. EMdrum: An Electromagnetically
Actuated Drum. In14th International Conference on New Interfaces for Musical
Expression (NIME). London, UK, 395–398.
[35] Johan Redström. 2006. Towards User Design? On the Shift from Object to
User as the Subject of Design.Design Studies27, 2 (2006), 123–139. https:
//doi.org/10.1016/j.destud.2005.06.001
[36] Edwin Reynders. 2012. System Identification Methods for (Operational) Modal
Analysis: Review and Comparison.Archives of Computational Methods in
Engineering19, 1 (2012), 51–124. https://doi.org/10.1007/s11831-012-9069-x
[37] Antoine Richard, Claus Lynge Christensen, and George Koutsouris. 2020.
Sine Sweep Optimization for Room Impulse Response Measurements. In9th
Convention of the European Acoustics Association (Forum Acusticum). European
Acoustics Association, Lyon, France, 147–154. https://doi.org/10.48465/fa.
2020.0163
[38] Matthew Rodger, Paul Stapleton, Maarten van Walstijn, Miguel Ortiz, and
Laurel S Pardue. 2020. What Makes a Good Musical Instrument? A Matter of
Processes, Ecologies and Specificities. In20th International Conference on New
Interfaces for Musical Expression (NIME). Zenodo, Birmingham, UK, 405–410.
https://doi.org/10.5281/zenodo.4813438
[39] Julius O. Smith III. 2011.Spectral Audio Signal Processing. W3K Publishing,
Stanford, CA.
[40] Karlheinz Stockhausen. 1964.Mikrophonie I. Universal Edition, Vienna,
Austria.
[41] Erik Stolterman. 2008. The Nature of Design Practice and Implications for
Interaction Design Research.International Journal of Design21, 1 (2008),
55–65.
[42] Erik Stolterman and Mikael Wiberg. 2010. Concept-Driven Interaction Design
Research.Human–Computer Interaction25, 2 (2010), 95–118. https://doi.org/
10.1080/07370020903586696
[43] David Torn. 2015. A Pre-Gig Mini-“gear Tour”.Electronic Music Magazine
(June 2015). Video Recording.
[44] Pierre Alexandre Tremblay, Gerard Roma, and Owen Green. 2021. Enabling
Programmatic Data Mining as Musicking: The Fluid Corpus Manipulation
Toolkit.Computer Music Journal45, 2 (2021), 9–23. https://doi.org/10.1162/
comj_a_00600
[45] Maarten Van Walstijn and Pedro Rebelo. 2005. The Prosthetic Conga: To-
wards an Actively Controlled Hybrid Musical Instrument. In31st International
Computer Music Conference (ICMC). Michigan Publishing, Barcelona, Spain.
[46] Simon Waters. 2013. Touching at a Distance: Resistance, Tactility, Proxemics
and the Development of a Hybrid Virtual/Physical Performance System.Con-
temporary Music Review32, 2-03 (2013), 119–134. https://doi.org/10.1080/
07494467.2013.775818
[47] Marc Wijnand, Brigitte d’Andréa-Novel, Thomas Hélie, and David Roze. 2020.
Active Control of the Axisymmetric Vibration Modes of a Tom-Tom Drum
Using a Modal-Based Observer-Regulator. In9th Convention of the European
Acoustics Association (Forum Acusticum). European Acoustics Association,
Lyon, France, 639–646. https://doi.org/10.48465/fa.2020.0439
[48] Marc Wijnand, Brigitte d’Andréa-Novel, Thomas Hélie, and David Roze. 2023.
Experimental Implementation of a Finite-Time Controller for the Axisymmet-
ric Vibration Modes of a Tom-Tom Drum. In10th Convention of the European
Acoustics Association (Forum Acusticum). European Acoustics Association,
Turin, Italy, 3635–3642. https://doi.org/10.61782/fa.2023.0602
[49] Lewis Wolstanholme and Francis Devine. 2022. terracotta. In22nd International
Conference on New Interfaces for Musical Expression (NIME). Auckland, New
Zealand. https://doi.org/10.21428/92fbeb44.7c140077
[50] Randy Worland and William Miyahira. 2019. Physics of Musical Drum Head
Damping Using Externally Applied Products. In176th Meeting of Acoustical
Society of America. Acoustical Society of America, Victoria, Canada. https:
//doi.org/10.1121/2.0001011