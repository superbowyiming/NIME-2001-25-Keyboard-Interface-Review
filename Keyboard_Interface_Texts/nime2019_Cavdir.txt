Taptop, Armtop, Blowtop: Evolving the Physical Laptop
Instrument
Doga Cavdir
CCRMA
Stanford University
660 Lomita Drive
Stanford, California 94305
cavdir@ccrma.stanford.edu
Juan Sierra
CCRMA
Stanford University
660 Lomita Drive
Stanford, California 94305
juans@ccrma.stanford.edu
Ge Wang
CCRMA
Stanford University
660 Lomita Drive
Stanford, California 94305
ge@ccrma.stanford.edu
Figure 1: The soloist and the conductor in Breeze in C.
ABSTRACT
This research represents an evolution and evaluation of the
embodied physical laptop instruments. Speciﬁcally, these
are instruments that are physical in that they use bodily in-
teraction, take advantage of the physical aﬀordances of the
laptop. They are embodied in the sense that instruments
are played in such ways where the sound is embedded to be
close to the instrument. Three distinct laptop instruments,
Taptop, Armtop, and Blowtop, are introduced in this paper.
We discuss the integrity of the design process with compos-
ing for laptop instruments and performing with them. In
this process, our aim is to blur the boundaries of the com-
poser and designer/engineer roles. How the physicality is
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’19, June 3-6, 2019, Federal University of Rio Grande do Sul,
Porto Alegre, Brazil.
achieved by leveraging musical gestures gained through tra-
ditional instrument practice is studied, as well as those in-
spired by body gestures. We aim to explore how using such
interaction methods aﬀects the communication between the
ensemble and the audience. An aesthetic-ﬁrst qualitative
evaluation of these interfaces is discussed, through works
and performances crafted speciﬁcally for these instruments
and presented in the concert setting of the laptop orches-
tra. In so doing, we reﬂect on how such physical, embodied
instrument design practices can inform a diﬀerent kind of
expressive and performance mindset.
Author Keywords
Laptop orchestra, physical laptop instrument, bodily inter-
action, design of digital musical instruments
53
1. INTRODUCTION
Design of digital musical instruments can be approached in
two ways: musicians’ exploring new possibilities in composi-
tion and performance, and engineers’ reﬁning new technolo-
gies for new interfaces, but mostly a combination of two [15].
In this work, we introduce three embodied physical laptop
instruments: Taptop, Armtop, and Blowtop, from design
process to performance. The main motivation behind these
laptop instruments lies in the exploration of the embodied
physical laptop instruments. The embodied physical laptop
instruments are physical in that they use bodily interaction,
take advantage of the physical aﬀordances of the laptop,
and oﬀer gestural expressions. They are embodied in the
sense that they are played in such ways where the sound is
embedded to be close to the instrument. Laptop orchestra
instruments pose examples of embodied instruments with
speakers in each station.
In laptop performances, the interactions between both
performer-to-performer and performer-to-audience vary sig-
niﬁcantly based on the piece. Relatedly, the presence of
laptops in an ensemble and non-obvious sound-to-gesture
mapping create surprises and unfamiliarity for listeners. For
example, instrument GUIs are rarely shared with the au-
dience. Similarly, the sound generation and manipulation
interfaces like keyboard, trackpad, or other frequently used
controllers (e.g., Gametrak [12]) lack explicit visual cues [4].
This research aims to improve the transparency of the map-
ping and the performance by designing visually communica-
tive instruments and adopting traditional ensemble settings
and roles. We include musical gestures in laptop orchestra
and more visible gesture-to-sound mapping. In the design
process, composer and designer roles are interchangeable;
the performers leverage existing software’s ﬂexibility; and
have an increased control over their instruments. Yet, dur-
ing the performance, the ensemble is crafted to present a fa-
miliar setting for the audience. For this purpose, the pieces
include a conductor, accompaniment and a solo instrumen-
talist using a combination of laptop’s built-in features.
The visual communication in the laptop orchestra perfor-
mances does not necessarily draw only from the division of
roles within the orchestra but also from our knowledge of the
instruments. An instrument’s sonic result is closely linked
to a particular way that the instrument is played within
a set of ”musical” and ”non-musical” gestures. As Godoy
identiﬁes such gestures as a motor-mimesis, they give infor-
mation allowing us to mentally imagine the sound we listen
to [7, 14]. This approach draws from the musical skills of
acoustic instrument playing and transfers them into their
digital counterparts. For example, Gotto presents a violin-
like instrument where the instrument shape is loosely based
on a violin and controlled certain granular synthesis param-
eters through violin playing techniques whereas the Bossa
uses bowing gestures as one of the main interaction meth-
ods [9, 17, 16]. Laptop accordion emphasizes the metaphor
for a traditional accordion by simulating the bellow move-
ment with the opening and closing of a laptop’s lid [11]
while the BodyHarp is played with string plucking tech-
niques along with its arm gestures [2]. The laptop instru-
ments discussed in this paper take direct inspiration from
the motor-mimetics-based approach from sound design to
crafting the physical interaction.
In this paper, we introduce the motivation behind the
embodied physical laptop instruments. It considers the aes-
thetic and technical issues relating to 1) their design and
implementation, 2) composing and crafting the bodily in-
teractions, and 3) performing with them in a laptop orches-
tra setting. We conclude with two case studies of pieces,
Breeze in C, and Harmony in the Wind.
2. RELATED WORK
This work draws from three research traditions; physical
laptop-based instrument design [6, 18, 11], embodied instru-
ment design [16, 3, 19], and dual physical interaction that
combines nuanced hand/ﬁnger gestures with larger, dance-
like gestures [2].
One of the main motivations behind three laptop instru-
ments, Taptop, Armtop, Blowtop, is creating expressive
musical instruments for computer-mediated performances
which are aﬀordable to implement. Fiebrink et al. argue
leveraging the laptop’s native capabilities while designing
instruments for group performance settings [6] as in lap-
top orchestras. In this work, built-in sensory controllers
and devices, such as microphones, cameras, accelerome-
ter, keyboards and trackpads of the ”self-contained lap-
top” are discussed to craft instruments in innovative ways.
Instruments relying on built-in components contribute to
smooth functioning. Additionally, the software ﬂexibility
oﬀers unexplored possibilities to strengthen the physical in-
teraction. Earlier examples of physical laptop instruments
can be found in the Princeton Laptop Orchestra, speciﬁ-
cally, the use of blowing gesture was presented with Breath-
alyzer in the piece called “Unplugged” [6].
The iPhone “Ocarina” [18] also focuses on the concept of
blowing into a mobile phone. “Ocarina” was designed to use
exiting features embracing the iPhone’s inherent capabilities
and limitations without hardware add-ons. These built-in
features, like the microphone for breath input, multi-touch
sensing for ﬁnger interaction, and accelerometers to map
expressive dimensions (such as vibrato rate and depth), in
addition to iPhone’s software capabilities, make possible to
support certain physical interactions. Similarly, Laptop Ac-
cordion refers to the metaphor for a traditional accordion
by simulating the bellow movement with opening and clos-
ing of a laptop’s lid and the musical button board with the
laptop keyboard [11].
As an embedded musical instrument, in the SqueezeVox
project [3], Lisa allows sound of the instrument to be pro-
jected from the instrument itself by mounting two speak-
ers inside an accordion. In Dan Trueman’s BoSSA [16], a
speaker array is implemented in the main instrument body
to ”place the sound source directly into the hands of the
performer” in addition to taking advantage of spatial diﬀu-
sion of the sound. BoSSA oﬀers a more intimate relationship
between the instrument and the performer [1]; ﬁrstly by em-
bodying the sound source in the instrument body; secondly,
by providing an instrumental presence; and ﬁnally, by re-
ceiving sonic feedback through gestural controllers (bowing
gestures with the R-Bow and the Bonge [16]).
The dual physical interaction adopted by the physical lap-
top instruments is based on a combination of ﬁne gestures,
mainly borrowed from musical gestures like ﬁnger and hand
control, and larger gestures which form the expressive and
communicative gestures in performances[2, 8]. We adopted
a similar approach to BodyHarp [2] incorporating varying
qualities of gestures into laptop playing. BodyHarp is de-
signed to introduce diﬀerent forms of gestural interaction
exchanging their roles in performance. While the nuanced
ﬁnger gestures are part of the direct sound creation, the
larger dance-like arm movements contribute to both sound
modifying and communicative gestures. This notion of the
dual physical interaction becomes essential in communica-
tion with the audience as well as with the other performers,
dancers and musicians, as in the pieceLiriope [2]. Either the
gestures are purely musical (like pressing the piano keys or
blowing gesture of a woodwind instrument), communicative
(as conductor gestures), or expressive; the physicality am-
pliﬁes both performer/instrument and performer/audience
54
Figure 2: The control interface of the Taptop for
the conductor.
relationships. Speciﬁcally, the communication between the
performers and the audience is described to be based on
a set of conventional signiﬁers and cues similar to the lan-
guage where the message is meant to be conveyed through
a set of expressions [5, 8]. The physical laptop instruments
take advantage of this design approach to present trans-
parency and visual cues in the performance as the compo-
sition allows.
3. DESIGN AND IMPLEMENTATION
The common core mechanic at the center of the embodied
physical laptop instruments (Taptops, Armtops, and Blow-
tops) is the use of native capabilities of the laptop to in-
corporate musical gestures with the existing hardware like
trackpad, keyboard, or microphone. The instruments are
designed to be interacted based on these built-in mechan-
ics in each piece. For example, in Breeze in C, instruments
are mainly combinations of trackpad and tethers, whereas,
in Harmony in the Wind, they are constructed with lap-
top’s microphone, trackpad, keyboard, and tethers. Again,
in Breeze in C, the conductor’s Taptop is designed to be
played with the laptop trackpad by dividing it into grids
and mapping to distinct instruments in the ensemble (Fig-
ure 2). Following subsections describe each instrument’s
design, implementation, and performance processes.
3.1 Taptop
Taptop instruments in both pieces are played by orchestra
members, conductor and as a part of the soloist’s instru-
ment. The main interaction mechanism of Taptops is built
on the ability of the trackpad to track multitouch gestures.
The capacitive grids in the trackpad allow detecting mul-
tiple ﬁnger touches [10]. It reports each ﬁnger’s touch po-
sition, timestamp, X and Y velocity, ﬁnger blob size, and
the angle of ﬁnger ellipsoid [13]. The information from the
trackpad is detected by the Python’s multitouch library,
PyMT Library, and transmitted via OSC [23]. The data
distributed via OSC again is mapped to the corresponding
sound parameters in FaucK [21].
The sound of Taptops played by four musicians in this
piece is produced by a combination of FM synthesis, a sinu-
soidal oscillator, and a pulsetrain generator. Instruments’
timber is modiﬁed by changing the corner resonance fre-
quency of the Moog Voltage Controlled Filter (VCF). The
ﬁlter is implemented using Faust’s eﬀects library, the vir-
tual analog ﬁlter eﬀect (Figure 3). The role of the track-
pad interface was again diﬀerent in the conductor’s station
(Figure 2) than accompanying musicians’. It was divided
according to the musicians in the ensemble to have direct
control over their sound levels and timing. Musician’s pitch
selection or timbre of sound is only controlled by them-
selves independent of the conductor. This provided a par-
ticular relationship between the ensemble and the conduc-
tor in which the performer deﬁnes what to play but the
conductor decides when it is played. By achieving uncon-
ventionally roles between the musicians and conductor, we
aim to blur boundaries within the traditional roles in an
ensemble. Hence, the trackpad in this piece serves not just
as an interface to produce and modify the sound, but it also
functions as a visualization of the interaction and a vehicle
for communication for performers and the conductor.
Although the size of the trackpad limits the types of in-
teraction, it oﬀers a reliable, expressive interface for per-
formers and ﬂexible coding for designers. In both pieces,
the trackpad is used by dividing it into grids while aiming
diﬀerent gestural interactions and sonic results. For exam-
ple, in Breeze in C, each musician changes the timbre of the
instrument by modifying the ﬁlter quality factor and cut-
oﬀ frequency sliding and pinching gestures on the trackpad.
Furthermore, Taptops include a level control slider on the
right side of the trackpad separated by the ﬁlter control grid.
This way, players could level their loudness with respect to
the neighboring performers. Diﬀerent from those played by
orchestra members, the conductor’s Taptop serves as a tool
to guide the orchestra. It allows the conductor to control
and visualize orchestra members’ performance and sound
levels (Figure 2).
Taptops are the main instruments for the ensemble mem-
bers in both pieces in addition to their use as a comple-
mentary instrument coupled with other gestural interaction
methods, like arm gestures in the Armtop (as the Soloist
plays in Breeze in C see Figure 4) or blowing gestures of
the Blowtops.
Figure 3: The Faust diagram for the Taptop in-
strument’s sound design. For the ﬁltering object,
Faust’s moog VCF ﬁlter is used.
3.2 Armtop
Armtops are integrated with tethers and trackpads. The
trackpad use is inspired by Taptop instruments, and mod-
iﬁed according to the musician’s need. In the soloist’s in-
strument, Armtop incorporates ﬁnger tapping on the track-
pad as sound generating gestures with arm swings as ac-
companying gestures (gestures that contribute to the sound
modiﬁcation rather than direct sound generation [8]). The
dual physical interaction inspired by BodyHarp’s expressive
movements [2] forms the main design consideration in Arm-
tops. It appears as a combination of ﬁne sound-producing
gestures (creating the melodic line on the trackpad) and
sound-facilitating and communicative gestures (modifying
the dynamics and expressive features with the arm swings)
(Figure 4) [8].
55
Figure 4: The Soloist in Breeze in C.
Soloist plays the melodic line on the trackpad as part of
her main instrument. Because the trackpad does not oﬀer
visual feedback, a simpliﬁed interface is printed on the ter-
minal following and visualizing the ﬁnger location on the
trackpad (Figure 5). The lower part visualizes the ﬁnger
location on the trackpad and how close it is to the next
note. Each grid is assigned to a pitch value. This setting
can be customized by the designer. The upper-left part de-
picts where the tether is with respect to its resting location;
hence, it gives a visual cue about how much vibrato and
tremolo applied. The upper-right part shows the gain level
controlled by the height of the tether. This interface was
only for performer’s use and it was only shared with the au-
dience after the performance. The expressive features like
vibrato and tremolo are played by stretching and extending
the tether forward. Soloist is also able to control the level
of her instrument independent of the conductor by control-
ling the length of the tether. Consequently, adding vibrato
by arm extensions puts emphasis on played notes by slight
volume increase. Merging expressive features and dynamics
control on the same interaction mechanism helps the soloist
to develop an unconventional gestural vocabulary.
The sound synthesis for soloist’s Armtop uses a combi-
nation of a triangle and a sinusoidal generators with both
tremolo and vibrato capabilities. The sound synthesis is
followed by a cubic distortion. The distortion is applied to
enrich the harmonic spectrum of the Armtop which is later
tamed by a ﬁlter based on the Moog Voltage Controlled
Filter (VCF). Diﬀerent than Taptops, ﬁlter parameters are
kept ﬁxed, vibrato and tremolo are available for the soloist.
The conductor in Harmony in the Windwears Gametrak
tethers on his hands to conduct the tempo and instrument
gain levels. The tempo is controlled by the conductor’s hand
gestures with the tether. The downward and upward motion
triggers the quantization and transmits periodic pulses via
OSC. Any changes in the tempo detected by the tether are
smoothly reached over a short period of time. Apart from
leveraging the network communication to augment the de-
gree of control, the conductor performed other traditional
conducting roles such as changing the dynamics, cueing, and
unifying performers. Similar to soloist’s Armtop in Breeze
in C, the use of the Gametrak tether both provides auto-
mated control; furthermore, it operates as a visual commu-
nication tool for performer and the audience. Still, some of
these messages are only delivered through conducting ges-
tures which is discussed in the following section in more
detail.
3.3 Blowtop
In Blowtop instruments from Harmony in the Wind, the
main mechanism is based on signal detection on the laptop
microphone. The breath pressure is picked up by the micro-
phone and followed by an amplitude follower. The detected
level is used to amplify the synthesized ﬂute sound. The in-
strument is also sensitive to the tilt motion using the Sudden
Motion Sensor (SMS). This sensing mechanism is normally
used to protect hard drives by the motion-detecting hard-
ware in the form of a triaxial accelerometer that can detect
movement in three axes or directions. The amount of up
and down motion data is mapped to the tremolo and vi-
brato parameters via SMS inputted as an Human Interface
Device (HID) in ChucK [20]. Hence, the combination of
two sensing systems requires the performers to blow into
the laptop microphone which is on the upper left corner of
the control panel and select the pitch using the trackpad
and the keyboard simultaneously (Figure 6). The location
of the microphone forces the performers to play their lap-
tops in an orientation such that it resembles a traverse ﬂute
playing.
The lower part of the trackpad is assigned to 3 chords
for easiness of playing in tilted position. The set of three
chords are selected using the “\”, “enter/return”, and “right
shift” keys (Figure 6). Those control keys are selected since
the right hand can still interact with them easily while sup-
porting the laptop. In this piece, the orchestra members
play the Blowtops with this mapping whereas the Blowtop
soloist uses a mapping with the trackpad divided into nine
tones to play the melodic line. Three keys on the right side
of the keyboard are devoted to octave selection.
Figure 5: The interface of the soloist’s instrument
in Breeze in C.
The design of Taptops, Armtop, and Blowtops focuses on
the sound quality and gestural interaction with the exist-
ing traditional instruments. Soloist’s Armtop is designed
to sound like a cello playing expressive features, like vi-
brato and tremolo, with the accompanying gestures such
as arm swings and extensions. In Blowtops, we adopt the
main playing mechanism of a ﬂute including holding posi-
tion, eﬀective gestures of blowing into the instrument and
the accompanying gestures of tilting the instrument up and
down. On the other hand, in Taptops, the sound is the pri-
mary focus which uses the metaphor of a string instrument
extending the techniques with the touchpad.
56
Figure 6: The interface of the Blowtop is provided
as a part of the score. The performers blow into
the microphone while they select the pitch from the
trackpad. The octave range is adjusted using the
keys labeled.
4. AESTHETIC EV ALUATION
As Dahl emphasized how complexity increases when com-
posing music for a laptop ensemble, the tasks of composi-
tion and instrument design interlace into a single one [4].
The composer/designer is required to compose not only the
pieces but also the instruments, interactions, and perfor-
mance. The fact that composers and designers are required
to work simultaneously in multiple tasks blurs boundaries
between the roles of the orchestra members during the de-
sign process. This quality is used as the primary principle in
both of the compositions, Breeze in Cand Harmony in the
Wind. The pieces are supported with the several gestural
cues for enhanced transparency for each instrument. Audi-
tory and visual cues from the physical interaction and well-
deﬁned roles of the ensemble members helps the audience,
as well as the performers, enjoy the musical performance
and the technology. It draws better transparency without
worrying about the details of the mapping behind the in-
struments as reported by the audience members. Thus, we
felt that the most honest way to evaluate these instruments
is a music-ﬁrst, aesthetic evaluation. In other words, can we
make music with it, and communicate this to an audience
in the performance? As such, we wrote music speciﬁcally
for these instruments and performed them in public laptop
orchestra concerts.
In Breeze in C, the dual physical interaction, the nuanced
interaction of the ﬁnger on the laptop trackpad and large-
gestural interaction as arm swings or conducting gestures,
shows itself in the Armtop performance the most. From
soloist’s perspective playing the Armtop, the performer’s
expressive intentions begin with the ﬁnger-based trackpad
interactions, and are then ampliﬁed using large arm-based
gestures, aﬀording a nuanced control over pitch, and pre-
cise expressive control over each note. From the audience
perspective, the virtue of the Armtop is that it visually am-
pliﬁes the musical gesture, expanding from the limited size
and visual context of a laptop. The instrument is designed
to be seen. Nothing is hidden, the focus is on the physical
gestures and their correspondence with the sound. This, in
a sense, reclaims a kind of physical aesthetic that is often
diﬃcult to communicate in laptop performance (including
laptop orchestra).
Again in the same piece, Taptops emphasize the notion of
embodied performance. Taptop’s control of the ﬁnger po-
sition on the trackpad allows each musician to modify the
sound quality of her instrument. Because laptop orches-
tras are performed with sound sources in each station, the
overall soundscape is kept balanced by the conductor. Sim-
ilarly, the individual timbral changes in musicians’ instru-
ments both enrich the harmony and perform well with the
nuanced ﬁnger interaction. What we observed is that the
balance between individualized instruments and conductor-
led performance reﬂected to the audience appreciation of
the musical interaction. The communication goes beyond
the performer and audience but also addresses a kind of
performer-to-performer communication. It emphasizes how
the performer relates to her instrument. Is the instrument
an object to be played? Or, is it a natural extension of
the body, and thereby, an extension of how the performer
thinks?
In Harmony in the Wind, the ﬁne gestural interaction
with the Blowtops is satisﬁed by leveraging previously ob-
tained instrumental skills. The microphone senses breath
above a certain threshold and parameters are modiﬁed by
the direct microphone input tracked by an envelope follower.
The dependence of the sound generation on continuous vari-
ables of the breath poses some challenges for the performer
such as practice, time commitment, and certain skill levels.
Such requirements are not necessarily part of the DMI or
laptop instrument learning process when musicians usually
expect to achieve a certain level in short periods [22]. Al-
though Blowtops seem to have a steeper learning curve, af-
ter suﬃcient practice, the musicians can adopt prior musical
skills easily. The timbral correspondence of the laptop in-
struments with their acoustic counterparts further enhances
the intimacy between the instrument and the performer. As
a result, it advances the learning progress. A similar, yet
relatively less demanding requirement can be observed in
Taptops in Harmony in the Wind. Taptop players pick a
bar long rhythm and play it for the next four bars. The
rhythms are variations of a simple arpeggiation (Figure 7).
When each percussionist simultaneously plays a diﬀerent
variation with Taptops, it creates a more complex and richer
rhythmic section. It also allows each member to improvise
in these sections. The musicians performing with Taptops
as the percussion instruments take advantage of the prior
experience of the piano playing techniques.
Figure 7: The score for section B for the Taptop
instruments. In section B, percussion players pick
a bar long rhythm and improvise within the set of
rhythms as provided in the score.
In both performances, all members are given the oppor-
tunity to engage in the musical output. The balance in the
participation of each member is made possible by the na-
ture of the composition; although there is a written score
for the pieces, it is intended to aid the performance and
to provide room for improvisation. The ﬁrst piece, Breeze
in C, is fully improvised within three sections. Similarly,
in Harmony in the Wind, each orchestra member is given
chances to improvise and have direct control over the sound
quality of their instruments. The presence of a conductor in
both pieces directing the musical ﬂow is only required due to
the design constraints, such as skill level, interaction, visual
communication, and available rehearsal time. The division
57
between the roles or the presence of the conductor does not
pose a hierarchical organization, instead, it is intended to
provide visual communication available to performers and
the audience. The presence of the conductor also does not
divide the interlaced roles between designer, composer, and
performer.
5. CONCLUSIONS
In this paper, the evolution and evaluation of the embodied
physical laptop instruments are presented through two case
study pieces. We focus on the physicality of the interaction
methods such that performers can leverage their existing
knowledge of musical gestures gained through years of tradi-
tional instrument practice. Our eﬀorts make use of the core
components of the laptop to oﬀer ﬂexibility and expressive
control to the composers/designers. We describe the de-
sign, implementation, and composition process as a whole.
A music-ﬁrst aesthetic evaluation of these interfaces is pre-
sented, through works and performances crafted speciﬁcally
for these instruments. We believe that this approach am-
plifying physicality and transparency can help to create an
intimate performer/instrument and performer/audience re-
lationships as well as it can oﬀer physical aesthetics that is
often diﬃcult to communicate in laptop performances.
6. LINKS
Performance with laptop instruments in Breeze in C can
be viewed here: https://youtu.be/6S80_X23dOc, and in
Harmony in the Wind, here: https://youtu.be/qqCg971_
s_E.
7. REFERENCES
[1] C. Bahn, T. Hahn, and D. Trueman. Physicality and
feedback: A focus on the body in the performance of
electronic music. In ICMC, 2001.
[2] D. Cavdir, R. Michon, and G. Wang. The BodyHarp:
Designing the intersection between the instrument
and the body. In Proc. of the 15th International
Conference on Sound and Music Computing (SMC,
2018), Limassol, Cyprus, 2018.
[3] P. R. Cook. Real-time performance controllers for
synthesized singing. In NIME, 2005.
[4] L. Dahl. Wicked problems and design considerations
in composing for laptop orchestra. In Proceedings of
the 162h international conference on New interfaces
for musical expression (NIME’12), 2012.
[5] C. Dobrian and D. Koppelman. The ’e’ in nime:
Musical expression with new computer interfaces. In
Proceedings of the 2006 Conference on New Interfaces
for Musical Expression, NIME ’06, pages 277–282,
Paris, France, France, 2006. IRCAM &#8212; Centre
Pompidou.
[6] R. Fiebrink, G. Wang, and P. R. Cook. Don’t forget
the laptop: using native input capabilities for
expressive musical control. In Proceedings of the 7th
international conference on New interfaces for
musical expression, pages 164–167. ACM, 2007.
[7] R. I. Godøy. Motor-mimetic music cognition.
Leonardo, 36(4):317–319, 2003.
[8] R. I. Godøy and M. Leman. Musical gestures: Sound,
movement, and meaning. Routledge, 2010.
[9] S. Goto. The aesthetics and technological aspects of
virtual musical instruments: The case of the
superpolm midi violin. Leonardo Music Journal, pages
115–120, 1999.
[10] A. Inc. Apple - macbook pro - technical speciﬁcations
of the 13-inch.
[11] A. Meacham, S. Kannan, and G. Wang. The laptop
accordion. In Proceedings of the International
Conference on New Interfaces for Musical Expression,
volume 16, pages 236–40, 2016.
[12] E. Myers. Gametrak. In2Games, 2000.
[13] K. Schlei. Relationship-based instrument mapping of
multi-point data streams using a trackpad interface.
In NIME, pages 136–139, 2010.
[14] D. Trueman. Why a laptop orchestra? Org. Sound,
12(2):171–179, Aug. 2007.
[15] D. Trueman. Digital instrument building and the
laptop orchestra. In US Frontiers of Engineering
Symposium. Armonk, 2010.
[16] D. Trueman and P. Cook. Bossa: The deconstructed
violin reconstructed. Journal of New Music Research,
29(2):121–130, 2000.
[17] M. M. Wanderley and P. Depalle. Gestural control of
sound synthesis. Proceedings of the IEEE,
92(4):632–644, 2004.
[18] G. Wang. Ocarina: Designing the iphone’s magic
ﬂute. Computer Music Journal, 38(2):8–21, 2014.
[19] G. Wang, N. J. Bryan, J. Oh, and R. Hamilton.
Stanford laptop orchestra (slork). In ICMC, 2009.
[20] G. Wang, P. R. Cook, et al. Chuck: A concurrent,
on-the-ﬂy, audio programming language. In ICMC,
2003.
[21] G. Wang and R. Michon. Fauck!! hybridizing the
faust and chuck audio programming languages. In
Proceedings of the 16th international conference on
New interfaces for musical expression (NIME’16),
2016.
[22] D. Wessel and M. Wright. 2001: Problems and
prospects for intimate musical control of computers.
In A NIME Reader, pages 15–27. Springer, 2017.
[23] M. Wright, A. Freed, and A. Momeni. Opensound
control: State of the art 2003. In Proceedings of the
2003 conference on New interfaces for musical
expression, pages 153–160. National University of
Singapore, 2003.
58