CyberSong 
Paulo Maria Rodrigues 
Departamento de Comunicação e Arte 
University of Aveiro  
Companhia de Música Teatral 
Campus de Santiago 
3810-193 Aveiro PORTUGAL 
+351 234 300 200 
pmrodrig@ca.ua.pt 
Luis Miguel Girão 
Artshare  
Investigação, Tecnologia e Arte, lda. 
Rua Agostinho Pinheiro, 19 2D 
3800-095 Aveiro PORTUGAL 
+351 234 427 809 
artshare@sapo.pt 
Rolf Gehlhaar 
School of Art and Design 
Coventry University  
Coventry School of Art & Design 
Priory St. Coventry CV1 5FB 
+44 247 688 8543 
r.gehlhaar@coventry.ac.uk 
 
 
ABSTRACT 
We present our work in the development of an interface for an 
actor/singer and its use in performing. Our work combines aspects 
of theatrical music with technology. Our interface has allowed the 
development of a new vocabulary for musical and theatrical 
expression and the possibility for merging classical and 
experimental music. It gave rise to a strong, strange, 
unpredictable, yet coherent, “ character”  and opens up the 
possibility for a full performance that will explore aspects of 
voice, theatrical music and, in the future, image projection.  
Keywords 
Theatrical music, computer interaction, voice, gestural control. 
1. INTRODUCTION 
 CyberSong is a collaborative piece of theatrical music created by 
Paulo Maria Rodrigues, Luís Girão and Rolf Gehlhaar. It is a 
structured improvisation that develops from a personal journey of 
discovery on the potential of the interaction between a performer 
and a computer. At the root of the performance lies the traditional 
“ classical”  singer’s clothing, the tails, which has been transformed 
to host a set of electronic controllers that communicate with a 
computer. CyberSong explores the challenges of meeting 
“ classical”  music (the sound utterance, the theatrical context) with 
new technologies (which causes the redefinition of the role of the 
performer/interpreter/composer). CyberSong involves a 
singer/actor that processes his own musical discourse in real-time. 
There is a set of “ sound objects”  and “ theatrical actions”  
(including the musical/theatrical treatment of scientific/artistic 
relevant texts) that serve as departing points for a dialogue 
between the performer with his memories (instant or long-term) 
and the gesture that results from the electronic manipulation of the 
sounds. In this paper we examine: 1) how the idea of developing a 
new instrument for musical expression allowed us to establish a 
dialogue between artists with very different backgrounds, 2) how 
the technical and performing possibilities of a simple idea gave 
rise to a coherent performance in musical and theatrical terms, 3) 
how this has changed or enlarged the usual range of tools for 
musical and theatrical expression by a performer from a 
classical/operatic background 4) how other people have perceived 
the performance. 
 
2. BACKGROUND 
The CyberSong project has its roots in the individual research and 
performance experience of its creators. Since 1970 Rolf Gehlhaar 
has been experimenting with both mechanical and electronic 
technology towards the development of new sound sources for the 
making of music. Most of them were quite simple; a few of them 
have matured and became musical instruments. One of these was 
‘superstring’, [1}. Gehlhaar performed with it many times, solo, 
accompanied by electronic sounds on tape or with others in an 
ensemble (Feedback Studio Ensemble, 1970-76). Most 
importantly, however, was that its sound was clearly very 
attractive to the ‘average’ listener, particularly to the musically 
untrained. The first thing people would say after a performance 
was always, “ Can I have a go?”  This fact inspired Gehlhaar to 
devise a musical installation with it –  a public improvisation room 
- in the Folkwang Museum in Essen, Germany in 1972. [2}  
The second set of ‘instruments’ Gehlhaar devised was for his 
personal use, within his compositions or to play in the Feedback 
Ensemble: They were called “ Nail Gongs” , [3], [4].  
In another different area, that of electronics and interactive music, 
Gehlhaar’s work led to the creation of SOUND=SPACE, an 
interactive musical environment that was used in installations, in 
creative play and therapeutic workshops, in dance or as virtual 
instrument for musicians. The general idea is that an Ultrasonic 
Ranging System using echo-location, surveys an empty space and 
measures very precisely the positions and movements of any 
persons or objects. These measurements are then employed by a 
computer to generate MIDI commands that control sound 
synthesizers. A full description of SOUND=SPACE is available at 
[5] and it has been a reference for many other researchers work in 
the field of interactive music. Recently, the work of 
SOUND=SPACE evolved into HEAD-SPACE, a MAX/MASP 
instrument for a disabled musician. [6] 
Another root of CyberSong comes from the work of Paulo 
Rodrigues and Luís Girão. In the first case, after many 
experiences as a classical/operatic singer, his work started to be 
developed more into the direction of creating new pieces of 
theatrical music [7]. In recent times, the collaboration of Girão 
and Rodrigues led to the inclusion of interactive multimedia in 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, or republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
Nime’05, May 26-28, , 2005, Vancouver, BC, Canada. 
Copyright remains with the author(s). 
 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
164
theatrical music projects, such as Bach2Cage, where very simple 
interactive tools were developed in order to integrate both sound 
and image manipulation in real-time performance [8].  
The emergence of a regular academic and artistic collaboration 
between the three led to the idea of developing an interactive 
garment that a performer could use in his performance. The idea 
was inspired by recent developments in wearable computing. The 
purpose was not, however, the development of a highly 
sophisticated instrument, but to create a simple and versatile tool 
that could allow the emergence of theatrical/musical “ character” , 
in other words, a “ performing being”  that would connect the cyber 
world with the classical music world.  
 
3. TECHNICAL ASPECTS 
3.1 Interface: the CyberTails 
A microphone is used to capture the singer/actor’s voice and to 
pass it to a computer where it is stored and processed. The 
performer has access to the commands of the computer program 
via sets of electronic circuits implanted in a coat (classical music 
“ tails” ). Buttons and sliders allow the performer to trigger or 
change continuously electrical current (5V). This information is 
processed by a programmable microprocessor (STAMP 2) and 
sent as MIDI information to a MAX/MSP patch in a computer 
(Fig 1) 
Fig 1. General scheme of the elements of the CyberTails 
A circuit with eight buttons allows the control of functions related 
with recording and playing audio in real-time. These functions 
are: start audio (switches on the audio output of the entire 
program), stop audio (the opposite), record on (activates the 
recording of the sound into a buffer of fixed size), record off 
(deactivates the record on), play (plays the contents of the buffer), 
clear (erases the content of the buffer), loop on (loops the contents 
of the buffer), loop off (stops the looping). A circuit with two 
faders controls the length and direction of the loop playing. A 
circuit with three faders controls two effects, feedback and delay 
and the dry/wet mix (Fig.2). 
 
 
Fig.2 Detail of set of controls. 
3.2 Max/MSP Programming 
The arquitcture of the Max/MSP program developed for the 
CyberTails is divided in two types of data. The first one is MIDI 
data, incoming from de PARALAX micro-processor STAMP2, 
that as been programmed to receive and convert analog current 
variation into digital serial communication. The second one is 
audio data. The program relates this two kinds of information and 
outputs processed sound as a result. 
The MIDI data is composed by start/stop messages coming from 
the buttons, and value variation messages (0-127) coming from the 
sliders. Three of them are used to control parameters of the 
sampling process: start/stop recording and erase. This process is 
based on a 2000 miliseconds buffer. The playing process has 7 
parameters, also controlled by the incoming MIDI data: play, stop, 
loop on and loop off as start/stop control, and loop length, loop 
start and loop direction/rate as value variation control. There is 
also the  possibility to record and recall an audio file with the 
buffer content, but this operation is not controlled by the singer. 
After this recording and playing process comes a process chain 
composed by two effects: LFO and reverberation. The LFO effect 
has feedback, delay and dry/wet balance parameters controled by 
incoming MIDI messages, and modulation rate and depth, and 
panning rate parameters controlled directly in the patch. The 
reverberation module as reverberation time and dry/wet balance 
controled by incoming MIDI messages and early reflections time 
and high frequency rolloff, controlled directly in the patch. 
A memory section composed by presets allows to record and recall 
values to all parameters. This section is associated to a MIDI on/off 
button that allows to recall these memories. The MIDI control has 
to be turned off in order to recall the memories, otherwise the 
program assumes the incoming MIDI values. 
STAMP2 
MIDI 
AUDIO  
MAX/MSP 
STOP 
RECORD OFF 
CLEAR 
LOOP OFF 
START 
RECORD ON 
PLAY 
LOOP ON 
LOOP LENGHT LOOP 
SPEED  
FX MIX DELAY 
FEEDBACK 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
165
All the parameters controlled by the singer can also be controlled 
by the second performer, due to the fact that all incoming MIDI 
messages are gated, i.e, the second performer can select to activate 
or deactivate each parameter control of the singer. 
4. PERFORMANCE 
Since late 2003 CyberSong has been presented in several 
circumstances: it has been part of a recital for voice and piano 
which followed the traditional/classical model, it has been 
presented in contemporary music concerts (in the line of classical 
tradition) and in experimental music performances (Fig. 3).  
 
 
Fig.3 Aspects of a performance of CyberSong 
In Discussion we will analyze these different situations and the 
peculiarities of CyberSong in these contexts. Although 
CyberSong has a strong improvisational component, we have used 
also some recurrent elements, both musical and theatrical. Some 
of them have been notated and that is what we mean by “ score” , a 
quite loose indication of sound and theatrical actions that we 
experimented and found particularly effective.   
4.1 The musical and theatrical content of 
CyberSong 
The “ score”  of CyberSong includes a set of possible “ sound 
objects”  that can be arranged by any order decided by the 
performer. It also includes a set of theatrical/sound actions. The 
idea of CyberSong is to provide an environment or a 
musical/theatrical “ instrument” . It is up to the performers to 
develop further their own “ vocabulary”  and to establish a 
“ syntax” .  
Possible (effective) “ sound objects”  include: encounters between 
consonants and vowels, sustained tones that explore microtonal 
harmony, melismae, and glissandi, rhythmic patterns built on the 
repetition of simple phonemes, combinations of voice utterances 
that involve aspects of the classically trained singer (a fully 
supported sound or a rich falsetto) with others that are far from 
that kind of sound/voice “ vocabulary”  (for example singing 
inwards, or fine details of unvoiced sounds of the vocal tract, that 
are possible to use due to the microphone), (Fig.4). 
Possible “ theatrical actions”  include: reading of a text (game like 
construction, and deconstruction of phrases using words stored in 
the “ buffer” ), sound production from daily activities (for example 
washing the teeth, laughing, crying or playing with sound toys). 
 
 
 
 
 
 
 
Fig.4 Aspects of the “ score”  of CyberSong. 
 
4.2 The role of the singer/actor in the 
manipulation of the electronic circuits in the 
CyberTails 
The singer/actor produces his own “ sound objects”  that can be 
stored in the computer. The idea is to create constantly new 
“ sound objects” , that arise from the combination of new events, 
with other events that have been previously stored in the 
computer, and triggered by “ play”  or “ loop on” . It is important to 
observe moments in which there is just the sound of the real voice 
or just the sound of the voice stored in the computer.  
4.3 The role of the second performer  
The second performer has direct access (in the Max “ patch” ) to 
the same parameters that the singer/actor controls, plus a sub-
patch that controls reverberation. Initially this was, too, part of the 
CyberTails, but experience showed us that this was something 
quite difficult to control and that the number of different actions 
to be performed, by the singer/actor, should be kept within his 
possibilities. The second performer has a very important role and 
the piece is truly a dialogue between both performers. It may be 
necessary, however, to agree upon specific parameters that just 
one of them will control, or plan specific moments of non-
dialogue.  
4.4 The structure and duration of the piece 
It is open: there are no restrictions. Our presentations, so far, have 
been around 10-12 min. The content and structure has had many 
forms: the theatrical actions, the objects used, the texts 
(Schopenhauer, Dawkins or a sentence in a newspaper or heard on 
the street). We have been always looking for contrast and a sense 
of balance between sound densities, types of “ sound objects” , 
theatrical actions and silence (both musical and visual). We have 
also worked on a general sense of direction, mainly within partial 
sections rather than on the all. This sense of direction is frequently 
the consequence of using “ evolutive”  processes as the basis for 
structuring the sound material. 
 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
166
5. DISCUSSION 
Another important fact of CyberSong is that allowed the singer 
(Paulo Rodrigues) to expand his notions of performance, as a 
whole. Coming from a classical/operatic background, CyberSong 
allowed a totally new approach to voice production, yet using also 
“ classical”  resources, and also “ character”  development. The 
“ character”  emerged not from text or drama but as a consequence 
of dealing with the new situations made possible by the interface. 
The reaction of audiences to a performance of CyberSong has 
been one of the most interesting aspects of the project. It seems to 
divide people. Some really enjoy the strangeness of the entire 
situation; some others find it difficult to accept. This has been the 
case regardless of the performing environment concerned. Some 
people extrapolate the pure musical and theatrical aspects and 
produced interpretations of what they see and listen, some others 
don’t do that exercise in imagination. The following are the 
impressions of Rui Eduardo Paes, one the main portuguese 
writers, critics and journalists specialized in experimental music, 
[9], [10], [11]. “ CyberSong, by Luís Miguel Girão, Paulo Maria 
Rodrigues and Rolf Gehlhaar, establishes a continuum between 
the cybernetic man of our time, with its extensive electronic tools, 
and the classical tradition of music and theater expression –  the 
singer/actor in tails. But not in a linear, pacific way, as it happens 
with all the other continuums that connect some contemporary 
arts to history and its paradigms, in a dependent way. CyberSong 
ironises the cybernetic condition, ironises the academic 
conventions (the singing in opera, for instance) and ironises the 
connection between the two worlds. It’s not a post-modernist 
perspective of the “ classical”  artist situation in an era very much 
defined by its technology and by scientific themes, but a mocking 
vision of that same post-modernist perspective. CyberSong is a 
critical work, but done with a smile. It’s an accusation, but with a 
good, very subtle, humor. A kind of soft protest song that doesn’t 
name it’s subject, letting the listener take his own conclusions, 
very differently from the militant music of the last century’s 
sixties and seventies. 
That’s why I consider this work not as a product of the classical 
music establishment, even if Rodrigues and Gehlhaar are both 
academics, but as the result of an experimental point of view. The 
word is tricky in what regards the arts, because even some 
experimental artists speak about the tendency of this kind of 
approach not to be definitive in its proposals (read: not enough 
serious), but the truth is that the great innovations in music in the 
last century happened in this experimental front, which is now the 
place for radical creativity when all the avantgardes seem to have 
collapsed. Not very strangely, the experimentalist practices have 
popular origin, even if they also have a strong intellectual support. 
The reason is simple: the conservatoires and universities aren’t 
usually very open to the new ways of doing and conceiving, 
because their purpose is to reproduce knowledge, not to create it. 
Of course, the exceptions are numerous, and you have here the 
proof, but they only confirm the rule. Even if Luís Miguel Girão 
had a classical education, he’s also a non-idiomatic and jazz 
improviser, with the flute, his first instrument. The fact that he’s 
not only a computer musician is very important to mention, 
because it implies the same distance to electronic composition and 
playing that these three artists have with their subjects. 
You need distance to observe this way the cybernetic order of 
things, the classical dictums and the particulars of music creation, 
and Rodrigues, Girão and Gehlhaar have that capacity of looking 
(listening) from outside while being inside. That’s not very 
common in the electro-acoustic music field, the Portuguese one 
included, with all its necessity to show academic status. The most 
interesting electronic music now made in Portugal comes from 
experimentalists, people with rock, dance or even non-music 
backgrounds (visual arts namely, from painting to design through 
cinema), people that in some cases don’t even know how to read a 
score. CyberSong was presented in February 2005 in a festival, 
Palavras Desencarnadas II, organized by an association of 
experimental sound and audiovisual artists, Granular, that wants 
to promote experimentalism, precisely, has a modus operandi, and 
the fact is that this piece found the best place to be heard, seen 
and understood. Maybe the language was a bit different, but the 
posture was the same...”  
New directions of CyberSong will lead to a full cycle of 
cybernetic theatrical songs and also to the inclusion of other 
resources, such as image projection controlled in the same manner 
as sound is at the moment, [12]. 
6. REFERENCES 
[1] Gehlhaar, R., Superstring, In Feedback Papers, 2, Feedback 
Studio Verlag, Cologne, 1971. 
[2] Gehlhaar, R., Superstring Raum Museum Folkwang, In 
Feedback Papers, 3, Feedback Studio Verlag, Cologne, 
1972. 
[3] Gehlhaar, R., SPEKTRA: for 4 trumpets and 4 trombones 
and nail gongs, Feedback Studio Verlag, Cologne, 1974. 
[4] Gehlhaar, R.,  Step by Step…  music for ears in motion: real-
time computer generated 3-dimensional sounds 
accompanied by 4 instruments, Feedback Studio Verlag, 
Cologne, 1981 
[5] Gehlhaar, R., SOUND=SPACE, In Contemporary Music 
Review, Harwood Academic Publishers, vol.6, 1, pp. 59-72, 
1992. 
[6] Gehlhaar, R., HEAD=SPACE, Feedback Studio Verlag, 
Cologne, 2000. 
[7] Companhia de Música Teatral, http://www.musicateatral.com 
[8] Rodrigues, P., Vairinhos, M., Girão, L., Figueiredo, A., 
Ferreira, D., Gomes, V., Dias, N., Integrating Interactive 
Multimedia in Theatrical Music: the case of Bach2Cage, In 
forthcoming Proceedings of ARTECH 2005, V.N. Cerveira, 
2005. 
[9] Paes, R., http://rep.no.sapo.pt 
[10] Paes, R., A orelha perdida de Van Gogh, Hugin-Editores, 
Lda., Lisboa, 1998 
[11] Paes, R., Phonomaton, Hugin-Editores, Lda., Lisboa, 2001. 
[12] Rodrigues, P., Girão, L., Gehlhaar, R., 
http://www.cyberlieder.com 
 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
167