All Y ou Need Is LOD : Levels of Detail in Visual
Augmentations for the Audience
Olivier Capra
CRIStAL, CNRS,
University of Lille, France
olivier.capra@univ-lille.fr
Florent Berthaut
CRIStAL, CNRS,
University of Lille, France
ﬂorent.berthaut@univ-lille.fr
Laurent Grisoni
CRIStAL, CNRS,
University of Lille, France
laurent.grisoni@univ-lille.fr
ABSTRACT
Because they break the physical link between gestures and
sound, Digital Musical Instruments oﬀer countless opportu-
nities for musical expression. For the same reason however,
they may hinder the audience experience, making the mu-
sician contribution and expressiveness diﬃcult to perceive.
In order to cope with this issue without altering the instru-
ments, researchers and artists have designed techniques to
augment their performances with additional information,
through audio, haptic or visual modalities. These tech-
niques have however only been designed to oﬀer a ﬁxed level
of information, without taking into account the variety of
spectators expertise and preferences. In this paper, we in-
vestigate the design, implementation and eﬀect on audience
experience of visual augmentations with controllable level
of detail (LOD). We conduct a controlled experiment with
18 participants, including novices and experts. Our results
show contrasts in the impact of LOD on experience and
comprehension for experts and novices, and highlight the
diversity of usage of visual augmentations by spectators.
Author Keywords
audience experience, augmented reality, visual augmenta-
tions, level of detail
CCS Concepts
•Applied computing → Performing arts; Sound and
music computing; •Human-centered computing →
Laboratory experiments; Mixed / augmented reality;
1. INTRODUCTION
Audience experience has become an important aspect in
the creation of Digital Musical Instruments (DMIs), either
as an evaluation method [2] or as a dimension which should
be addressed at the design or performance stages [18]. In
fact, DMIs may degrade the audience experience in perfor-
mances, compared to acoustic instruments. Because they
break the physical link between gestures and sound, they
degrade the attributed agency, i.e. the perceived level of
control of the musician [6].
Furthermore, their diversity and complexity makes it dif-
ﬁcult for the audience to build a familiarity with every in-
strument. As an attempt to compensate for these issues
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’20, July 21-25, 2020, Royal Birmingham Conservatoire,
Birmingham City University , Birmingham, United Kingdom.
L0 NONE
 L1 SENS
L2 PROC
 L3 SENS PROC
L4 MAPPINGS
 L5 FULL COMBINED
L6 FULL GRAPH
Figure 1: The 7 global levels of detail (LODs) used
in our experiment, as seen by the participants. Each
is built as a combination oflocal LODs for the In-
terface, Mappings and Processes sections (details in
2.2 and 2.3).
and restore the audience experience, artists and researchers
alike have designed techniques which augment the instru-
ments with additional information. While these techniques
explore diﬀerent modalities (visual, haptic, auditory) and
address diﬀerent aspects of the performance (technical, ges-
tural, intentional), they oﬀer the same ﬁxed level of infor-
mation to all spectators.
However, augmenting the audience experience implies con-
sidering spectators from an individual perspective. The in-
formation needed by each spectator can diﬀer depending
on their personal sensitivity and expertise. In order to en-
sure an optimal experience for spectators, we propose to
allow the audience to dynamically change this level of in-
formation using visual augmentations with variable levels
of detail (LODs).
1All stimuli, illustration videos of the conditions,
anonymised raw results, statistical analyses and implemen-
tation demos can be found here :http://o0c.eu/0NA
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
67
1.1 Augmenting the audience experience
A number of augmentation techniques for spectator experi-
ence have been designed. Perhaps the simplest is the organ-
isation of pre-concert demonstrations, such as described by
Bin et al. [8]. More common is the use of visual projections
that represent the instrument structure and parameters or
musician’s gestures. Examples can be found in many elec-
tronic performances, with accompanying visuals displaying
changes in sound processes as abstract or ﬁgurative ele-
ments. Perrotin et al. have proposed to display the musical
controls of musicians in an orchestra with a video projection,
to help the audience perceive the actions of each orchestra
member [17] by representing both gestures and musical pa-
rameters. Similarly, Correia et al. discuss the role of visu-
als in live performances [11] and insist on the importance
of showing both the gestures (interface) and parameters to
the audience. Berthaut et al. [7] describe an augmented re-
ality which can be used to reveal the mechanisms of DMIs.
Haptic augmentations can also be created to increase the
audience’s engagement, as proposed by Turchet et al. [19].
All these augmentation techniques however only oﬀer the
audience ﬁxed levels of detail.
Benford et al. [5] combine projected visual augmentations
during the performance and visual/textual augmentations
on a mobile app after the performance, which allow specta-
tors to access two levels of detail. Capra et al. [9] propose
adaptive augmentations as part of a pipeline for augmented
familiarity, but they do not provide an implementation or
evaluate the impact of the described levels.
Contrary to these, in this paper we describe the design
and evaluation of visual augmentations with controllable
levels of detail, which allow the audience to choose the
amount of information they want.
1.2 Level of detail
The level of detail (LOD) approach originates from the ﬁeld
of computer graphics where it is used to adapt 3D models
and scenes complexity in order to reduce rendering load. It
can also be found in the ﬁeld of information visualisation
to adapt quantity of information in order to limit visual
overload. In the HCI literature, LODs allow users to access
diﬀerent levels of complexity in the interface, such as with
Zoomable User Interfaces [3], or in a musical context to
build and manipulate complex musical structures [1].
In our case, LODs allow spectators to adapt the amount
and the type of information provided by visual augmenta-
tions about the interactions of a musician with a DMI.
1.3 Contribution
In this paper, we describe the design and implementation
of visual augmentations of Digital Musical Instruments for
the audience with dynamic and controllable levels of de-
tail. Through a controlled experiment based on a protocol
proposed in [10], we study the eﬀect of LODs on the audi-
ence experience, and investigate how they would be used in
performance settings1.
2. DESIGN AND IMPLEMENT A TION
In this section, we describe the design and implementation
of visual augmentations with controllable levels of detail for
Digital Musical Instruments (DMIs).
2.1 Visual augmentations
Throughout this paper, we use the termvisual augmenta-
tions to describe graphical representations of the controls
and mechanisms of a DMI, which are superimposed on the
physical performance with the help of an augmented reality
display. The purpose of visual augmentations is to reveal
aspects of DMIs that are not easily perceived by the au-
dience due to their lack of familiarity with them and the
absence of physical link between gesture and sound. This
includes subtle and/or hidden gestures sensed by the inter-
face, complex or unusual mappings between the gestures
and the various controllable parameters and the dynamic
behaviour, potential range of output and internal structure
of a DMI. Following what Berthaut et al. proposed [7], our
visual augmentations represent the three main sections of
the instrument : 1) the physicalinterface composed of sen-
sors (e.g. a MIDI control surface); 2) the mappings, i.e. the
connections between sensors and musical parameters (e.g.
the ﬁrst fader controls the volume of the ﬁrst audio track);
3) theprocesses (e.g. tracks, loops, patterns) that generate
the sound.
An important aspect of visual augmentations is that they
do not restrain the design of DMIs. Instrument designers
and musicians are free to choose their interfaces, mappings
and processes with expressiveness in mind, without worry-
ing about the transparency [12] of the musicians’ actions or
the familiarity [13] of the audience with the instrument.
However, the potential complexity of DMIs implies that
visual augmentations may become too detailed if one aims
at representing all their events and components, which might
in turn degrade the spectator experience that we are try-
ing to improve [16]. Spectators might also prefer more or
less detailed information for aesthetic reasons and at various
times in the performance.
To that extent, we propose to deﬁne dedicated levels of
detail for each section (Interface, Processes, Mappings) of
the visual augmentations. Theselocal LODs can be chosen
independently or combined as global LODs such as the ones
we describe in section 2.3.
2.2 Local LODs
The augmentations speciﬁcally designed for a section of the
instrument are calledlocal LODs. We propose 4 levels of
detail for the Interface section, 3 levels for the Mappings sec-
tion, and 5 levels for the Processes section1. Each local LOD
features a level 0 in which the section is not augmented. If
all three sections are at level 0, no information is added
to the performance. One should note that the information
provided by each level can be displayed in diﬀerent ways,
the representations proposed in our implementation are only
one of the many possibilities that artists can explore.
In the Interface section , Level 1 only indicates the
global activity, e.g. when the musician performs a gesture
sensed by the system. Level 2 represents the activity of
each sensor of the physical interface, allowing one to per-
ceive fast and complex gestures such as bi-manual or multi-
ﬁnger interactions. Level 3 describes both the activity and
the type of each sensor (discrete/continuous, shape of sen-
sor ...). Level 4 adds a representation of their values and
range.
In the Mappings section level 1 only describes to which
processes the sensors are connected. Level 2 reﬁnes the con-
nection to the parameter level. Level 3 adds a representa-
tion of the operation or series of operations which transform
sensor values into parameters values [12], e.g. scaling, in-
verting, combining and so on.
In the Processes section , Level 1 visualises the out-
put of the system as a whole, merging the activity of all
sound processes. Level 2 provides a detailed activity for
each process of the system, e.g. a distinct shape whose size
indicates the volume of the corresponding sound process.
Level 3 adds a dynamic representation of parameters (i.e.
inputs) that can be controlled on the processes. Level 4
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
68
a b c
Figure 2: Possible implementations 1 of visual augmentations with LODs : a) Shared close-up with V ideo AR
projected behind the musician and artist deﬁned LOD, b) Mobil e AR with individual LOD control, c) Spatial AR
with an optical combiner shared between all spectators and m obile control to vote for the LOD.
adds parameters names, types and values range, i.e. as per-
formers would see them when performing with a GUI. Level
5 provides a detailed representation of the complete internal
graph of audio synthesis and eﬀects that generate the sound
of each process. It corresponds to what the musician would
access when designing their instrument, and is potentially
similar to the mental model they have when performing.
2.3 Global LODs
Global LODsare a combination of local LODs. They pro-
vide the spectators with a convenient way to control the
level of detail by modifying several sections at a time : In-
terface (I), Mappings (M) and Processes (P). For instance,
”SENSORS (I4-M0-PO)”is a global LODcalled ” SENSORS”
and uses Level 4 for the Interface section and Level 0 for
the others.
In the following study, we use 7 global LODs with in-
creasing quantity of information (See Figure 1).
NONE (I0-M0-P0) provides no information at all. The
performance remains unchanged.
SENSORS (I4-M0-PO) ampliﬁes the gestures performed
by displaying representations of the types and values for
all sensors of the interface. It is therefore similar to the
level of details provided by Turchet and Bartet [19] with
haptics, and Perrotin et al. [17] for visuals. In the case of
our study, faders, knobs and buttons of a MIDI controller
are displayed.
PROC (I0-M0-P2) displays the sound processes of the
instrument as separate shapes with graphical parameters
associated to extracted audio features (loudness with size,
pitch with color hue, brightness with color luminance), al-
lowing spectators to identify the broad structure of the in-
strument and the activity of processes. This LOD corre-
sponds to the representations traditionally used to illustrate
electronic music performances (e.g VJiing) and deﬁned as
audiovisual entities by Correia et al. [11].
SENS
PROC (I4-M0-P2) shows both ampliﬁed gestures
and the activity of separate processes. It provides informa-
tion on both the interface and processes of the instrument,
without detailing its internal structure or behaviour.
MAPPINGS (I4-M1-P2) adds information pertaining to
how sensors are mapped to the sound processes. It shows
when a sensed gesture has an eﬀect on a sound process but
not what eﬀect it has, i.e. not what is exactly controlled by
each sensor. In our implementation, mappings are displayed
as lines between sensors and processes, which appear when
a control is performed and then fade out. It is similar to the
level of information proposed in the Rouages project [7].
FULL
COMBINED (I4-M2-P3) reﬁnes both the Map-
pings and Processes sections. It shows which parameter
are controlled by each sensor and displays both the param-
eters and activity of the processes. In our implementation,
each process is represented by a composite shape with an
outer ring displaying the input parameters (i.e. gain with
size, ﬁlter cutoﬀ with color luminance, position in sample
with rotation, delay feedback with shape repetition, pitch
with color hue), while the activity is shown by an inner
graphical element. This level is similar to the augmenta-
tions described by Berthaut et al. [6].
FULL
GRAPH (I4-M2-P5) provides a complete overview
of the instrument with parameters names and value range,
processes names and mappings between each sensor and the
parameters. It corresponds to the mental model musicians
might have of their instrument, with the exact structure,
mappings and range of sonic possibilities. In our implemen-
tation, each process is labelled and displayed as a group of
graphical sliders and buttons representing each parameter,
with their names, value and range of values, and another
slider serves as a VU-meter. Although thisglobal LOD uses
the maximum of each local LODs, we chose to limit the Map-
pings section to level M2 so that the amount of information
remains reasonable. Similarly, the structure of the instru-
ment used in our study is essentially a stack of samplers
and eﬀects with one parameter each, so that level P5 adds
very little information compared to level P4. This structure
was chosen in order to reduce the gap in quantity of infor-
mation from the previousglobal LOD, i.e. we do not add a
complex audio graph in addition to the details on param-
eters when going fromFULL
COMB to FULL GRAPH.
FULL GRAPH can be seen as similar to approaches where
the full complexity of the instrument is shown such as in
live-coding performances.
2.4 Implementation
The implementation of visual augmentations with control-
lable LODs raises questions regarding how to retrieve the
information from the instrument and how to give the audi-
ence access to the LODs. In this paper the visual augmen-
tations were implemented using the Godot game engine.
The information, including activity and mappings, was re-
trieved in real time from the instrument, implemented with
Pure Data, via OpenSoundControl messages. This extrac-
tion might however be more diﬃcult with less open software,
in which case only the lower LODs might be accessible, i.e.
interface and processes activity but not the internal map-
pings. We envision multiple possibilities for implementing
visual augmentations with LODs in a performance setting.
A ﬁrst one relies on individual views of the augmenta-
tions, in order to allow each spectator to choose their LOD
freely. This can be implemented with a mixed-reality head-
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
69
set or a mobile device as shown in Figure 2.b.
To avoid forcing the audience to wear or hold devices
which may impair their experience, another possibility is
to use a single spatial AR display, either projection map-
ping or an optical combiner (e.g. Pepper’s ghost display),
such as depicted in Figure 2.c, in which case viewers all per-
ceive the augmentations spatially aligned with the physical
instrument. Another possibility is to ﬁlm and reproject a
close-up view of the interface integrating the augmentations,
as shown in Figure 2.a. This solution however moves the
focus away from the physical performer. In these scenarios,
only one LOD can be displayed at a time. LOD control may
be performed by musicians or accompanying visual artists,
so that they can modulate the audience experience during
the performance. But the shared LOD can also be chosen
by spectators. Voting system such as the one used in the
Open Symphony project [20] may be used, in the form of
a web interface accessible from their mobile devices, as de-
picted in Figure 2.c. In this case the displayed LOD reﬂects
either the majority or the average vote.
Finally, an intermediary solution is to provide multiple
views of the augmentations for groups of spectators, using
video (i.e. multiple or multiscopic screens) or optical AR
(mirrors at multiple angles). For each group, the LOD can
be ﬁxed at a diﬀerent value, so that spectators can move
towards or look at the display they prefer. A voting system
may also be setup separately for each group.
3. USAGE AND EFFECTS OF LODS
In this section, we present an experiment that aims at eval-
uating the impact of LODs on audience experience and un-
derstanding, and studying the use of controllable LODs by
spectators with diﬀerent expertise. In order to retrieve ac-
curate and individual data on spectator experience we chose
to conduct a controlled experiment in the lab. We discuss
the advantages and limitations of such ’in the lab’ studies
in more details in [10] and plan to address social and envi-
ronmental aspects of public performances in a future work.
3.1 Procedure
18 participants (16 M, 2 F) took part in the experiment,
aged of mean 29 (± 7. 3 , min=20, max=43). Before the
beginning of the experiment, they were presented with the
details of the experiment and signed a consent form. Par-
ticipants sat in front of a 24” screen, equipped with head-
phones and a Pupil-labs Core eye-tracking device (the de-
tails of the eye tracking are addressed in a forthcoming
study). We measured their expertise with the instrument
presented in the study using questions regarding their prac-
tice of DMIs, their use of graphical user interfaces similar
to the one in Figure 1 and their use of control surfaces. We
also asked how often they attended electronic music per-
formances. This allowed us to compute an expertise score,
and we used it to separate them into two groups : 9 ex-
perts and 9 novices. The experts had a music practice of
17.3± 6. 4 years and an electronic music practice of 10.7 ± 7. 3
years against 1.6 ± 2. 6 of music practice and no electronic
music practice for the novices. Experts had all used both
graphical interfaces for music and control surfaces such as
the ones presented in the experiment. Per year, experts
claimed going to 12.8± 8. 3 electronic music performances,
while for novices the average was 0.6 ± 1. 5.
3.1.1 Dynamic stimuli
The stimuli were videos of short performances with a DMI
composed of a Korg NanoKontrol controlling a set of Pure
Data patches with three sound processes (melodic, rhythm,
granular texture) each with multiple parameters (See Figure
1). We designed 3 sets of mappings between the interface
sensors (knobs, faders, buttons) and the parameters. Each
set was intended to target a diﬀerent level of contribution
of the musician, i.e how much of the changes in the sound
are due to them vs automated. The ﬁrst set is completely
manual so no changes happen without a gesture. It cor-
responds to the maximum contribution level. The second
features automations for half the parameters, the rest being
manipulated by the musician. In the third set of mappings,
most parameters are automated and the musician is able to
take control of some of them temporarily, giving the highest
contribution to the computer.
In order to play the videos with dynamic overlapping
visual augmentations, we designed the experiment in the
Godot game engine. Videos were played synchronised with
the playback of control data recorded in Pure Data, so that
the sound and the visual augmentations were generated dy-
namically during the playback. This technical setup gave us
the ﬂexibility to play the video footage of a performance and
to accompany it with arbitrary audio processes and visual
augmentations in real time. The experiment lasted around
45mn and was composed of 2 blocks.
3.1.2 Block 1 : ﬁxed LODs
In the ﬁrst block, participants watched 7 LODs x 3 contri-
bution levels = 21 videos of short performances (20s). Each
video was followed by a questionnaire of 9 order-randomized
questions to evaluate their experience and comprehension.
The survey included only one objective question. We eval-
uated the ability of the participants to correctly detect the
contribution levels that we induced by the mappings by an-
swering the question ” Who from the musician or the com-
puter contributed the most to the performance ?” . They
also could choose ’both equally’.
The other questions were subjective and were based on 5
communication design issues introduced by Bellotti et al [4]
and transposed to the spectator perspective by Gurevitch
and Fyans [13]. We complement them withAssociation
that targets the capacity to expose to spectators the contri-
butions of the user (musician) and the system (DMI) [10].
These design challenges are well adapted to the evaluation
of NIMEs as they allow for an assessment by components
of the subjective experience of spectators. Participants an-
swered on 7-step scales to the question” To which extent do
you agree with the following statement ?”. Only the extreme
values of the scales had a label : ” I totally disagree” and ” I
totally agree” .
•” In this video, I know when the musician is interacting
with the instrument and when he is not.” (Address)
• ” In this video, I can see when the instrument is responding
to the musician gesture and when it is not.” (Attention)
• ” In this video, I can see if the musician is controlling the
instrument or if he is not.” (Action)
• ” In this video, I can see when the instrument is properly
functioning and when it is not.” (Alignment)
• ” In this video, I can see if the musician or the instrument
made a mistake.” (Accident)
• ” In this video, I can see the contribution of the musician
and the one of the computer.” (Association)
Finally, the participants had to report their personal rating
of the performer’s virtuosity and the overall performance on
a 7-point scale.
3.1.3 Block 2 : dynamic LODs
In the second block, participants could change with the
scroll wheel the LOD of the augmentations as the video
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
70
NONE SENS PROC SENS
PROC
FULL
GRAPH
FULL
COMB
MAPP NONE SENS PROC SENS
PROC
FULL
GRAPH
FULL
COMB
MAPP
4
3
2
1
0
EXPERTS
PERCEIVED 
CONTRIBUTION
SCORES
BLOCK 1 BLOCK 2
NOVICES
0
25
0
25
N
COMPREHENSION 
SCORE BY LOD
EXPERIENCE SCORE
BY LOD
S P SP M FG FC
Experts
Novices
C ONTRIBUTION
OBJECTIVE  TASK
SUBJECTIVE  TASKS
A DDRESS
A LIGNMENT
V IRTUOSITY
A TTENTION
A CCIDENT
A CTION
A SSOCIATION
E XPERIENCE
NOVICES
EXPERTS
Figure 3: Left Regardless of the LOD, Experts perceived a higher contribut ion of the musician than Novices.
Center LODs did not impact equally the subjective perception of the interactions. Experts reported higher
evaluations of the subjective dimensions of the spectator ex perience. Right When participants could choose
their favourite LODs in real time, strategies emerged as illu strated. They were reﬁned in the interviews.
was playing. In a ﬁrst task, they watched 3 short (60s) per-
formances and were asked to select the LOD that gave them
the best experience, i.e. that they preferred. In a second
task, they watched the same performances and were asked
instead to choose the LOD that allowed them to understand
best what the musician was doing.
3.2 Results
Data was recorded, anonymised and stored in real time dur-
ing the experiment by a bespoke experiment software de-
veloped in the Godot game engine. Subjective reports were
obtained via likert scales and were analysed with parametric
tools when the normality assumptions were met. The analy-
ses were conducted under the common frequentist paradigm
and were combined to Bayesian statistics [15]. A Bayes fac-
tor is reported asBF01 when data better support the null
hypothesis and as BF10 when data support the alternative
hypothesis (note that ’01’ becomes ’10’). For example, the
statementBF10 = 2 . 4 means that the data are 2.4 times
more likely to occur under a model including the corre-
sponding eﬀect. The posterior odds have been corrected for
multiple testing by ﬁxing to 0.5 the prior probability that
the null hypothesis holds across all comparisons. Analyses
were performed with SPSS v25, R studio 1.2 and JASP [14].
3.2.1 Block 1 : ﬁxed LODs
Analysis did not revealed any group eﬀect and any eﬀect of
the levels of detail (LODs) on the objective task. Overall,
the evaluation of the factual contribution ratio between the
musician and the computer proved diﬃcult.
Still, from a subjective perspective, an interesting group
eﬀect ( χ 2 = 12 , p = 0 . 002, BF 10 = 11) showed that Experts
considered the musician contributed more than the com-
puter in 62% of the stimuli compared to 45.5% for Novices
(Figure 3- Left).
As depicted in Figure 3 - Center, experts reported higher
evaluations of the subjective questions. Regardless of the
group, theAccident was the least rated, meaning that par-
ticipants were not so conﬁdent in their capacity to detect er-
rors. The eﬀect of the LOD was revealed on most of the sub-
jective questions (all p − values < 0. 027, all BF 10 > 6), with
the exception of Accident and Virtuosity ( all p − values >
0. 22, all BF 01 > 4). Two LODs were particularly eﬀec-
tive, SENS and FULL
COMB. Reading the graph (3 - Cen-
ter) from left to right, compared to NONE, the control
condition, SENS, the level of detail exposing the sole sen-
sors activity, presents a signiﬁcant boost in all dimensions,
thenPROC exposes an equivalent score to NONE. From
SENS
PROC to FULL COMB a rather linear progression
is observed. In the Experts group, the progression tends
to extend toFULL
GRAPH. In a much more volatile dis-
tribution, the results for the Novices group nevertheless
presentFULL
COMB as the most eﬀective. The eﬃciency
of FULL COMB for Novices is also supported by an analy-
sis of the diﬀerence with the Experts’ scores. For 6 (out of
9) dimensions, the smallest diﬀerence is measured when vi-
sual augmentations are presented withFULL
COMB. This
result is a good illustration of the expected role of visual
augmentations, compensate the lack of expertise of novices
for a better experience.
3.2.2 Block 2 : dynamic LODs
The score for these tasks was calculated by accumulating the
time participants spent using each LOD. Both tasks, experi-
ence and comprehension, show comparable evolution char-
acterised by a minimum for the control conditionNONE
and a maximum for the higher LODs (Figure 3, Right).
A decisive eﬀect of LODs was found (F(6,90) = 9 . 94, p <
. 001, BF 10 > 10000) but with no diﬀerence between the
groups ( BF01 = 4). Novices favoured FULL
COMB and
SENS for experience and FULL GRAPH for comprehen-
sion. Experts chose the highest LODs for experience and
FULL
COMB and FULL GRAPH for comprehension.
3.3 Discussion
LODs aﬀect subjective comprehension. The inter-
views conﬁrmed and extended the quantitative analyses.
Despite the absence of eﬀect of LODs on factual perception,
participants favoured levelsFULL
GRAPH and SENSORS
for understanding the performance, especially when the mu-
sic got more complex with many fast changes in the sound.
This suggests that LODs inﬂuence the subjective compre-
hension of spectators, even if their factual understanding is
not improved. It also suggests that amplifying the gestures
(SENSORS level) might be more informative than display-
ing the activity of processes alone ( PROC level).
The role of expertise . Our study reveals interesting in-
sights on the nature of expertise in DMI spectators. Results
of Block 1 showed that experts perceive an higher contri-
bution of the musician when novices perceive a higher con-
tribution of the computer. Also, experts put more trust in
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
71
their personal representation of the interactions as proven
by their higher evaluation of the Bellotti-Fyans challenges.
This contrast is conﬁrmed in Block 2 where only novices
favoured theSENSORS LOD over no augmentations for
a better comprehension and experience (Fig. 3 - Right),
as if experts already had an internal representation of the
interactions with the sensors and therefore did not need
that LOD. Apart fromSENSORS, both experts and novices
mostly utilised FULL
COMB when they could choose their
favourite LOD. But when they had to choose a LOD in order
to better understand the interactions, experts equally used
FULL
COMB and FULL GRAPH when novices massively
favoured FULL GRAPH. As both groups scored poorly in
the objective task in Block 1, whatever the LOD, these pref-
erences in LOD are to be taken as subjective beliefs in a
facilitation of understanding rather than a factual help.
Errors and virtuosity . The absence of eﬀect of LODs
on both the Accident dimension (i.e. the feeling of being
able to perceive a potential error) and the virtuosity rat-
ings underlines the crucial role of error perception in the
emergence of a judgement of virtuosity [13]. A solution to
this issue could be inspired by music video games where the
virtuosity is materialised by screen indications of combos
of successful moves. Such informative contents are eﬃcient
and spectacular but imply the restriction of any improvi-
sation or non-expected techniques. Another solution would
be to design LODs that inform on the virtuosity, such as
visualisations of input complexity or extra-ordinary values
for controls and musical parameters.
LOD choice strategies Strong diﬀerences in the choice
of favoured LODs at the individual level were revealed by
the data and reﬁned by the interviews. When analysing
the answers of participants regarding how they would use
the LODs in public performance, we can distinguish 3 clear
strategies:all or (almost) nothing: 4 participants
claimed they would alternate between the maximum LOD
(or just start with it) in order to form a mental image of how
the instrument works (i.e. its capabilities) and then go back
to no augmentations or to theSENSORS level, in order to
focus on the musician’s gestures. adapting to complexity
/ performance: 4 participants claimed they would use
LODs as a way to adapt to the complexity of the instrument
or music, or change it depending on the musician playing;
progression:2 participants mentioned that their appre-
ciation of LODs evolved over time, the more complex ones
becoming more enjoyable and accessible, so that they would
end up not going back to the lower LODs. One must note
than even within these strategies there are interpersonal
variations, again highlighting the utility of a controllable
LOD on visual augmentations.
4. CONCLUSION
In this paper, we investigated the design of levels of detail
(LODs) in visual augmentations and their eﬀect on the au-
dience experience. While our results provide useful insights,
we believe the controlled experiment approach that we took
could be combined with in the wild study of performances.
As future work, we think that augmentations with LODs
should be extended to other interfaces, e.g. gestural con-
trollers or graphical interfaces such as live-coding, and that
the eﬀect of aesthetic choices should be investigated.
5. REFERENCES
[1] J. Barbosa, F. Calegario, V. Teichrieb, G. Ramalho,
and G. Cabral. Illusio: A drawing-based digital music
instrument. In Proceedings of NIME, 2013.
[2] J. Barbosa, F. Calegario, V. Teichrieb, G. Ramalho,
and P. McGlynn. Considering audience’s view towards
an evaluation methodology for digital musical
instruments. InNIME, 2012.
[3] B. B. Bederson and J. D. Hollan. Pad++: a zooming
graphical interface for exploring alternate interface
physics. InProceedings ACM UIST, 1994.
[4] V. Bellotti, M. Back, W. K. Edwards, R. E. Grinter,
A. Henderson, and C. Lopes. Making sense of sensing
systems: ﬁve questions for designers and researchers.
InProceedings of ACM CHI, 2002.
[5] S. Benford, C. Greenhalgh, A. Hazzard,
A. Chamberlain, M. Kallionp ¨a¨a, D. M. Weigl, K. R.
Page, and M. Lin. Designing the audience journey
through repeated experiences. InProceedings of ACM
CHI, 2018.
[6] F. Berthaut, D. Coyle, J. W. Moore, and H. Limerick.
Liveness through the lens of agency and causality. In
Proceedings of NIME, 2015.
[7] F. Berthaut, M. Marshall, S. Subramanian, and
M. Hachet. Rouages: Revealing the mechanisms of
digital musical instruments to the audience. In
Proceedings of NIME, 2013.
[8] S. Bin, A. McPherson, N. Bryan-Kinns, et al. Skip
the pre-concert demo: How technical familiarity and
musical style aﬀect audience response. InProceedings
of NIME, 2016.
[9] O. Capra, F. Berthaut, and L. Grisoni. Toward
augmented familiarity of the audience with digital
musical instruments. InProceedings of CMMR, 2017.
[10] O. Capra, F. Berthaut, and L. Grisoni. Have a seat on
stage : Restoring trust with spectator experience
augmentation techniques. InProceedings of ACM
DIS, 2020.
[11] N. N. Correia, D. Castro, and A. Tanaka. The role of
live visuals in audience understanding of electronic
music performances. InProceedings of Audio Mostly,
2017.
[12] S. Fels, A. Gadd, and A. Mulder. Mapping
transparency through metaphor: towards more
expressive musical instruments.Organised Sound,
7(2):109–126, 2002.
[13] M. Gurevich and A. C. Fyans. Digital musical
interactions: Performer–system relationships and
their perception by spectators.Organised Sound,
16(2):166–175, 2011.
[14] JASP Team. JASP[Computer software], 2019.
[15] M. Kay, G. L. Nelson, and E. B. Hekler.
Researcher-centered design of statistics: Why
bayesian statistics better ﬁt the culture and incentives
of hci. InProceedings of ACM CHI, 2016.
[16] M. Leman et al. Embodied music cognition and
mediation technology. MIT press, 2008.
[17] O. Perrotin and C. d’Alessandro. Visualizing gestures
in the control of a digital musical instrument. In
Proceedings of NIME, 2014.
[18] W. A. Schloss. Using contemporary technology in live
performance: The dilemma of the performer. Journal
of New Music Research, 32(3), 2003.
[19] L. Turchet and M. Barthet. Haptiﬁcation of
performer’s control gestures in live electronic music
performance. InProceedings of Audio Mostly, 2019.
[20] Y. Wu, L. Zhang, N. Bryan-Kinns, and M. Barthet.
Open symphony: Creative participation for audiences
of live music performances.IEEE MultiMedia, 2017.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
72