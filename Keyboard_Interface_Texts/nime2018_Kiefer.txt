Towards New Modes of Collective Musical Expression
through Audio Augmented Reality
Chris Kiefer
Experimental Music Technologies Lab
Department of Music
University of Sussex, Brighton, UK
c.kiefer@sussex.ac.uk
Cécile Chevalier
Experimental Music Technologies Lab
Department of Media and Film
University of Sussex, Brighton, UK
c.chevalier@sussex.ac.uk
ABSTRACT
We investigate how audio augmented reality can engender
new collective modes of musical expression in the context
of a sound art installation, Listening Mirrors, exploring the
creation of interactive sound environments for musicians
and non-musicians alike. Listening Mirrors is designed
to incorporate physical objects and computational systems
for altering the acoustic environment, to enhance collec-
tive listening and challenge traditional musician-instrument
performance. At a formative stage in exploring audio AR
technology, we conducted an audience experience study in-
vestigating questions around the potential of audio AR in
creating sound installation environments for collective mu-
sical expression.
We collected interview evidence about the participants’
experience and analysed the data with using a grounded
theory approach. The results demonstrated that the tech-
nology has the potential to create immersive spaces where
an audience can feel safe to experiment musically, and showed
how AR can intervene in sound perception to instrumen-
talise an environment. The results also revealed caveats
about the use of audio AR, mainly centred on social inhibi-
tion and seamlessness of experience, and ﬁnding a balance
between mediated worlds to create space for interplay be-
tween the two.
Author Keywords
augmented reality, sound art installation, collective musical
expression, mobile music making
CCS Concepts
•Applied computing →Media arts; •Human-centered
computing →User studies; Mixed / augmented re-
ality;
1. AUGMENTED REALITY INSTRUMENTS
Designers of new musical instruments typically focus on ma-
terial interfaces, mappings, and sound generators to create
new modes of musical expression. A further way to inter-
vene in the process of music making is to directly alter the
player’s perception of an instrument through digital aug-
mentation of the senses. We deﬁne audio augmented reality
as realtime computational mediation of sound perception,
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’18,June 3-6, 2018, Blacksburg, Virginia, USA.
mixing live digitally processed sound with real environmen-
tal sound, and investigate how this can engender new modes
of musical expression. This investigation forms part of an
ongoing sound art installation project, exploring the cre-
ation of environments for collective musical expression in-
corporating augmented reality (AR), for musicians and non-
musicians alike.
In the last few years there has been a resurgence of inter-
est in AR with the introduction of widely accessible new in-
terfaces (e.g. mobile phones, Microsoft Hololens [19], hear-
ables) and new applications [15]. Azuma’s [2] original dis-
cussion of AR took a multisensory perspective (e.g. visual,
audio, haptic), although artists and technologists have pri-
marily explored this medium in the visual domain [1] by
layering graphics over realtime environments, as found for
example in Shaw’s early work [10]. Within NIME, research
that deﬁnes itself as AR has primarily been focused on vi-
sual augmentations for technology-assisted learning [12, 9].
There has also been extensive work on augmenting the sense
of touch (e.g. [17, 11]), which could inform future AR ap-
plications.
A key development in the ﬁeld of audio AR has been apps
such as RJDJ [5], which use mobile phones with connected
headphones as a platform to reprocess the sound environ-
ment, creating new listening experiences. We use similar
technology to RJDJ to examine the aesthetics of collective
musical expression at the intersections between collective
mobile instruments (e.g. [16]), sound art installations and
audio AR.
At the core of this research we question how can au-
dio augmented reality enable collective musical expression?
Consequently leading us to ask: how does musical experi-
ence become collective within a sound art installation envi-
ronment? How are diﬀerent communication channels used?
We examine these questions in an audience experience
study. This study took place at a formative time in the
development of our installation, as a way of exploring the
sound art aesthetics of AR and the contribution they will
make to the ﬁnal design.
2. DESIGN TOW ARDS INSTRUMENTNESS
The sound art installation is designed as a composed acous-
tic environment towards playfulness for both musicians and
non-musicians. It brings together audio AR and acoustic re-
ﬂectors with the aim to alter the installation space towards
instrumentness by mediating the audience sound perception
and hearing experience. Instrumentness is seen here as the
way in which a musical instrument is controlled and con-
ceptualised as a medium for creative action (e.g. virtuosity,
playability)[4], as a feedback loop between interface, soft-
ware and audience creative expression. In this sound art
installation, the feedback loop is situated between the app
and peripherals, the acoustic reﬂector and the audience.
25
2.1 App and peripherals
An iOS app was built using OpenFrameworks. It hosted a
PureData patch, using LibPD[6], enabling processing of the
phone microphone signal, which was played back through
bone-conduction headphones. Two variants of the app were
built with diﬀerent signal processing conﬁgurations, each
one designed to alter the natural balance of environmen-
tal sound so as to change perception of interpersonal space;
bringing the audience closer to each other. The ﬁrst (ﬁg-
ure 1) used heavy compression of upper-mid frequencies to
emphasize the breath and bodily sounds. The second (ﬁg-
ure 2) expanded on this patch, additionally altering spatial
qualities by presenting diﬀerent band-pass ﬁltered reverbs
in each ear. Here the audience’s own movements and vo-
cals were ampliﬁed. Audience members were given the app
Figure 1: Patch 1
with a mobile phone (which they were free to hold in ways
they saw ﬁtted best) and a pair of bone-conduction head-
phones1 [14]. These headphones transmit sound directly to
the cochlear, bypassing the outer ear and ear drum, and so
do not intervene in natural hearing. This allows our sys-
tem to mediate the sonic environment by creating a mix
of the real sound environment and digital reprocessing of
the same environment, collected through the phone micro-
phone. It also allows the audience to interact with each
other while they experience the merging of real and digi-
tal environments. This system aims to fulﬁl our deﬁnition
Figure 2: Patch 2
of audio AR as realtime computational mediation of sound
perception, mixing live digitally processed environmental
sound with the real sound of the environment.
2.2 Acoustic Reﬂectors
In wanting to control the acoustic environment to create
a deeper sense of hearing/listening for the audience mem-
bers, the design was initially inspired by wartime sound
mirrors [8], the Tv´ ıs¨ongur sound sculpture[13], Unplugged
Kingsize Megaphones[7], and the design of Inside the Hear-
ing Machine [3]. Each of these sound sculptures or artefact
ampliﬁes its own environment resonance through the use
of a parabolic shape. Parabolic shapes with l/a = 4 [20]
have been established as the most eﬃcient dimensions for
the structure to become an optimal sound reﬂector. With
this in mind, and to maximize the parabolic resonance, the
1https://aftershokz.co.uk/
parabola was built from aluminium metal sheets, 16 x 1
meter long piano wires and polymorph. Both wood and tin
metal had been used in previous non-electronic resonators
for similar reasons [3]. Each metal sheet was cut broadly
following a parabolic design for DIY solar reﬂectors [21] and
tied up and brought under tension with 401 copper threads,
bending each piano wire and aluminium sheet to form the
parabolic shape (see ﬁgure 3). Two further acoustic reﬂec-
tors were used in the installation, a 1m x 0.5m semicircular
reﬂector made from framed sheet aluminium, and an 80cm
diameter ceiling hung plastic parabolic reﬂector taken from
a sound dome.
Figure 3: Acoustic Reﬂector
2.3 Feedback loop design
In composing the acoustic environment, two sound sources
were being mediated by the app, its peripherals and the
acoustic reﬂectors (see ﬁgure 4): (i) the airborne sound
(from the reﬂectors and audience’s own vocal sounds), (ii)
structure-borne sonic vibrations (from the bone-conduction
headphones and the reﬂectors).
Figure 4: Feedback Loop. A and B are acoustic
reﬂectors
3. AUDIENCE STUDY
The study was designed to provide formative feedback on
the use of audio AR as a core part of a sound art installa-
tion. It was intended as a means to locate key concepts that
26
will frame ongoing development of the piece. We set-up a
testing environment in an empty room using three types of
parabolic sound reﬂector, and two versions of the audio AR
app, and asked small groups of participants to explore it
freely.
3.1 Method
The study was structured in 3 parts: (i) initial basic instruc-
tions (5 minutes) were oﬀered to participants to become fa-
miliarised with the bone-conducting headphones, as well as
how to navigate between the two mobile applications; (ii) 4
groups of 2-3 participants engaging with the spatial phys-
ical and digital instrument with limited instruction (10-30
minutes); (iii) group interviews (30 minutes) that were de-
signed to address the user/audience experience in terms of
their own experience as a whole, in terms of seamlessness
between the mixed realities and in terms of playfulness and
engagement with the installation.
The 4 groups were randomly organised. 9 participants
took part in the study, aged between 26 to 55 (mean: 43)
with 4 female and 5 male. 6 identiﬁed as practising artists.
8 had received formal musical training, ranging from 4 years
to lifetime. 7 participants considered themselves to be ac-
tively engaged with arts events. One participant had previ-
ous experience of bone-conduction headphones.
Four group-interviews were recorded, transcribed and anal-
ysed using a grounded theory approach [18], by two re-
searchers in collaboration. The transcriptions were coded;
these codes were grouped into concepts, and then into broader
categories.
3.2 Results
The grounded theory analysis resulted in three categories:
‘audio augmented reality experience’, ‘instrumentness’ and
‘collectiveness’.
3.2.1 Audio Augmented Reality Experience
Discussions fell into concepts around seamlessness, immer-
sion and boundaries. Comments concerning immersion (i.e.
the sense of being in the installation environment) all cen-
tred around experience of the mobile software. Participants
talked of a striking diﬀerence when the app was switched
oﬀ2. Some participants felt a deep sense of immersion within
the environment 3. One participant felt the app interrupted
the sense of immersion 4, and another talked of exploring
the augmentations rather than accepting them 5. There
were mixed opinions about the seamlessness of the bone-
conducting headphones, ranging from them feeling unnatu-
ral to very natural6, or in-between7.
2“it was quite a shock when i turned the app oﬀ” , “it was
quite striking that when you took the headphones oﬀ, it sud-
denly seemed really boring ... it suddenly seemed very dif-
ferent”
3“ it felt immersive in the sense that it’s part of my phys-
iology” , “[the app] felt immersive, it did give that sense of
being in an interesting little world” , “everything felt like it
had deep signiﬁcance” , “that feeling when i turned oﬀ the
reverb, one of slight disappointment” , “...felt like I was in a
ﬁlm”
4“the thing became the instrument, which is unfortunate be-
cause it kind of separates out that sense of immersion”
5“when you’re in a space that you’re unfamiliar with, it al-
ways seems like you’re trying to work out what the param-
eters of that augmentation are, rather than accepting that
augmentation rather than a world that you already kind of
have a perception of”
6“once you get into it, I totally forgot I had something on
my ears ... I think at the end it was very natural”
7“it wasn’t quite natural but it was going that way”
3.2.2 Instrumentness
The piece enabled various forms of playful approaches to
exploration of the environment8. Asked “when does a space
become instrumental to you?” , participants replied “when
it gives things back... I felt like I was getting a lot back
from the imaginary space” and “when you can learn from
it”. Several participants felt that the experience of the soft-
ware overrode the experience of the physically constructed
environment 9.
3.2.3 Collectiveness
Responses in this category centred on how collective interac-
tions in the installation worked well, and where diﬃculties
lay. Participants reported feeling comfortable and safe 10.
This was attributed to the feeling “enclosed in this sound
world” and “hearing [sounds] in this wonderful electronic
haze”, and feeling encouraged by other audience members11.
Diﬃculties arose from social inhibition in openly creating
sound within the installation environment 12. Further dis-
cussion focused on ambiguity of sound sources within the
environment, with diﬃculty in determining who was mak-
ing a sound, or whether it was synthetic 13.
4. DISCUSSION
The results highlighted some diﬀerences in opinion between
participants, ﬁrstly about inhibition and experimentation;
while some felt safe and comfortable to experiment within
the installation environment, others felt more reserved. Spec-
ulatively, this may have been connected with the particular
mix of the groups, as some groups were more performative
than others, or developed a desire to hear each other collec-
tively within the audio AR environment. It also needs to be
noted that a few participants pointed out how the sensation
of feeling safe was linked to the immersive experience in the
audio AR environment.
There were some mixed opinions about the seamlessness
of the bone conduction headphones. It may be possible
to improve the experience of these by giving each partici-
pant a mobile phone holder to free their hands to adjust the
headphones for a comfortable ﬁt. One of the main successes
was the degree of immersion the participants reported, with
several participants describing a feeling of shock or disap-
pointment when the headphones were removed and they
left the AR environment. There were also comments about
ambiguity of whether sounds sources originated in the real
or AR environment, again demonstrating a high degree of
immersion. Success in this area however contributed to diﬃ-
culties in balance between the AR and constructed physical
environment, and highlights the compositional challenge of
8“it was fun to try diﬀerent sounds and see how they re-
acted to the environment and the sonics eﬀects, to decide
which ones were the best” , ” I got interested in banging the
phone about to get feedback, and I tried it with the acoustic
reﬂectors” , “I found it quite fun just ﬂicking the end of the
headphone connector ... as an impulse”
9“because the electronic soundscape is so strong, I’m very
much less aware of the real space” , “with the app you don’t
get to see the magic of this [object]”
10“when I put the app on, it was such a contrast and, not
being a vocalist of any kind, it was very exciting because it
felt safe to make sounds of any kind, even though we were
present in the room, and I found that very exciting”
11“but when there are other people around, somehow the fact
that it sounded great to me, individually, is making me
braver in what I would do vocally”
12“I have an inhibition about making strange purposeless
noises”
13“you might not know if you were interacting with what was
in front of you, or a person”
27
creating an interplay between acoustic and digital aesthetics
without over-dominance of the AR system.
A key aim of the sound installation design was to in-
vite play, to create a musical environment physically and
virtually. In the study, this occurred in unexpected ways.
The apps were tuned towards amplifying bodily sound (e.g.
breath, voice), however participants were also very inter-
ested in using the parabola itself to generate sound, as if
it was an instrument, by striking, taping and plucking it,
creating a need for the parabola to speak back.
Finally, we acknowledge that the majority of participants
had musical experience; we are also interested for future
studies to include more non-musicians.
5. SUMMARY AND FUTURE WORK
We have presented an audience experience study of a sound
art installation environment whose design was aimed at pro-
moting collective musical play and expression between audi-
ence members, and within an environment whose acoustics
where altered by both physical objects and an audio AR
system.
Returning to our core research questions - how can au-
dio augmented reality enable collective musical expression?
- we were not expecting to ﬁnd deﬁnitive outputs with this
formative study, only to shed light on the research areas
and support future directions in the development of the in-
stallation. We successfully promoted collective playfulness
and experimentation with sound through digitally mediated
audio perception, in the augmentation of both virtual and
real environments and the audience’s listening perception.
For example, it is possible to recompose an environment
as a musical instrument by changing sonic perception of
it, while playfulness was enabled through a sense of safe
immersion in both environments (e.g, the apps, collective
audience experience), central to any mode of creativity.
The way in which audio AR draws sonic experience in-
wards, creates a dissonance in the design of collective expe-
rience with this technology. It alters a fundamental norm
of musical instruments that they can be used to perform to
others. In the case of audio AR, the player is experienc-
ing their own personal transformation of the sound-world
around them. However, in contrast to this, AR can also pro-
mote collective creative experience by extending the scope
of what is playable, by extending that personal space with
altered or heightened sound perception and disrupting the
natural hierarchy of a sound environment by, for example,
prioritising bodily sounds. When a sound installation en-
vironment itself becomes more instrument-like then it can
become a collective instrument and consequently a shared
channel of communication between audience members in the
AR world, despite the personal or even intimate nature of
their experience.
In response to the study and considering future develop-
ment of this installation, it is clear that the AR apps can
stand alone as mediators of new sonic experiences. However,
in making the personal experience of AR into an interper-
sonal experience - central to collective musical expression, it
is key to think further about how to network and merge the
real and virtual environments. It also necessary to question
how to create a balance of interplay between audience and
composed environments for creative expression, real and vir-
tual, and how to reduce social inhibition in the installation
environment for it to become instrument.
6. REFERENCES
[1] L. Aceti. Not here, not there: An analysis of an
international collaboration to survey augmented
reality art. Leonardo Electronic Almanac, 19(1), 2013.
[2] R. T. Azuma. A survey of augmented reality.
Presence: Teleoperators and virtual environments,
6(4):355–385, 1997.
[3] T. Beghin. Inside the hearing machine.
https://www.insidethehearingmachine.com/,
Accessed January 2017.
[4] O. W. Bertelsen, M. Breinbjerg, and S. Pold.
Instrumentness for creativity mediation, materiality &
metonymy. In Proc. Creativity & cognition, pages
233–242. ACM, 2007.
[5] Breidenbruecker. RJDJ, 2008.
[6] P. Brinkmann, P. Kirn, R. Lawler, C. McCormick,
M. Roth, and H.-C. Steiner. Embedding pure data
with libpd. In Proc. Pure Data Convention , volume
291, 2011.
[7] Estonian Academy of Art. Unplugged kingsize
megaphones, 2015.
[8] R. Ganchrow. Perspectives on sound-space: The story
of acoustic defense. Leonardo Music Journal, -:71–75,
2009.
[9] S. Glickman, B. Lee, F. Y. Hsiao, and S. Das. Music
everywhere - augmented reality piano improvisation
learning system. In Proc. New Interfaces for Musical
Expression, pages 511–512, Copenhagen, Denmark,
2017.
[10] E. R. Group. Art and technology - some notes on our
position at the present time, February 1980.
[11] L. Hayes. Vibrotactile feedback-assisted performance.
In Proc. New Interfaces for Musical Expression , pages
72–75, Oslo, Norway, 2011.
[12] D. Johnson and G. Tzanetakis. Vrmin: Using mixed
reality to augment the theremin for musical tutoring.
In Proc. New Interfaces for Musical Expression , pages
151–156, Copenhagen, Denmark, 2017.
[13] L. K ¨¨uhne. Tv´ ıs¨ongur sound sculpture. Iceland, 2012.
[14] S. C. Nanayakkara, L. Wyse, S. H. Ong, and E. A.
Taylor. Enhancing musical experience for the
hearing-impaired using visual and haptic displays.
Human–Computer Interaction, 28(2):115–160, 2013.
[15] H. Papagiannis. Augmented Human. O’Reilly Media,
2017.
[16] N. Schnell, S. Robaszkiewicz, F. Bevilacqua, and
D. Schwarz. Collective sound checks: Exploring
intertwined sonic and social aﬀordances of mobile web
applications. In Proc. Tangible, Embedded, and
Embodied Interaction, pages 685–690. ACM, 2015.
[17] E. Sheﬃeld, E. Berdahl, and A. Pfalz. The haptic
capstans: Rotational force feedback for music using a
ﬁrefader derivative device. In Proc. New Interfaces for
Musical Expression, volume 16 of 2220-4806, pages
1–2, Brisbane, Australia, 2016. Queensland
Conservatorium Griﬃth University.
[18] A. Strauss. Qualitative Analysis For Social Scientists .
Cambridge University Press, 1987.
[19] Studio Drift. Concrete storm. Armory Show, New
York, 2017.
[20] S. Wahlstr ¨om. The parabolic reﬂector as an acoustical
ampliﬁer. J. Audio Eng. Soc , 33(6):418–429, 1985.
[21] L.-Y. Zhu. Making a parabolic reﬂector out of a ﬂat
sheet. http://solarcooking.org/plans/
parabolic-from-flat-sheet.htm (Accessed July
2017), Apr 2002.
28