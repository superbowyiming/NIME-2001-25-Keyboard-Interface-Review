netBody - “Augmented Body and Virtual Body II” with  the System, BodySuit, 
Powered Suit and Second Life  
- Its Introduction of an Application of the System
Suguru Goto 
IRCAM/Pompidou Center 
1, place Igor Stravinsky 
75004 Paris 
France 
Suguru.Goto@ircam.fr
Rob Powell 
The Aesthetic Technologies Lab 
Athens, OH  45701 
USA 
oneiros99@yahoo.com
Abstract 
This is intended to introduce the system, which combines 
BodySuit, especially Powered Suit, and Second Life, as 
well as its possibilities and its uses in a musical 
performance application. The system which we propose 
contains both a gesture controller and robots at the same 
time. In this system, the Data Suit, BodySuit controls the 
avatar in Second Life and Second Life controls the 
exoskeleton, Powered Suit in real time. These are related 
with each other in conjunction with Second Life in 
Internet. BodySuit doesn't contain a hand-held controller. 
A performer, for example a dancer, wears a suit. Gestures 
are transformed into electronic signals by sensors. Powered 
Suit is another suit that a dancer wears, but gestures are 
generated by motors. This is a sort of wearable robot. 
Second Life is software that is developed by Linden Lab. It 
allows creating a virtual world and a virtual human 
(avatar) in Internet. Working together with BodySuit, 
Powered Suit, and Second Life the idea behind the system 
is that a human body is augmented by electronic signals 
and is reflected in a virtual world in order to be able to 
perform interactively.  
Keywords: Robot, Gesture Controller, Humanoid Robot, 
Artificial Intelligence, Interaction, Internet 
1. Introduction 
Suguru Goto and Rob Powell have been working on this 
project since 2007. The first development was done in 
2007 at the Aesthetic Technologies Lab, Ohio University. 
The next major development was from October 2007 until 
October 2008 at KHM (Academy of Media Arts Cologne) 
in Cologne, Germany. The first performance was given at 
the Ridges Auditorium, Ohio University, Athens, Ohio, 
USA, on May 25, 2007. The last performance was given at 
Aula, KHM, Cologne, Germany, on October 13, 2008 (Fig. 
1). This is a collaboration project in which Suguru Goto 
has been developing Concept, Music, and the BodySuit 
and Powered Suit, and Rob Powell has been developing 
custom programming for integrating the BodySuit and 
Powered Suit with Second Life. 
This project consists of the creation of new musical 
performance work, new technological development and 
performance in public. Much of this work concerns 
science, art and musical performance. Here, new 
technology refers to scientific research and new 
technological developments for Internet applications as 
well as sensor and robotic technologies. 
The development work being done in this project is the 
Powered Suit and Second Life implementations in 
conjunction with scientific/technological and musical 
fields. The scientific research and technological 
developments of the Powered Suit and Second Life will 
help to extend the concept of the relationship between 
artificiality and reality of the human body in a context of 
dance / musical theater, to complete an artistic work 
entitled, “netBody” - Augmented Body and Virtual Body 
II. 
 
Fig. 1: The last performance was given at Aula, KHM, 
Cologne, Germany, on October 13, 2008. 
2. Description of performance 
In this performance, we link the real world to the online 
reality of Second Life. We do this at the physical level: the 
bodily movements of a person in the real world control an 
Permission to make digital or hard copie s of all or part of this work for 
personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists 
requires prior specific permission and/or a fee.  
NIME09, June 3-6, 2009, Pittsburgh, PA 
Copyright remains with the author(s).  
 
 
Ohio University, College of Fine Arts, Putnam Hall 235  
NIME 200948
avatar in Second Life, while an avatar’s movements guide 
a human being’s. 
Second Life is a 3D online digital platform created by 
its residents. Here, each flesh -and-blood human creates a 
unique identity – an avatar – to inhabit  the digital 
community environment. The contact between these 
realities is usually effected through a monitor, keyboard 
and mouse. In this work, the whole body takes part; we 
develop technology that makes communication between 
the two realities two -way and physical. 
A movement -registering mechanism built into the 
BodySuit allows a person’s movements to directly control 
the behavior of an avatar in Second Life (Fig.2). 
Conversely, the Powered Suit contains motors that control 
the human body like a marionette. It is a sort of robot you 
can wear, controlled by a computer and an avatar (Fig. 3).  
 
Fig.2: A movement-registering mechanism built into the 
BodySuit allows a person’s movements to directly control the 
behavior of an avatar in Second Life.  
 
Fig.3: The Powered Suit is a sort of robot one can wear, 
controlled by a computer and an avatar.  
With this technology, geography, location and space no 
longer hinder physical interaction between bodies. A 
Second Life avatar becomes a vehicle fo r physically  
connecting the individual to society. This could make it 
possible for people all over the world with the correct 
hardware to share each other’s bodies over the Internet.  
We play with our perception of an individual’s body as his 
or her identity. In this project, we do not know exactly who 
is controlling the Powered Suit or where they are in the 
world. Our bodies become a combination of ‘real’ and 
computer-generated information and are thereby improved. 
Perhaps this could lead to new ways of usi ng our bodies 
we can discover only by controlling them from outside, 
through the Internet.  
3. Conclusion 
These systems are utilized in the project entitled, 
"netBody” - Augmented Body and Virtual Body II. 
Especially, these will complete the theme in a deeper sense 
to explore this dualism and the relationship between 
artificiality and reality of human body in a context of 
dance / musical theater. Different realities will be 
connected using physical interfaces, such as a Virtual (= 
Internet) World and the Human Body (which is augmented 
by a robot).  The world we may usually call the “real” 
world connects with the Internet-based world called 
Second Life. This updated project involves developing 
hardware and software to accomplish deeper 
communication between these  worlds via the Internet.  
Ultimately, the actions of one world will be reflected in the 
other world.  Specifically, the “avatar” (a unique character 
or identity) in Second Life will be controlled by 
movements of a human body, and a human body will be 
controlled by movements of an avatar. For this project, this 
would be done using two types of physical interfaces - a 
motion capture suit called BodySuit and a robotic, 
controllable suit called Powered Suit - and custom 
software developed to enable communicati on between 
Second Life software and the physical interfaces.  These 
developments will be further explored in musical 
performance contexts in artistic works.  The Internet will 
be used to accomplish physical communication between 
bodies that would normally be impeded by geography and 
space constraints. 
References 
[1] Tomoyuki Furuta, Atsushi Konno, Masaru Uchiyama: 
Development of the Arms for the Humanoid Robot Saika -3, 
192th SICE Control Engineers Tohoku Chapter, 2000, Japan  
[2] Masafumi Okada and Yoshihiko Nakamur a: Shoulder 
Mechanism for Humanoid Robots that Coexist with Human 
-Morphological Affinity and Mechanical Passive 
Compliance-, Journal of the Robotics Society of Japan, Vol. 
19 No. 7, pp.818-821, 2001, Japan 
[3] Kirsty Beilharz: Interactively Determined Generat ive Sound 
Design for Sensate Environments: Extending Cyborg 
Control, IE2004, Sydney, Australia  
[4] Suguru Goto: Virtual Musical Instruments: Technological 
Aspects and Interactive Performance Issues, IRCAM, 
Trends in Gestural Control of Music, 2000, Paris, France 
[5] Suguru Goto: The Aesthetics and Technological Aspects of 
Virtual Musical Instruments: The Case of the SuperPolm 
MIDI Violin, Leonardo Music journal, Vol.9, 1999, 
California, U.S.A 
[6] Suguru Goto: The Case Study of An Application of The 
System, BodySuit and “RoboticMusic” -Its Introduction and 
Aesthetics, Proceedings of the 2006 International 
Conference on New Interfaces for Musical Expression 
(NIME06), Paris, France  
[7] BodySuit: 
http://suguru.goto.free.fr/Contents/Works/BodySuit/B
odySuit-e.html 
[8] Video: 
http://jp.youtube.com/watch?v=lEYJgRC9gxc&featur
e=channel_page 
[9] Second Life: 
http://secondlife.com
 
 
 
 
49