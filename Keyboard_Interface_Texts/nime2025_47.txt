Mixer Metaphors: audio interfaces for non-musical applications
Tace McNamara
SensiLab, Monash University
Caulfield East, Victoria, Australia
Tace.McNamara@monash.edu
Jon McCormack
SensiLab, Monash University
Caulfield East, Victoria, Australia
Jon.McCormack@monash.edu
Maria Teresa Llano
University of Sussex
Brighton, UK
Teresa.Llano@sussex.ac.uk
Figure 1: The Memetic Mixer
Abstract
The NIME conference traditionally focuses on interfaces for mu-
sic and musical expression. In this paper we reverse this tradi-
tion to ask, can interfaces developed for music be successfully
appropriated to non-musical applications? To help answer this
question we designed and developed a new device, which uses
interface metaphors borrowed from analogue synthesisers and
audio mixing to physically control the intangible aspects of a
Large Language Model. We compared two versions of the device,
with and without the audio-inspired augmentations, with a group
of artists who used each version over a one week period. Our
results show that the use of audio-like controls afforded more
immediate, direct and embodied control over the LLM, allowing
users to creatively experiment and play with the device over
This work is licensed under a Creative Commons Attribution 4.0 International
License.
NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia
¬© 2025 Copyright held by the owner/author(s).
it‚Äôs non-mixer counterpart. Our project demonstrates how cross-
sensory metaphors can support creative thinking and embodied
practice when designing new technological interfaces.
Keywords
Mixing, Audio Metaphor, HCI, LLM
1 Introduction
While there is a rich history of innovation and experimentation in
the NIME community in developing interfacesfor musical expres-
sion and control, less research has been devoted to the application
of musical interfaces to non-musical systems. Musical interfaces
and their associated musical expressions are tangible, embodied,
and interactive; strengths which are increasingly important when
designing technology in any domain.1 To practically demonstrate
how musical interfaces can enhance non-musical design, we draw
on interface elements and metaphors from audio mixing and syn-
thesizers to create the Memetic Mixer ‚Äîa bespoke tangible device
for creative interaction with large language models (LLMs). Our
1We acknowledge of course the broader field of tangible interaction design has
addressed this area for many years [23, 24, 38, 41].
NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia McNamara et al.
work demonstrates how audio and music metaphors can serve
as effective design tools beyond musical contexts.
Our application of musical metaphors comes from two perspec-
tives. First, we consider how key paradigms from audio mixers
and hardware synthesisers can be applied as conceptual tools
by designers. To do so, we outline the physical and functional
affordances of faders, knobs, presets, filters and effects [19]. We
then pose these audio norms as an exploratory framework for
the design of non-musical interfaces that encourage expressive
interactions, similar to what they do for musicians and audio
engineers.
Following this, we consider how musical metaphors may be
beneficial to the users of non musical-interfaces. To evaluate
how the use of music metaphors changes both perception and
creative thinking, we built two versions of our tangible LLM
device ‚Äì one with and one without the audio-inspired controls ‚Äì
and provided them to a group of six fine-art graduate students in
their shared studio space for a one week period for each version
of the device. We found that the use of controls inspired by
audio mixing and synthesiser design positively affected their
conceptual approach, use and creative thinking about the device
and its possible purposes. The immediate, direct and embodied
control afforded by the audio-inspired interface allowed user‚Äôs
to creatively experiment and play with the device over it‚Äôs ‚Äúnon-
mixer‚Äù counterpart.
2 Related Work
2.1 Metaphor in Musical Interface Design
The value of metaphor, widely used in HCI [ 3], has been ex-
tensively applied to mapping functions for new, expressive mu-
sical interfaces [ 12, 21, 42]. Metaphor can be a useful tool to
understand functions of innovative technologies which extend a
musician beyond the bounds of traditional musical norms. For
example, Gadd and Fels [16] used a rainfall metaphor to assist
users in understanding granular synthesis. Others have focused
on embodied and gestural metaphors in musical interaction de-
sign [22] and live performance [43]. Bau et al. [1] utilised musical
metaphors at two levels of abstraction in their design process, the
‚Äúinstrument‚Äù level focused on hardware and software specification,
while the ‚Äúcomposition and interpretation ‚Äù level entailed unique
contextual interactions with their audio in-out device. They con-
cluded the use of metaphor allowed for ‚Äúopen-endedness‚Äù in the
design process.
These examples demonstrate the benefit of metaphor in the
design of musical interfaces has been established, both in the
process of design and in user interaction. However, whether
musical metaphors could be effective tools outside the disciplines
of music interface design remains largely under-explored.
2.2 Musical Control Paradigms
The intuitive control offered by audio mixers in particular has
been a feature of HCI research [27]. The gestural control mecha-
nisms of audio interfaces are designed to facilitate ‚Äútinkerability‚Äù:
experimenting with alternatives, rapid shifts in directions and re-
sets [36]. Many expressive control mechanisms from music and
audio have become paradigmatic, each representing a unique
type of control and creative function. There are no better exam-
ples of this than knobs and faders, classic gestural controls now
common to musical interfaces. Recognising the importance of
these mechanism in music interfaces more than a decade ago,
Gelineck and Serafin [18] performed a quantitative evaluation of
the differences between knobs and faders, with both receiving
above averages scores as ‚Äúintuitive‚Äù and ‚Äúinspiring‚Äù. Gelineck
et al. [17] presented a comparative study of two other musical
paradigms, ‚Äúthe channel-strip ‚Äù and ‚Äúthe stage ‚Äù finding both to be
effective for a simple spatial panning task. More recently, Rossmy
[37] did a survey on musical grid interface standards, focusing
on buttons, faders and keys. They concluded there are clear con-
ventions for these control mechanism in UI design and proposed
that their work contributed to standardising these practised but
yet to be formalised definitions.
Extending beyond the musical domain, faders have even been
considered philosophically in speculative epistolary fiction, warn-
ing against the risks of ‚Äúwidespread Slider use and abuse‚Äù wherein
faders are used to control extremes of personalities [29]. Others,
such as Morrison and McPherson [35] recognise the power of
modes of musical interaction without the trepidation and instead
argue for the need to further embrace interdisciplinary design
within HCI. Though the strength of musical control paradigms
have been recognised within this field of origin, there is much
potential to apply these norms as design tools in other disciplines.
In the following section, we discuss musical paradigms from
audio mixing consoles and how they could be applied to other
disciplines as functional and metaphorical tools.
3 Mixer Paradigm
In this section, we describe control mechanisms from audio mix-
ers that have become paradigmatic manipulation tools. For the
benefit of designers from other fields who may not be familiar
with audio mixer interfaces, we briefly describe their functional
affordances and where relevant, sensory affordances of key con-
trol mechanisms. We then provide a list of questions which help
apply audio mixer paradigms to non-musical domains. Our aim
is to present the mixer paradigm as a tool for divergent thinking
to inspire new forms of expression for designers in both musical
and non-musical fields.
3.1 Faders
A foundation of audio mixer consoles, faders are linear control
mechanisms which were invented to control multiple channels
simultaneously [25]. Commonly, there is a single function as-
signed per fader, like the volume control of an instrument. A
single fader function can also be applied to a group of instru-
ments or effects so the exact degree of change can be applied
simultaneously to each channel. Faders may be bipolar, with two
polar values either side of a neutral centre point, or polar, with
a single sided spectrum or range [ 37]. This simplicity plays a
large role in the intuitive nature of faders, or ‚Äúsliders‚Äù as they
are sometimes called. The position of the faders offers a visual
representation of the internal parameter mapping allowing the
user to understand the mix at a glance [10]. Faders have become
synonymous with smooth transitions‚Äîfading in and fading out,
allowing the control of a parameter free from the jagged edges
of discrete time functions.
Tom Dowd, scientist, audio engineer and inventor of faders,
aimed to create a mode of fluid gestural control that would allow
him to play a mixer console like a piano [ 13, 39]. Faders allow
sound engineers to manipulate unique points of expressive con-
trol under each finger, whilst moving each hand independently.
BBC broadcasting desks were originally designed so that the
engineer would pull the fader towards themselves if they wanted
to hear more of that instrument [ 34, 40]. Today, the action of
Mixer Metaphors: audio interfaces for non-musical applications NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia
Figure 2: A Moog Subsequent 37 synthesiser with classic analogue aesthetic (left) and an audio mixer console with knob
and fader controls (right).
turning up a parameter is mapped to sliding a fader vertically
higher on a screen, or outwards on a physical console.
The following questions may serve as points of inspiration
when considering how faders could be used as conceptual tools
in a design:
F.1 What could be faded in or out?
F.2 What parameters are being mixed together to create a
whole?
F.3 Which parameters could be assigned an independent fader
to allow greater expressive control?
F.4 What parameters could I group together with a single
fader, to fade in and out together?
F.5 Am I allowing both hands independent movement and
expressive control?
F.6 Am I allowing the fingers to used be independently and
expressively?
3.2 Knobs
Knobs are a versatile control mechanism common to audio and
many non-musical fields. Knobs, or ‚Äúpots‚Äù are rotary control
mechanisms which offer the benefit of varying parameters based
on rotational movement. Many knobs are labelled with numbers
to indicate exact points of adjudgements. The concept of a knob
to dial up the volume is now common on many sound producing
apparatus. Knobs offer the possibility to pan between two binaries
with a zero point in the centre or to dial up a single continuous
parameter. The later norm, encourages users to explore extremes
unlike the nuanced and subtle control encouraged by faders.
‚ÄúTurn it up to eleven‚Äù has become common vernacular after Spinal
Tap (1984) parodied the musicians tendency to turn a knob as
high as it will go.
Knobs are also very intuitive as gestural control mechanisms.
Knobs are tweaked or dialled and our embodied understanding
of these gestures conjures a very specific type of parameter ad-
justment. Most knobs fit neatly between two fingers and twisting
them delicately to adjust a parameter creates a sensation quite
distinct to sliding a fader. Additionally, knobs with discrete steps
often provide a satisfying haptic feedback as the click into place.
Inspired by the sensory and functional affordances of knobs in
musical domain, the following questions may serve to translate
these affordances to other disciplines:
K.1 Which parameters could be expressively controlled in dis-
crete increments?
K.2 Could I offer creative control by panning between two
binaries?
K.3 What is the centre point between two binary extremes?
K.4 Which parameters should be tweaked?
K.5 Which parameters could be dialled up?
K.6 What could I turn up to eleven?
3.3 Presets
Many synthesisers and effects interfaces come with built-in sound
presets which provide an automatic mapping to an internal ma-
trix of parameters that developers have chosen as functional and
aesthetic examples. Despite the integration of presets, synthesis-
ers are designed to allow musicians to shape their own unique
sound by manipulating each parameter to their taste. However,
the presets of some synthesisers are so commonly used by musi-
cians that many popular synthesises are defined by the sound of
their presets.
Presets are commonly activated by turning a selector knob and
are given descriptive names to define the parameter mapping they
represent. Using presets, a user may ‚Äúplug-in and play‚Äù, instead
of setting each parameter independently before beginning. The
immediate, no-fuss creative interaction offered by presets reduces
the complexity of musical interface so as not to interfere with the
potential for user flow states [11]. In one study, presets allowed
inexperienced users to achieve similar results to expert users
[28].
The following questions can be used to consider how presets
may be applied:
P.1 What quick start ‚Äúpresets‚Äù have I allowed the user?
P.2 Which parameter mapping/setting of characteristics could
be considered the aesthetic/tone of this work?
P.3 Which four presets would best demonstrate the range and
contrast in this system/work?
P.4 What example/preset would best display the capabilities
of this system?
3.4 Filters
Filter controls, common to synthesizers and audio mixing con-
soles, allow certain frequencies to be sculpted away or selec-
tively emphasised. Filters are often used as expressive tools for
transitions and dynamics. Gradually opening up high or low
frequencies will ‚Äúfilter‚Äù an instrument into a mix. Likewise, a
sound source can be slowly removed by closing a filter and the
NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia McNamara et al.
SLATE
(IMAGABLE AREA)
PERSONALITY
MIXERE-PAPER DISPLAY
WORD STORAGE DRAW
PERSONALITY PRESETS
SYSTEM/FILTERS
CREATIVE MODE
EFFECTS
LEDS
Figure 3: Schematic diagram of the Memetic Mixer.
frequency range it controls. Filters are applied on top of a sound
source or instrument meaning the original sound can also be
returned to. This means there is no need for the careful treading
which may be necessary if there were risk of changing a sound
irreversibly.
The following questions may help to apply the concept of
filters to other disciplines:
ùúà.1 What aspects would I like to filter into/out of this work?
ùúà.2 How could filtering in a certain feature be used to create
a transition?
ùúà.3 What could be filtered in and out to add more dynamic
range?
3.5 Effects
Effects refer to a range of sound manipulation techniques that
shape timbre. In some cases, these effects are fundamental to
the defining sound of an instrument and are thus captured as
part of the source sound. This means they can not be removed or
changed in post-production. Commonly, effects are also added
on top of a sound source to add colour, or other creative qualities.
Effects can evolve a sound from basic and uninteresting to unique
and dynamic. An effect can be applied to a single instrument or
collectively to a group of instruments serving to unite their sound,
and ‚Äúglue‚Äù them together a space. Some commonly used effects in
music production and performance are reverb, delay, distortion
and chorus.
The following questions may prompt ideas on how effects
concepts can be applied beyond musical domains:
E.1 What effect could I apply to this element/work to morph
it into something completely different?
E.2 What effect could I apply to different elements to unify
them?
E.3 What element (ie. adjective, feature, condition) could I
treat metaphorically as an effect?
E.4 How could I metaphorically apply (example effect: reverb,
delay, distortion) to this work?
We will now describe how we applied these audio mixer con-
trol norms as functional and conceptual tools in a tangible LLM
interaction device.
4 The Memetic Mixer
In this section, we offer an example of how we applied the audio
mixer paradigm to LLM-interaction design, as a conceptual tool
for design and to create greater expressive potential for users. Be-
fore introducing the details of the audio and synthesizer inspired
controls, we briefly introduce theMemetic Mixer device and appli-
cation here. Further details, including technical implementation,
are available in [30].
Our motivation comes from exploring new ways of interact-
ing with generative AI systems, in particular LLMs, where the
dominant mode of interaction is the ‚Äúchat-bot‚Äù style interface.
While suitable for transactional modes of interaction, such as
simple question and answer interactions, chat-bot interfaces em-
phasise the transitory, which quickly can become superficial. To
encourage a slower and more considered mode of interaction ‚Äì
something that felt more ‚Äúspecial‚Äù and purposeful than a chat
screen ‚Äì we settled on a physical design that used physical word
‚Äútiles‚Äù (inspired by magnetic poetry and its well known ability to
stimulate writer‚Äôs creativity [26]).
Words are placed on the device‚Äôs slate (Fig. 3) where they are
recognised by the system and used to construct a complex se-
ries of internal prompt-chains [44]. The prompt chain is sent to
the LLM, ChatGPT4-o in this case. The LLM response is then
displayed on the device‚Äôs e-Paper screen, along side the user
input text as recognised by the device. It was necessary to de-
sign a means to manipulate the output-response without the
cognitive demands and constraints typically imposed by prompt
engineering. Hence the use of the ‚Äúmixer‚Äù in the device.
Inspired by the modes of interaction used in analogue synthe-
sisers and audio mixing technology (Fig. 2), we conceptualised
the Memetic Mixer interface as a ‚Äúpersonality mixer‚Äù. In the same
way an audio mixer is used to creatively mix together different
audio tracks to create a final output, the Memetic Mixer allows
different traits to be fused into a personality for the LLM response
(F.2).
Thus, audio mixing metaphors formed the conceptual model
for a control interface to explore creative manipulation of the
LLM‚Äôs personality and behaviour. This design process began by
drawing inspiration from analogue synthesisers like the Moog
Subsequent 37 (Fig. 2, left). Inspired by the analogue audio aes-
thetic, we added knobs and faders similar to an audio mixer (Fig. 2,
right).
We integrated five faders to create the LLM personality mixer
(F.1,F.3). The personality traits were inspired by the ‚ÄúBig 5‚Äù; five
phenotypes recognised as the core characteristics of personality
in psychology [ 9, 15, 20, 32]. We refined these phenotypes to
more intuitive labels based on more recent research on the Big
5, [14, 31, 33] and applying these personality categories to AI
models [8]. The personality mix is created by positioning the
faders on axes of opposed personality traits which are as follows:
Optimist‚ÄîPessimist
Dreamer‚ÄîPractical
Dominant‚ÄîSubmissive
Playful‚ÄîSerious
Trusting‚ÄîSuspicious
Similar to the way an audio input is sent through distinct sections
of a mixer console, each designated to particular functions, the
knobs on the MM fall under the categories: system, filters, modes,
effects, filters and presets (Fig. 4).
The first preset knob allows the user to select one of four stages
of creative process sending an internal prompt to instruct the
LLM behaviour (P.1, P.4). The second preset knob was designed
for personality presets (P.1). The presets provide four contrasting
Mixer Metaphors: audio interfaces for non-musical applications NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia
Mode
Presets
Description Personality
Presets
Description
Explore Divergent
exploration
of ideas
Guru For toxic positivity
look to the guru;
the all-knowing
teacher (and their
ego)
Compose Convergent
structuring
of ideas
Bestie The best friend
who has complete
faith in their coun-
terpart but can
always be trusted
to be honest
Critique Feedback
and
evaluation
Accountant They may be down
in the dumps
but the practical
accountant will
always get straight
to business
Refine Polishing
and refining
Cynic Difficult to please
and sure of them-
selves, the cynic
will always play the
contrarian
Table 1: Memetic Mixer Preset Knobs
REFINE
CRITIQUECOMPOSE
EXPLORELENGTHVOCABULARYAGETEMPERATURE
BESTIE ACCOUNTANT
CYNICGURU
SARCASMPOLITICSDISTRESSMORALITY
PERSONALITY
TYPE
MODES
SYSTEM FILTERS
EFFECTS
PRESETS
MODES
Adjusts the ‚Äúcreativity‚Äù of 
the LLM 
Changes the ‚Äúvoice‚Äù of the output. Adjusting these controls re-
interprets the inner response with a different voice 
Creative mode: from 
divergent to convergent 
Preset personality types: 
adjusts the position of 
the 5 personality sliders
Adjusts the disposition or environment in which the 
current personality is situated
Figure 4: Knobs and their function groupings in the
Memetic Mixer
personalities and tones of speech (P.2), which were chosen with
the intention of creating personas that roughly covered the op-
posing spectres represented by the faders (P.3). Upon choosing
one of four segments labelled with an archetypal persona, the
motorised faders automatically move to the saved values repre-
senting that persona. A brief explanation of our chosen presets
can be found in Table 1.
The filter knobs on the Memetic Mixer were designed to add
creative constraints to the LLM response without changing the
personality mix or the mode preset (ùúà.1). In this way, the user can
explore variations of a single response as it changes according
to the filter settings. We also integrated four effects knobs to
Filter Function Effect Function
Age baby to senior
citizen
Morality malevolent to
benevolent
Vocabulary very simple to
extremely
advanced
Politics liberal to conser-
vative
Length one word to
multiple
paragraphs
Distress increases hyste-
ria
Temperature2 increases
uncertainty or
randomness
Sarcasm increases sar-
casm
Table 2: Filter and Effects Knobs
‚Äúcolour‚Äù the tone of the LLM output (E.1, E.3). Table 2 outlines
our choice of filter and effect labels.
5 Comparative Study Design
For the purpose of exploring if audio mixing metaphors can
be used to facilitate more effective interaction with LLMs, we
performed a comparative user study and analysis. This involved
testing two tangible LLM devices; one which relied solely on
word tiles and control markers to interact with an LLM (The
Mimetic Poet ), and The Memetic Mixer , described in the previous
section, a new iteration augmented with physical controls knobs
and faders to create a ‚Äúpersonality-mixer‚Äù .
Both devices were tested in an ecological setting [2, 6, 7] with
six Fine Art Honours students (4 males, 2 females, age range
24-57). These students regularly worked from the same art stu-
dio where the devices were installed for the study upon consent.
Being an ecological study, we did not add any participants from
outside the art studio environment in order to inflate numbers.
The number of participants was also suitable to allow each partic-
ipant enough time to interact with a single device in a meaningful
and sustained way.
Participants attended an information session where they learnt
about the functionality of the non-mixer device (The Mimetic
Poet) and how data would be used and collected. Participants were
not aware they would be evaluating another device in a following
study and were initially asked to engage with the Mimetic Poet
alone. While the study was carried out along side participants‚Äô
usual creative practice, they were free to use the device whenever
and however they saw fit. In this way, our method drew from
ecological studies [2, 6, 7] which benefit from experiments taking
place in a user‚Äôs habitual environment rather than being obliged
to test a device for a limited amount of time in a fabricated
laboratory setting.
At the conclusion of the first study period using the non-
mixer device, participants attended an in-person focus group
consisting of semi-structured interviews and open discussion
to gain insights from their experiences interacting with the de-
vice. The questions made no mention of the following study
with the Memetic Mixer . All comments were audio recorded and
transcripts produced, along with researcher‚Äôs notes and still pho-
tography.
2A native system parameter of many LLMs.
NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia McNamara et al.
Figure 5: The Mimetic Poet(left) a previous design without the use of audio-inspired controls, and the Memetic Mixer(right),
a re-imagined version of the Mimetic Poetinspired by audio metaphors.
Following this, the same cohort of Fine Art honours students
partook in another week-long study, approximately one month
after the first. This time, interacting with the augmented per-
sonality mixer device ( Memetic Mixer ) which was once again
installed in the same communal area of their studio under the
same conditions. Being familiar with the non-mixer device, par-
ticipants were not given any new instruction on the use of the
Memetic Mixer , nor on the meaning or function of the additional
controls, beyond the labels on device.
At the conclusion of the second study period, we held a second
1-hour focus group, following the same format and protocols as
the initial study. Each participant received two $50 vouchers for
participation, one following each focus group. Using a reflexive,
inductive thematic analysis approach [4, 5], the interview tran-
scripts and notes were independently coded by two members
of the research team to draw out the significant themes from
both studies. We summarise the results of this analysis in the
next section. The studies were approved by our university ethics
committee.
5.1 User experience with non-mixer device
In discussion with participants about their experience through-
out the week using the non-mixer device ( Mimetic Poet ), their
appreciation of the tangible nature of the device was apparent.
One participant remarked, ‚Äúthe physicality of it is a nice touch, es-
pecially because it is an AI model‚Äù . Another expressed approval of
the ‚Äúanalogue style‚Äù of the interface. The importance of physical-
ity was cemented by a claim that this was in fact the only appeal
of the device: ‚ÄúIf it was completely digital, it wouldn‚Äôt have [any]
attraction to it. ‚Äù However, the physicality of the device alone was
not enough to sustain the participants‚Äô interest. One reported, ‚ÄúI
got bored of [it] pretty quickly‚Äù which was supported by another
participant who admitted, ‚ÄúI couldn‚Äôt do a sustained session with
this.‚Äù
The rapid decline in engagement seemed connected to a lack
of expressive range in the interactions. One user imagined a more
appealing device wherein, ‚Äúmaybe you had a variation of things
and you weren‚Äôt a hundred percent sure what they mean would
probably keep you into it a little bit longer and maybe you‚Äôd get
more of those iterations and stuff happening. ‚Äù
Participants wanted the LLM to expand upon their ideas with
divergent associations, not just redress the same ideas with syn-
onyms. One expressed, ‚ÄúI was being quite associative. And it
would have been fun if it came back at me quite associative as
well. With just, like, a few other words that were not the same. ‚Äù
Cross-disciplinary correspondences were mentioned as a way
to incorporate divergent sources for ideas: ‚Äútaking what you‚Äôve
written and transposing it into like a different discipline. And it
might even pick a discipline. . . randomly. This is what an architect
would think. ‚Äù Another participant elaborated, ‚ÄúIt‚Äôs like how they
say to us as creatives . . . ‚Äògo and consume other art‚Äô, or if someone‚Äôs
a dancer and they do ballroom. . . go and learn river dancing or
something, because that‚Äôs going to have an impact on your creative
output. So it‚Äôs like dropping it into something that‚Äôs completely
different. . . And that‚Äôs probably what. Maybe it was, like, missing a
bit. ‚Äù
The desire to draw on ideas from other disciplines was reit-
erated throughout several points of the discussion. A creatively
satisfying interaction with a LLM was envisioned as ‚Äúalmost like
a brainstorming session‚Äù wherein it could provide‚Äúunconventional
combinations of . . . things. ‚Äù The ability it iterate upon ideas was
perceived as a straight of AI models. One participant elaborated,
‚ÄúI always think about AI as. . . limitless in its ability to conceptualize
stuff. So you kind of want to see what it‚Äôs going to come up with. ‚Äù
This was confirmed by one participant‚Äôs want for an interaction
‚Äúthat might reveal something that you just would have never oc-
curred to you because you‚Äôre already in this fixed way of thinking.
And that‚Äôs what I would be using it for, to help spark some other
thoughts that I could then go away with myself. ‚Äù
Interestingly, participants began to develop their own cross-
disciplinary metaphors in imagining the type of device which
could be more creatively satisfying. One user expressed their
desire for ‚Äúan ugly or extreme sound‚Äù , drawing on an auditory
metaphor to describe a more stimulating response. Another par-
ticipant suggested the LLM could be manipulated with tactile
‚Äúknobs and sliders‚Äù . They imagined a knob could be used to ‚Äúdial
up or down‚Äù personality traits such as ‚Äúsnarkiness‚Äù or ‚Äúverbosity‚Äù.
Mixer Metaphors: audio interfaces for non-musical applications NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia
These comments indicate that modes of interaction with audio
were culturally established in our participants, being a standard
reference for intuitive control styles even amongst non-experts.
5.2 User experience with mixer device
In recounting their experiences interacting with the Memetic
Mixer augmented with knobs, faders and presets, participants
perceived a notable difference in the potential range of expres-
sion. There was a new found ability to experiment with different
‚Äúmixes‚Äù of the LLM response, to ‚Äúmorph it through the effects ped-
als, see what else happens. ‚Äù The filter and effects knobs allowed
participants to explore different tones of LLM response. One
shared, ‚Äúthere was a nice kind of play where you could just put
your input in and then just keep dialling. . . like setting something
and then just dialling one thing up or down. Yeah, definitely had a
greater impact. ‚Äù
In exploring the expressive capabilities offered by the mixer
controls, some participants preferred a ‚Äúkind of fine tuning. ‚Äù This
process of ‚Äúrefining the refining‚Äù , as described by one user, al-
lowed users to make precise and nuanced changes to the LLM
response. Another participant however found that ‚Äúit was more
interesting when the parameters were set to extremes, ‚Äù seeing the
obvious changes in tone as ‚Äúmore fun and interesting‚Äù . Experi-
menting with the results from different parameters also provided
incentive for continued interaction. As one participant put it,
‚Äúyou‚Äôre still wanting to work with quite strict parameters to then
see the unpredictable predictability to be interesting‚Äù .
The participants found the idea of a personality mix ‚Äúintu-
itively makes sense for those sliders‚Äù. They were not inhibited by
the lack of instructions for these new control parameters as the
audio interface metaphor made the interaction style immediately
apparent. One participant expressed, ‚ÄúI kind of like that. . . there‚Äôs
no instructions, ‚Äù while another affirmed, ‚Äúto be clear, I would not
read the manual!‚Äù Participants believed an instruction manual
was not necessary for the exploratory and open-ended style of
interaction facilitated by the audio control mechanisms. One elab-
orating on this idea stating, ‚Äúhaving instructions or a manual, like
would be very relevant if you‚Äôre using this, like, very intentionally,
like. . . towards whatever project you‚Äôre working on. I think just for
this, it was good in a way not to‚Äù .
In general, participants believed the audio mixer metaphor
allowed for a more ‚Äúmalleable discussion‚Äù , wherein the mixer
offered more expressive control over the LLM output. There was
a sense of satisfaction in using the controls to ‚Äúshape it in front
of you, ‚Äù which was not possible in the non-mixer iteration of the
device.
6 Discussion
User experiences with the non-mixer LLM device made evident
that the word tiles alone did not provide incentive for ongo-
ing interaction. This problem was largely related to the pred-
icable nature of the LLM responses which did not expand on
user input in the way of ‚Äúbrainstorming‚Äù or providing ‚Äúunconven-
tional combinations‚Äù of concepts. It was interesting to observe
that participants suggested that cross-disciplinary connections
(‚Äútransposing it into. . . different discipline ‚Äù) would potentially offer
more creative value to the interaction. At this stage of the study,
the Memetic Mixer did not exist. This comment was completely
unprompted and stemmed directly from the desires of the partic-
ipants themselves evidencing that they too recognise the value
in cross-disciplinary design.
Just as cross-disciplinary associations arose as a suggestion to
improve the non-mixer device, participants also spontaneously
began to use sound and audio control metaphors to describe a
more fruitful interaction. One participant‚Äôs desire to be able to
‚Äúdial up or down ‚Äù personality traits (K.5) and another‚Äôs suggestion
to integrate ‚Äúknobs and sliders ‚Äù, suggests that the parametrisation
of these gestural controls has become paradigmatic outside of
their use in audio and music.
Comparatively, users were decidedly more positive in describ-
ing their experience using theMemetic Mixer device. Participants
were enthusiastic about the increased level of control over the
LLM output they were offered by the mixer control mechanisms.
The distinct affordances of knobs and faders allowed for both
an exploration of ‚Äúextremes‚Äô‚Äô (K.3) and a more nuanced ‚Äúrefining‚Äù
(K.4). This suggests that the audio mixer controls were effective
in allowing a spectrum of control which was suited to a range
interaction modes.
There was the potential that users unfamiliar with audio and
music paradigms may not have grasped the mixer metaphor, or
found the control mechanisms unintuitive. However, this fear
was calmed by the adamant statement that users did not feel
the necessity for a device manual, nor would they read it if one
was provided. They were of the opinion that a personality mixer
‚Äúintuitively makes sense‚Äù .
The effectiveness of audio paradigms as conceptual tools was
also revealed through the participants‚Äô (unprompted) use of music
metaphors to describe their experiences with the Memetic Mixer
despite the lack of any actual sound or auditory affordances in the
design. Participants spoke of language as akin to ‚Äúchords‚Äù which
they could ‚Äúmorph through. . . effects pedals , ‚Äù rather than describing
the output editing process using technical or dry language. These
sonic descriptions of language suggest that mixer metaphor was
effective enough for the participants to carry the analogy into
their own language use.
Comparing the interviews about user experiences with the
Mimetic Poet (non-mixer device) and the Memetic Mixer made
clear that the personality mixer metaphor greatly improved the
participants‚Äô experience interacting with the LLM. The personal-
ity mixer metaphor was functional in allowing a greater control
of the LLM response and also gave users an embodied agency
in manipulating the text output with gestural knob and fader
controls.
This study did not focus on a goal-oriented interaction with
the Memetic Mixer but allowed users the freedom of open-ended
exploration. In future work, we believe it would be valuable to ex-
plore whether the personality mixer metaphor may be useful for
users with more specific creative goals. It may also be interesting
to explore whether the personality mixer is equally appealing to
creatives who work in audio and musical fields, or whether the
cross-disciplinary metaphors cause cognitive tension to arise.
7 Conclusion
In this paper, we have demonstrated the application of audio and
music metaphors as creative design tools for interaction with non-
musical devices. Beginning from the perspective of the designer,
we outlined the functional affordances of control mechanisms
common to audio mixer consoles: faders, knobs, presets, filters
and effects. We then offered a template of questions to assist in
translating each control paradigm to non-musical disciplines as
design metaphors.
NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia McNamara et al.
Following our exploration of musical metaphors in the design
process, we assessed their effectiveness in user interactions. We
undertook two, week-long ecological studies wherein users ex-
plored using a tangible LLM device, first without, and then with
an audio-mixer control interface. Our study found the audio-
mixer control mechanisms not only afforded participants more
nuanced control of the LLM output, but also allowed them to
consider language metaphorically as a sound they were shaping.
This lead to divergent ideas and an increase in multi-sensory
analogies which are associated with creative activity. The music
and audio metaphors created a more satisfying style of interac-
tion for users and increased incentive for ongoing interaction
with the device.
Overall, applying metaphors and physical control mechanisms
from audio and music to other disciplines proved effective in
guiding our creative process as designers. It also allowed users
an expressive style of interaction with the LLM device due to the
embodied nature of the gestural controls and the cross-sensory
metaphors they inspired.
It is evident that applying knobs, faders and effects will not
make an interface musically expressive if it was not designed
for this function. However, any interface with adjustable param-
eters can be considered through the lens of audio mixing so as
to foster new perspectives and draw on the creative strengths
of the musical domain. We would encourage other designers to
consider how paradigms from musical norms could be applied in
their work. We believe musical expression has much potential to
enrich other fields for its conceptual and functional fullness.
8 Ethical Standards
Our project received competitive funding support from our fed-
eral government‚Äôs main research funding body. Conditions of
funding require that all research undertaken with the funding
meets our country‚Äôs responsible standards of professional re-
search and ethics, which we followed at all times in undertaking
this research.
Our user study with human participants was approved by
our university ethics committee and participation was opt-in
and voluntary. Participant‚Äôs were free to opt-out at any time
and the true nature and purpose of the study was made clear
to participants before seeking their consent, as was the data
collection and privacy requirements. Participants received a small
financial compensation for proving their time and opinions over
two one-hour focus group sessions.
No individual personal data, apart from each participant‚Äôs
name, gender and age was collected from participants and data
sent to OpenAI‚Äôs servers used a role account, not linked to any
individual participant or person. The method of communicating
with the LLM ‚Äì using a small vocabulary of fixed word tiles ‚Äì
meant that no personally identifiable information was sent to
the LLM.
As acknowledged in Section 7, the visual nature of the device
raises issues of accessibility, for example to the blind and low-
vision (BLV) community. We outlined how we would seek to
address this issue in further developments of the research.
Acknowledgments
This research was supported by an Australian Research Council
grant DP220101223. The Mimetic Poet and Memetic Mixer hard-
ware was built by Elliott Wilson.
References
[1] Olivier Bau, Atau Tanaka, and Wendy E Mackay. 2008. The A20: Musical
Metaphors for Interface Design. In Proceedings of the 2008 Conference on New
Interfaces for Musical Expression (NIME08) . University of Genova, Genova,
Italy, 91‚Äì96. https://doi.org/10.5281/zenodo.1179489
[2] Steve Benford, Chris Greenhalgh, Andy Crabtree, Martin Flintham, Brendan
Walker, Joe Marshall, Boriana Koleva, Stefan Rennick Egglestone, Gabriella
Giannachi, Matt Adams, Nick Tandavanitj, and Ju Row Farr. 2013. Performance-
Led Research in the Wild. ACM Trans. Comput.-Hum. Interact. 20, 3 (July 2013),
14:1‚Äì14:22. https://doi.org/10.1145/2491500.2491502
[3] Alan F. Blackwell. 2006. The reification of metaphor as a design tool. ACM
Trans. Comput.-Hum. Interact. 13, 4 (Dec. 2006), 490‚Äì530. https://doi.org/10.
1145/1188816.1188820
[4] Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in
psychology. Qualitative Research in Psychology 3, 2 (Jan. 2006), 77‚Äì101.
https://doi.org/10.1191/1478088706qp063oa Publisher: Routledge _eprint:
https://www.tandfonline.com/doi/pdf/10.1191/1478088706qp063oa.
[5] Virginia Braun and Victoria Clarke. 2022.Thematic Analysis: A Practical Guide .
Sage Publications, London, UK. https://au.sagepub.com/en-gb/oce/thematic-
analysis/book248481
[6] Egon Brunswik. 1956. Perception and the representative design of psychological
experiments (2 ed.). University of California Press, Berkley and Los Angeles,
CA. tex.date-added: 2019-10-31 16:30:31 +1100 tex.date-modified: 2019-10-31
16:43:38 +1100.
[7] Alan Chamberlain, Andy Crabtree, Tom Rodden, Matt Jones, and Yvonne
Rogers. 2012. Research in the wild: understanding ‚Äôin the wild‚Äô approaches to
design and development. In Proceedings of the Designing Interactive Systems
Conference (DIS ‚Äô12) . Association for Computing Machinery, New York, NY,
USA, 795‚Äì796. https://doi.org/10.1145/2317956.2318078
[8] Jorge Cordoba and G.P. Jaramillo. 2012. Inclusion of the Latent Person-
ality Variable in Multinomial Logit Models Using the 16pf Psychometric
Test. Procedia - Social and Behavioral Sciences 54 (Aug. 2012), 169‚Äì178.
https://doi.org/10.1016/j.sbspro.2012.09.736
[9] Paul T. Costa, Jr. and Robert R. McCrae. 1976. Age Differences in Personality
Structure: A Cluster Analytic Approach1. Journal of Gerontology 31, 5 (Sept.
1976), 564‚Äì570. https://doi.org/10.1093/geronj/31.5.564
[10] Andy Coules. 2020. Mixing Evolution: Key Steps In The Journey To The Digital
Console Platform - Page 2 of 2.
[11] David Cronin. 2008. Into the Groove: Lessons from the Desktop Music Revo-
lution. Interactions 15, 3 (May 2008), 72‚Äì78. https://doi.org/10.1145/1353782.
1353800
[12] Luke Dahl and Ge Wang. 2010. Sound Bounce: Physical Metaphors in De-
signing Mobile Music Performance. In Proceedings of the 2010 Conference on
New Interfaces for Musical Expression (NIME 2010) . University of Technology,
Sydney, Australia, 178‚Äì181. https://doi.org/10.5281/zenodo.1177751
[13] Daley Dan. 2004. The Engineers Who Changed Recording.
https://www.soundonsound.com/people/engineers-who-changed-recording.
[14] Colin G. DeYoung, Lena C. Quilty, and Jordan B. Peterson. 2007. Between Facets
and Domains: 10 Aspects of the Big Five. Journal of Personality and Social
Psychology 93, 5 (2007), 880‚Äì896. https://doi.org/10.1037/0022-3514.93.5.880
[15] John M. Digman. 1989. Five Robust Trait Dimensions: Development, Stability,
and Utility. Journal of Personality 57, 2 (1989), 195‚Äì214. https://doi.org/10.
1111/j.1467-6494.1989.tb00480.x
[16] Ashley Gadd and Sidney Fels. 2002. MetaMuse: Metaphors for Expressive
Instruments. In Proceedings of the 2002 Conference on New Instruments for Mu-
sical Expression (NIME-02) . National University of Singapore, Dublin, Ireland,
1‚Äì6.
[17] Steven Gelineck, Dannie Korsgaard, and Morten B√ºchert. 2015. Stage- vs.
Channel-strip Metaphor - Comparing Performance When Adjusting Volume
and Panning of a Single Channel in a Stereo Mix. In NIME 2015: Proceedings
of the International Conference on New Interfaces for Musical Expression . The
School of Music and the Center for Computation and Technology (CCT),
Louisiana State University, Baton Rouge, Louisiana, USA, 343‚Äì346.
[18] Steven Gelineck and Stefania Serafin. 2009. A Quantitative Evaluation of the
Differences Between Knobs and Sliders. In Proceedings of the International
Conference on New Interfaces for Musical Expression . The Carnegie Mellon
School of Music, Pittsburgh, PA, United States, 13‚Äì18.
[19] James J. Gibson. 2014. The Ecological Approach to Visual Perception: Classic
Edition. Psychology Press, New York. https://doi.org/10.4324/9781315740218
[20] Lewis R. Goldberg. 1993. The Structure of Phenotypic Personality Traits.
American Psychologist 48, 1 (1993), 26‚Äì34. https://doi.org/10.1037/0003-066X.
48.1.26
[21] Ricky Graham and Brian Bridges. 2014. Gesture and Embodied Metaphor in
Spatial Music Performance Systems Design. In Proceedings of the International
Conference on New Interfaces for Musical Expression . Goldsmiths, University of
London, Goldsmiths, University of London, UK, 581‚Äì584.
[22] Richard Graham and Brian Bridges. 2015. Managing Musical Complexity with
Embodied Metaphors. In Proceedings of the International Conference on New
Interfaces for Musical Expression (NIME 2015) . The School of Music and the
Center for Computation and Technology (CCT), Louisiana State University,
Baton Rouge, LA, USA, 103‚Äì106.
[23] Hiroshi Ishii. 2008. The tangible user interface and its evolution. Commun.
ACM 51, 6 (June 2008), 32‚Äì36. https://doi.org/10.1145/1349026.1349034
Mixer Metaphors: audio interfaces for non-musical applications NIME ‚Äô25, June 24‚Äì27, 2025, Canberra, Australia
[24] Hiroshi Ishii and Brygg Ullmer. 1997. Tangible bits: towards seamless in-
terfaces between people, bits and atoms. In Proceedings of the ACM SIGCHI
Conference on Human factors in computing systems (CHI ‚Äô97) . Association for
Computing Machinery, New York, NY, USA, 234‚Äì241. https://doi.org/10.1145/
258549.258715
[25] Roey Izhaki. 2023. Faders. In Mixing Audio (4 ed.). Focal Press, New York, 7.
[26] Dave Kapell and Sally Steenland. 1997. The Magnetic Poetry Book of Poetry .
Workman Publishing Company, New York NY. https://www.abebooks.com/
9780761107378/Magnetic-Poetry-Book-Dave-Kapell-0761107371/plp
[27] Jesper Kjeldskov, Jeni Paay, Aleksander Nilsson, Kasper Plejdrup, and Mette
Pedersen. 2020. Spatial Mixer: Cross-Device Interaction for Music Mixing. In
Proceedings of the 31st Australian Conference on Human-Computer-Interaction .
Association for Computing Machinery, Fremantle WA Australia, 85‚Äì94. https:
//doi.org/10.1145/3369457.3369465
[28] Gwendal Le Vaillant and Thierry Dutoit. 2020. Analytic vs. Holistic Ap-
proaches for the Live Search of Sound Presets Using Graphical Interpola-
tion. In Proceedings of the International Conference on New Interfaces for Mu-
sical Expression . Birmingham Cirty University, Birmingham, UK, 227‚Äì232.
https://doi.org/10.5281/zenodo.4813330
[29] Pete Mandik. 2023. Sliders. Journal of Consciousness Studies 30, 9 (Sept. 2023),
154‚Äì163. https://doi.org/10.53765/20512201.30.9.154
[30] Jon McCormack, Elliott Wilson, Nina Rajcic, and Maria Teresa Llano.
2024. Mimetic Poet. In Proceedings of 15th International Conference on
Computational Creativity, ICCC‚Äô24 . ICCC, J√∂nk√∂ping, Sweden. https://
computationalcreativity.net/iccc24/papers/ICCC24_paper_133.pdf
[31] Robert R. McCrae, Jr. Costa, Paul T., and Thomas A. Martin. 2005. The
NEO‚ÄìPI‚Äì3: A More Readable Revised NEO Personality Inventory. Journal of
Personality Assessment 84, 3 (June 2005), 261‚Äì270. https://doi.org/10.1207/
s15327752jpa8403_05
[32] Robert R. McCrae and Paul T. Costa. 1987. Validation of the Five-Factor Model
of Personality across Instruments and Observers. Journal of Personality and
Social Psychology 52, 1 (1987), 81‚Äì90. https://doi.org/10.1037/0022-3514.52.1.81
[33] McCrae, Robert R and Costa, Paul T. Jr. 1986. Clinical Assessment Can Benefit
From Recent Advances In Personality Psychology. American Psychologist 41,
9 (Sept. 1986), 1001‚Äì1003.
[34] David Mellor. 2006. Broadcast Practice - Why Should Faders Work the Wrong
Way Round? https://www.audiomasterclass.com/blog/broadcast-practice-
why-should-faders-work-the-wrong-way-round.
[35] Landon Morrison and Andrew McPherson. 2024. Entangling Entanglement:
A Diffractive Dialogue on HCI and Musical Interactions. In Proceedings of
the CHI Conference on Human Factors in Computing Systems (CHI ‚Äô24) . ACM,
Honolulu HI USA, 1‚Äì17. https://doi.org/10.1145/3613904.3642171
[36] Mitchel Resnick, Brad Myers, Kumiyo Nakakoji, Ben Shneiderman, Randy
Pausch, Ted Selker, and Mike Eisenberg. 2005. Design Principles for Tools to
Support Creative Thinking.
[37] Beat Rossmy. 2022. Buttons, Sliders, and Keys ‚Äì A Survey on Musical Grid
Interface Standards. In International Conference on New Interfaces for Musical
Expression. The University of Auckland, Auckland, New Zealand, 2‚Äì15. https:
//doi.org/10.21428/92fbeb44.563bfea9
[38] Shneiderman. 1983. Direct Manipulation: A Step Beyond Programming Lan-
guages. Computer 16, 8 (Aug. 1983), 57‚Äì69. https://doi.org/10.1109/MC.1983.
1654471 Conference Name: Computer.
[39] David Silverstein. 2017. The Pioneers of Audio Engineering: Tom Dowd
‚Äî SonicScoop. https://sonicscoop.com/pioneers-audio-engineering-tom-
dowd/,https://sonicscoop.com/pioneers-audio-engineering-tom-dowd/ Sec-
tion: Producer Profile.
[40] David Taylor. 2021. 1960‚Äôs ‚Äì Pye Broadcast Audio Consoles | Part Four: The
Innovative Pye Transistor Tv Studio Mixer. https://postfade.co.uk/1960s-pye-
broadcast-audio-consoles-part-four-the-innovative-pye-transistor-tv-studio-
mixer/.
[41] B. Ullmer and H. Ishii. 2000. Emerging frameworks for tangible user interfaces.
IBM Syst. J. 39, 3-4 (July 2000), 915‚Äì931. https://doi.org/10.1147/sj.393.0915
[42] Si Waite. 2016. Church Belles: An Interactive System and Composition Us-
ing Real-World Metaphors. InInternational Conference on New Interfaces for
Musical Expression . Queensland Conservatorium Griffith University, Griffith
University Australia, 265‚Äì270.
[43] David Wessel, Matthew Wright, and John Schott. 2002-05-24/2002-05-26. Inti-
mate Musical Control of Computers with a Variety of Controllers and Gesture
Mapping Metaphors. In Proceedings of the 2002 Conference on New Instruments
for Musical Expression (NIME-02) . National University of Singapore, Dublin,
Ireland, 1‚Äì3.
[44] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Trans-
parent and Controllable Human-AI Interaction by Chaining Large Language
Model Prompts. In Proceedings of the 2022 CHI Conference on Human Factors
in Computing Systems (CHI ‚Äô22) . Association for Computing Machinery, New
York, NY, USA, 1‚Äì22. https://doi.org/10.1145/3491102.3517582