Occupational Therapy Methods in the Design of Accessible Musical Instruments   Andrew McMillan Te Whare o ngā Pūkōrero Pūoro Waipapa Taumata Rau Aotearoa (New Zealand) drewmcm@blackbridge.co.nz 
Fabio Morreale Te Whare o ngā Pūkōrero Pūoro  Waipapa Taumata Rau Aotearoa (New Zealand) f.morreale@auckland.ac.nz  
 
ABSTRACT This study explores the integration of Occupational Therapy techniques within the evaluation of movement and functionality concerning users of Accessible Musical Instruments (AMI). It examines the current application of these techniques in design methodologies and contemplates their potential adaptation and incorporation into AMI design. The paper presents findings derived from a conventional occupational therapy approach alongside two inquiries that modify and expand upon this approach through the integration of sensor technologies. The outcomes of two tasks, each employing sensor technology to gauge and appraise movement and functionality, are presented. These findings are to illustrate how designers can integrate methodologies pertaining to the analysis of a range of movement and functionality within their design frameworks.  Author Keywords Accessibility, DMI Design, Disability studies  CCS Concepts • Applied computing → Sound and music computing; Performing arts; • Information systems → Music retrieval;  1. INTRODUCTION Accessible Musical Instruments (AMIs) are adapted, augmented, or bespoke musical instruments designed to assist musicians with physical, neurological or other limitations in the activity of music making. The focus of these designs is to promote inclusivity [17] and participation [23] and to offer assistance in therapy and Special Educational Needs (SEN) settings [27]. Through inclusivity and participation, musicians who have either become disabled or were born with impairments have been able to continue, develop, or begin their creative practice. With a few notable exceptions, AMI design methods are typically adaptations of those adopted in Digital Musical Instruments (DMIs).  We argue that design methods specific to AMIs could be devised to better analyse the complexity surrounding individual needs. In particular, we found limited engagement with how to identify specific limitations of movement, functionality, and other areas related to an individual’s disabled identity.  This limitation is significant as bespoke instruments are usually designed for a specific musician, as the needs and physical limitations of any disabled or limited-ability musician are quite different. Even within the same class of disability (e.g. spinal cord injury), every person has unique and specific 
limitations to their movements and how they can access them. Due to these distinctive qualities, the design of AMI necessitates a comprehensive understanding of movements and functionalities that aligns with the musician-instrument relationship goals [20], performance strategies, and technological solutions. This objective requires a thorough evaluation of each individual user. We contend that it is crucial to discern which assessment methods are used to determine how unique individuals’ qualities are mapped to technological solutions in the design process. Occupation Therapy (OT) methods are traditionally used to address this uniqueness through activities, questionnaires or task-orientated tests [4]. Despite the obvious potential use of these methods for AMI, we found a surprising lack of engagement with such methods to assess movement and functionality in AMI design. In this paper, we therefore propose two approaches to understanding movement and functionality that are based on and extend upon OT methods. The first approach adapts a standard OT upper limb test method, the CUE-Test (Capabilities of Upper Extremity Test). For the second approach, we propose sensor technologies that are often embedded into bespoke AMIs to assess musicians’ movements and functionalities. While they are normally used to detect musicians’ gestures, we used those sensors to collect data on specific movements and functionalities. We then use this information in combination with musicians’ reflections on their bodily gestures and how they might be used to achieve their musical intentionalities. In the rest of the paper, we first cover the background of AMI and OT methods. Then, we present our two proposed methods and offer considerations around presenting a range of movement and functionality in discussions around AMI design. Finally, we delve into the outcomes and explore potential approaches for presenting the range of movement and functionality when discussing AMI design. 2. BACKGROUND 2.1 Accessible Musical Instrument Design Digitalisation and embedded computing resulted in a revamped interest in AMIs. However, similarly to other NIMEs [26], AMIs have a rich and diverse history that predates the digital era. For example, the Rhodes electric piano was designed to be used by patients in hospital beds during World War II [7]. After a stroke, Rhasan Roland Kirk was still able to perform on his tenor saxophone with one hand because he had had it adapted prior so he could play more than one saxophone at once [29]. Fast forward to the current time, while conventional instruments are still being adapted and developed for “generic” 
NIME’24, September 4–6, 2024, Utrecht, The Netherlands
Licensed  under a Creative Commons Attribution 4.0 International License (CC BY 4.0). Copyright remains with the author(s).
disabled musicians (e.g. OHMI1 and Meru2), an increasing number of designers are working on developing bespoke instruments that are designed specifically for one user. Collaboration with disabled artists is necessary to address the specific needs, physical limitations, and functional movements of any disabled person as they differ from the next. Due to these highly individual needs, creating instruments with generic inputs and outputs that can easily adapt to a wide range of users in AMI can indeed be problematic. Each individual has unique and specific limitations to their movements and how they can access them. Designing for and with disabled musicians is thus becoming increasingly popular at NIME and related communities such as Drake Music3, OHMI, Open Orchestras4, and Enabling Devices5, to name a few. Communities supporting the engagement and activities associated with inclusion and participation (e.g. Mapura Music6 and Open Up Music7) may not necessarily develop new designs but play an important part in promoting access to music making. The maturity of AMI as a disciplinary field at the intersection of NIME, Human-Computer Interaction [22], and Disability Studies [13] is witnessed by the increasing number of scholarly publications aimed at identifying design methods for this category of instruments termed Accessible Digital Musical Instruments (ADMIs) [18] when they include sensors and digital technologies.  Frid and Lisar compiled a survey on ADMI [9], and Frid has also reviewed ADMI interfaces in inclusive music [8]. These studies identified categories of technologies that apply to AMI, which offer a valuable resource for designers to explore when considering technological solutions. Other research, such as that by Ward [28], provides designers with a toolkit, a framework and individual ADMI through participatory design and action research. In the article, Ward provides both broad and refined insight into design practices and methods around design and how users or stakeholders are defined and engaged within the process.  Examining unique instrumentation and methodologies devised by designers in ADMI has provided significant insights regarding their handling of defining target user groups and refining design practices and results. For elucidating the specific nuances of bespoke ADMI applications, investigating examples from particular designer portfolios serves as a useful resource. One such example is the online catalogue of existing instruments and design methods by Harrison8. Harrison provides examples and documentation of current projects: Strummi, the one-handed bass guitar, StroBeat, and the One Button MIDI Controller. He also provides links to the literature related to some of those projects [10,11]. Additional studies delving into the evolution of interfaces to enhance accessibility for individuals with disabilities tend to comprehend the ecosystems within which these interfaces operate, as well as the frameworks employed in their design [17,18,25]. These contributions seek to increase our understanding of inclusivity and participation in design and creative practice. Each project or investigation looks at defining individuals and communities involved in ADMI participation and how they interact with current design interfaces, instruments, whole ecologies, or frameworks. This work is well supported by a number of recent surveys [9, 16].   1 https://www.ohmi.org.uk/instruments.html 2 https://www.merushop.org/meru-creations-helping-disabled-people-play-musical-instruments/ 3 https://www.drakemusic.org/ 4 https://www.openorchestras.org/ 
Larsen and colleagues [16], in particular, extend the survey of technologies into the current state of developments in technology and music therapies associated with them, along with recent trends in the area of ADMI use. This survey highlights the dynamic evolution of AMI and ADMI creation and how it results in ongoing scrutiny of design practices, frameworks, and ethical considerations regarding participation. This continual assessment takes place through various avenues, including forums, articles published in journals, conferences, workshops, concerts, and a range of formal and informal events. The AMI community is committed to improving access to music-making and creative expression for people with disabilities, and, with the few resources available, providing valuable opportunities for the artists they serve. The sheer number of unique and individual designs demonstrates how creating bespoke instruments seems to be necessary to serve individual needs. These instruments require commitment from designers who can orientate well towards participatory design to be successful [2,16,17,28]. Given the distinctive and unique relationships existing between designers and participating artists, the sharing of knowledge of each design process assists the wider community in developing their own methodologies and designs. In the related work, stakeholders, target users, or participating artists are mostly mentioned and defined as being important and valuable contributors to designs or methods. However, when it comes to defining individuals or groups with disabilities, the terms are often broad. In the literature we reviewed, there is minimal focus on specifics around a disabled person’s limited movement or function and how these are assessed. Some articles specifically describe musicians’ abilities, for instance, the capability to move a hand, extend fingers, and use a pincer grip [17]. Other descriptions include conditions such as cerebral palsy, stroke, amputation [16,17], using a manual wheelchair, dancing with an intellectual disability [2], neurodiversity, impaired motor function in one’s hands, having learning disabilities and right-hand impairment [12]. [2] refers to social construct, cultural engagements, and power imbalances discussed by [1] before defining people as manual wheelchair users or dancers with an intellectual disability. Each of those descriptions sit within a category of various impairments or medical descriptions but provides little insight into the specifics around a range of movement or functionality.  Providing these examples underscores the infrequency of explicitly disclosing specific movement ranges and functions, as well as what assessment methods have been used, which are not common parts of discussions around design creation or evaluation. We argue that such limitation is significant when considering that ADMI require specific and nuanced movements and interactions to serve target users. It seems plausible that designers and participants invest substantial effort in investigating how the interactions with the instrument will occur and how user interactions will best serve their performance strategies and musician-instrument relationship [20]. However, the mechanisms underpinning those decision-making processes remain largely overlooked within academic writings. 
5 https://enablingdevices.com/product-category/adapted-toys-games/adapted-musical-instruments/ 6 http://www.mapurastudios.org.nz/mapura-music-group 7 https://www.openupmusic.org/ 8 https://jtfh.wordpress.com/about/ 
2.2 Occupational Therapy Occupational Therapy (OT) methods provide insights into participants’ movements and functionality. The methods are mainly task-focused and orientated around domestic situations where a person needs to be assessed for how they will navigate their interactions with objects and places around the home, office, or other environments. Some examples of those methods are the CUE (Capabilities of Upper Extremity)9 and WOLF tests10. These tests are used to assess an individual’s ability to carry out tasks, including lifting and manipulating objects or doing repetitive movements. The tasks are monitored by a physiotherapist or an occupational therapist who records the results. These results can be used as part of rehabilitation or to assess an individual’s ability, safety, and what assistance they may need at home. This assistance might either be a person (caregiver) or some form of disability equipment. In addition to assessment methods, OT also has its own assessment tools, such as the Goniometer, a device to measure the angles of limbs, and the Dynamometer, which measures grip pressure. The therapist would note ranges of angle from the Goniometer or the amount of pressure from grasping the Dynamometer. When observing whether tasks can be completed, they would add details such as how they are completed, how many repetitions, or what strength/weight is required.  Chan and colleagues [5] created a toolkit with an extensive range of existing OT methods for therapists to access through one resource on a website called Outcome Measures11. Researchers and some therapists have increasingly incorporated wearable sensor technologies not only to assess patients, clients, or participants but also to be able to monitor their progress and work. This can be extended to the home environment towards tracking goals and outcomes [15]. This area includes using camera technology available on domestic devices, such as webcams on computers and tablets[14].  Ergonomics and methods of occupational therapy have been adopted in certain areas related to design processes. [6] reviewed practices around anthropometric ergonomics in design. Even with the advent of 2-D and 3-D modelling, they found there is a lack of guidelines and standardisation across the field of methodologies in this area, especially regarding user-centric products or environments. Branowski and colleagues [3] highlighted the challenges inherent in conventional ergonomic anthropometric measurement techniques for determining reach zones applicable to wheelchair users. This discrepancy arises because typical correlations linking standing individuals’ upper reach capabilities and stature differ substantially and irregularly among persons seated in wheelchairs. Specifically, the researchers concentrate on analysing the upper limb reach and force generation potential exhibited by wheelchair occupants. Through the aforementioned analysis, they create a 3-D model and discuss how those results could be applied to improve commercial spaces (e.g. supermarket isles, automobile interiors) for wheelchair users. Additionally, in 2012, Veytizou and colleagues [25] explored utilising 3D modelling to create a user-
  9 https://www.jefferson.edu/academics/colleges-schools-institutes/rehabilitation-sciences/departments/outcomes-measurement/measures-assessments/upper-extremity-test-cue-t.html 
focused design method that enabled disabled musicians to play acoustic instruments. Their technique includes using the Kinect device to record motion scope and rate, forming a 3D depiction of an individual’s efficient and accessible movement spectrum critical for designing suitable adaptations. 3. OT METHODS FOR AMI The methods outlined in this section were identified and developed by leveraging the lived experience of Andrew, the first author, who is a musician with a disability. Throughout the years, he has undergone many sessions of assessment using some OT methods such as ASIA, an assessment of range, strength, and sensation undertaken by a physiotherapist, and WOLF, a task-orientated test involving moving and manipulating objects. Recently, he has been assessed using the CUE-Test to see what upper limb movements and functions he could match with his performance strategies and musical interfaces and technologies. Understanding those performance strategies came through reflective practice associated with past repertoire of pre-accident and disability recordings. 3.1 CUE-Test Andrew initially worked with an occupational therapist using standard OT methods to start identifying ranges of movement and functionality. For his assessment, the occupational therapist and Andrew opted for the Capabilities of Upper Extremity Test (CUE-Test) as it was deemed the best fit for gathering data on Andrew’s upper limb mobility. The test required him to carry out repeated movements over a period of time (usually 30 seconds). Other tasks required him to grasp, manipulate, or move an object or push, pull, or lift an object or weight. For each one of those tasks, the OT kept an account of whether they were able to be carried out at all, the number of repetitions within the time, as well as the amount of weight or pressure. One of the more insightful discoveries was being able to recognise and measure actions, movements, or functions Andrew cannot perform. Table 1 shows the results of the test. Although the CUE-Test gave some insight into available and non-available movements as well as on some function and weight strengths, it only provided a broad understanding rather than a nuanced account required when designing a bespoken AMI. It is of particular interest to note any discrepancies between the left and right arm and actions that cannot be done.  Though the CUE-Test offered preliminary perception about achievable versus constrained movements, along with rudimentary comprehension of functional capabilities and torque aptitudes, it failed to deliver the granular perspectives necessary for crafting customised AMIs. Noteworthy distinctions between bilateral arm proficiencies and incapacitated manoeuvres constitute vital details requiring further scrutiny to ensure effective design tailored to meet specific requirements.     
10 https://strokengine.ca/en/assessments/wmft/ 11 https://scireproject.com/outcome-measures/ 
Table 1 Results from the CUE-Test Task Right arm Left arm Notes Reach Forward (reps over 30s) 22 28   Reach Up (reps over 30s) 13 24   Reach Down (reps over 30s) 6 11   Lift Up (force in kg) 2 2   Push Downs   Cannot complete Wrist Up (extension)   Cannot complete Grasp Dynamometer (acquire) no Yes Ability to get fingers around Dynamometer  Grasp Dynameter (release) no No Ability to let go of Dynamometer  Grasp Dynameter (force in kg) 0 0  Lat. Pinch (credit card)   Unable to hold Lat. Pinch (force) 0 0   Pull Weight (in kg) 4 4   Push Weight (in kg) 4 4   Able to get fingers around the top of container lid - no specific size determined  Acquire no no   Release no no   Container Lift (weight) no no Unable to lift L or R Hand Pinch, Hold, and Move to marker and back     Pinch Die (dice) no yes/partial LH partial completion of one Pencil (grasp, put down - reps) no no Unable to grasp with L or R Hand Manipulate Pencil - 360 deg Turn   Unable to do with L or R Had Push index finger on calculator buttons 22.6 22 RH using 5th knuckle; LH uses 4th finger tip Push buttons on cell phone with thumb (seconds) 10s 19s RH using 5th knuckle; LH uses 4th finger tip 3.2 Sensors as OT Assessment Tools This section introduces two tasks we designed to extend OT techniques. In the first task, we used an ultrasonic sensor to create a model of measurements for the range of each arm at various points. This information, similar to [25], provides us with Andrew’s workable range limit. In the second task, we mounted an analogue slider or fader in a way that enabled us to move to various points around Andrew’s seating position. This task was to better understand the speed and accuracy of the object at various positions. 3.2.1 Ultrasonic Sensor to Measure Arm Movement To begin with, we used an ultrasonic sensor placed at various points directly in front of Andrew. A shield was attached to his hand so the ultrasonic sensor could measure how close he could position his hand towards it., The ultrasonic sensor was moved through 10cm points in a straight line horizontally opposed to his body. The ultrasonic sensor was set at a height of 103cm, the same height as the sternum in Andrew’s seated position. This provided us with readings, which are presented in Table 2, from which we could then create a visual model. The visual model- Figure 2- shows the Person-to-Point (PTP) measurements, in which the person is taken from Andrew’s sternum, and the point 
is the position in which the reach was measured. Those measurements helped us understand an area of range of motion that should be considered usable within the design process. The metric used when measuring ergonomics and positioning is usually the Seat Reference Point. This measurement is normally taken from the centre of the backrest to the position of the object measured. However, we adapted this method based on the position of Andrew to the object, which we termed Person Reference to Position. In order to measure the range of each arm, the ultrasonic sensor was positioned on the movable trolley 77cm in front of him at an X point ranging between 90cm to the left and 90cm to the right of the centre. At each position, Andrew moved his arm towards the sensor until the lowest number was recorded, measuring the length of the range of reach. After a position was recorded, the ultrasonic sensor was moved horizontally 10cm, either left or right from the centre, until Andrew was unable to reach towards the sensor to create a usable reading. Table 2 shows the recorded results and how they were scaled up for graphic modelling coded using Processing 4, and Figure 3 shows a visual representation of this data in a two-dimensional space.   
Table 2. Range of arm movement using an ultrasonic sensor data table. Person is the sternum of Andrew at a Height, ‘Y’ of 103cm from the floor. X is the position of the sensor - placed on a movable trolley - along the horizontal line from the centre of the person, or sternum. Point is the range measured by the Ultrasonic Sensor giving the result: Z. LEFT HAND  RIGHT HAND Person Y X Point Z Person Y X Point Z 77 103 30 60 17 77 103 -30 38 39 77 103 20 47 30 77 103 -20 39 38 77 103 10 39 38 77 103 -10 48 29 77 103 0 33 44 77 103 0 34 43 77 103 -10 30 47 77 103 10 31 46 77 103 -20 28 49 77 103 20 34 43 77 103 -30 29 48 77 103 30 36 41 77 103 -40 31 46 77 103 40 35 42 77 103 -50 33 44 77 103 50 37 40 77 103 -60 35 42 77 103 60 44 33 77 103 -70 37 40 77 103 70 50 27 77 103 -80 42 35 77 103 80 50 27 77 103 -90 52 25 77 103 90 54 23    
 Figure 1. Setup to measure range of arm movement using ultrasonic sensor 
 Figure 2. Graphic model from results of ultrasonic sensor measurements 3.2.2 Analogue Fader and Time to Target Test For the second analysis, we created a bracket to which we attached an analogue fader. We were able to position the fader at various points, creating variable PTP measurements and targets to measure timings to within an acceptable margin of the target. This information can be used to assist in understanding what positions and points are best for accessing an accurate range of motion/movement or functionality. In this investigation, the 
analogue slider or fader was connected to an Arduino, which uploaded data to a Max/MSP patch recording all positions of the fader in real time, and output visual representations for when the target was at a set number with an acceptable margin below and above.  
 Figure 3. Analogue fader on bracket setup for time to target test – from above 
 Figure 4. Analogue fader on bracket setup for time to target test – from side The images in Figures 4 and 5 show the fader mounted - with an Arduino Uno unit stored inside the steel box - at a position we measured from various points. In this instance, we were 

measuring the position of the body on the object and the position of the object on the chair/frame. In order to achieve this, we measured various points from Andrew’s shoulder, creating a Shoulder Reference to Position. The points were: • Middle of right shoulder - middle line of the slider in the ‘0’ lowest position & ‘1023’ highest position: Shoulder Slider Point. • Centre line of aluminium frame/bracket - middle of the slider in the ‘0’ lowest position: Centre of Frame to Slider. • Centreline of aluminium frame/bracket to the position of the inner edge of steel box: Centre of Frame to Box. • Distance between aluminium frame/bracket and bottom of the steel box: Height from Frame to Box By knowing the exact dimensions of the box and fader/slider, we could accurately reposition them at their previous locations for repeated testing or for setting up prototypes. When the visual reference, a square on the computer screen, was showing green, it meant that the target, within the margins, had been reached, and timing would stop. This showed the time it took to reach the target. By inspecting the Max/MSP console, extra data was available showing how long was spent under the target and overshooting the target until the target was reached and settled. 4. DISCUSSION Using the current OT methods can play an important role in understanding the basics around a person’s available movements and functions. Numerous methodologies are currently accessible through an online toolkit known as Outcome Measures, established based on research conducted by [5]. Those methodologies serve the purpose of evaluating an individual’s movement and functionality. In the context of design application, designers may contemplate accessing archival data or collaborating with a therapist at the outset of the design endeavour to incorporate those assessments effectively. We also found that current OT methods can play an important part in understanding fundamental grasps of an individual’s attainable movements and operational faculties. Accessing historical records or working with a therapist at the beginning of the design process can be useful to assist in the beginning of forming ideas of movement and functions related to how a design might take shape. Involving an occupational therapist in the AMI design process proves beneficial not only for gathering information through assessment but also for fostering a deeper understanding of the nuances involved in analysing movement and function for AMI. This holds true for all parties involved, including the designer, participant, and therapist. The CUE-Test additionally supplied an analysis of movements, offering promising potential to be used in the design process of AMI. The ability to list, categorise, and describe those movements offered useful perspectives, aiding in the avoidance of interfaces and sensor technologies that might prove impractical or unusable. These results serve as a foundational standpoint for future development and design, providing valuable insights to be shared with fellow designers within the community for ongoing work and advancement. Although valuable, the current methods in OT are indeed not specifically aligned with the nuances of creating bespoke instruments. We found we needed to extend or adapt methods to gain a more specific insightful range of movement and function data. As standard occupational therapy methods are being enhanced with wearable devices and sensors [15,16], and 2D and 3D modelling of ergonomics is possible [3,6,25], ADMI designers can utilise existing research and technology to develop methods of assessment in their design process. OT methods might have been used in related AMI work but were not disclosed. To the best of our knowledge, discussions 
regarding bespoke instruments or the development of new or extended practices and methods specifically for the design of such instruments have not been shared [2,11,12,16,17,28]. We believe that sharing this part of the process would benefit many across the design community. Presently, designers share insights into their participatory design methods by utilising prototypes and engaging in discussions about interactions during development. This approach, commonly known as design probes [24], is a prevalent method. However, we contend that divulging specific movements, functions, or assessment methods related to participant artists, users, or designers will significantly contribute to advancing the understanding of target users within the ADMI design community. Finally, our final investigations that employed the ultrasonic sensor to discover a range of movement enabled us to model a functional space within which an instrument can be made accessible. Using the analogue fader as an assessment tool ensures we can experiment with Position-to-Target or -Point outcomes and directly apply them to the instrument. This approach is reliable and functional, leverages the accessibility of the already-built sensor, and demonstrates how sensors can be used as design tools to assess movement and functionality as an extension or adaptation of occupational therapy methods. 5. CONCLUSION This research significantly adds to the discourse on the adaptation and extension of Occupational Therapy methods to cater for the unique demands and intricacies associated with Digital Musical Instruments (DMI), Accessible Musical Instruments (AMI), and Accessible Digital Musical Instruments (ADMI). A key emphasis of our work lies in advocating for the utilisation of existing sensors and technology, recognising them as valuable opportunities within this domain. Looking ahead, our future endeavours involve expanding the dataset by incorporating additional Person-to-Point positions. We aim to develop more sophisticated methods that leverage sensors and tools specifically tailored to the nuanced requirements of DMI/AMI. This expansion aims to enhance our capacity for assessing movements and functionality in a more comprehensive manner. The overarching objective is to foster a collaborative and informative environment within the DMI/AMI community. We aspire to share these evolving practices and methods through in-depth discussions focused on the design and advancement of DMIs and AMIs. 6. ETHICAL STANDARDS The authors do not identify any other conflicts of interest or any other ethical issues identified in [21] in relation to this work. Generative AI tools were only used to check grammar and for linguistic refinement. 7. REFERENCES [1] G. Armagno, ‘The Role of HCI in the Construction of Disability’, presented at the The 26th BCS Conference on Human Computer Interaction, BCS Learning & Development, (2012).  [2] A. Best-Dunkley, ‘The Wind Is the Power: Social Empowerment for Disabled Performers Through Development and Performance of Personalised New Musical Interfaces’, SYNNYT/ORIGINS, vol. 2018, no. 2, pp. 1–24, (2018) [3] B. Branowski, L. Pacholski, M. Rychlik, M. Zabłocki, and P. Pohl, Studies on a New Concept of 3D Data Integration about Reaches and Forces of a Disabled Person on a Wheelchair (CAD Methods in Car and Market Ergonomics), Human Factors and Ergonomics in 
Manufacturing & Service Industries, vol. 23, no. 4, pp. 255–266, (2013). [4] J. Creek, N. Pollard, & M. Allen, (Eds.). Theorising occupational therapy practice in diverse settings. Routledge. 2023 [5] C. W. L. Chan, W. C. Miller, M. Querée, V. K. Noonan, D. L. Wolfe, and SCIRE Research Team, The development of an outcome measures toolkit for spinal cord injury rehabilitation, Can J Occup Ther, vol. 84, no. 2, pp. 119–129, (2017). [6] I. Dianat, J. Molenbroek, and H. I. Castellucci, A review of the methodology and applications of anthropometry in ergonomics and product design, Ergonomics, vol. 61, no. 12, pp. 1696–1720, (2018). [7] M. Elissa and A. Barona, ‘The Fender Rhodes’, SoundGirls.org. Accessed: 5 Feb 2024. Available: https://soundgirls.org/the-fender-rhodes/ (nd) [8] E. Frid, Accessible Digital Musical Instruments - A Survey of Inclusive Instruments Presented at the NIME, SMC and ICMC Conferences, In Proceedings of the International Computer Music Conference. (2018). [9] E. Frid and A. Ilsar, ‘Reimagining (Accessible) Digital Musical Instruments: A Survey on Electronic Music-Making Tools’, in International Conference on New Interfaces for Musical Expression (NIME), (2021). [10] J. Harrison and A. P. McPherson, Adapting the Bass Guitar for One-Handed Playing, Journal of New Music Research, vol. 46, no. 3, pp. 270–285, (Jul. 2017). [11] J. Harrison, R. Jack, F. Morreale, and A. McPherson, When is a Guitar not a Guitar? Cultural Form, Input Modality and Expertise, in International Conference on New Interfaces for Musical Expression (NIME), (2018). [12] J. Harrison, A. Chamberlain, and A. P. McPherson, Accessible Instruments in the Wild: Engaging with a Community of Learning-Disabled Musicians, in CHI EA ’19. New York, NY, USA: Association for Computing Machinery, (2019). [13] R. Jack, J. Harrison, and A. Mcpherson, ‘Digital Musical Instruments as Research Products’, In Proceedings of the International Computer Music Conference. (2020). [14] W.S. Kim, S. Cho, D. Baek, H. Bang, and N.-J. Paik, Upper Extremity Functional Evaluation by Fugl-Meyer Assessment Scoring Using Depth-Sensing Camera in Hemiplegic Stroke Patients, PLoS One, vol. 11, no. 7, p. e0158640, (2016). [15] G. J. Kim, A. Parnandi, S. Eva, and H. Schambra, The use of wearable sensors to assess and treat the upper extremity after stroke: a scoping review, Disability and Rehabilitation, vol. 44, no. 20, pp. 6119–6138, (2022). [16] J. V. Larsen, D. Overholt, and T. B. Moeslund, The Prospects of Musical Instruments For People with Physical Disabilities: New Interfaces for Musical Expression, International Conference on New Interfaces for Musical Expression (NIME), (2016.)  
[17] A. Lucas, M. Ortiz, and F. Schroeder, Bespoke Design for Inclusive Music: The Challenges of Evaluation, in International Conference on New Interfaces for Musical Expression (NIME), (2019) [18] A. Lucas, J. Harrison, F. Schroeder, and M. Ortiz, Cross-Pollinating Ecological Perspectives in ADMI Design and Evaluation, International Conference on New Interfaces for Musical Expression, (2021)  [19] R. J. Marino, S. B. Kern, B. Leiby, M. Schmidt-Read, and M. J. Mulcahey, Reliability and validity of the capabilities of upper extremity test (CUE-T) in subjects with chronic spinal cord injury, The Journal of Spinal Cord Medicine, vol. 38, no. 4, pp. 498–504, (2015). [20] A. McMillan and F. Morreale, Designing accessible musical instruments by addressing musician-instrument relationships, Frontiers in Computer Science, vol. 5, (2023). [21] F. Morreale, N. Gold, C. Chevalier, & R. Masu, (2023). NIME Principles & Code of Practice on Ethical Research (1.1). Zenodo. https://doi.org/10.5281/zenodo.7545682 [22] N. Orio, N. Schnell, and M. M. Wanderley, Input Devices for Musical Expression: Borrowing Tools from HCI, arXiv:2010.01571. (2020) [23] K. Samuels and F. Schroeder, Performance without Barriers: Improvising with Inclusive and Accessible Digital Musical Instruments, Contemporary Music Review, vol. 38, no. 5, pp. 476–489, (2019). [24] K. Tahıroğlu, T. Magnusson, A. Parkinson, I. Garrelfs, and A. Tanaka, Digital Musical Instruments as Probes: How computation changes the mode-of-being of musical instruments, Organised Sound, vol. 25, no. 1, pp. 64–74, (Apr. 2020). [25] J. Veytizou, C. Magnier, F. Villeneuve, and G. Thomann, Integrating the human factors characterization of disabled users in a design method. Application to an interface for playing acoustic music, Association for the Advancement of Modelling and Simulation Techniques in Enterprises, vol. 73, no. Issue 3, p. 173, (2012). [26] M. Wanderley, Prehistoric NIME: Revisiting Research on New Musical Interfaces in the Computer Music Community before NIME, in International Conference on New Interfaces for Musical Expression (NIME), NIME, (2023) [27] A. Ward, L. Woodbury, and T. Davis, Design Considerations for Instruments for Users with Complex Needs in SEN Settings, International Conference on New Interfaces for Musical Expression (NIME), (2017) [28] A. Ward, The development of a Modular Accessible Musical Instrument Technology Toolkit using action research, Frontiers in Computer Science, vol. 5, (2023) [29] J. S. Wilson, Rahsaan Kirk Comes Back Strong, The New York Times. Accessed: 2 Feb 2024. Available https://www.nytimes.com/1976/07/23/archives/new-jersey-weekly-rahsaan-kirk-comes-back-strong.html , (1976) 