Seaboard: a new piano keyboard-related interface
combining discrete and continuous control
Roland Lamb
Design Products Department
School of Architecture and Design
Royal College of Art
Kensington Gore,
London SW7 2EU
roland.lamb@network.rca.ac.uk
Andrew N. Robertson
Centre for Digital Music,
School of Computer Science and Electronic
Engineering,
Queen Mary University of London,
Mile End Road, London, E1 4NS
andrew.robertson@eecs.qmul.ac.uk
ABSTRACT
This paper introduces the Seaboard, a new tangible musical
instrument which aims to provide musicians with signiﬁcant
capability to manipulate sound in real-time in a musically
intuitive way. It introduces the core design features which
make the Seaboard unique, and describes the motivation
and rationale behind the design. The fundamental approach
to dealing with problems associated with discrete and con-
tinuous inputs is summarized.
Keywords
Piano keyboard-related interface, continuous and discrete
control, haptic feedback, Human-Computer Interaction (HCI)
1. INTRODUCTION
The Seaboard is a new musical instrument which enables
real-time continuous polyphonic control of pitch, amplitude
and timbral variation. This novel tangible interface was
invented, designed and developed by Roland Lamb, in the
context of his studies in the Design Products Department at
the Royal College of Art. During the software development
stage of the third prototype, Andrew Robertson joined the
project to assist with the software design and implementa-
tion. The initial motivation for the Seaboard came from
the desire to augment the capabilities of the piano and, in
particular, to combine the capacity for real-time polyphonic
expression with the ability to bend the pitch of every note
independently.
Keyboard controllers have been designed with the acous-
tic piano keyboard as the interface paradigm on which they
are based. Many electronic keyboards have pitch wheels
which add pitch-bending capabilities. Pitch wheels, how-
ever, are of limited use for serious musical performance and
do not enable real-time note-by-note polyphonic pitch bend-
ing. Piano-like polyphonic pitch-bending interfaces do exist,
most notably the Haken Continuum Fingerboard [3], which
allows for multiple pitch bends at the same time and also
registers the vertical location of an input and its downward
pressure. However, the Fingerboard provides the musician
with a limited amount of tactile information about ﬁnger
location, and thus (especially when playing polyphonically)
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’11,30 May–1 June 2011, Oslo, Norway.
Copyright remains with the author(s).
Figure 1: The Seaboard surface
if software correction is not utilized to force tones to snap
to the tuning of the twelve-tone scale, then either visual
conﬁrmation of each note is necessary or a vibrato tech-
nique must be employed. The Rolky Asproyd, designed by
Eric Johnstone [5], is a poly-touch controller that makes use
of illumination to detect the position of several ﬁngers on
a transparent surface, thereby providing control over each
note in the chord. Nevertheless, no instrument based on the
piano layout has previously provided a musically intuitive
way of providing polyphonic pitch-bending capacity while
also enabling eﬀective tuned playing.
2. DESIGN
At the broadest level of description, one can identify two
ways of making music: traditional musical instruments on
the one hand and modular technology—various kinds of
synthesizers, sampling, and digital eﬀects—on the other.
Traditional instruments provide great depth, reﬁnement,
and performative possibilities, but more limited scope, whereas
modular technology has enormous scope but is often poorly
integrated and diﬃcult to use in real time.
The goal of the Seaboard design process, like that of many
new digital interfaces and instruments, has been to deliver
an integrated music-creation device which combines the best
of both of these approaches. Our aim has been to make use
of both the more fundamental intuitive associations (i.e.
pressure relates to volume) which enable the learning pro-
cess and the connection between musician and instrument,
and the possibility of taking advantage of more arbitrary
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
503
but nevertheless established intuitions in considering key
design choices.
In concrete terms, the Seaboard interface takes the basic
design layout of the piano keyboard and refashions it with
a new surface shape and a new material. The discrete keys
of the piano have been physically re-imagined as a single,
continuous, non-ﬂat surface, where the relatively raised and
recessed areas of the surface correspond with the centers of
the white and black keys (See Figure 1). The top of the
interface is made of a soft silicone, which rests upon an
array of force sensing resistor (FSR) sensors. A software
algorithm measures the variations in pressure and location
of the pressure peaks in the sensor array, thereby forming
a representation of which notes the user is playing on the
Seaboard, and sends out the corresponding MIDI or OSC
messages.
In addressing the question of how to make an eﬀective tac-
tile instrument that would allow for a wide range of sound
and music creation possibilities, and yet remains intuitive,
the piano keyboard layout was a good place to start. The
visual and logical layout is one of the reasons for the success
of the piano, especially as a general interface for musicians
to learn basic music theory.
Another reason to adopt the piano keyboard as a start-
ing place lay in its familiarity. New musical instruments
and interfaces are often proposed, especially in the digital
age, yet comparatively few become established and widely
accepted. One reason has to do with the enormous amount
of energy that one has to devote to learn a new instrument
well, and unless an instrument garners a small community
of musicians who play it very well, it is diﬃcult for it to
ﬁnd a path to wider acceptance. Dobrian and Koppelman
[?] point out that for a new interface to facilitate musical
expression, not only must the interface be well designed,
for example with respect to mapping gesture to sound pa-
rameters, but players must also take the time to master
the interface in order to achieve the level of virtuosity we
associate with traditional instruments.
In addition to designing the Seaboard in such a way that
a musician could transfer keyboard skill and understanding,
a strong emphasis was placed on making the new capabili-
ties one that could be learned and endlessly reﬁned through
practice, rather than providing easy software workarounds.
Highly skilled manipulation of complex sound variables and
attributes depends on practice, and the reason practice is
eﬀective in these areas is that one can train one’s muscu-
lar memory to repeat certain delimited tasks without con-
scious direction or control. We observed that in order for
such training to be possible though, there are three require-
ments: a) the activity must not inherently require visual
conﬁrmation and direction (activities that require visual
conﬁrmation, like shooting a target, can of course also be
practiced, but involve a diﬀerent form of practice involv-
ing hand/eye/body coordination); b) the physical interface
must give positional tactile feedback (in the sense that a
ﬂat or merely decorated surface does not, and thus some
kind of variation in surface, texture, or resiliency can con-
sistent give the user something tactile to which to spatially
orient his or her trained automatic muscular adjustments
and correction); and c) these physical qualities of the inter-
face have to be standardized and unchanging, so that they
provide very similar tactile information in every instance.
3. CONTINUOUS VS DISCRETE
In the development process of the interface, we found it
helpful to track the concepts of ’discrete’ and ’continuous’
through three areas—musical outputs, tactile feedback, and
sensor processing. The goal of reimagining the piano keyboard—
into a form in which the pitch, volume and timbre of each
note could be continuously controlled without a loss of ca-
pability with respect to discrete outputs—emerged from a
set of assumptions about desirable outputs for a versatile
musical instrument.
3.1 Musical outputs
Even if one considers majors areas of music on a spectrum
from rhythm, harmony, to melody, we see that conventional
musical outputs require discrete, identiﬁably separate beats
or notes, on one side, and more continuous variations in
pitch, volume, and timbre on the other side.
We consider a single output a sound with pitch, volume,
and timbral characterstics which has a particular duration.
Variations in these parameters can either take place con-
tinuously within the duration of such an output, or varia-
tions can take place between members of a set of discrete
outputs. Typically, discrete variations between outputs are
more common in rhythmic musical outputs, especially at
faster tempos, whereas continuous variation within an out-
put is more common in melodic outputs, especially at slower
tempos. To achieve the broadest range of control, one would
want to be able to maximize the capacity for discrete vari-
ations between outputs and continuous variations within
outputs, in terms of pitch, volume, and timbre, and to do
so without loss of accuracy.
3.2 Tactile feedback
This aspiration with respect to musical output has to be re-
lated to a tactile feedback system which allows one to input
both discrete and continuous variations in a way that enable
accuracy and real-time micro-adjustments. Speciﬁcally, a
given range in pitch, volume, and a particular variable that
changes some aspect of timbre can be mapped to the x, y,
and z axes of a touch-sensitive surface. However, if the sur-
face is ﬂat, then accurately ﬁnding the correct locations for
discrete or even just starting pitches, for example, is highly
problematic.
In the case of the Seaboard, the three-dimensional input
surface, made of silicone (see Figure 2), has a wave-shape
form where the peaks of the waves produce, when pressed,
musical notes corresponding to the notes of a standard mu-
sical keyboard. In this way, the Seaboard can, to a signiﬁ-
cant extent, mimic a conventional keyboard in its operation
with respect to enabling the musician to polyphonically play
a set of accurate discrete outputs. For example, by pressing
on one of the ’peaks’ or ’crests’ and vibrating a ﬁnger, an
oscillating signature can be generated by the sensors, which
will be interpreted by the processor as a vibrato. In addi-
tion, the shape of the surface means that a player can also
play into the troughs, i.e. the areas between the crests, to
produce microtonal pitches between any half or whole step.
Since the input surface is in places continuous, it is able to
produce smooth glissando eﬀects on the keyboard.
As shown by Goebl and Palmer [2], tactile information
makes an important contribution to the timing accuracy of
piano performances. The interface provides three distinct
forms of tactile feedback to the user. Firstly, the texture,
angle, and other characteristics of the three-dimensional top
surface (see Figure 2) give the user immediate information
about the location of the touch, in a way that would be
impossible on a ﬂat uniform surface where there is no tac-
tile basis for spatial orientation. Secondly, the soft resilient
material transmits forces back to the user to provide fur-
ther tactile feedback to the user who will be able to sense
the amount of pressure that he is applying to the interface.
Thirdly, the soft material ampliﬁes the variation in the sur-
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
504
Figure 2: Closeup of the silicone surface of the
Seaboard.
face area of the tactile feedback.
In these ways, the tactile feedback provided by the Seaboard
has been designed to maximize the capacity for discrete
variations between inputs and continuous variation within
inputs, in a way that intuitively matches with the demands
of musical outputs.
3.3 Sensor processing
These observations about discrete and continuous musical
outputs, and user inputs, relate also to a distinction between
two kinds of sensor-processing paradigms, related to the
distinction between discrete and continuous touch interfaces
found in Hinckley and Sinclair [4], and the discrete and
inﬁnite types of sensors described by Vertegaal et al[8].
A given sensor or array of sensors can provide anything
from a single binary message to a continuous ﬂow of high
resolution data with respect to multiple parameters.
Currently, most user interfaces for the capture of phys-
ical movement or touch fall somewhere on a spectrum be-
tween two extremes which could be called ’Discrete Con-
trol Interfaces (DCI),’ which use a set of discrete sensors,
which can register either an on or oﬀ position to provide
simple discrete inputs, and ’Continuous Action Interfaces
(CAI),’ which register spatial or gestural movement in time
to enable more complex inputs based on continuous move-
ment. Ultimately, the spectrum is deﬁned by levels of reso-
lution and numbers of identiﬁable, distinct parameters, but
in practice, especially with respect to pressure based tac-
tile input sensing, the distinction between continuous and
distinct is a relevant one.
The DCI side of the spectrum is typiﬁed by simple switches
and arrays in devices like typing keyboards, and other inter-
faces that use direct analog (usually switch-based) controls
that usually simulate a mechanical action, while the CAI
end of the spectrum might be typiﬁed by something like a
Kinect tracking system that gathers a rich set of data which
can then be mapped in various ways. A piano keyboard does
measure a continuous action with respect to striking veloc-
ity, but is clearly on the DCI side of the spectrum. In the
middle of the spectrum we ﬁnd technologies such as touch
screens, touchpads, other two-dimensional touch sensitive
interfaces, and devices like a computer mouse, which use a
rolling ball or some other continuous action apparatus that
allows for continuous input, but might be more limited in
terms of the number of parameters that they can track.
The advantages of DCI interfaces are that they allow for
clear discrete inputs and they typically form a tactile and
rich kinaesthetic input feedback system that does not rely
on visual conﬁrmation, since the user can feel a responding
pressure when he depresses a key, for example. These ad-
vantages relate not just to the kind of sensing device but
also to the design of the input surface, the topmost part of
the interface with which the user actually interacts. In the
case of typing interfaces, the springing quality of a typing
keyboard allows the user to understand at the level of ki-
naesthetic perception that a key has been depressed, and
the contours of the individual keys allows the user to make
micro-adjustments to facilitate constant, fast, accurate typ-
ing without having to look at the keyboard. Indeed, tactile
cues have been shown experimentally to strongly aﬀect the
accuracy of experts in carrying out touch-typing tasks [7].
For the musician, visual feedback has a greater role dur-
ing the learning phase than the expert phase, when tactile
information about ﬁnger location and action and habitual
skill play an increasing role in navigating the ﬁngers about
the keyboard [8].
The disadvantage of DCIs is that they are limited in the
types of input that can be made, especially when the goal
is to input quantitative or continuous information, as op-
posed to qualitatively separate, distinct commands. On the
other hand, CAIs have the advantage of allowing for contin-
uous input and subtle or complex forms of information to
be communicated very quickly. For example, touch-screen
interfaces allow the user to choose between an arrangement
of options that can be simultaneously presented in an easily
understandable manner.
In the Seaboard design, we found that by using an array
of pressure sensors, and then implementing an algorithm
which tracked each input we could oﬀer some of the fea-
tures of both kinds of interfaces. In other words, the non-ﬂat
nature of the Seaboard surface, in conjunction with its hy-
brid sensor-processing paradigm, means that one can choose
whether to play a note in a musically discrete or continuous
way. Since the Seaboard enables seamless transitions for
both discrete input (e.g. inputs to generate the notes of a
chromatic scale) and continuous inputs (e.g. glissando and
slide eﬀects, timbral and dynamic variations in real time), it
is ideally suited for the complexity of both enabling discrete
and continuous real-time, note-by note polyphonic varia-
tions in pitch, timbre, and volume.
4. PROTOTYPING
The Seaboard has gone through three prototype iterations;
the ﬁrst was a concept non-functioning prototype, the sec-
ond a small working prototype, and the third a full-size
working prototype. Each prototype has allowed us to re-
solve particular problems and questions that have arisen
during the design and development process.
Figure 3: The ﬁrst sketch of the Seaboard concept.
The ﬁrst prototype was a concept prototype was based
on the sketch shown in Figure 3. The goal was simply to
model the main idea in a physical way, and no attempt was
made to make it function at that stage. Primarily, then,
the Seaboard 1 gave the opportunity to work on the partic-
ular shape of the surface, and to test a variety of possible
materials. The surface of the Seaboard had to simulate the
physical layout of a piano keyboard and the basic size of the
distance between each ’wave’ was thus given. The trade-oﬀ
between replicating the exact height diﬀerential of the black
and white keys on the one hand and making a surface that
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
505
was gentle enough in its curvature to allow for easy slid-
ing between positions (and thus pitches) was explored. The
relative roundness of the keys, as well as the ways that the
surface should extend above and below the key also had to
be tested and resolved. In terms of the material, it was
necessary to ﬁnd a solution that had the right level of ‘give’
and yet also had a fast response time and allowed for a
diﬀusion of forces from the top of the surface through to
the sensors underneath. Seaboard 2 was the ﬁrst working
prototype, and thus its development also encompassed the
selection of sensors, the electronics to make them work and
send correct data, and of course a signiﬁcant amount of soft-
ware development. Seaboard 3 has allowed us to develop a
more mature prototype and software algorithm, discussed
in overview below, and otherwise to resolve all the design
questions in a more complete way.
4.1 Input
Marshall and Wanderley [6] ﬁnd that FSR sensors are the
preferred input sensor over linear and rotary potentiome-
ters for relative dynamic control, required for vibrato ef-
fects. The input from the Seaboard is via an Arduino Mega
multiplexed to provide readings from the array of FSR sen-
sors, each with values ranging from 0 to 1023. The sensor
values are currently sampled at approximately 55Hz which
provides a relatively low latency when playing.
4.2 Output
The Seaboard sends MIDI information to a sequencer that is
used to generate sound. For each note sent, we require the
ability to change the volume and pitch of each note, and
thus we set up separate MIDI channels for the maximum
number of simultaneous notes we wish to send (typically
8). We have made use of Logic and Ableton Live as audio
sequencers with which to generate sound from the interface.
It is also possible to send OpenSound Control (OSC) mes-
sages [9] to communicate the amplitude and pitch of each
note.
4.3 Algorithm
Noise Reduction
For playing notes: 
Attribute peaks to playing 
Update pitch 
and volume
Remaining peaks: 
look for note on
Look for
 note off
Peak Detection
Figure 4: Software Architecture
A diagram showing the design for the software architec-
ture is shown in Figure 4. A noise reduction process makes
use of the the maximum sensor values experienced when the
instrument is not being played and reduces the sensor val-
ues appropriately to prevent false triggering. We then look
for peaks in the range of sensors, that is, where a sensor has
a pressure value greater than both the adjacent sensors. We
calculate a localization in proportion to the pressure that
determines each peak’s central location and overall pressure.
Every MIDI note that is sent out from the Seaboard has an
associated location and pressure in terms of the sensor ar-
ray. Thus, for each playing note, we ﬁnd the closest peak
that has not yet been attributed to an existing note and
depending on the pressure, we either update the location
and pressure associated with that note or else send a ‘Note
Oﬀ’ message and remove the note from our list of playing
notes. Then we iterate through any remaining unattributed
peaks and if the pressure is greater than a set threshold, we
send a ‘Note On’ message and add the note (with associated
peak location and pressure) to the list of playing notes. A
mapping function is used to translate between peak location
and continuous note location.
5. CONCLUSION
In this paper, we presented the Seaboard, a polyphonic in-
terface that provides continuous dynamic control over the
pitch and volume of each note. We have described the itera-
tive design process that led to its construction, highlighting
the ethos of the design and the importance of rich kinaes-
thetic and tactile feedback in new hybrid interfaces that
enable both discrete and continuos control.
6. REFERENCES
[1] C. Dobrian and D. Koppelman. The ’E’ in NIME:
Musical expression with new computer interfaces.
Proceedings of the 2006 Conference on New Interfaces
for Musical Expression, 277, 2006.
[2] W. Goebl and C. Palmer. Tactile feedback and timing
accuracy in piano performance. Experimental Brain
Research, 186, 2008.
[3] L. Haken, E. Tellman, and P. Wolfe. An indiscrete
keyboard. Computer Music Journal, 22(1):30–48, 1998.
[4] K. Hinckley and M. Sinclair. Touch-sensing input
devices. In Proceedings of the SIGCHI conference on
Human factors in computing systems: the CHI is the
limit, pages 223–230, 1999.
[5] E. Johnstone. The Rolky: A poly-touch controller for
electronic music. In Proc. of the International
Computer Music Conference, pages 291–295, 1985.
[6] M. T. Marshall and M. M. Wanderley. Evaluation of
sensors as input devices for computer music interfaces.
InProc. of Computer Music Modeling and Retrieval
2005 Conference, LNCS 3902. Berlin Heidelberg, pages
130–139. Springer-Verlag, 2006.
[7] E. Rabin and A. M. Gordon. Tactile feedback
contributes to consistency of ﬁnger movements during
typing.Experimental Brain Research, 155:362–369,
2004.
[8] R. Vertegaal, T. Ungvary, and M. Kieslinge. Towards a
musician’s cockpit: Transducers, feedback and musical
function. InProc. of the International Computer Music
Conference, pages 308–311, 1996.
[9] M. Wright and A. Freed. OpenSound Control: A new
protocol for communicating with sound synthesizers. In
in Proceedings of the International Computer Music
Conference, Aristotle University, Thessaloniki, Greece,
pages 101 – 104, 1997.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
506