Contextualizing Musical Organics:  An Ad-hoc Organological Classification Approach    Thor Magnusson Experimental Music Technologies Lab Department of Music University of Sussex     t.magnusson@sussex.ac.uk     
    
ABSTRACT New digital musical instruments are difficult for organologists to deal with, due to their heterogeneous origins, interdisciplinary science, and fluid, open-ended nature. NIMEs are studied from a range of disciplines, such as musicology, engineering, human-computer interaction, psychology, design, and performance studies. Attempts to continue traditional organology classifications for electronic and digital instruments have been made, but with unsatisfactory results. This paper raises the problem of tree-like classifications of digital instruments, proposing an alternative approach: musical organics.   Musical organics is a philosophical attempt to tackle the problems inherent in the organological classification of digital instruments. Shifting the emphasis from hand-coded classification to information retrieval supported search and clustering, an open and distributed system that anyone can contribute to is proposed. In order to show how such a system could incorporate third-party additions, the paper also presents an organological ontogenesis of three innovative musical instruments: the saxophone, the Minimoog, and the Reactable. This micro-analysis of innovation in the field of musical instruments can help forming a framework for the study of how instruments are adopted in musical culture.  Author Keywords Organology, musical organics, classification, NIME, digital musical instruments, ontogenesis, innovation.  ACM Classification H.5.5 Sound and Music Computing. 1.  INTRODUCTION As a research field, NIME is characterised by a plethora of design approaches, hardware, and software technologies. Formed of an interdisciplinary research community with divergent end-goals, the diversity of aims, objectives, methods, and outcomes is striking. Ranging from expressive interfaces, to musicological concerns, novel sensor technologies, and artificial creativity, the research presented is heterogeneous, distinct, and original.  The design of digital instruments is very different from the making of acoustic instruments, due to the bespoke traditions and production environments of the disciplines mentioned above, but notably also because of the heightened epistemic dimension inscribed in the materiality of digital systems [25]. These new materialities are often hardware and software technologies manufactured for purposes other than music. Without having to support established traditions and relationships between the instrument maker and the performer or composer, new digital musical instruments often develop at the speed of the computer’s technical culture, as opposed to the slower evolution of more culturally engrained acoustic instrument design.  
 Examples of the new materials used in digital instruments include: buttons, knobs, sliders, ribbons, accelerometers, photocells, infrared sensors, web-cameras, motion capture systems, 3D range cameras, and various biosensors. These are for embodied control, but the sensorial scope can also be extracorporeal, for example using GPS satellites, network data, or social media activity in sonification. These are materials with particular agencies as they are interwoven into complex techno-cultural structures, often borrowed from utilization contexts that are not related to music at all, for example gaming, sports, web design, military, etc.  A large part of the technical expertise in the making of new musical instruments is therefore not necessarily related to music, but rather human-machine ergonomic factors. The digital luthier [19] applies a new type of knowledge required to build, test, perform, analyze, and understand the new instruments. This does not involve the tacit skills of the artisanal master-to-disciple relationship, but rather the know-how gained from reading manuals and technical specs, understanding code libraries and APIs. The applied knowledge and techniques might originate in product design, human-computer interaction, computer games, web design, ergonomics, science fiction, and even virtuosic sports, such as skateboarding or karate.   Traditional classification schemes for musical instruments have analysed their material nature, sound, and performer activity. With digital instruments, classification has proven difficult, due to the heterogeneous material nature, the complexity of sound generation, the fluidity of the instruments, and so on. A new analytical approach is required that engages with the repository of digital instruments from a multiplicity of perspectives: materials (e.g., plastic, metal, glass, fibre, cloth); sensors (e.g., ultrasound, CMOS, bend, potentiometers); sound (e.g., physical models, FM, subtractive, concatenative, granular, sampling); mapping (e.g., one-to-one, one-to-many, many-to-one, convergent, learned, evolutionary, stochastic); gestures (e.g., wave, hit, stroke, pluck, shake, strike, bow, blow); reuse of proprioceptive skills (such as the trained playing of keyboard, strings, wind, and percussion); manufacturer (e.g., of sensors, chips, motors), and many more, including cultural context, musical style, and other areas that have been, or indeed will be, called for as extensions to existing organological classifications.  This paper engages with NIME organology. After a brief survey of historical instrumental classifications and recent attempts dealing with digital instruments, the concept of musical organics1 is proposed as an approach that might benefit the organology of new digital instruments. Musical organics is not a classification system designed for spatial considerations (how to organize instruments in a museum) or outlining chapters of a printed book: it is a philosophical study raising some ontological issues of classifying digital instruments, and, in so doing, proposing an information-architectural space whose                                                                     1 The term ‘organics’ here references an early work in organology, Adolph Bernhard Marx’s 3rd section of Allgemeine Musiklehre, (1839, e. 1853), where ‘Organik’ is translated as ‘Musical Organics.’ It also relates to Deleuze and Guattari’s concept of the rhizome. 
470
representation can be dynamically generated, depending on the research interests and perspective of the user. Musical organics is an open system that supports third party organological additions (or plugins). To exemplify this, the paper gives an example of such a plugin, addressing the ontogenetic analysis of musical instruments. 2.  ORGANOLOGICAL CLASSIFICATIONS All musical cultures create systems for analyzing and grouping their instruments. These systems sort them into categories that are meaningful for the particular culture [20]. Cultural values differ: what might be meaningful in one culture might be of little interest in another, and we often find that extra-instrumental concerns, such as mythology, tradition, societal structure, cosmology, or religious function, contribute to or constitute the principles of categorization.   Organologists have presented a plethora of useful approaches to sorting and classifying musical instruments. The organizational principles typically relate to the material substance of the instrument and its vibrational function, as exemplified in the classical Indian Nāṭyaśāstra system, the museum classification of Mahillon in 1880, and the system designed by Hornbostel and Sachs in 1914 [17].  The Hornbostel-Sachs system has become the most universally accepted classification, and, albeit imperfect, it has been widely used in organological and musicological literature, as well as in museum collections. This is where we find the well-known division of musical instruments into membranophones, idiophones, chordophones, and aerophones. The system enables a tracing down to the unique features of individual instruments, through logical divisions at each level. For example, the numerical denominator of 111.242.222 would refer to sets of hanging bells with internal strikers (1 = idiophone; 11 = struck idiophone; 111 = idiophones struck directly; 111.2 = percussion idiophones; 111.24 = percussion vessels; 111.242 = bells; 111.242.2 = sets of bells; 111.242.22 = sets of suspended bells; 111.242.222 = sets of clapper bells). Other twentieth century systems range from Dräger’s [9] method of microtaxonomical organology that added cluster variables to instrument descriptions, through Elschek and Stockman’s work on upward typology of musical instruments [11] to Herbert Heyde’s [14], ‘natural system,’ focusing on instrumental evolution, conceptualized via a complex analysis of instrumental classes at various abstraction levels. 
 Figure 1. The upper levels of the H/S classification. In 1940, Sachs introduced the electrophone category as a response to new musical materialities including oscillators, filters, pickups, and amplifiers. The electrophone category is divided into instruments with electronic action (51), electromechanical action (52), and electroacoustic action (53). At the time, this addition was a sufficient plasterwork, but with the advent of digital technologies and diverse mappable controllers, the fix has long since collapsed. Bakan et al. [1] address the problems of the electrophone category by proposing considerable additions to the H/S system. They suggest a rethinking where electric and amplified instruments are returned back to their acoustic siblings (where the electric guitar is a subcategory of the chordophone guitar, but with a +E at the end, or: 321.322-E). Here 
the electrophone category is used exclusively for instruments that generate sounds electronically as opposed to amplified acoustics.   The Hornbostel-Sachs system has been subject to improvements: Birley and Myers [3] have recently published a revision of the classification that has been taken into use by the MIMO consortium (Musical Instruments Museums Online. See www.mimo-international.com). Considering how widely used the system is, this is a welcome and timely project, as the update makes it more inclusive of non-Western instruments, and, in particular, expanding the electrophone category. Weisser and Quanten also attend to the problems of the H/S system, providing two alterations: the first introducing timbre modifiers as important organological concerns; the second adding a modular syntax to the electrophone category (represented by symbols such as +, *, and =). Having proposed some solutions to the problems of the electrophone category, the authors come to the conclusion that perhaps a more holistic framework should be devised, moving away from tree-like classifications.  Recent studies in organology tend to broaden the scope of the field, often emphasizing the cultural context of musical instruments [27][6], lived organology based on stories, historical meanings and relationship with the sacred [16], or the ‘social life’ of musical instruments [2]. Widening the analytic context, Tresch and Dolan [31] conduct a study comparing scientific and musical instruments, introducing an organological classification based on ethics. 3.  NIME CLASSIFICATIONS There is a clear demand for establishing organizational principles for new digital instruments. Such a system would enable inventors to share knowledge [26][27], performers would benefit from a stronger recognition of their musical context, musicologists would gain the necessary terminology to analyze and reference developments in the field, and composers would acquire a resource to understand the instrumentation principles of these new technologies. In the light of the heterogeneous materiality and design approaches of digital instruments discussed above, we might ask whether it would make sense to introduce yet another category to the H/S system – the digiphone – to address their arbitrary and semi-material nature? The answer is likely to be negative, primarily for two reasons: tree-like classifications cannot cope with complex materials, and we can now greatly benefit from modern information retrieval technologies.   However, we need to engage in organological analysis before attempting any classificatory work, since lacking an ontological structure there is nothing to mine. Here we find plenty of useful work, for example Cance et al. [5] who ask what instrumentality means in new instruments. They apply cognitive linguistic research to the field, analyzing both English and French discourse, concluding that instruments are not defined as such from being hardware devices or software, but rather qualify as such as a consequence of their interaction with users. Sarah Hardjowirogo [13] further explores the construction of instrumental identity, presenting seven criteria that are potentials for something to be a musical instrument: 1) Sound production, 2) intention/ purpose, 3) Learnability/ virtuosity, 4) Playability/ control/ immediacy/ agency/ interaction, 5) Expressivity/ effort/ corporeality, 6) ‘immaterial features’/ Cultural Embeddedness, 7) Audience perception/ liveness.   Sergi Jordà [19] raises issues about the conceptual frameworks we need when analyzing new digital instruments. Jordà introduces validating criteria such as playability, progression, and learnability. Birnbaum et al. [4] introduce a visual representation of a dimension space of digital musical devices. Their analytic categories are: required expertise, musical control, feedback modalities, degrees of freedom, inter-actors, distribution in space, and role of sound. Their approach was phenomenological, focusing on the embodied performer, and Magnusson [24] developed a related analytical tool engaging with the epistemological nature of digital instruments: how theory is inscribed in the build of new instruments, and how users engage with this embedded theory. The analytic categories in the 
Instrument
IdiophonesStruck
PluckedFriction
BlownUnclassified
Membranophones
Struck
Plucked
Singing
FrictionUnclassified
ChordophonesSimple
Composite
Unclassified
Aerophones
FreeNon-freeUnclassified
Electrophones
Electric action
AmplifiedRadioelectric
471
epistemic dimension space are: expressive constraints, autonomy, music theory, explorability, required foreknowledge, improvisation, generality, and creative-simulation.   In a 2006 NIME paper, Kvifte and Jensenius [21] propose a terminology for describing instruments. They point out that the level of details differs according to the roles of a listener, a performer, or a constructor (instrument builder). The parameters to be analyzed include gestural, technical, and musical parameters, all depending on the level of specificity. In 2006, Magnusson and Hurtado conducted a survey they reported on at NIME 2007 [22]. This survey probed into practitioners’ conceptions of acoustic, electric and digital instruments, as an organological study, but not aiming at a classificatory scheme. In 2010, Paine [27] presented an attempt towards a taxonomy of interfaces for electronic music, based upon a survey created as part of the TIEM (Taxonomy of Interfaces for Electronic Music performance) project. The questionnaire had the following sections: 1) General description, 2) design objectives, 3) physical design, 4) parameter space, 5) performance practice, and 6) classification.  Finally, in 2016, key NIME researchers [26] ran a workshop called NIMEhub, focusing on how to archive and share instrument designs. Their proposed database would be beneficial for designers and instrument makers, as knowledge could be shared between practitioners, successes and mistakes, facilitating collaboration, archiving older designs for possible reuse, reducing duplication efforts, promoting easier fabrication, detailed documentation, and supporting the reproducibility of studies. This is clearly a beneficial project for the field, but the authors acknowledge the problem of classification when creating the database for such a repository. One such database is currently in development MuzHack (muzhack.com), but its focus is on embedded hardware only, currently ignoring controllers and software instruments.  4.  MUSICAL ORGANICS Hornbostel and Sachs, as well as other organologists have described how tree-like classifications cannot be fully coherent and functional for traditional acoustic instruments, and in the analysis of digital instruments they break completely. The approach proposed here under the name of musical organics is not a new classification system, but a heterarchical, rhizomatic method of analysing, classifying, and representing instruments. A hypothetical technical system, it is presented here as a methodology of looking: of re-searching, investigating, querying, probing; of comparing and re-contextualising; of explaining transitions and transductions in the evolution and design of instruments [23]. This system could easily support earlier descriptive organologies of downward classifications, as well as Heyde’s interpretive organologies that ask ‘why and how’ questions, offer explanations, and put the queries into historical and musicological contexts [15].   To classify is first to decide what we deem as relevant to our current interests and here we enter the field of ontology. Although it is a millennia old philosophical domain, computer scientists have applied a slightly different approach to ontology, in the attempt to transcribe and represent the physical world as digital objects that are typically stored in database systems [18]. Computational systems allow us to define and store data in what DeLanda defines as a ‘flat ontology’ [7]. It would be problematic to manage this type of an ontology in traditional classification schemes, but less so in systems that make use of databases that can be dynamically probed, resulting in machine generated constellations of presentation. Such ad-hoc classification is what Wolfgang Ernst has defined as informatized organization of knowledge: What is being digitally “excavated” by the computer is a number of information patterns which human perception perceives as “text”, “sound” or “images”. Contrary to traditional semantic research hermeneutics, an active, audio-visual, coded archive will no longer list text, sound and image sequences according to their authors, subjects, and metadata only. Instead, 
algorithmically driven digital data networks will allow verbo-audio-visual sequences to be systematized according to genuinely signal-parametric notions (mediatic rather than narrative topoi), revealing new insights into their informative qualities and operative aesthetics [12].  The musical organics system needs to be fluid and flexible in design, respecting Deleuze and Guattari’s statement that the rhizome ‘is open and connectable in all of its dimensions; it is detachable, reversible, susceptible to constant modification’ [8]. It would support all media types (e.g., text, sound, images, video), as modern machine learning techniques can search and analyse materials beyond text. What is produced by a probe into the musical organics system would be a representation of objects, relations, qualities, quantities, metaphors, imaginaries, all serving the unique user query. These presentations are not built by hand, but pulled out of the results of an extensive search that applies machine learning for clustering and classification. The results can subsequently be presented in diverse visualization clients. With today’s potential of information retrieval and machine learning, we can analyse, compare, connect, and synthesize data in larger spatial domains and at faster speeds than conceivable before, often significantly outperforming humans.  The system structure resulting from a musical organics approach to classification would suggest a threefold system: 1) a system of search that applies computational linguistics and machine learning in registered databases as well as online search engines; 2) an open API, where users can contribute an organology and register it as a database with the search system. The API will support standards of the semantic web, allowing for probes to be returned in commonly used data interchange formats (e.g, JSON or XML); 3) the representational engine that presents the search results. These can develop over time, with changing currents in aesthetics and media technologies, especially in terms of information display. The primary reason for suggesting that a clear separation is set between the data stored and how it is parsed and presented, is that the source data does not change (except for growing), but our methods of probing into the database will benefit from new information retrieval techniques and systems of data representation, for example applying new augmented or virtual reality technologies which are certain to improve over time.   The mentioned ad-hoc representation of big data is the topic of recent research in information display. Johanna Drucker has written extensively about this in her work on graphesis, which is the study of the visual production of knowledge:  [G]raphesis is concerned with the creation of methods of interpretation that are generative and iterative, capable of producing new knowledge through the aesthetic provocation of graphical expressions [10].  Similarly, at the Institute for Research and Innovation, Stiegler and colleagues have engaged in practical research in data manipulation and representation. In recent work, Stiegler also applies the term organology, but always with the prefix ‘general’, aimed to signify how technologies become extended organs, instruments for performance and thought, as well as social activities:   the thinking of grammatization calls for a general organology, that is, a theory of the articulation of bodily organs (brain, hand, eyes, touch, tongue, genital organs, viscera, neuro-vegetative system, etc.), artificial organs (tools, instruments and technical supports of grammatization) and social organs (human groupings … social systems in general).’ [30].  If the musical organics classification system is dynamic, open and flexible, it could indeed engage with the three levels of Stiegler’s general organology, where organologists would incorporate the study of bodily organs in music making, in particular learning, proprioception, kinaesthetic, collaboration, skills, virtuosity. They would clearly also study artificial organs, the musical prosthetics: our instruments. This is what traditional organology has focussed on, but 
472
this organology would include broader technological contexts such as phonographic, notational, and ergonomic technologies. Finally, the musical organics would include social organs: the modes through which we collaborate, communicate, share, and enjoy music. 5.  ONTOGENETIC ANALYSIS OF NIMES The diversity of approaches to the analysis and classification enabled by musical organics are practically infinite. In an open and flexible system, specialists can contribute their expert knowledge by adding analytic approaches to the system. To provide an example of such a plugin, we present a preliminary analysis of the ontogenesis of musical instruments, here asking: what are the conditions that form the innovation processes of a musical instrument? Who is the inventor? What materials are used? Where does the invention take place? In response to which problems? How is the invention brought to users or the “market place”? What kind of resistance are the inventors met with? How is the instrument received by the general public? These are questions that can typically be extracted from histories of musical instruments and their makers. These categories are not exhaustive or fixed.  This section presents three instruments whose history of origins is relatively well known. In this ontogenesis, we look at commonalities and differences in their development, demonstrating in a table items that would link to a further in-depth analysis of historical facts, something that does not fit the size of this paper. This addition to the system would combine textual description, in a more extensive form than below, as well as more details of the classificatory categories represented in the tables in the following sections. 5.1  The saxophone Working in his father’s workshop on improving the bass clarinet, Adolphe Sax (1814-94) was interested in the clarinet’s shortcomings, resulting in the saxophone. Sax presented the new instrument at the Brussels Exhibition in 1841, visited by an aide of the French king, Louis-Philippe, who decided to use the saxophone for military band use. Sax moved to Paris, where he met composer Hector Berlioz, who became interested in the expressivity of the saxophone. Soon after, funding was secured to establish the Adolphe Sax Musical Instrument Factory. The attention Sax was receiving engendered enmity from other Parisian instrument makers, mostly due to the popularity of the Sax, not mitigated by the fact that Sax had patented the saxophone, making it impossible for other manufacturers to make similar instruments. Sax was not affected much by this turbulence, but after the revolution in 1848, his fortune dwindled with the king’s exile and the revoking of the military band instrumentation. Table 3. Selected ontogenetic categories of the saxophone Instrument The saxophone Inventor Adolphe Sax Opposition L’Association générale des ouvriers en instruments de musique Adopter Berlioz, Military bands, Debussy – later jazz Marketer Sax Innovation strategies Publishing house for music written for the sax. Teaching the instrument at the Paris conservatory. Time 60 years to establish Networks 2-3 first degree networks (providers of materials) Team size 1 Rationale Overblow at octave. Stronger sound. The voice. Nonhuman actors Clarinets, tools, concert halls, marching bands. Patents Whole instrument Public awareness Word of mouth  The saxophone has various ancestors, such as the alto fagotto, but it is not clear how much Sax was influenced by these instruments. The changes the saxophone has undergone since its invention are well documented and its design is now very different from its conception. The question of the “origin” of the saxophone thus branches out into 
further genealogical and phylogenetic investigations of older musical instruments, as well as later refinements and changes in design.  The innovation of an invention (of establishing it as part of social practice) is often harder than the work behind the invention itself. Sax realized this and was eager to teach at the Paris Conservatory, even offering to teach without salary when his saxophone class was discontinued after the Revolution. Sax also set up a publishing house which published over 200 works for the saxophone, many of which were written by famous contemporary composers. 5.2  The Minimoog Bob Moog began working on electronic sound instruments in his father’s amateur radio workshop. Like Sax, Moog spent his youth in this workshop, developing radios, one-note organs, playing with oscillators, and eventually building a replica of the Theremin. Moog studied electrical engineering at Columbia University, starting the same year (1957) as the RCA Mark II synthesizer was installed in the Columbia-Princeton Electronic Music Center, but he never saw the RCA synthesizer, as it was occupied by composers of a musical culture alien to Moog, such as Vladimir Ussachevsky and Milton Babbitt. In 1961, Moog began selling Theremin kits for $50, the business grew, and two years later he founded the R.A. Moog Co. Table 1. Selected ontogenetic categories of the Minimoog Instrument The Minimoog Inventor Bill Hemsath Opposition Bob Moog; Musicians’ Union (AFM); Buchla; Ussachevsky; Babbit Adopter Sun-Ra; Keith Emmerson; Wendy Carlos Marketer Van Koevering Innovation strategies Electronic music evenings with concerts and hands-on sessions. Collaboration with musicians. Time 30 years to become established Networks 2-3 first degree networks (providers of materials) Team size 3 Rationale Interest in new sounds, Joy of exploring electronics Nonhuman actors Oscillators, electronics, labs, amateur culture, technoculture. Patents Filters Public awareness Print and broadcasting media. Eventually music in radio.  Much of Moog’s improvements of his technology resulted from discussions and collaboration with users and composer friends. Composer Herb Deutsch inspired the design of voltage-controlled pitch. This led to the idea that the output of one oscillator (low frequency oscillator, or LFO) could become pitch or amplitude input into the next one. Moog’s designs were not particularly “original” as there were instruments and synthesizers already built, and well documented, such as the work of German inventor Harald Bode. However, his unique approach was the close relationship he had with composers and musicians and how quickly he responded to their requests. From Wendy Carlos, Moog got the idea of implementing touch-sensitive keyboards, portamento control, and filter banks. For example, equipping the synthesizer with a discrete keyboard was a decision Moog took after encouragement from his collaborators, and was much criticized by other synth makers, such as Don Buchla.  The Moog Modular was too large and unstable to serve as a stage instrument. A Moog employee, Bill Hemsath, had been working on a more compact synthesizer where the patch-cords were hidden away (thus called the “integrated synthesizer”). Moog was not interested in the idea. However, the company was having financial difficulties and during one of Moog’s business trips, the engineering team decided on the production of the Minimoog (Model D). Moog was initially not happy with the item, but changed his mind when it started selling. David Van Koevering embarked on a sales tour around music stores all over the States. That was not easy as the market was highly resistant to these new instruments. Finally, his strategy was to ask musicians to enter instrument shops and ask if they had Moog 
473
synthesizers. Pinch and Trocco [28] state that the market for sound synthesizers was created by manufacturing the demand. 5.3  The Reactable  The Reactable was developed by a core team at the Pompeu Fabra University in Barcelona. It took ideas of the interactive table into the domain of music, and through the design came up with many interesting solutions, such as deciding upon a round table such that it would minimize player power structure and who was in control. It builds on modular synth ideologies, thus continuing directly work that Moog was also doing. The complexity of the materials used in the Reactable – projectors, cameras, shape recognition libraries, sound libraries, communication protocols, etc. – meant that the university was an ideal environment for the development of the project. The complexity of the project required an interdisciplinary team with diverse musical, programming, and engineering skills.  The Reactable visually represents the internals of a synthesizer. Apart from the obvious play and educational value of this interface (where people frequently spread around the table and play together on the instrument), it provides us with an interesting hybrid of the physical and the virtual. Physical objects are used to represent the digital oscillators, effects, and filters. The Reactable combines, in a powerful way, ideas from various directions into a unique user-interface. From the Moog modular it gets the idea of modular patching; from various TUI (Tangible User Interfaces) projects, it derives the camera vision system and idea of physical blocks to represent virtual objects; from Pure Data it got the power of its sound engine, allowing for the dynamic patching of oscillators, filters and other effects; OpenGL techniques for drawing sound take care of visualising the patchwork; and finally from the fields HCI and CSCW (Computer Supported Cooperative Work) they derive the decision to have a circular table in order to erase power structures and allow for ad-hoc organization of work. All this is combined together with highly effective interface design, usability design, and sophisticated sound and graphics. Table 1. Selected ontogenetic categories of the Reactable Instrument The Reactable Inventor Team at Pompeu Fabra Opposition Some Catalan media were critical at first Adopter Björk Marketer Sergi Jordà Innovation strategies The release of reacTV source-code, the use of YouTube and social media for marketing purposes. Time 5 years to become stablished Networks 100 primary networks  Team size 5-10 Rationale Physicality in virtual instruments. Synth visualization Nonhuman actors Projectors, cameras, real-time video libraries, software protocols, sound synthesis software, etc. Patents none Public awareness YouTube, project website, social media, festivals and media appearances  The Reactable has been presented in academic conferences, such as NIME, ICMC, and Linux Audio; in art festivals, such as Ars Electronica, Transmediale; and the startup company behind the technology hired two musicians to tour the world and perform with the instrument. In a similar manner to Van Koevering’s innovation of the Moog synthesizer, the advertisements in the media for Reactable performances focus on the instrument itself and not the musician playing it: the market is being created. The Reactable has also its power-adopter (an early user of the technology with high social capital), namely Björk who used the instrument in her 2007 world tour. Similarly to how Moog could follow Emerson, Lake and Palmer’s touring schedule by noting the location of the music stores phoning in to order Moogs, Jordà (personal communication) has reported on how the Reactable team was able to follow Björk’s Volta tour, studying how the instrument was used via her fans’ YouTube 
uploads. Before Björk’s tour, the Reactable had about eight thousand visitors on its YouTube page, but suddenly there were millions. 5.4  Discussion The musical organics system would support this type of comparative research. Firstly, through information retrieval techniques of scraping the web, secondly, by means of enabling researchers to present their own organology plugins for the system; and thirdly, by allowing users to add metatags – a folksonomy – to the system and thus contribute their findings. The ontogenesis view, here presented, would not work well in the tree-structure representation of musical classification, but it suits well for database approaches. Furthermore, the openness of the system would enable other researchers or inventors to contribute their research or instruments to the system.  The comparison of the origins of these three objects of music technology, reveals that they have much in common. All of them were created by enthusiastic inventors responding to limitations identified in existing instruments or practices. However, equally important was the instrument maker’s joy of invention: of bottom-up development using the materials at hand, following the inherent technical potential. All of the inventors were relatively young – in their 20s or 30s. All had to deal with certain initial inertia or criticism, overcoming that through a process of innovation that required certain market and social engagement skills. All of the instruments had key “power-adopters” who boosted public interest and thus helped in creating the market. For Sax, Berlioz’s comments, the military bands, and the saxophone classes in the Paris Conservatoire were important to create the demand. In a different media context, Moog was happy if print and broadcasting media reported on the use of the Minimoog, thus creating the demand, and the reputation of the Reactable spread around the world with the link-ranking structure of YouTube and the social networking of blogs, open source communities, and maker communities impressed by the technology.   There are many differences as well, especially in terms of materials, technique, and design. In the case of Adolphe Sax, he was working with physical materials, learning from his father, and developing the instrument without precise scientific knowledge of its functionality. Bob Moog’s practice was different: his materiality was that of electronics, where the objects are impregnated with scientific understanding, and there are specs, schematic diagrams, and manuals available for each of the items used. There is an increased logic of calculation, science and engineering. The Reactable team come from a very different situation: the “workshop” is in the form of offices in a university department with desks and computer monitors. Their materials are many: tabletop made of glass, projector, camera, physical cubes, designed “fiducial” shapes, amplifiers, speakers and computers. Behind this surface lie audio programming languages, shape recognition systems, motion tracking libraries, sound visualization systems, mapping engines between gestural recognition (cubes and/or fingers), and dedicated sound engines.  From an actor-network perspective, Sax ‘enrolled’ perhaps ten first-order networks in his instruments, Moog’s scope would be in the hundreds, and the Reactable team (considerably larger than the teams of Sax or Moog) might speculatively enroll (if we follow the exponential curve) ten thousand networks. The dependencies, or what can be seen as a first-order or second-order network, are blurry and vague. The fact is that there is a drastic increase in complexity, which means that the inventors necessarily have to rely on blackboxes (or enclosed technological objects whose functionality is hidden unless opened up). Moog might not question the oscillator until it malfunctions and the Reactable team would not question the shape recognition library they used until it proved insufficient. All the systems used in the Reactable originate from techno-scientific knowledge. There are relatively few physical material properties at play (although of course at the machine level we find matter) compared with the symbolic code that constitutes its internal (and symbolic) machinery. The inventors are knowledgeable about digital 
474
signal processing, sound physics, audio synthesis, gesture recognition, human-machine interaction, and the culture of musical performance. In general, it is a non-tacit knowledge of symbolic systems in the form of code; how the systems work and interact with each other. The concept of virtuosity is therefore transformed according to which type of instrument the performer is operating.  There is a large number of factors and events that led to the innovations of the Sax, the Minimoog and the Reactable. The success of an invention depends on factors such as social context, access to materials and workshops, and outward mentality required in the innovation process. A clear direction of conceptual and material energies, being at the right time and place, a dose of luck and an awareness of the importance of innovation, and public relations, all combine resulting in an instrument with longevity and popularity.  There is no room here for discussing the expressive parameter axis of each of the above instruments. We could attempt to fit them into top-down classification trees, or decide to map them to newer classifications (e.g., Spiegel, Dolan, Hardjowirogo, Birnbaum et al, Magnusson, Paine). Such approaches could be part of the new musical organics methodologies. However, the point here was to demonstrate an example of how a particular organological description, that of instrumental ontogenesis, could be written as a resource plugin for the system. This does not mean that the author of the plugin will write the same for all the instruments found in typical organology classifications: the idea is not to be comprehensive, firstly because it is practically impossible, but it might also not be needed in many cases. For example, an analytic parameter such as a ‘mapping model’ might be relevant in the analysis of a digital musical instrument, but less relevant for describing the harp or the cello. 6.  CONCLUSION This paper has presented an approach to thinking about modern organological classification of musical instruments, both acoustic and digital. A comprehensive all-encompassing system is not seen as a suitable approach, but this paper has suggested a move towards a more organic, bottom-up, and collaborative approach. For this to work in praxis as an evolving and developing organology, a system for database registration, an API, and an interface system would have to be built. The technical specifications are outside the remit of this paper, but it would serve well for a larger research project, for example, in collaboration with institutions that engage with cultural preservation, such as the Europeana project (www.europeana.eu).  A rhizomatic system like musical organics is clearly bound to be heterarchical in its organization, taking its collaborative principles from open source projects such as those we find applied on Github or Wikipedia, and we do now find examples of such collaborations by communities that cross institutions, organizations, and businesses. 7.  REFERENCES [1]  M.B. Bakan, W. Bryant, G. Li, D. Martinelli and K. Vaughn. Demystifying and Classifying Electronic Music Instruments. Selected Reports in Ethnomusicology: Volume VII - Issues in Organology. 1990, 37-64.  [2]  E. Bates. The social life of musical instruments. Ethnomusicology, 56, 3, 2012. 363-395. [3]  M. Birley and A. Myers. A revision of the Hornbostel Sachs classification in 2011 by the MIMO Consortium. In Proceedings of a Conference organised by the Levi Foundation, Venice, 2015. [4]  D. Birnbaum, R. Fiebrink, J. Malloch and M.Wanderley. Towards a Dimension Space for Musical Artifacts. In Proceedings of NIME. University of British Columbia, Vancouver, 2005. [5]  C. Cance, H. Genevois and D. Dubois. What is Instrumentality in New Digital Musical Devices? A Contribution from Cognitive Linguistics & Psychology. In Proceedings of the Fifth Conference on Interdisciplinary Musicology. Paris, 2009. 
[6]  K. Dawe. People, Objects, Meaning: Recent Work on the Study and Collection of Musical Instruments. Galpin Society Journal. 54, 2001. 219–32. [7]  M. DeLanda. Intensive Science and Virtual Philosophy. Continuum, New York. 2002. [8]  G. Deleuze and F. Guattari. A Thousand Plateaus: Capitalism and Schizophrenia. Continuum, London. 1987. 10. [9]  H.H. Dräger. Prinzip einer Systematik der Musikinstrumente. Bärenreiter, Kassel & Basel, 1948. [10]  J. Drucker. Graphesis: Visual Knowledge Production and Representation. Poetess Archive Journal. 2, 1, 2010. 14. [11]  O. Elschek and E. Stockman. Zur Typologie der Volksmusikinstrumente. SIMP, 1, 1969. 11-12. [12]  W. Ernst. Digital Textuality: The Implicit (Re-)Turn of the Gutenberg Galaxy. Report from the Gutenberg Galaxy. Blaker, Oslo, 2015, 10. [13]  S. Hardjowirogo. Instrumentality. On the Construction of Instrumental Identity. Musical Instruments in the 21st Century, Springer, New York, 2017. 9-24. [14]  H. Heyde. Grundlagen des natürlichen Systems der Musikinstrumente. Broschiert, Leipzig, 1975.  [15]  H. Heyde. Methods of Organology and Proportions in Brass Wind Instrument Making. In Historic Brass Society Journal. 13, 1, 2001. 1-51. [16]  P. Hooshmandrad. Performing the Belief: Sacred Musical Practice of the Kurdish Ahl-I Haqq of Gūrān. Ph.D. Dissertation, Berkeley: University of California. 2004. [17]  E.M.v. Hornbostel and C. Sachs. Systematik der Musikinstrumente. Ein Versuch. In Zeitschrift für Ethnologie, xlvi. 1914. 553-590. [18]  Y. Hui. On the Existence of Digital Objects. University of Minnesota Press, Minneapolis. 2016. [19]  S. Jordà. Instruments and players: Some thoughts on digital lutherie. In Journal of New Music Research. 33, 3, 2004. 321. [20]  M.J. Kartomi. On Concepts and Classifications of Musical Instruments. University of Chicago Press, Chicago. 1990. [21]  T. Kvifte and A.R. Jensenius. Towards a coherent terminology and model of instrument description and design. In Proceedings of NIME, IRCAM, Paris. 2006. [22]  T. Magnusson and E.M. Hurtado. The Acoustic, the Digital and the Body: A Survey on Musical Instruments. In Proceedings of NIME. New York University, New York. 2007. [23]  T. Magnusson. Musical Organics: A Heterarchical Approach to Digital Organology. Journal of New Music Research. 46, 3, 2017. [accepted for publication, unpaginated as to yet] [24]  T. Magnusson. An Epistemic Dimension Space for Musical Devices. In Proceedings of NIME. University of Technology Sydney, Sydney. 2010. 43-46. [25]  T. Magnusson. Of Epistemic Tools: musical instruments as cognitive extensions. Organised Sound. 14, 2, 2009. 168–176. [26]  A. McPherson, E. Berdahl, M.J. Lyons, A.R. Jensenius, I.I. Bukvic, and A. Knudsen. NIMEhub: Toward a Repository for Sharing and Archiving Instrument Designs. In Proceedings of NIME. Griffith University, Brisbane. 2016. [27]  G. Paine. Towards a Taxonomy of Realtime Interfaces for Electronic Music Performance. In Proceedings of NIME. University of Technology, Sidney. 2010. [28]  T. Pinch and F. Trocco. Analogue Days: The Invention and Impact of the Moog Synthesizer. Harvard University Press, Cambridge, MA. 2004. [29]  R. Qureshi. How Does Music Mean? Embodied Memories and the Politics of Affect in the Indian Sarangi. American Ethnologist. 27, 4, 2000. 805–38. [30]  B. Stiegler. For a New Critique of Political Economy. Polity Press, Malden, MA. 2010. 34. [31]  J. Tresch and E.I. Dolan. Toward a New Organology: Instruments of Music and Science. Osiris. 28, 1, 2013. 278-98.  
475