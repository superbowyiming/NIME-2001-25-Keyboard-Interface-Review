Proceedings of the 2002 Conference on New Instruments for Musical Expression (NIME-02), Dublin, Ireland, May 24-26, 2002  
 NIME02-01
Introducing Composed Instruments, 
Technical and Musicological Implications 
 
Norbert Schnell and Marc Battier 
IRCAM 
1, place Igor Stravinsky 
Paris, France 
{Norbert.Schnell, Marc.Battier}@ircam.fr 
 
Abstract 
In this paper, we develop the concept of “composed 
instruments”. We will look at this idea from two 
perspectives: the design of computer systems in the 
context of live performed music and musicological 
considerations. A historical context is developed. 
Examples will be drawn from recent compositions. 
Finally basic concepts from computer science will be 
examined for their relation ship to this concept. 
Keywords 
Instruments, musicology, composed instrument, 
Theremin, Martenot, interaction, streams, MAX. 
 
INTRODUCTION 
Musicians performing with electronic devices have been 
a major turning point in the practice of music for over a 
century. When computers became available for music 
performance, the question of turning a general-purpose 
machine into a music packed device became sensitive. In 
particular, developing interfaces and specially-designed 
peripherals for music composing and performance led a 
very active and increasingly large community of 
researchers and artists to develop solutions.  
A metaphor which is easily employed for a wide range of 
artistic performances with computers is that of the 
musical instrument. The term of the composed 
instrument underlines the fact that computer systems 
used in musical performance carry as much the notion of 
an instrument as that of a score, in the sense of 
determining various aspects of a musical work. This 
paper will merely designate which metaphors and 
concepts are implicit or explicit in the creation and 
performance of music using computers. We are at the 
onset of a larger research and we think that allying 
musicology and engineering will be fruitful. We would 
like to present the hypotheses and intention of our 
research. 
 
Composed instruments in the XXth Century 
The concept of composed instrument became possible 
when musical instruments became dematerialised. In 
other words, with electronic technology, it was possible 
to conceive a sound producing device independently 
from its gestural interface. As an example, the 
thereminvox (Russia, 1920), well known for its unique 
gestural interface in which performers move their hands 
in front of antennas, thus having no physical contact with 
the instrument, uses the same sound-producing 
technology as the ondes Martenot (France, 1928), 
namely the heterodyne effect . Yet, both Leon Termen 
and Maurice Martenot developed quite different modes 
of playing. As a result, the theremin became of landmark 
for film music (notably Hitchcok’s) in which its ability 
to produce portamenti and glissandi was widely used for 
effects, while a substantial number of more conventional 
pieces were written for the ondes. Although this 
instrument is perfectly able to produce glissandi too, it 
was its chromatic keyboard and its timbre variety, thanks 
to a number of specialized loudspeakers which attracted 
composers. 
A composed instrument is one in which several 
conditions must be met. One of them is that the two main 
components of a musical instrument, the sound 
producing part and the gestural performance part, are 
decoupled, or isolated one from another. In a composed 
instrument, gesture is linked to sound production in a 
non-direct, oftentimes non-obvious fashion. This is quite 
clear for digital devices. The two electronic instruments 
from the first half of the 20th century show that, in some 
ways, this is also true for analog instruments. Electronic 
synthesizers, dating from the 1952 - 1955 RCA 
synthesizer Mark I or the 1965 Buchla, Moog and 
Synket synthesizers, are perfect examples of the 
decoupling. While the Moog and the Synket machines 
had organ keyboards - and the Synket actually had a 
stack of three small monophonic keyboards - Donald 
Buchla developed other ways of generating control 
voltages to manually and automatically control its 
Electronic Music box [1]. 
 
Electronic Music Studios: an Electronic 
Environment 
The advent of Electronic music studios in musical 
history offer a transition in the development of 
composed instruments. Although considered an 
instrument only by a few, the Electronic music studio 
helped create the sense that composers were, if they 
chose to do so, able to create their own working 
 
 NIME02-02
environment. This began to be clear when, in 1951, the 
first electronic music studio was conceived from scratch 
at the WDR Radio of Cologne (Germany) to enable the 
composition of electronic music sounds. Based on the 
conception of physicist Werner Meyer-Eppler, the 
Cologne studio was organised around the control of 
synthesis resources, albeit limited in scope and power 
[2]. Briefly, the concept of studios evolved up to the 
1955 design of the Phonology studio in Milan by 
Luciano Berio and Bruno Maderna, With nine 
oscillators, various filters and other sophisticated 
equipment [3][4], the presence of a technician/musician 
and of a scientist who helped design and build specific 
processing devices, the studio was the best equipped in 
the world at that time. Composers, then, were required to 
adopt a low profile and accept the “conditions and 
limits” of the technical environment, and his or her work 
was to be mediated by a technician[5]. In this case, the 
composer was considered unable to “compose an 
instrument” from the overwhelming technical 
environment of the studio. Nevertheless, one should not 
take this official studio rule too seriously, and musical 
analysis of various pieces coming out of this studio 
during the late 1950s show that, on the contrary, degrees 
of liberty were quickly explored by in-house and visiting 
composers, as shown in pieces by Berio (Tema, Visage), 
Pousseur (Scambi), Cage ( Fontana Mix ), and others. In 
the same period, Pierre Boulez defined in his manner 
another goal for electronic music studios: 
“Electroacoustic means, which are offered to us by 
current technology, should be integrated with a 
generalized musical vocabulary” [6]. 
In 1984, the Italian composer Luigi Nono made a 
striking statement about the evolution of the electronic 
music studio at that time. For him, electronic music 
studios are “new instruments which need to be studied 
over time (also to avoid falling into the trap of using 
small commonplace ways), to learn and study again and 
again, to explore other possibilities, different from the 
ones usually chosen and given, other musical thoughts, 
other infinite spaces...” [7]. 
Furthermore, almost 20 years later, when Berio became 
involved in the direction of the new electroacoustic 
department of IRCAM, he took an opposite route and 
declared “We now try to conceive and formulate widely 
open ideas and devices, in which researchers and 
musicians may project themselves and be able to 
familiarize themselves.” [8]. Probably thanks to the then 
new computer music means which began to appear, such 
as the very first digital synthesizers, it was at last 
perfectly natural for composers to “compose” their 
instrument. 
 
Instrument, Machine, Representation 
Although the concept of composed instrument is recent, 
the brief considerations above attempt to show that it 
can, within a musicological context, be applied to the 
history and practice of electronic music. Historically, the 
invention of electronic instruments followed industrial 
research and development. Radio technique was on the 
forefront of technology in the 1910s and 1920s, and it is 
from it that the thereminvox and the ondes Martenot 
were made possible. In many ways, this transition phase 
for musical instruments is related to the industrial 
revolution in which the technique of the individual tool 
was replaced by the machine, for which man is merely an 
operator. A machine is built around a mechanism which 
encodes the representation of a task. Although in music 
a task can take many forms and may be applied to 
various phases of the making ad performing of a piece, 
musical systems can be seen from three different 
perspectives. 
Three categories can be defined to help understand the 
complex nature of electronic instruments [9]: 
 
• musical instrument, 
• machine, 
• representation. 
 
As a musical instrument, it should enable the performer 
enough degrees of liberty to explore personal and 
original ways of playing with it. 
As a machine, it is under the control of complex 
computational and algorithmic layers. 
The representation integrates the two first categories. 
Composers use the representational nature of the system 
to define events, write scores and specify the 
computational and algorithmic layers while performers 
can apply gestural controls and adjust parameters [10]. 
A composed instrument can be seen as the result of an 
implementation of  these three categories. 
 
Musicological Analysis and Composed Instruments  
The musicological analysis of electronic music is 
confronted with works composed of a variety of 
heterogonous structures and processes having different 
representations. In general the notion of a musical 
instrument is interweaven with that of the musical work. 
We believe that the composed instrument can be a 
helpful concept for musicological analysis in this 
context.  
Examples of such analyses will be drawn from recent 
pieces realized at IRCAM: by Philippe Manoury, Jupiter 
(1987) for MIDI flute and real-time processor, and En 
écho (1993-1994) for voice and real-time processor; by 
Brice Pauset, Perspectivae Syntagma I (1997) for piano 
and processing; by Jonathan Harvey, Advaya (1994) for 
cello and electronic set-up; and, by Yan Maresz, 
Metallics (1994-1995) for trumpet and live electronics. 
 
 NIME02-03
In the first examples, a passage of Jupiter by Philippe 
Manoury show the effect of processing a short flute 
moment with harmonizers and reverberation. 
 
Figure 1. Extract from Jupiter by P. Manoury 
 
The approach taken by the composer can be seen as an 
electronic counterpoint permitted by a precise notation 
of time, duration and pitches which are interpreted by 
the machine in interaction with the performer. 
The next example, from Metallics by Yan Maresz, uses a 
similar set-up. However, the notation and the result are 
quite different. It is as if the composer had chosen to 
create another environment, although, technically, the 
electronic processing used in the former example and in 
this one are comparable. In the score excerpt given in 
figure 2, the live instrument appears on top staff. 
 
 
Figure 2. Extract from Metallics by Y. Maresz 
 
Metaphors 
With some simplification, the act of composing could be 
described as the determination of a musical work and the 
performance as its execution. In order to reintroduce the 
freedom of the performer to this image, a concrete work 
could  be associated to a position in a continuous space 
between the perfectly determined (and identically 
reproducible) execution of a composition and totally 
freely improvised music. 
A similar distinction can be found for the interaction 
between the performer and a composed instrument. The 
extreme points here can be illustrated by two examples: 
 
• a performer pushing a button triggering the 
execution of a precomposed work; 
 
• a performer controlling every smallest detail of 
the performance similar to playing a violin.  
 
In the former case, the music is entirely determined by 
the computer system. In the latter case, it is in the hands 
of the performer (whether they improvise or act 
according to an additional score is not the important 
here, apart from the possibility that the score could be 
generated by the computer system during the 
performance). The composed instrument “lives” in the 
space spanned by these extreme points. 
Interpreting the attitude of the performer of a composed 
instrument with the help of categories from the 
traditional way music is created leads to various 
metaphors such as that of playing a musical instrument, 
conducting an orchestra, playing together (ensemble) 
with a machine, acting as a one-man band [11], and so 
on. Each of these metaphors implies certain expectations 
towards the computer system and requires different 
techniques of its design. The metaphor of playing a 
musical instrument implies that the computer system 
behaves like a musical instrument. The final system may 
even be compared to traditional musical instruments 
regarding the quality of the interaction with the player. 
Further metaphors can be found directly in the domain of 
engineering such as executing, navigating (for example 
in timbre spaces or other virtual spaces) [12], or mixing 
in the sense of a DJ’s work [13].  
 
Streams, Objects and Functions 
What are composed instruments composed of? 
Computer science provides us with various data 
structures, models of computation, and families of 
programming languages. These multiple approaches 
allow us to structure the resources of a computer system 
in various ways with different results in terms of their 
expressiveness and efficiency. Some of these techniques 
are developed for the modelling and simulation of real-
world systems, while others provide powerful tools for a 
wide range of mathematical and logical problems. From 
the engineering point of view composed instruments 
appear to be composed of very different elements such 
as data structures, algorithms and procedures, functions 
and mappings, as well as configuration settings. 
 
 NIME02-04
The composed instrument approaches the requirements 
of real-time simulation and control systems. The 
problematic concerning the of the design of such 
computer systems and their software is handled in 
domains such as discrete event and data flow systems. In 
the following we will briefly present three perspectives 
on the composed instrument using three elementary 
computer science concepts: streams, objects, and 
functions. The aim is to work out inspiring concepts for 
the design of such instruments as an artist’s (composers) 
domain, which can interface with corresponding domains 
of computer science.  
 
 
 
Figure 3. The performer and the composed instrument 
 
The figure from above can be easily interpreted with the 
notion of streams. The performers gestures are input to 
the computer system in form of streams. The system 
processes these streams and outputs streams back to the 
performer and the audience via the display devices. For 
many applications the computer system can be seen as 
composed of processing modules passing streams 
between them. For a first approach the composition of 
the instrument from different modules can be seen as 
static. 
Streams are always unidirectional flowing from the 
systems input to the system output and from the output 
of one module into the input of another. Many software 
tools such as Max [14] in the musical domain or Ptolemy 
[15] in the more general domain of modelling and 
simulation allow to represent and manipulate these 
modules (actors) and the connections between them in a 
graphical programming environment. 
Since these streams are unidirectional, the interaction of 
the performer with the composed instrument needs at 
least a couple of streams. From this point of view 
interaction must be seen as defined by the processing of 
the systems input streams producing its output streams. 
An important distinction for streams is whether they are 
composed of discrete events or constitute a continuous 
flow of (homogeneous) data. Even if the semantic of the 
information carried by different streams can be quite 
different and in for a given case closer to one or another 
domain such as discrete events or data flow, four 
categories can be commonly defined for their 
processing: transformation, analysis, synthesis, and 
memorization. A composed instrument can be seen as 
composed of streams running through processing 
modules of these four categories. 
The components fitting the case of transformation 
modules are those which receive one or multiple streams 
at their inputs and output streams of the same type and 
semantic at their output. For example this can be a pitch 
transposed audio signal or stream of MIDI notes. 
Modules of the type analysis, in the contrary, will output 
streams of a different semantic than their input streams. 
The streams output are the result of a parameter 
extraction of the input streams. While the type of an 
output stream of an analysis module can be the same as 
that of the input (e.g. an audio signal) the semantic is 
surely different (e.g. the continuous pitch or mean value 
of the input signal). An analysis module can be used to 
change the representation of a stream from one domain 
to another. 
It is easy to create an example which shows the difficulty 
to clearly distinguish the notion of transformation from 
those of analysis. After all it will be always the semantic 
one associates to a given stream and processing module 
which counts. And the categories defined here can  be 
helpful tools for the design of composed instruments 
only in this sense. 
 
 
 
 
 
Figure 4. Stream processing modules 
 
Synthesis represents the inverse case of analysis. 
Modules of this category are the origin of streams 
produced using a parametrization given by the inputs of 
the synthesis module. An interesting possibility is given 
by an analysis/resynthesis approach to transformation. 
The actual transformation is applied to the stream 
between the analysis and the synthesis in a different 
domain to that of the input stream. 
In theory the input and output streams of the computer 
system are considered as infinite and without 
persistence. Nevertheless the memorization of sub-
sequences and their (re-)composition is an evident 
ingredient of many composed instruments. Even if a 
subsequence still strongly related to the notion of 
streams its actual nature is those of an object 
manipulated by the performer.  
Without changing its appearance the image above can be 
interpreted as a performer manipulating an object, the 
instrument, and consequently the instrument composed 
of dynamically muting objects. The performer acts on 
the state of the instrument, which is continuously 
displayed at the output. As done above for the 
processing of streams we can assign the actions 
A S T M
 
 NIME02-05
performed on objects to different semantic categories 
such as creation (and destruction), mutation, 
interpretation (or execution), etc. 
Typical classes of passive objects are notes, chords, 
entire musical sequences, video sequences, audio files 
(samples), tree structures and such. An audio or video 
file player as well as an “actor synthesizing melodies 
depending on a tree structure of chords and 
probabilities” are examples of active objects. Some 
metaphors mentioned above more easily match this 
object oriented approach than others. For example an 
instrument providing the possibilities to work like DJ 
does, with multiple record players and disks, is easier to 
describe in terms of objects and their functions than in 
terms of streams.  
A third perspective on the performer/instrument situation 
is given by the functional approach. Here the overall 
image could be interpreted as an instrument defining the 
output of the instrument as a mutable function of the 
performers input and the instrument itself composed of 
functional entities. Even if functional approaches in the 
context of real-time systems are less explored than those 
mentioned above they become particularly interesting  
for the definition of more complex relationships between 
the performer and the instrument using algorithms for 
example based on machine learning, recognition or 
constraints. 
It has been shown that different approaches such as data 
flow, object oriented and functional programming can be 
seen as equivalent in the sense that a program expressed 
with the means of one approach can be translated to 
another. The major question to be ask in this context is 
those about the relationship of a certain approach or 
model or paradigm to the artistic idea of the designer of 
a composed instrument. Which model fits best a certain 
artistic idea of composition and performance and which 
artistic idea can be inspired by a certain approach? 
In this sense an authoring environment for composed 
instruments has to integrate multiple models of 
computation and programming paradigms in 
correspondence to a variety of different interfaces for 
expressive musical performance. 
REFERENCES 
[1] Chadabe, Joel, Electric Sound, Upper Saddle River, 
Prentice-Hall, 1997. 
[2] Ungeheuer, Elena, Wie die Elektronische Musik 
erfunden wurde, Schott, 1992. 
[3] R. Veniero and A. I. De Benedictis, New Music on 
the Radio/Nuova Musica alla Radio, Rai Eri, 2000. 
[4] Vidolin, Alvise, “Avevamo nove oscillatori,” I 
Quaderni della Civica Scuola di Musica, Dicembre, 
21-22, p. 13- 16, 1992. 
[5] Berio, Luciano, “Prospettive nella musica,” 
Elettronica, 5(3), 1956. 
[6] Boulez, Pierre, “Musique concrète,” Encyclopédie 
de la musique, p. 577, Paris, Fasquelle, 1958. 
[7] Nono, Luigi, “Verso Prometeo. Frammenti di diari,” 
in Verso Prometeo, Ricordi, 1984. 
[8] Berio, Luciano, “Prospective musicale,” Musique en 
Jeu 15, p. 63, 1974. 
[9] Battier, Marc, “Les polarités de la lutherie 
électronique. Instrument, machine, représentation,” 
in Méthodes nouvelles, musiques nouvelles, 
musicologie et création , M. Grabocz, ed., 
Strasbourd, Presses universitaires de Strasbourg, p. 
307- 318, 1999, 
[10] M. M. Wanderley and M. Battier (eds.), Trends in 
Gestural Control of Music , IRCAM - Centre 
Pompidou, 2000. 
[11] Paradiso, Joe A., et. Al. “Design and 
Implementation of Expressive Footwear,” IBM 
Systems Journal, 39(3-4), 2000. 
[12] Wessel, David “Timbre Space as a Musical Control 
Structure,” Computer Music Journal , 3(2) , pp 45-
52, 1979.  
[13] D. Wessel, David and M. Wright, “Problems and 
Prospects for Intimate Musical Control of 
Computers,” NIME 1, Workshop, 2001. 
[14] Puckette, M. “Combining Event and Signal 
Processing in the MAX Graphical Programming 
Environment,” Computer Music Journal  15(3), 
1991.  
[15] J. T. Buck, S. Ha, E. A. Lee, and D. G. 
Messerschmitt, “Ptolemy: A Framework for 
Simulating and Prototyping Heterogeneous 
Systems,” Int. Journal of Computer Simulation , 
special issue on Simulation Software Development, 
1994. 
 