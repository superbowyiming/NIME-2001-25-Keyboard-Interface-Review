 
 
Textural Crossfader  Matthew Blessing Louisiana State University Baton Rouge, LA 70820 mbless@cct.lsu.edu 
 Edgar Berdahl Louisiana State University Baton Rouge, LA 70820 edgarberdahl@lsu.edu ABSTRACT A LapBox derivative, the Textural Crossfader is a keyboard-based embedded acoustic instrument, which sits comfortably across the performer s lap and radiates sound out of integrated stereo speakers. The performer controls the sound by manipulating the keys on a pair of mini-keyboard interfaces. A unique one-to-one mapping enables the performer to precisely crossfade among a set of looped audio wave files, creating a conveniently portable system for navigating through a complex timbre space. The axes of the timbre space can be reconfigured by replacing the wave files stored in the flash memory. Keywords Crossfade, embedded acoustic instrument, Satellite CCRMA, Raspberry Pi, timbre, texture ACM Classification H.5.5 [Information Interfaces and Presentation] Sound and Music Computing, C.3 [Special-Purpose and Application-based Systems] Real-time and Embedded Systems, and H.5.2 [Information Interfaces and Presentation] User Interfaces. 1.  INTRODUCTION The present work aims to introduce a new and powerful embedded acoustic instrument, which has a simple and easy-to-replicate design based on Satellite CCRMA. This instrument is essentially an enhanced version of the original LapBox [1]. The enclosure is made out of two layers of 0.2 (0.508cm) laser-cut birch wood, so that it can be easily modified and replicated.  In the interest of simplicity, it was decided to employ USB-interfaced digital sensors instead of electronics customized all the way down to the sensors. USB mini-keyboards were agreed upon because each hand can manipulate multiple keys on a single keyboard at a time, providing more degrees of freedom for controlling the sound. 2. DIGITAL KEYBOARD INTERFACES The authors were inspired by the elegant design of prior digital keyboard interfaces. For example, early MIDI keyboards became successful because they standardized a way for musicians to control a vast range of synthesizers using a familiar interface [3]. Later keyboards sensed additional parameters, which could be employed for more precise control of the sound. For example, the Moog Multiply-Touch-Sensitive Keyboards could sense the positions of the fingers along the keys [6]. Other designers created keyboards that could measure real-time variations in the key-press pressure, known as aftertouch [2], which could be employed to modify the timbre of a note or bend its pitch over time. Notably, in the past few years, Andrew McPherson has developed a series of augmented or otherwise enhanced keyboard-based interfaces, such as TouchKeys [5]. 3. HARDWARE DESIGN Designed for a right-handed performer of keyboard-based instruments, the Textural Crossfader includes a two-octave MIDI keyboard for each hand. The right hand is responsible for the 
continuous control of the sounds and therefore manipulates a Keith McMillan QuNexus keyboard (see Figure 1, left) [4]. This keyboard measures multiple parameters for each key press, including the initial pressure and the position of the finger along the length of the key. The position and pressure are aftertouch features that are activated following the initial key press, and can be varied and tracked over time to modulate the sounds. In informal testing, it was determined that this keyboard provided a lot of useful information for expressively controlling sound, but it also required significant attention to control, which is why it was designated for the right hand only. Accordingly, it was decided that the performer s left hand should play the more typical Korg nanoKey keyboard (see Figure 1, right), which provides only traditional MIDI velocity information for note onsets. 
4. SOUND DESIGN AND MAPPING Blending sound fragments is a useful method for developing unique textures and timbres. Drawing inspiration from the work of David Wessel et al. [10] and Diemo Schwarz [8], the Textural Crossfader aims to provide the performer with expressive and precise control for live performance with MIDI keyboards in a simple context.  Twenty-five waveforms are stored in the flash memory of the Textural Crossfader, from which the performer can select up to four waveforms simultaneously. The selected waveforms are then mapped to a separate keyboard where they are looped, time-stretched and crossfaded, allowing for textural morphing across a reconfigurable and wide range of timbres. 4.1. Left Hand: Waveform Selection By default, the twenty-five waveforms are divided into three categories: repetitive percussive sounds, noise-based sounds, and pitch-based sounds. The sound categories were chosen to allow the 
Figure 1: The Textural Crossfader 
Figure 2: Left hand mapping on the Korg nanoKey keyboard 
180
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
 
 
performer a wide variety of timbral options. The percussive sounds also allow for interesting phasing effects when played with polyphonic time stretching. The performer chooses from these sounds with the left hand using a standard MIDI keyboard, in this case the Korg nanoKey keyboard. The sound categories are divided along the keyboard as shown in Figure 2. 4.2. Right Hand: Pitch, Crossfade, and Volume In the performer s right hand, the QuNexus keyboard tracks key pressure as well as the position of the fingers along the lengths of the keys. This, along with a specific mapping, allows for individual amplitude control as well as smooth crossfading. Specifically, as the performer selects up to four sounds in the left hand, they are assigned in the order selected to the designations Voice 1 through Voice 4. These voices are mapped to the right hand as shown in Figure 3. The voices are then crossfaded with each other, depending on the positions of the fingers along the keys.  The sounds can be changed throughout the performance. If the key assigned to a Voice N is released, that designation becomes available and is replaced by the next key pressed in the left hand. Voices 1 and 3—as well as Voices 2 and 4—are linked so that if only one of the two voices is selected, the other voice is mapped in its place. If one of the voices is unselected, the Textural Crossfader leaves that contribution from that key silent (see the white portions of the keys in the “Voice1”example of Figure 3). 
 In addition, the QuNexus keyboard also acts as a traditional keyboard in that the keys adjust the pitch of the sounds according to a chromatic scale. This is accomplished by adjusting the playback speed of the waveforms. Each waveform plays back at normal speed when the performer presses middle C, while each key above and below middle C pitch shift the sample progressively by one half step. The Textural Crossfader is polyphonic and can respond to up to five right-hand key presses simultaneously. If the keys are pressed and held, the samples loop at their respective playback speeds allowing for the samples to gradually fall out of phase.  Finally, the overall downward pressure on the keys controls the amplitude for each pair of waveforms. This allows for individual volume control from key to key. Also, when crossfading with silence (e.g. if one of the waveforms for the key is unselectedsee Voice 1 in Figure 3), the performer obtains a secondary volume control. 4.3. Flexible Configuration The Textural Crossfader has a top-mounted Ethernet port allowing for quick ssh connection to the Raspberry Pi. The composer/performer can design sound sets that can easily be loaded into the flash memory. This allows for a prepared-piano like adjustment of the sounds from performance to performance. Due to its modular design, the hardware configuration, which is presented in Figure 4, can be easily reconfigured for the creation of other new instruments. 5. CONCLUSION By crossfading among a set of looped waveforms, the Textural Crossfader enables the real-time control of diverse and powerful sonic textures, including the possibility to play notes using pitched sounds. This capability is demonstrated in the 
videos in the supplementary material: a demo video and a performance recording of the piece Textural Overlap, by the lead author. The instrument produces a strong enough sound pressure level that it was not necessary to amplify it with a microphone at a performance in a full-size recital hall. In a moment s notice, it can also be performed without additional amplification in diverse locations, owing to its internal battery. However, in especially large performance spaces, the instrument could be amplified as is commonly done with acoustic instruments. 6. REFERENCES [1] E. Berdahl. How to Make Embedded Acoustic Instruments. In Proc. of the International Conference on New Interfaces for Musical Expression, pp. 140-143, London, UK, June 2014.  [2] D. Buchla. Velocity and aftertouch sensitive keyboard. US Patent No. 4,558,623, 1985. [3] A. Hunt, M.M. Wanderley, and R. Kirk. Toward a Model for Instrumental Mapping in Expert Musical Interaction. In Proceedings of the International Computer Music Conference, pp. 209-212, Berlin, Germany, 2000. [4] K. McMillen and D.E. McAnulty. Multi-touch Pad Controller. US. Patent No. 20130239787-A1, Sept. 19, 2013. [5] A. McPherson. TouchKeys: Capacitive Multi-Touch Sensing on a Physical Keyboard. In Proceedings of the International Conference on New Interfaces for Musical Expression, Ann Arbor, MI, USA, May 2012. [6] R.Moog and T.L. Rhea. Evolution of the Keyboard Interface: The Bösendorfer 290 SE Recording Piano and The Moog Multiply-Touch-Sensitive Keyboards. Computer Music Journal, 14(2), pp. 52-60, Summer 1990. [7] D. Overholt, E. Berdahl, and R. Hamilton. Advancements in Actuated Musical Instruments. Organized Sound, 16(2), pp. 154-165, June 2011. [8] D. Schwarz. Musical Applications of Real-Time Corpus-Based Concatenative Synthesis, Proc. of the International Computer Music Conf., Copenhagen, Denmark, August 2007. [9] J. Snyder. Exploration of an Adaptable Just Intonation System. Dissertation. Columbia University, 2010. [10] D. Wessel, R. Avizienis, and A. Freed. A Force Sensitive Multi-touch Array Supporting Multiple 2-D Musical Control Structures. In Proc. of the Conf. on New Interfaces for Musical Expression, pp. 41-45, New York, USA, June 2007. 
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. NIME15, May 31-June 3, 2015, Louisiana State University, Baton Rouge, LA. Copyright remains with the author(s). 
Figure 3: Right hand mapping on the McMillan QuNexus keyboard 
Figure 4: Schematic diagram 
Raspberry Pi
supply12V power 12V to 5Vconverter
Audioamp
USB
USBcable
1/8"(2.54mm)audiocable
stereo
USB
running Satellite CCRMA
loop isolatorin−line groundcable includes
keyboardnanoKeyQuNexusKorg keyboard
181
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 