Prehistoric NIME: Revisiting Research on New Musical
Interfaces in the Computer Music Community before NIME
Marcelo M. Wanderley
Input Devices and Music Interaction Laboratory
Centre for Interdisciplinary Research in Music Media and Technology
McGill University
Montreal, QC
marcelo.wanderley@mcgill.ca
ABSTRACT
The history of the New Interfaces for Musical Expression
(NIME) conference starts with the first workshop on NIME
during the ACM Conference on Human Factors in Comput-
ing Systems in 2001. But research on musical interfaces has
a rich ”prehistoric” phase with a substantial amount of rel-
evant research material published before 2001. This paper
highlights the variety and importance of musical interface-
related research between the mid-1970s and 2000 published
in two major computer music research venues: the Interna-
tional Computer Music Conference and the Computer Mu-
sic Journal. It discusses some early examples of research
on musical interfaces published in these venues, then re-
views five other sources of related literature that pre-date
the original NIME CHI workshop. It then presents a series
of implications of this research and introduces a collabora-
tive website that compiles many of these references in one
place. This work is meant as a step into a more inclusive
approach to interface design by facilitating the integration
of as many relevant references as possible into future NIME
research.
Author Keywords
NIME, ICMC, CMJ, Historical, theoretical or philosophical
discussions about designing or performing with new inter-
faces
CCS Concepts
•Applied computing → Sound and music computing; Per-
forming arts; •Human-centered computing → Interaction
design;
1. INTRODUCTION
Several publications from the international conference on
New Interfaces for Musical Expression (NIME) have focused
on various aspects of the research in the NIME community.
Among these, a comprehensive book compiling a selection
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’23, May 31–June 2, 2023, Mexico City, Mexico.
of NIME research papers over fifteen years (2001 - 2015)
[50], each of them put into perspective by their authors and
by experts [49], as well as many research papers looking into
research practices in NIME research. Among them, works
on ”the notion of community as commonly employed within
NIME discourses”[64], the role of terminology in NIME, e.g.
what is meant by ”gesture” [48] or ”evaluation” [7], as well
as contributions arguing for a more inclusive history of the
NIME community [9]. Such papers present an invaluable
insight into the community itself, bringing up the strengths
and limitations of our current research.
A common trend amongst these references, though, is to
limit these analyses to the research published since the in-
ception of NIME in 2001 and only look at research papers
published in the NIME conference proceedings. These lim-
itations are not necessarily major issues, provided they are
duly acknowledged and adequately justified with respect to
the context being addressed. Unfortunately, this acknowl-
edgment is not always explicitly made in review papers or
books. Indeed, this exclusive focus on research papers pub-
lished on NIME events risks a) disregarding decades of rel-
evant previous research on musical interfaces, b) ignoring
pertinent recent papers published in other venues or c) not
taking into account other forms of information from NIME
events.
This paper partially addresses item a) by revisiting musi-
cal interface research published in the computer music com-
munity before the establishment of NIME. It presents early
perspectives on musical interface design and posits that sev-
eral of these works, having established many of the research
topics seen at recent NIME conferences, are still relevant
today. It also shows that several smaller communities inter-
ested on musical interfaces existed and were active at differ-
ent times prior to 2001, though the NIME workshop was the
essential catalyst needed to bring these and other commu-
nities together. The following sections introduce early dis-
cussions on musical interfaces, focusing on works from the
mid-1970s to 2000 in the computer music community’s two
main publication venues, the International Computer Mu-
sic Conference (ICMC) and the Computer Music Journal
(CMJ). The paper then reviews five other primary resources
directly related to current topics at the NIME conference,
highlighting the innovative aspects of pre-NIME research
outside the ICMC and CMJ. Finally, the paper discusses
several implications and limitations of this research, pro-
viding suggestions for incorporating these earlier references
into future research by the NIME community.
2. COMPUTER MUSIC INTERFACES
Electronic music has a rich history, with innovative instru-
ments built (and, for some, extensively used) by many peo-
ple for several decades [26]. Research in computer music,
though more recent, is roughly as old as digital computers
themselves [33] [5] [87]. Though different facets of computer
music were already present at the dawn of the field, e.g.
computer-aided composition and sound synthesis, interac-
tive computer music systems took a bit longer to appear,
with early examples introduced in the 1960s [69] [83].
In the 1980s, the introduction of the Musical Instrument
Digital Interface (MIDI) [63] and the appearance of portable
digital synthesizers were significant breakthroughs for NIME
research. Not only could these instruments send & receive
MIDI signals, but digital synthesizers also offered easy stor-
age and retrieval of presets, allowing for straightforward ex-
perimentation with radically different sounds at one’s fin-
gertips. Nevertheless, input devices used with computer
music systems were mainly limited to keyboards, sliders,
knobs, switches and joysticks.
The need for innovative devices liberating users to per-
form gestures not captured by existing computer input de-
vices was clearly stated by L. Sasaki and colleagues already
in 1981 [94]:
Conventional computer input devices (such as
sliders, joysticks, tablets, and keyboards) are be-
ing used to increased advantage [...] However,
additional research is required to design new de-
vices which lend themselves to the articulate ex-
pression of musical gestures.
And later by W. Buxton, in J. Appleton’s 1984 article on
the use of real-time performance systems [4]:
A major problem of synthesizers to date, espe-
cially recently, is that they constrain the per-
former to express ideas through a limited set
of gestures. (Ironically, some electronic instru-
ments from the 1930s to the 1960s were more
flexible in this regard.) This “straitjacket” of
most“over-the-counter”systems (for example the
piano-type keyboard synthesizer), has meant that
in many cases, the medium of expression is to-
tally at odds with the musical idea. To follow on
this, then, if gesture and idea are tied, and the
device is the instrument for capturing the ges-
ture, then the range of input devices could be as
diverse as the range of musical ideas.
It is interesting to note that shortly afterwards, a sig-
nificant breakthrough destined to become a landmark in
NIME was introduced, M. Wais-visz’s The Hands [110]. It
was one of the earliest examples of musical interfaces that
did not resemble existing acoustic or electric musical in-
struments. Even though the number of musical interfaces
developed grew steadily since then, The Hands has become
an icon to NIME 1, having been showcased multiple times
at early NIME conferences 2. It has been extensively used
by Waisvisz for more than 20 years [103], demonstrating
that musical interfaces can become long-term performance
instruments.
3. PUBLICATION VENUES
This section focuses on two of the oldest academic venues for
research on musical interfaces: the International Computer
1It appears on the opening page of https://www.nime.org,
accessed on April 05, 2023.
2For instance, in concerts in NIME 2002 & NIME 2006, as
well as in Waisvisz’s keynote in NIME 2003.
Music Conference (ICMC) and the Computer Music Journal
(CMJ). Though several other sources are also important,
for instance, the journals Interface, later renamed Journal
of New Music Research , Leonardo Music Journal, and the
more recent Organised Sound, they will not be reviewed here
due to space limitations.
3.1 International Computer Music Conf.
The ICMC was established in the mid-1970s and has been
held annually from 1980 onward3. Since then, the ICMC has
been one of the main channels for disseminating research on
the use of computers in music 4.
From its inception to 2000, researchers have published a
large number of papers related to musical interfaces. Several
themes/key terms in current research consistently appeared
in the titles of ICMC papers from that period, including:
• The terms ”real-time”, ”real time”or ”realtime”appear
in the titles of 202 articles;
• The sequence “interact” is used 130 times in paper
titles, e.g. as in interactive (103 times) or interaction
(25 times), indicating that the word interact ive was
more commonly used at that time;
• “Control”appears 127 times, including the term “con-
troller”, which appears 20 times (once as microcon-
troller, but in that case also in the context of interac-
tive music systems;)
• “Interface” appears 42 times, though around half of
the occurrences refer to graphical interfaces for non-
interactive software.
• The sequence ”gestur”, as in ”gesture” or ”gestural”,
appears 32 times;
• “Mapping” appears in 10 titles, roughly half the time
referring to work related to interactive systems and
instruments.
Other topics are less common, though they are still present.
For instance, terms related to haptic interfaces appear in
7 titles and include the terms haptic, tactile and force-
feedback. Similarly, [musical] robots appear in 3 titles.
Several papers at ICMC dealt with the above themes
early on, as early as 1975. Among them, one can cite works
dealing with interactive electronic musical instruments [89]
or interactive composition [25], gesture and gestural control
[1] [20] [6] [16], including discussions on performance with
gesture interfaces [23] [101], mapping [13], [60], [37], [28],
and force [20] [39] or tactile [27] feedback.
Research preparation for writing the book ”New Digital
Musical Instruments: Control and Interaction Beyond the
Keyboard” [72] identified some 220 ICMC references rele-
vant to musical interfaces5, out of some 2,100 papers pub-
lished.
3A. Hufschmitt [45] mentions related conferences in 1974
and 1976, but those proceedings are not available on the
ICMA website, with the first available volume being ICMC
1975. No conference was held in 1979. In this paper, we will
limit our analysis to publicly available ICMC proceedings
from the ICMA website, making a total of 24 conferences
between 1975 and 2000.
4ICMC proceedings are available online (until 2018) at
https://quod.lib.umich.edu/i/icmc?page=home.
5The list of references is available at https://www.idmil.
org/project/prehistoric-nime/
Recent research focusing on 40 years of digital musical
instrument (DMI) design up to 2016 conducted a linguis-
tic analysis of proceedings from three conferences dedicated
to computer music: ICMC (from 1974), NIME (from 2001)
and the International Sound & Music Computing Confer-
ence (SMC, from 2004). It identified 295 ICMC articles
between 1974 and 2000 containing six keywords related to
DMI design: stability, reliability, durability, compatibility,
maintainability and robustness [100]. These numbers at-
test to sustained activity related to musical interfaces at
the ICMC at that time.
3.2 Computer Music Journal
The CMJ, published by MIT Press, was established in 1977
[88] [98] and has since been the flagship venue for all aspects
of computer music.
In the 24 years from 1977 to 2000, many CMJ articles
dealt with interactive systems and electronic musical in-
struments6. Topics of interest include interactive conduct-
ing systems [59] [15], alternate controllers and interfaces
[68] [91] [57] [32] [44], sensors for musical performances [24]
[77], musical haptics [18] [17], collaborative performances
[47], and interactive dance systems [96].
Several CMJ special editions before 2001 focused on“New
Performance Interfaces”, namely issues 14:1 and 14:2 (1990)
and 22:1 (1998), presenting a comprehensive view of the
area thanks to authoritative contributions which, for the
most part, are still relevant today. The following quote by
CMJ editor S. T. Pope from issue 14(1) attests to the early
interest of the journal in NIME-related topics [80]:
This is the first of two special issues that will
address one of the major areas of contributions
of computer technology to music as a whole -
the development of new performance interfaces
and instrument paradigms. The other feature
articles provide an in-depth focus on this special
topic.
Figure 1: A picture of the partial covers of three CMJ special
issues on New Performance Interfaces, 14(2) and 14(2) in
1990 and 22(1) in 1998.
Other interesting CMJ articles take the form of reviews
of events focusing on interactive music [86] [61], inspiring
6The index of the first 24 volumes of CMJ is available at
http://alinehuf.fr/bibliographie-systematique/
index.html [45]. More recent CMJ volumes
are available from the journal’s homepage at
https://direct.mit.edu/comj, while all the back is-
sues (back to Volume 1) are available through JSTOR:
https://www.jstor.org/journal/computermusicj
overviews by researchers at the forefront of their fields [4]
[82] [67] [115], and in-depth interviews with key actors in
computer music [62] [58] [12]. These contributions are quintessen-
tial for researchers to get a fuller view of an area beyond
research articles in peer-reviewed venues.
3.3 A Few Innovative Developments: ‘85-’89
To provide a rough idea of the richness of the early research
on musical interfaces published in academic computer music
venues, let us review a few of the developments introduced
in the five years between 1985 and 1989. The choice of this
period is somewhat arbitrary. It does, though, provide an
excellent example of the activity in the area at that time.
In 1985, apart from the Hands , a few other innovative
interfaces were presented at ICMC. One of them was E.
Johnstone’s the Rolky [51], a very early version of a multi-
touch screen for musical control using a peripheral interface
adapter (parallel I/O interfacing) to communicate with a
6502 microcontroller (and no MIDI) 7. Another early de-
velopment presented in 1985 was a dance-music interface
controlled by myoelectric signals (EMG) by R. Gillett and
colleagues [42]. Also of interest were two publications about
systems for real-time interactive computer accompaniment,
[10] and [105], following the original papers published a year
before by R. B. Dannenberg [31] and by B. Vercoe [104].
M. Starkier and P. Prevot presented thePACOM in 1986
[99], a MIDI controller in the shape of a mixing desk using
various input devices such as potentiometers, sliders, joy-
sticks and ribbon controllers allowing for a wide choice of
control options. This console follows earlier attempts by
H. G. Alles [2] or by J. Snell [97], but this time it is en-
tirely MIDI compatible (using SysEx messages). A further
development that used multiple low-degree-of-freedom de-
vices in a musical interface was R. Vertegaal and colleagues’
“Musician’s Cockpit” [107] from 1996.
D. Wessel and colleagues discussed the control of phrasing
and articulation in sound synthesis [114], an essential topic
with implications for mapping, and G. Grossman presented
an interesting analysis of control mechanisms in mechanical
and computer-based tools [43].
A camera-based musical controller, the Oculus Ranae ,
was introduced by D. Collinge and S. Parkinson, providing
simple computer vision input to control synthesis (again, no
MIDI) [29]. Among several video camera-based musical con-
trollers widely used by the computer music community be-
fore 2001, one can cite T. Demeyer (STEIM)’sBig Eye8 and
A. Camurri and colleague’s EyesWeb [21]. D. Rubine and
P. McAvinney presented the VideoHarp[90], a multi-touch
optical-scanning MIDI gestural controller. An extended
version of this paper was published in the CMJ [91]. At
the same conference, a real-time unit for I. Xenakis’ UPIC
(Unit´ e Polyagogique Informatique du CEMAMu) compo-
sition system was introduced by J.-M. Raczinski and G.
Marino [84].
In 1989, the Radio Drum (also known as the Radio Ba-
ton) MIDI controller was introduced by R. Boie, M. Math-
ews, and A. Schloss [11]. In the same conference, X. Chabot
introduced three MIDI controllers and associated software
tools: the Sonar, the Pendulum and the Airdrum [23], and
D. Keane and P. Gross introduced the MIDI baton [56], one
of several conducting controllers presented around that time
[72].
Since 1990, a plethora of instruments have been proposed,
many of them discussed in [87] and in [72]. Though there
7Johnstone would later create a foot control interface for
seated performers called the PodoBoard [52].
8https://monoskop.org/STEIM
are too many to cover here, two examples of long-term de-
velopments stand out:
• The series of articles by H. Katayose and colleagues
[55] [54] and [53], on various iterations of advanced
systems using a variety of sensors for musical interac-
tion.
• The long-term work at ACROE, France, widely pub-
lished in early computer music venues and lasting for
over 40 years, blending theory and practical devel-
opments related to musical systems based on haptic
feedback, sound and image synthesis using physical
models [18]. A review of ACROE’s research has been
presented by C. Cadoz in his keynote address during
NIME03 [19].
Interestingly, the terminology used by the computer mu-
sic community at that time differed somewhat from the one
currently used today. For instance, controller and control
surface were commonly used to refer tointerface; as already
mentioned, interactive (adjective) seemed to be preferred to
interaction (noun), while gestural control was widely used
in the sense of musical human-computer interaction.
These terminology variations must be considered in meta-
reviews using automated tools when collecting information
about older publications to obtain an accurate view of past
research.
4. OTHER SEMINAL REFERENCES
Despite the importance of musical interface research in the
ICMC and the CMJ, many important works dealing with
NIME topics were presented in elsewhere. For instance,
an article published by B. Pennycook [78] describes many
of the early interactive systems of the 1970s and 1980s
and discusses significant issues related to musical interfaces.
Other references include A. Mulder’s analysis of alternate
controllers and how they can be designed to adapt to per-
formers’ movement capabilities [74], and J. Ryan’s article
on instrument design at STEIM [93].
Similarly, critical pre-NIME references exist in the form
of books [26] [87] 9 and websites gathering resources, e.g.
[73], though, unfortunately, the latter are primarily obsolete
today.
Several academic theses from the 1970s to 2000 also dealt
extensively with NIME issues: [38] [41] [22] [85] [34] [106]
[35] [65] [46] [75] [71] and [66], among others.
The following sections focus on five primary sources of
information outside the ICMC and CMJ, describing the ef-
forts made and their impact on NIME research.
4.1 STEIM Symposia, Controllers, Tools
The STudio for Electro-Instrumental Music (STEIM) in
Amsterdam, the Netherlands, was established in 1967 10.
Directed between 1981 and 2008 by M. Waisvisz, it was
a critical player in all aspects of interactive music and new
interfaces for musical expression. Waisvisz presented a com-
prehensive history of STEIM developments in his keynote
address at NIME0311.
Quoting M. Waisvisz [108]:
9Specifically, the chapter on Musical Input Devices, pages
617-658.
10https://monoskop.org/STEIM
11Available at https://www.youtube.com/watch?v=
RJ4zliNA7eI, in 6 parts.
STEIM was created as a laboratory for the re-
search and development of the modern practice
of electronic music. Right from its inception
some twenty-five years ago, STEIM has supported
an “instrumental” approach to the performing
of electronic music. It means that in STEIM’s
view, this kind of music only attains its defini-
tive form once it reaches the concert platform
and that, via direct, physical action, the per-
forming music-maker must create sound in the
public’s presence.
STEIM has been called “the land of alternate controllers”
[3] or “a legendary institution of live electronic music” 12
due to the intense activity around new musical interfaces
[92], mainly through residencies of composers, musicians
and artists who would develop their novel interfaces in close
collaboration with STEIM’s staff. An excellent overview of
numerous projects from the first 25 years of STEIM is pro-
vided in [109].
Three STEIM symposia were held from 1984 to 1986 [86]
[61]. These are especially interesting for NIME as many
discussions around interactive music performance and in-
strument design [93].
The Touch Festival 13, organized by S. J. Norman, M.
Waisvisz, and J. Ryan, was held in Amsterdam in 1998.
It consisted of two main events: a symposium with several
guest speakers and the Touch exhibition, where STEIM’s
controllers were displayed. The Touch instruments, includ-
ing the Hands , the Web and many others, became a “big
travelling’ playable exhibition’ with many new instruments”
[8]. The exhibition has been shown in several locations,
including at IRCAM, in Paris, around 2000, cf. Fig. 2
Figure 2: The poster made for the Touch Exhibition at IR-
CAM in Paris around 2000. Note the number of interfaces
displayed at the event, with their names in French.
12https://newmusicusa.org/nmbx/
theres-no-place-like-steim/
13http://www.steim.org/steim/texts.php?id=2
Thanks to the development of tools for musical control,
such as the already mentioned software Big Eye or the
well-known mapping tool junXion, as well as for organizing
events that had a critical impact on the future of interactive
music, STEIM was instrumental in creating a community of
practitioners around the idea of real-time computer music
performance. Indeed, it is hard to overstate STEIM’s con-
tribution to the NIME community.
4.2 Les Nouveaux Gestes de la Musique
In April 1997, the Centre National de Cr´ eation Musicale
(GMEM) in Marseille, France, organized a two-day event
called “Les Nouveaux Gestes de la Musique” with 14 talks
by leading researchers and artists, including J.-C. Risset,
M. Waisvisz, D. Wessel, C. Cadoz and S. de Laubier, and
two round tables on new musical interfaces [111]. A book
(in French) with chapters issued from the 1997 talks was
published in 1999, edited by the original workshop organiz-
ers H. Genevois and R. de Vivo [40]. It is, to our knowledge,
one of the first books specifically focused on NIME-related
topics. This event, together with the STEIM symposia, was
a landmark in the prehistory of NIME. Several of the book’s
chapters are seminal contributions to the field.
4.3 Trends in Gestural Control of Music
Another early comprehensive overview of NIME-related top-
ics is Trends in Gestural Control of Music (TGCM)[113], an
e-book devoted to research on musical interfaces. TGCM,
cf. Fig. 3, was one of the references cited in the proposal
for the CHI 2001 workshop on NIME [81].
Figure 3: Cover of the electronic book Trends in Gestural
Control of Music, one of the early works dedicated to musical
interfaces, released in 2000.
TGCM consists of twenty-four articles, tutorials and case
studies on gestural control of music (or, as it would be called
today, musical interfaces), an extensive bibliography on re-
lated issues, with around 500 entries, and a detailed list
of resources 14. The e-book articles, formatted for screen
reading or printing, included videos and sound examples
illustrating the contributions. Topics covered include in-
terface history and design, gestures, mapping, sensors and
interaction.
14Printable versions of the articles in TGCM are
available at https://github.com/mmwanderley2/
Trends-in-Gestural-Control .
One interesting resource in TGCM is a round table with
nine music interface pioneers: W. Buxton, D. Buchla, C.
Chafe, T. Machover, M. Mathews, R. Moog, J.-C. Risset,
L. Sonami, and M. Waisvisz. It is a unique document, a tes-
timony by key pre-NIME designers, researchers, composers
and performers on musical interfaces. Their answers are en-
lightening, discussing how they got involved with the field,
how they approached it in their practices, and what they
thought its future would be.
TGCM was another instance when a community of re-
searchers and practitioners came together to discuss the
field of new musical interfaces. Together with J. Paradiso’s
“Electronic Music, New Ways to Play” [76], they present
a comprehensive overview of the early research on musical
interfaces.
4.4 The ISIDM Working Group
The Interactive Systems and Instrument Design in Music
(ISIDM) working group15 was established after discussions
during ICMC 2000 in Berlin when a group of conference at-
tendees was willing to put together a comprehensive online
list of references on interactive systems and instruments.
The working group came out of a more focused effort carried
out at IRCAM, France, between 1997 and 2001, the “Ges-
ture Research in Music” group16. ISIDM was supported by
the International Computer Music Association (ICMA) and
the Electronic Music Foundation (EMF) and the website
was initially hosted by the ICMA [112].
The ISIDM website, created before the establishment of
accessible digital libraries, still has useful introductory texts
and extensive lists of references on interaction & perfor-
mance, sensors & actuators, interface design, mapping, soft-
ware tools, and dance technology, from pre-NIME papers to
more recent references, up to around 2010. A special issue
of the journal Organised Sound mentioning the ISIDM ac-
tivities was published in 2002 (volume 7, issue 3).
Though there are no links to the actual papers, NIME
researchers can use the ISIDM website as a rich source of
off-nime references. For instance, the ISIDM bibliography
on interface design has 463 entries, the bibliography on map-
ping has 83 entries, and the one on sensors has 62 entries, in-
cluding some of them from NIME conferences. The ISIDM
website has been up and running for two decades and is still
accessible to this date, though not recently updated.
4.5 Electronic Music and Interactivity
J¨org Piringer’s thesis [79], published in 2001 shortly after
the NIME workshop, is fundamental in several ways. It
a) presents an in-depth overview of the field done, for the
most part, before it was called NIME and b) compares musi-
cal interfaces in terms of three characteristics: expressivity,
immersion and feedback. This comparison (chapter 4) is
available in English thanks to a translation by C. Brunner
[14]. Finally, c) it provides a list of more than 100 interfaces,
classified as one primary type of device (e.g. free-gesture,
wearable, keyboard, sting-, wind-, drum-controller, etc.)17.
This work is outstanding due to its comprehensive nature,
covering decades of developments, and the choice of analysis
methodology that helps the reader make sense of the main
trends in musical interfaces up to 2001.
15https://sensorwiki.org/isidm
16http://recherche.ircam.fr/anasyn/wanderle/Gestes/
Externe/. The website is still online (April 2023)
17The complete list is available from https://joerg.
piringer.net/index.php?href=research/research.xml&
mtitle=info
5. IMPLICATIONS
Taking into account pre-NIME works18 will help under-
stand what currents were instrumental in creating the com-
munity we know today.
Implications of this research include the following:
• Awareness of the massive amount of early references
helps avoid re-inventing the wheel , a crucial step in
academic research. Conversely, learning from previ-
ous works can help the community develop innova-
tive designs based on time-tested pre-existing results.
It can, for instance, inspire practitioners to repro-
duce obsolete or unavailable devices with today’s tools
[102] without proposing something necessarily new,
the curse of the N in NIME .
• There is a need to federate pre- and off-NIME refer-
ences in a unique place, or at least in a few accessible
sites that can be easily perused. The field of NIME is
broader than the papers published in the yearly NIME
conference, and this richness needs to be considered
[9]. Though a few works have gone beyond NIME
proceedings examining issues related to musical inter-
faces, e.g. [100] and [70], still many of the works dis-
cussing NIME focus exclusively on the contents of the
conference’s proceedings. Excellent reviews of NIME
research, such as [36], a groundbreaking X-ray of the
20 first years of the NIME workshop/conference, could
be expanded by including such references to reflect an
even more accurate picture of the field.
As a practical outcome of this research, a proof-of-
concept website collecting pre-NIME (and eventually,
off-NIME) references was developed by J. Tragten-
berg19. We hope that expanded versions of this web-
site will be helpful as a complementary source of ref-
erences for research on musical interfaces.
• There is a need to consider the terminology used in
earlier works, which might differ from the one used
today. For instance, gestural control, controllers, and
control surfaces were used extensively in the computer
music community before musical interfaces became
the de facto term representing this field of research.
• There is a need to value research dealing with topics
that are not mainstream in other conferences. For in-
stance, reports on extended practice with new musical
interfaces, which were relatively common in computer
music venues (e.g. the CMJ interviews with com-
posers and performers or the ICMC studio reports)
are enlightening to NIME designers. Similarly, there
is crucial value in reports on innovative designs & en-
gineering solutions leading to the provision and avail-
ability of innovative, responsive and reliable tools for
musical expression, even when these do not undergo
formal user evaluation.
• Given the availability of automatic translation tools,
accessing texts about musical interfaces originally writ-
ten in other languages becomes a reality. A few sem-
inal works in French and German were mentioned in
this paper, but many more exist in those and in other
languages. Taking into account relevant works from
other languages and cultures can furthermore help
defy ”the hegemony of the computer and electroacous-
tic music history narrative, helping to break barriers
18As well as off-NIME works, i.e. NIME-related works pub-
lished in other venues since 2001.
19https://github.com/anonymousnimer/off-nime
and widening the way their history is understood”[30].
Initiatives such as the Latin American NIME Research
Network (LATAM NIME)20 are excellent steps in this
direction.
• Finally, it is time to update the narrative about the
origins of NIME to reflect a more inclusive perspec-
tive recognizing the diversity of sources that led to
the community we know today. Integrating different
points of view in the rich tapestry of NIME helps de-
colonize the field from a unique inheritance, reference,
or time. The field of NIME can be seen as a “tiers-
instruit” [95], a mix of different identities that makes
it unique.
6. LIMITATIONS
This paper has several limitations, which should be ad-
dressed in future works. Among them:
• It focuses on academic research (published research
papers), and does not mention non-academic sources.
• It addresses works from a given time (mid-1970s -
2000) and from one domain (computer music), leav-
ing out earlier and later works as wel as works in other
areas.
• The proposed website collecting off-NIME references
only links to PDFs of papers freely available online.
Papers with restricted copyright are consequently not
accessible.
7. CONCLUSION
This paper reviewed early research on NIME-related topics
in the computer music community. Focusing on two of its
earliest venues, the ICMC and the CMJ, it was shown that
a wealth of research directly related to current NIME inter-
ests predates the NIME workshop/conferences and are still
relevant today. Five other seminal sources of information
on musical interfaces were revisited, showcasing the work of
several researchers in this area over more than two decades.
A list of implications of this work was presented, aiming to
help the NIME community broaden its scope and acknowl-
edge multiple sources of relevant material in their research.
8. ACKNOWLEDGMENTS
Part of this work stems from text written for a book project
started several years ago in collaboration with J. Chadabe,
one of the keynote speakers of NIME 2002, a project un-
fortunately aborted by his passing in 2021. Apart from
being an exceptional person and a true pioneer, Joel’s con-
tribution to interactive computer music (and, therefore, to
NIME) cannot be overstated.
Several colleagues read earlier versions of this paper and
provided helpful insights, including F. Berthault, F. Cale-
gario, P. Castine, D. Keislar, A. Mulder, and J. Tragten-
berg. The three anonymous reviewers and the meta-reviewer
made suggestions that helped focus this work. Many IDMIL
students commented on this paper’s several drafts: M. Frad-
kin, E. Meneses, Z. Piao, K. Pocius & C. Reimer. Thank
you all.
I would like to thank INRIA - Lille, France (St´ ephane
Huot and colleagues at the Loki Team), for a 12-month
INRIA International Research Chair that made part of this
20https://latam.nime.org/
work possible. Several research grants from the Natural Sci-
ences and Engineering Research Council of Canada (NSERC)
provided ongoing support for this research.
9. ETHICAL STANDARDS
The author is a member of Computer Music Journal’s Ed-
itorial Advisory Board since 2016, a position that does not
involve pecuniary or other direct benefits. The author does
not identify any other conflicts of interest related to this
work. No artifical intelligence tool was used to write this
text. Grammar and spelling checks were done using Gram-
marly Premium.
10. REFERENCES
[1] C. Abbott. Remembering Performance Gestures. In
Proc. of the International Computer Music
Conference, pages 188–193, 1982.
[2] H. G. Alles. A 256-Channel Performer Input Device.
Computer Music Journal , 1(4):14–15, 1977.
[3] C. Anderton. STEIM. In the Land of Alternative
Controllers. Keyboard Magazine, pages 54—-62,
1994.
[4] J. Appleton. Live and in Concert:
Composer/Performer Views of Real-Time
Performance Systems. Computer Music Journal ,
8(1):48–51, 1984.
[5] C. Ariza. Two Pioneering Projects from the Early
History of Computer-Aided Algorithmic
Composition. Computer Music Journal , 35(3):40–56,
2011.
[6] F. Azzolini and S. Sapir. Score and/or Gesture: the
System RTI4I for Real-Time Control of the Digital
Processor 4I. In Proc. of the International Computer
Music Conference, pages 25–34, 1984.
[7] J. Barbosa, J. Malloch, M. M. Wanderley, and
S. Huot. What does ’Evaluation’ mean for the NIME
community? In Proceedings of the International
Conference on New Interfaces for Musical
Expression, pages 156–161, 2015.
[8] M. Battier, J. Rovan, and M. M. Wanderley, editors.
Electronic Controllers in Music Performance and
Composition. A Round table with W. Buxton, D.
Buchla, C. Chafe, T. Machover, M. Mathews, R.
Moog, J.-C. Risset, L. Sonami and M. Waisvisz.
Trends in Gestural Control of Music . Ircam - Centre
Pompidou, 2000.
[9] S. M. A. Bin. Discourse is Critical: Towards a
Collaborative NIME History. In Proceedings of the
International Conference on New Interfaces for
Musical Expression, 2021.
[10] J. J. Bloch and R. B. Dannenberg. Real-Time
Computer Accompaniment of Keyboard
Performances. In Proc. of the International
Computer Music Conference, pages 279–289, 1985.
[11] R. Boie, M. Mathews, and A. Schloss. The Radio
Drum as a Synthesizer Controller. In Proc. of the
International Computer Music Conference , pages
42–45, 1989.
[12] B. Bongers. An Interview with Sensorband.
Computer Music Journal , 22(1):13–24, 1998.
[13] I. Bowler, A. Purvis, P. Manning, and N. Bailey. On
Mapping N Articulation onto M Synthesiser-Control
Parameters. In Proc. of the International Computer
Music Conference, pages 181–184, 1990.
[14] C. Brunner. Electronic Music and Interactivity:
Principles, Concepts and Applications. Unpublished
translation of chapter 4 of J. Piringer’s 2001
Diplomarbeit, 2008.
[15] W. Buxton, W. Reeves, G. Fedorkov, K. C. Smith,
and R. Baecker. A Microprocessor-based Conducting
System. Computer Music Journal , 4(1):8–21, 1980.
[16] C. Cadoz. Instrumental Gesture and Musical
Composition. In Proc. of the International Computer
Music Conference, pages 1–12, 1988.
[17] C. Cadoz, L. Lisowski, and J.-L. Florens. A Modular
Feedback Keyboard Design. Computer Music
Journal, 14(2):47–51, 1990.
[18] C. Cadoz, A. Luciani, and J.-L. Florens. Responsive
Input Devices and Sound Synthesis by Simulation of
Instrumental Mechanisms: The Cordis System.
Computer Music Journal , 8(3):60–73, 1984.
[19] C. Cadoz, A. Luciani, J.-L. Florens, and
N. Castagn´ e. ACROE — ICA Artistic Creation and
Computer Interactive Multisensory Simulation Force
Feedback Gesture Transducers. In Proc. of the
International Conference on New Interfaces for
Musical Expression, pages 235—-246, 2003.
[20] C. Cadoz, A. Luciani, J.-L. Florens, and
T. Dars-Berberyan. The Control Channels of
Instrumental Playing in Computer Music - Real
Time in Computer Music, Incidence on the Choice of
the Basic Models. In Proc. of the International
Computer Music Conference, pages 73–91, 1982.
[21] A. Camurri, S. Hashimoto, M. Ricchetti, A. Ricci,
K. Suzuki, R. Trocca, and G. Volpe. EyesWeb:
Toward Gesture and Affect Recognition in
Interactive Dance and Music Systems. Computer
Music Journal, 24(1):57–69, 2000.
[22] P. Castine. An Evaluation of the User Interface in
Digital Audio Systems. Master’s thesis, Technical
University Berlin, 1988.
[23] X. Chabot. Performance with Electronics: Gesture
Interfaces and Software Toolkit. In Proc. of the
International Computer Music Conference , pages
65–68, 1989.
[24] X. Chabot. Gesture Interfaces and a Software
Toolkit for Performance with Electronics. Computer
Music Journal, 14(2):15–27, 1990.
[25] J. Chadabe. System Composing. In Proc. of the
International Computer Music Conference , pages
7–10, 1975.
[26] J. Chadabe. Electric Sound: The Past and Promise
of Electronic Music. Prentice-Hall, 1997.
[27] C. Chafe. Tactile Audio Feedback. In Proc. of the
International Computer Music Conference , pages
76–79, 1993.
[28] I. Choi, R. Bargar, and C. Goudeseune. A manifold
interface for a high dimensional control space. In
Proc. of the International Computer Music
Conference, pages 385–392, 1995.
[29] D. J. Collinge and S. M. Parkinson. The Oculus
Ranae. In Proc. of the International Computer
Music Conference, pages 15–19, 1988.
[30] R. Dal Farra. Part of Computer Music History...
(Trust Me, Latin America Has Always Been There!).
Computer Music Journal , 46(1/2):1–17, 2022.
[31] R. B. Dannenberg. An On-Line Algorithm for
Real-Time Accompaniment. In Proc. of the
International Computer Music Conference , pages
193–198, 1984.
[32] S. de Laubier. The Meta-Instrument. Computer
Music Journal, 22(1):25–29, 1998.
[33] P. Doornbusch. Computer Sound Synthesis in 1951:
The Music of CSIRAC. Computer Music Journal ,
28(1):10–25, 2004.
[34] G. Dubost. Technologies de Capteurs et leurs
Applications Musicales. Master’s thesis, Universit´ e
Paris Sud, Orsay, 1993.
[35] E. B. Egozy. Deriving Musical Control Features from
a Real-Time Timbre Analysis of the Clarinet.
Master’s thesis, MIT Media Laboratory,
Massachusetts Institute of Technology, 1995.
[36] S. Fasciani and J. Goode. 20 NIMEs: Twenty Years
of New Interfaces for Musical Expression. In Proc. of
the International Conference on New Interfaces for
Musical Expression, 2021.
[37] S. Favilla. Non-linear Controller Mapping for
Gestural Control of Gamaka. In Proc. of the
International Computer Music Conference , pages
89–92, 1996.
[38] J.-L. Florens. Coupleur gestuel interactif pour la
commande et le contrˆ ole de sons synth´ etis´ es en
temps r´ eel. PhD thesis, Institut National
Polytechnique de Grenoble - INPG, 1978.
[39] J.-L. Florens, A. Razafindrakoto, A. Luciani, and
C. Cadoz. Optimized Real-Time Simulation of
Objects for Musical Synthesis and Animated Image
Synthesis. In Proc. of the International Computer
Music Conference, pages 65–70, 1986.
[40] H. Genevois and R. de Vivo, editors. Les Nouveaux
Gestes de la Musique . Parenth` eses, 1999.
[41] S. Gibet. Codage, Repr´ esentation et Traitement du
Geste Instrumental. PhD thesis, Institut National
Polytechnique de Grenoble, 1987.
[42] R. Gillett, K. C. Smith, and B. Pritchard. MADDM
– Dance-Directed Music. In Proc. of the
International Computer Music Conference , pages
329–330, 1985.
[43] G. Grossman. Instruments, Cybernetics, and
Computer Music. In Proc. of the International
Computer Music Conference, pages 212–219, 1987.
[44] L. Haken, E. Tellman, and P. Wolfe. An Indiscrete
Music Keyboard. Computer Music Journal ,
22(1):30–48, 1998.
[45] A. Hufschmitt. Bibliographie Syst´ ematique des
P´ eriodiques en Musique et Technologie, 2001.
Groupe de recherche MINT/OMF de la Sorbonne,
Paris IV.
[46] A. Hunt. Radical User Interfaces for Real-time
Musical Control. PhD thesis, University of York,
1999.
[47] D. A. J. Jaffe and W. A. Schloss. The
Computer-Extended Ensemble. Computer Music
Journal, 18(2):78–86, 1994.
[48] A. R. Jensenius. To gesture or Not? An Analysis of
Terminology in NIME Proceedings 2001–2013. In
Proceedings of the International Conference on New
Interfaces for Musical Expression, pages 217–220,
2014.
[49] A. R. Jensenius and M. J. Lyons. Trends at
NIME—Reflections on Editing A NIME Reader. In
Proceedings of the International Conference on New
Interfaces for Musical Expression, pages 439–443,
2016.
[50] A. R. Jensenius and M. J. Lyons, editors. A NIME
Reader: Fifteen Years of New Interfaces for Musical
Expression. Springer International Publishing AG,
2017.
[51] E. Johnstone. The Rolky: A Poly-Touch Controller
for Electronic Music. In Proc. of the International
Computer Music Conference, pages 291–295, 1985.
[52] E. Johnstone. A MIDI Foot Controller - The
Podoboard. In Proc. of the International Computer
Music Conference, pages 123–126, 1991.
[53] T. Kanamori, H. Katayose, , S. Simura, and
S. Inokuchi. Gesture Sensor in Virtual Performer. In
Proc. of the International Computer Music
Conference, pages 127–129, 1993.
[54] H. Katayose, T. Kanamori, and S. Inokuchi. An
Environment for Interactive Art - Sensor Integration
and Applications. In Proc. of the International
Computer Music Conference, pages 173–176, 1996.
[55] H. Katayose, H. Shirakabe, T. Kanamori, and
S. Inokuchi. A Toolkit for Interactive Digital Art. In
Proc. of the International Computer Music
Conference, pages 1–3, 1996.
[56] D. Keane and P. Gross. The MIDI Baton. In Proc.
of the International Computer Music Conference ,
pages 151–154, 1989.
[57] R. B. Knapp and H. Lusted. A Bioelectric Controller
for Computer Music Applications. Computer Music
Journal, 14(1):42–47, 1990.
[58] V. Krefeld. The Hand in the Web: An Interview
with Michel Waisvisz. Computer Music Journal ,
14(2):28–33, 1990.
[59] J. Lawson and M. V. Mathews. Computer Program
to Control a Digital Real-Time Sound Synthesizer.
Computer Music Journal , 1(4):16–21, 1977.
[60] M. Lee, A. Freed, and D. Wessel. Real-time neural
network processing of Gestural and Acoustic Signals.
In Proc. of the International Computer Music
Conference, pages 277–280, 1991.
[61] G. W. Logemann. Report on the Last STEIM
Symposium on Interactive Composing in Live
Electronic Music. Computer Music Journal ,
11(3):44–47, 1987.
[62] H. Lohner. Interview with Robert Moog. Computer
Music Journal, 9(4):62–65, 1985.
[63] G. Loy. Musicians Make a Standard: The MIDI
Phenomenon. Computer Music Journal , 9(4):8–26,
1985.
[64] A. Marquez-Borbon and P. Stapleton. Fourteen
Years of NIME: The Value and Meaning of
‘Community’ in Interactive Music Research. In
Proceedings of the International Conference on New
Interfaces for Musical Expression, pages 307–312,
2015.
[65] T. Marrin. Toward an Understanding of Musical
Gesture: Mapping Expressive Intention with the
Digital Baton. Master’s thesis, MIT Media
Laboratory, Massachusetts Institute of Technology,
1996.
[66] T. Marrin-Nakra. Inside the Conductor’s Jacket:
Analysis, Interpretation and Musical Synthesis of
Expressive Gesture. PhD thesis, MIT Media
Laboratory, Massachusetts Institute of Technology,
2000.
[67] M. V. Mathews. The Radio Baton and Conductor
Program, or: Pitch, the Most Important and Least
Expressive Part of Music. Computer Music Journal ,
15(4):37–46, 1991.
[68] M. V. Mathews and C. Abbott. The Sequential
Drum. Computer Music Journal , 4(4):45–59, 1980.
[69] M. V. Mathews and F. R. Moore. GROOVE: A
Program to Compose, Store, and Edit Functions of
Time. Communications of the ACM , 13:715–721,
1970.
[70] A. McPherson, F. Morreale, and J. Harrison. New
Direction in Music and Human-Computer
Interaction, chapter Musical Instruments for
Novices: Comparing NIME, HCI and Crowdfunding
Approaches, pages 179–212. Springer Nature
Switzerland AG, 2019.
[71] D. Menzies. New Electronic Performance
Instruments For Electroacoustic Music. PhD thesis,
Department of Electronics, University of York, 1999.
[72] E. R. Miranda and M. M. Wanderley. New Digital
Musical Instruments: Control and Interaction
beyond the Keyboard. A-R Editions, 2006.
[73] A. Mulder. Human Movement Tracking Technology.
Technical report, Simon Fraser University, 1994.
Hand Centered Studies of Human Movement
Project.
[74] A. Mulder. Getting a Grip on Alternate Controllers:
Addressing the Variability of Gestural Expression in
Musical Instrument Design. Leonardo Music Journal,
6:33–40, 1996.
[75] A. Mulder. Design of Gestural Constraints Using
Virtual Musical Instruments. PhD thesis, School of
Kinesiology, Simon Fraser University, Canada, 1998.
[76] J. A. Paradiso. Electronic Music: New Ways to Play.
IEEE Spectrum, 34:18–30, 1997.
[77] J. A. Paradiso and N. Gershenfeld. Musical
Applications of Electric Field Sensing. Computer
Music Journal, 21(2):69–89, 1997.
[78] B. W. Pennycook. Computer-Music Interfaces: A
Survey. Computing Surveys, 17(2):267–289, 1985.
[79] J. Piringer. Elektronische Musik und Interaktivit ¨at:
Prinzipien, Konzepte, Anwendungen. Master’s thesis,
Institut f¨ur Gestaltungs und Wirkungsforschung der
Technischen Universit¨at Wien, 2001.
[80] S. T. Pope. Editor’s Notes. Computer Music
Journal, 14:3, 1990.
[81] I. Poupyrev, M. J. Lyons, S. Fels, and T. Blaine. New
Interfaces for Musical Expression. In Proceedings of
CHI 2001, Extended Abstracts , pages 491–492, 2001.
[82] J. Pressing. Cybernetic Issues in Interactive
Performance Systems. Computer Music Journal ,
14(1):12–25, 1990.
[83] J. K. Pulfer. Man-Machine Interaction in Creative
Applications. International Journal of Man-Machine
Studies, 3(1):1–11, 1971.
[84] J.-M. Raczinski and G. Marino. A Real-time
Synthesis Unit. In Proc. of the International
Computer Music Conference, pages 90–100, 1988.
[85] C. Ramstein. Analyse, Repr´ esentation et Traitement
du Geste Instrumental . PhD thesis, Institut National
Polytechnique de Grenoble, December 1991.
[86] C. Roads. The Second STEIM Symposium on
Interactive Composition in Live Electronic Music.
Computer Music Journal , 10(2):44–50, 1986.
[87] C. Roads. The Computer Music Tutorial . MIT Press,
1996.
[88] C. Roads, J. Snell, C. Abbott, and J. Strawn. A
History of ”Computer Music Journal”. Computer
Music Journal, 10(1):13–16, 1986.
[89] D. Rosenboom. A Model for Detection and Analysis
of Information Processing Modalities in the Nervous
System Through an Adaptive, Interactive,
Computerized, Electronic Music Instrument. In
Proc. of the International Computer Music
Conference, pages 54–78, 1975.
[90] D. Rubine and P. McAvinney. The VideoHarp. In
Proc. of the International Computer Music
Conference, pages 49–55, 1988.
[91] D. Rubine and P. McAvinney. Programmable
Finger-tracking Instrument Controllers. Computer
Music Journal, 14(1):26–41, 1990.
[92] J. Ryan. The STEIM Studio Report. In Proc. of the
International Computer Music Conference , pages
325–328, 1992.
[93] J. Ryan. Some Remarks on Musical Instrument
Design at STEIM. Contemporary Music Review,
6:3–17, 1993.
[94] L. Sasaki, G. Fedorkow, W. Buxton, C. Retterath,
and K. C. Smith. A Touch-Sensitive Input Device. In
Proc. of the International Computer Music
Conference, pages 293–297, 1981.
[95] M. Serres. The Troubadour of Knowledge. University
of Michigan Press, 1997.
[96] W. Siegel and J. Jacobsen. The Challenges of
Interactive Dance: An Overview and Case Study.
Computer Music Journal , 22(4):29–43, 1998.
[97] J. Snell. The Lucasfilm Real-Time Console for
Recording Studios and Performance of Computer
Music. Computer Music Journal , 6(3):33–45, 1981.
[98] J. Snell. How Did ”Computer Music Journal” Come
to Exist? Computer Music Journal , 30(1):10–20,
2006.
[99] M. Starkier and P. Prevot. Real-Time Gestural
Control. In Proc. of the International Computer
Music Conference, pages 423–426, 1986.
[100] J. Sullivan and M. M. Wanderley. Stability,
Reliability, Compatibility: Reviewing 40 Years of
DMI Design. In Proceedings of the Sound and Music
Computing Conference, pages 308–315, 2018.
[101] A. Tanaka. Musical Technical Issues in Using
Interactive Instrument Technology with Applications
to the BioMuse. In Proc. of the International
Computer Music Conference, pages 124–126, 1993.
[102] A. J. Tom, H. J. Venkatesan, I. Franco, and M. M.
Wanderley. Rebuilding and Reinterpreting a Digital
Musical Instrument — The Sponge. In Proceedings
of the International Conference on New Interfaces
for Musical Expression, pages 37–42, 2019.
[103] G. Torre, K. Andersen, and F. Bald´ e. The Hands:
The Making of a Digital Musical Instrument.
Computer Music Journal , 40(1):22–34, 2016.
[104] B. Vercoe. The Synthetic Performer in The Context
of Live Performance. In Proc. of the International
Computer Music Conference, pages 199–200, 1984.
[105] B. Vercoe and M. Puckette. Synthetic Rehearsal:
Training the Synthetic Performer. In Proc. of the
International Computer Music Conference , pages
275–278, 1985.
[106] R. Vertegaal. An Evaluation of Input Devices for
Timbre Space Navigation. Master’s thesis,
Department of Computing - University of Bradford,
1994.
[107] R. Vertegaal, T. Ungvary, and M. Kieslinger.
Towards a Musician’s Cockpit: Transducers,
Feedback and Musical Function. In Proc. of the
International Computer Music Conference , pages
308–311, 1996.
[108] M. Waisvisz. STEIM - de zoetgevooisde BLIKSEM ,
chapter Twenty-five Years of STEIM: an overture,
pages 2–4. STEIM, 1993.
[109] M. Waisvisz, J. Ryan, and N. Collins, editors.
STEIM - de zoetgevooisde BLIKSEM . STEIM, 1993.
[110] M. Waiswisz. The Hands, a Set of Remote
MIDI-Controllers. In Proc. of the International
Computer Music Conference, pages 313–318, 1985.
[111] M. M. Wanderley. Les Nouveaux Gestes de la
Musique. Unpublished Report. IRCAM - Groupe
Analyse/Synth` ese, 1997.
[112] M. M. Wanderley. Report on the First 18 Months of
the ICMA/EMF Working Group on Interactive
Systems and Instrument Design in Music – ISIDM.
Array, ICMA, 2002.
[113] M. M. Wanderley and M. Battier, editors. Trends in
Gestural Control of Music . Ircam - Centre
Pompidou, 2000.
[114] D. Wessel, D. Bristow, and Z. Settel. Control of
Phrasing and Articulation in Synthesis. In Proc. of
the International Computer Music Conference , pages
108–116, 1987.
[115] D. L. Wessel. Instruments That Learn, Refined
Controllers, Source Model Loudspeakers. Computer
Music Journal, 15(4):82–86, 1991.