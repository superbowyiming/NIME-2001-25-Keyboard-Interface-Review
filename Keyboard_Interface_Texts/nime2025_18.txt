Collaborative Musical Expression Through Interactive VR
Scores
David Kim-Boyle
Sydney Conservatorium of Music, The University of Sydney
Sydney, Australia
david.kim-boyle@sydney.edu.au
Abstract
While the technical affordances of virtual reality (VR) have pro-
vided new ways for artists to aestheticize immersion, spectator
agency, embodiment and multi-sensory engagement, they have
also opened new possibilities for composers interested in ex-
ploring how interactive musical scores might become a means
through which collaboration itself becomes the locus of aesthetic
expression. In this paper, the author will provide an overview
of an ongoing project which explores new ways of thinking
about musical collaboration in VR through the 3D visualization
of interactive, graphic scores adapted from works by composers
Earle Brown, Christian Wolff, and Toru Takemitsu. The research
demonstrates how VR can transform traditional score interpreta-
tion by creating dynamic, interactive environments that enable
collaborative musical expression, challenge conventional nota-
tion, and offer novel ways of negotiating musical performance
through networked, multi-user interactions.
Keywords
Virtual Reality, Music Notation, Musical Collaboration, Network-
ing, Multiplayer
1 Introduction - The Ontology of the Score
Musical scores are not ordinarily thought of as objects which
can be interacted with in a material sense. Traditionally existing
as static containers of information that unfolds over time, they
are usually subsumed into the background during performance
or altogether absent should performers have memorised the in-
formation bound within their pages. Given this legacy, it would
seem counterintuitive for the visual aesthetics of scores to re-
ceive much attention. Nevertheless, the design and appearance of
musical scores has received greater investigation in a growing va-
riety of practice since the mid-twentieth century. The increasing
adoption of digital displays [21], has facilitated the development
of animated scores [9], networked scores [13], and even reactive
scores responsive to performer and audience agency [12]. All of
these developments have opened new creative affordances for
musical expression and new pathways for critical discourse.
These rapid developments have presented particular chal-
lenges for how such digital, dynamic scores might be theoretically
situated and in this respect object-oriented ontology offers a par-
ticularly helpful framework. Simondon’s theory of individuation
[19], suggests that the score can be understood as an individuated
entity that embodies a set of pre-individual potentials, awaiting
actualisation through the act of performance. It exists not merely
as a passive set of instructions but as a dynamic reservoir of
This work is licensed under a Creative Commons Attribution 4.0 International
License.
NIME ’25, June 24–27, 2025, Canberra, Australia
© 2025 Copyright held by the owner/author(s).
possibilities that shapes and is shaped by its interactions with
musicians and listeners. Yuk Hui’s extension of Simondon’s ideas
into the realm of digital objects extends and illuminates this
perspective [10], suggesting that as digital objects such scores
operate within a network of relations, continuously redefined
by their context and interactions. Through such a theoretical
framework, the score is thus an active participant in the digital
ecosystem, possessing its own influence independent of human
engagement.
The particular network of relations within which reactive
scores operate - and how they can both facilitate collaboration
and establish collaboration as a holder of aesthetic value - is
the fundamental driving force of the project outlined in this
paper. Leveraging the affordances of VR, the score no longer
sits as a passive repository of information but rather, offers new
modalities of performance and challenges our understanding of
what a score can be. Some of these possibilities will emerge in
the following sections of this paper which will focus on how
the musical potentials of a score can be actualised through the
collective agency of networked participants.
2 VR Adaptations
The mid-twentieth century witnessed an explosion of interest
in non-linear musical forms which could not typically be easily
represented by standard, common-practice notation. Coupled
with a related consideration of how performance agency might
be leveraged in novel ways, the score for works such as Earle
Brown’s iconic December 1952 (1952) offered radical new ways
of representing musical form, see Figure 1.
Despite their idiosyncratic approach to musical notation, such
scores were nevertheless bound by the physical constraints of the
medium upon which they were inscribed. While composers such
as John Cage experimented with different printed medium such
as transparencies in the 1950s, it was not until the adoption of
digital displays that scores could transcend the inherent physical
constraints of fixed mediums. The use of generative or procedural
techniques of composition, for example, and the development
of notation software such as MaxScore [5] and Bach [1] allowed
scores to be instantiated in real-time during performance and
displayed for performers on digital displays. These creative and
aesthetic affordances have been considerably extended through
the rapid evolution and growing accessibility of VR technologies.
In adapting various historical works for a VR environment, the
aesthetic affordances of multiplayer collaboration has emerged
as a key focus.
The selection of works by Brown, Wolff, and Takemitsu for
VR adaptation was deliberate, based on several specific criteria
that make these compositions particularly suitable for virtual
reality implementation. First, each score already challenges con-
ventional notational paradigms through its graphic approach,
NIME ’25, June 24–27, 2025, Canberra, Australia David Kim-Boyle
Figure 1: December 1952 by Earle Brown. This seminal
graphic score leaves much of the musical decision making
to performers.
providing conceptual openness that aligns with VR’s spatial af-
fordances. Second, these works span different compositional ap-
proaches to indeterminacy — Brown’s geometric abstraction,
Wolff’s network-like structures, and Takemitsu’s circular organi-
zation—allowing exploration of diverse VR visualization strate-
gies. The inherent non-linearity of these scores harmonizes with
VR’s capacity to break from the left-to-right reading tradition of
Western notation, enabling truly spatial musical thinking. Ad-
ditionally, these works were chosen for their explicit invitation
of performer agency in the realization process, a characteristic
that extends naturally to the collaborative manipulation possible
in networked VR. The progression from Four Systems to Jasper
to Corona also represents an increasing complexity in both no-
tational approach and VR implementation, providing a path of
logical development for the research.
2.1 Related Work in VR
While the work discussed in this paper extends existing research
by the author on graphic scores in immersive environments [11],
it is helpful to situate this within the broader landscape of sym-
bolic music representations and instruments in VR. El Raheb et
al. investigated transferring symbolic languages from paper to
spatial cues in mixed reality [6], while Zellerbach and Roberts
proposed a framework for a Mixed Reality Musical Instrument
(MRMI) examining relationships between performers, virtual ob-
jects, and physical environments [24]. Their work emphasizes
how symbolic representations in mixed reality can create intu-
itive relationships between gesture and sound, particularly rele-
vant to an exploration of immersive graphic scores. This spatial
representation of musical information presents unique opportuni-
ties for embodied cognition that traditional paper-based notation
cannot provide, allowing performers to engage with musical
structures through physical movement and spatial awareness.
The field of Virtual Reality Musical Instruments (VRMIs) has
received considerably more attention, as evidenced by several
systematic reviews and frameworks. Serafin et al. outlined nine
design principles for VRMIs, emphasizing that they should not
merely replicate existing instruments but offer new possibilities
leveraging virtual environments [18]. Gómez-Sirvent et al. iden-
tified seventy-four studies of musical instruments in extended
reality with applications ranging from education to rehabilitation
[8], while Berthaut et al. proposed a scenography framework for
immersive virtual musical instruments addressing dimensions
such as musician visibility and gestural continuity [? ]. Webster
and Kourkoulakou examined the challenges of avatar represen-
tation and embodiment in immersive 3D audio composition en-
vironments [22]. Their research on the VRAS project highlights
how questions of presence and virtual body representation signif-
icantly impact musical experience in VR, informing the approach
to representing participants in shared score environments. The
work explored in this paper bridges these approaches by explor-
ing how immersive visualization of graphic scores can enhance
collaborative performance through spatial understanding and
multi-user interaction in ways traditional physical scores can-
not achieve. Unlike many VRMIs that focus primarily on solo
performance, these adaptations specifically investigate the affor-
dances of networked multiplayer environments for collaborative
music-making, addressing Serafin’s principle of making VR ex-
periences social while exploring how score interpretation can be
collectively negotiated in real-time.
3 Implementations
3.1 Four Systems(1952-53) - Earle Brown
In terms of its visual design, the score for Earle Brown’s Four
Systems, for pianist, bears distinct similarities to December 1952
featuring four systems of rectangles of different sizes and spatial
arrangements, see Figure 2a.
Figure 2: a) The first system from Earle Brown’s Four Sys-
tems (1952-53) (upper), b) Part of the score presented in a
VR adaptation as viewed by the pianist through an Oculus
Quest 3 headset in pass-through mode
Brown’s work is the first that the author has adapted for a
networked, multiplayer VR environment where the score is pre-
sented as an interactive, three-dimensional visualization and
viewed by a pianist through an Oculus Quest 3 head-mounted
display (HMD) in pass-through mode, see Figure 2b. During per-
formance, networked participants enter the space in which the
score is situated and effect various transformations to its com-
ponents which are visible to all connected clients. This transfor-
mations in turn affect the interpretive possibilities available to
Collaborative Musical Expression Through Interactive VR Scores NIME ’25, June 24–27, 2025, Canberra, Australia
the pianist. There are two ways in which the score may be trans-
formed. Firstly, the rectangular prisms which make up the score
can be grabbed via hand-tracking and carefully repositioned, or
even thrown, within the virtual room with their behaviour sub-
ject to room gravity and inertia. These relocations may result in
collisions with other components of the score resulting in cas-
caded movements amongst other objects. Secondly, score objects
can be resized by increasing or decreasing the distance between
thumb and index finger which in addition to affecting the way
the pianist might engage with the score, also affects some of the
audio functionality of the score which will be discussed shortly.
Much as in the real world, virtual hands cannot interact with
objects at a distance. For the Four Systems adaptation, two dif-
ferent solutions to this problem were implemented. In the first
solution, raycasts were attached to the hands to target distant
objects, see Figure 3, while in the second, the safety boundaries
established when launching the application were changed to
"Roomscale" so that users can physically wander over to distant
objects and manipulate them directly. Such wandering is by de-
fault not available when an application is launched for obvious
safety reasons.
Figure 3: Raycasts attached to each hand allow the manip-
ulation of score objects situated at a distance.
The VR adaptation also functions as a virtual instrument with
each score object directly correlated to a prerecorded piano sam-
ple which is triggered back when objects collide or when a client
"pinches" them within the VR space. The size of the objects is
correlated to musical pitches - larger objects correspond to lower
pitches while smaller objects correspond to higher pitches. The
piano samples triggered by agents are broadcast to all connected
clients and also to the live performance space in which the piano
is located such that the pianist is performing amongst a tapestry
of virtually activated piano sounds. In addition, the live interpre-
tation of the pianist, is also streamed to each connected client for
them to hear locally.
The VR adaptation of Four Systems thus presents a somewhat
unusual performance model that is both localized within a live
performance space and distributed to all connected clients. This
performance modality is schematized in Figure 4.
3.2 Jasper (1991) - Christian Wolff
Christian Wolff’s creative output is extraordinarily vast and defies
easy summarization. Nevertheless, perhaps his most recognized
thematic pursuit has been a long-running engagement with how
the collaborative, dynamic nature of performance can be aes-
theticized in distinctive musical forms and, following from this,
Figure 4: Performance framework for Four Systems.
how such collaborative processes might be denoted in perfor-
mance scores. This foregrounding of collaborative relationships
encourages an inclusive and participatory approach to composi-
tion and performance and is closely aligned with Wolff’s political
sensibilities [7].
While Jasper is a relatively late work in Wolff’s oeuvre, it
continues his exploration of many of the aesthetic possibilities of
collaborative processes. Written for double-bass and violin, the
third movement features a graphic score that closely resembles a
node-graph, see Figure 5.
Figure 5: An excerpt from the score to the third movement
of Jasper (1991) with the upper bracket denoting the violin
part and the lower bracket the double-bass part. The short,
horizontal lines denote the four strings of each instrument
while the open and closed diamonds indicate notes.
The author’s VR adaptation of the third movement of Jasper
builds on many of the techniques developed in the earlier Four
Systems adaptation including hand-tracking interaction and the
same performance modality illustrated in Figure 4. Given there
is no need for the two performers to be able to see their instru-
ments in the same way as a pianist might, the presentation of the
score does not require the AR-like presentation of pass-through
mode. Rather, the score is presented to the two performers as
an immersive visualization which can be fully read by turning
through 360-degrees, see Figure 6.
In Jasper three classes of sonic events are denoted by differ-
ent colored nodes - 1. Events of long duration (green nodes),
2. Events of short duration (red nodes), 3. Harmonics of either
short or long duration (white nodes). In the VR adaptation, these
nodes are wrapped around each of the performers preserving
the original distribution along the x-axis in the original score. To
NIME ’25, June 24–27, 2025, Canberra, Australia David Kim-Boyle
Figure 6: The immersive VR score for Jasper (1991) viewed
from outside.
help distinguish the vertical position of each of the nodes, the
strings - which in the original score are denoted by short hori-
zontal lines - are drawn as rings surrounding the viewer within
the VR scene, as shown in Figure 6. In Unity3D, the development
platform used for all VR adaptations discussed in this paper, each
of these rings are rendered as splines which helps facilitate the
interactive capabilities of the score. Finally, nodes are connected
by thin lines, corresponding to edges in a node graph, which in
the VR adaptation are given a slightly different colour mapping
to contrast them from the string lines.
As in Jasper, players within the VR scene can interact with the
components of the score which directly affects the interpretive
possibilities available to the two live musicians. There are two
possibilities for score interaction both of which are facilitated via
hand tracking - 1) By pushing nodes along the string lines, 2) By
“plucking” the edges that connect nodes. Similarly to an abacus,
nodes can be pushed either left or right along the string upon
which they sit. Each of the nodes is subject to Newtonian physics
behaviours upon collision with other nodes with the force of
hand movement directly correlated to the velocity of movement
along each string. This behaviour is implemented within Unity
by aligning the movement of each node to the closest position
along the spline upon which it sits. The second type of score
interaction implemented is the plucking of edges that connect
nodes which is implemented by a simple collision detection with
the hands and which results in the playback of an audio sample
of a prerecorded plucked string. The force of the collision is
correlated to the volume of the playback sample and the length
of the string is correlated to pitch with long strings sounding
as low frequencies and short strings sounding as higher pitches.
These audio samples are played to all connected clients.
3.3 Corona (1962) - Toru Takemitsu
In the late 1950s and early 1960s, composer John Cage began ex-
ploring how musical scores constructed from materials other than
paper might offer new musical possibilities and creative affor-
dances. Profoundly coupled with his well-documented concerns
with the aesthetics of intention and listening, these experiments
resulted in a series of works such as Fontana Mix (1958), Vari-
ations I (1958), Cartridge Music (1960), and Variations II (1961),
amongst others, which radically repositioned relationships be-
tween performers, audiences, and scores. The works to emerge
from this period found a particularly receptive audience in Japan,
this no doubt also from the strong influence of Zen Buddhist tra-
ditions on Cage’s creative practice, amongst its own experimental
music practice represented by artist collectives such as Group
Ongaku [14] and composers like Toshi Ichiyanagi whose Music
for Piano No. 7 (1961) features a score constructed from superim-
posed transparent sheets. Ichiyanagi’s student Toru Takemitsu,
continued to explore the musical possibilities of graphic notation
in a series of works produced in the early 1960s the most strik-
ing of which perhaps is Corona (1962) which was premiered by
Ichiyanagi and pianist Yuji Takahashi in February 1962.
Takemitsu created the score for Corona in collaboration with
graphic designer Kôhei Sugiura [3]. The piece exists in two ver-
sions - one for solo piano, and the other for string orchestra.
The piano version comprises five studies - 1. Study for Vibration,
2. Study for Intonation, 3. Study for Articulation, 4. Study for
Expression, and 5. Study for Conversation. Each study features a
single-page score printed in blue, red, yellow, grey, and white ink,
respectively, on individual transparencies. While Takemitsu’s
performance notes are somewhat ambiguous, he suggests that
each of these transparencies may be cut and intersected with
others to form different arrangements [20]. The score for each
study is characterized by its circular, non-linear structure with
various musical events graphically presented along its perimeter.
The pianist commences performance of a particular study by
selecting a point along the perimeter and transversing their way
around the circle in either a clockwise or anticlockwise direction
at a speed loosely indicated as 1. possibly slow, 2. 2 min or 4 min,
3. possibly fast, 4. 1 min or 3 min or 5 min, and 5. tempo free [20].
The circular structure ofCorona, where no one spatial location
is more privileged than any other and where this in turn helps
support a non-linear temporal ontology, lends itself particularly
well to an arrangement and presentation in an immersive, virtual
reality space. The author has chosen "Study for Intonation" for
such an adaptation, see Figure 7.
In the VR adaptation of "Study for Intonation" developed by
the author, the notational descriptors which denote the properties
of various sonic events are stochastically distributed along the
perimeter of the circle. The score is uniquely generated upon each
instantiation within constraints defined in a set of predetermined
rules - for example no more than three nodes may be drawn along
any radial and no more than eight radials may be generated in
any instantiation. Two such instantiations are presented in Figure
8.
Just like the VR scores developed for Four Systems and Jasper,
the VR score for Corona is expressly intended for a performance
model wherein the performer is presented with a score that
is manipulated and also performed or sounded by networked
clients in what amounts to both a local and distributed mode
of performance. In Corona, clients enter the VR space in which
the score is situated and interact with its various components
by either 1) repositioning them, or 2) playing or sounding them
as if they are a musical instrument. Both modes of networked
interaction are broadcast to all other connected clients including
the live pianist who views the score as it is being transformed
through an Oculus Quest 3 HMD in pass-through mode. The
repositioning of score components includes the stretching of the
radials which extend outwards from the score’s central circle
Collaborative Musical Expression Through Interactive VR Scores NIME ’25, June 24–27, 2025, Canberra, Australia
Figure 7: a) The score for "Study for Intonation" from Toru
Takemitsu’s Corona (1962) (upper), b) A key to some of the
notational descriptors (lower)
via repositioning of the "nodes" which are positioned at its end
terminals, and the spatial repositioning of these nodes along
invisible circular splines. These interactions are effected and
facilitated through hand-tracking in a similar method to that
outlined in earlier discussion of Four Systems and Jasper.
Since pianists cannot physically rotate while performing to
read an immersive score, the score presented to the pianist of
Corona is simply presented along an imaginary y-plane located
in a position closely aligned to the piano music rack. As the score
is transformed and sounded by networked clients, the live pianist
is presented with an ever-changing variety of interpretive possi-
bilities. Similarly to Four Systems , this interpretation is broadcast
to connected clients in what amounts to a closed feedback loop.
3.4 Multiplayer Connectivity
The multiplayer functionality of the three VR adaptations pre-
sented enables clients to manipulate the score from any location
in the world. This connectivity is facilitated through the Photon
Fusion 2 SDK, using a network topology classified as "Shared
Mode. " In this implementation, the virtual room in which the
score is situated retains state authority over the score objects.
Each object has a unique Network ID when instantiated. Each
object has a unique Network ID when instantiated. When clients
directly manipulate a score object, state authority is temporarily
Figure 8: Two uniquely generated instantiations of "Study
for Intonation" from Corona (1962).
transferred to them, allowing all connected clients to see the
spatial transformations of score objects in real time.
The room is hosted on a Photon server which requires a fixed
region to enable multiplayer interaction. Remote procedure calls
(RPCs) are sent to the server when an action by a client needs to
be distributed to all connected clients. InFour Systems, Jasper, and
Corona, RPCs are triggered when audio cues need to be played
on all connected HMDs as a result of score interactions.
Network performance is affected by geographical distance
from the server. During testing, the application was hosted in
Singapore with multiple clients simultaneously connected in
Australia and Europe. Network performance was measured using
Photon network statistical tools. The consumer bandwidth per
client averaged around 710 bytes per second, with approximately
30 packets in and 65 packets out. These values were low enough to
minimize the impact of packet loss on performance and usability.
In all three adaptations, the performance of the live musicians
is captured in real time and streamed to all connected clients
via the Photon Voice SDK. The SDK was originally designed to
facilitate live voice chat between players within a multiplayer
gaming environment and can support chat at 48kHz with a bitrate
up to 512kbps. Anecdotal evaluations of the audio performance,
as heard through the internal loudspeakers of the Quest HMD
NIME ’25, June 24–27, 2025, Canberra, Australia David Kim-Boyle
reported satisfactory quality although this is somewhat mitigated
by the frequency response of the internal Quest 2 loudspeakers
with a significant roll off below 150Hz and above 5kHz [15].
4 Aestheticizing Collaboration in VR
The question of how collaboration between agents can be aes-
theticized to facilitate the development of novel musical forms
and performance modalities is a key driver of this project. While
this question is not new, having been a core focus of composers
such as Wolff [16] and Cardew [4], it has received limited artistic
investigation within the framework of VR. In the VR adaptations
discussed above, collaboration leverages the multiplayer, net-
worked framework offered by the Photon Fusion SDK. Given this
SDK was primarily developed to facilitate multiplayer game de-
velopment, game theory offers helpful insights into collaborative
musical experiences.
Salen and Zimmerman analyse various modes of multiplayer
interaction which are largely shaped by the types of goals and
whether such play is cooperative or competitive. Their discussion
of "collaborative play" and the value of alliances is particularly
relevant to musical aesthetics [17].
4.1 Facilitating Collaboration
Alliances can be facilitated or hampered by game-play mechanics
and the ways in which networking requirements are integrated
within game design. The degree of network latency, for exam-
ple, can help facilitate or disrupt collaborative experiences and
has been a fundamental consideration in network-based musi-
cal performance [2]. For performances that depend on precise
synchronization, even slight latency can disrupt the rhythmic
integrity of a piece. In the VR projects discussed here, however,
a more fluid and flexible approach to performance is presented
where the timing of events is open to interpretation, thus miti-
gating latency’s impact on musical collaboration.
4.2 Strategic Collaboration
Given the live performers of Four Systems , Jasper, and Corona
are not able to manipulate the scores which they interpret, i.e.
reactive agency is only afforded to the virtual participants, it is
possible for agents within the virtual space in which the score is
situated, to engage in strategic transformations of the score to
shape the live interpretation in predetermined ways.
For example, in Jasper agents may choose to minimize the dis-
tance between nodes or alternatively keep them maximally sepa-
rated both strategies of which will lead to perceivable changes in
the live performance. In these strategic situations, the relation-
ship between performers becomes more overtly goal-directed.
Conversely, it is equally possible that relationships between
agents not be directed towards common goals. In this situation,
performance adopts a more exploratory focus with the perform-
ers navigating their way around the various musical possibilities
presented by the score.
4.3 VR Specific Affordances
Correlations between music compositions and games, and be-
tween music performance and game play have been a source of
creative inspiration for various composers such as Iannis Xenakis
[23] and John Zorn. To what extent, however, might the specific
affordances of multiplayer XR offer unique musical possibili-
ties? The question is perhaps founded on the inherent physical
distance and disembodiment through which networked agents
interact. The subtle bodily cues and gestures which typify in-
teraction amongst musical performers situated within the same
room cannot be replicated in a multiplayer, networked space and
the poor haptics of most VR technologies adversely impacts any
simulation of real-world experiences.
Rather than attempting to replicate traditional performance
interactions, the key to leveraging the aesthetic affordances of
multiplayer VR is to design aesthetic experiences founded on the
medium’s inherent technical capacities. These might include:
• Creating unique physical forces that mediate interactions
within virtual spaces • Tracking interactions and using this data
to drive score transformations• Using 3D spatial audio as a means
of mediating interaction between clients
4.4 Transformed Musical Experience
VR score adaptations fundamentally alter the performer’s re-
lationship with notation and collaborative music-making. For
pianists engaging with Four Systems , the experience shifts from
reading a fixed score to navigating a dynamic, evolving visual
field manipulated by multiple agents. This creates a heightened
awareness of the score as a living entity rather than a static pre-
scription. Sonically, this transformation manifests in several ways:
performers tend to respond more directly to spatial reconfigura-
tions with corresponding changes in dynamics and articulation;
the continuous feedback loop between virtual manipulations and
acoustic performance creates emergent musical structures im-
possible in traditional scoring; and the blending of pre-recorded
piano samples with live performance creates a rich sonic tapestry
where the boundaries between different agents’ contributions
become veiled. In Jasper and Corona, the dimensional expansion
of the score into fully immersive 3D environments encourages
performers to approach pitch selection, timing, and timbre with
greater freedom, as the traditional linear reading of notation
gives way to a more exploratory engagement with musical pa-
rameters. Initial observations suggest that performers develop
new frameworks for interpreting these scores, with a heightened
sense of collaborative agency despite the physical separation
between participants.
5 Summary and Future Work
While the development of VR technology and associated de-
sign software continues to be largely driven by the gaming in-
dustry, they nevertheless provide exciting new possibilities for
creative expression and aesthetic investigation. For the author,
these possibilities are manifested in the exploration of interac-
tive multiplayer performance scores presented in 3D immersive
visualizations.
The author is extending the work described in this paper in
three areas - 1. The integration of player avatars to provide better
awareness of the activity of other agents, 2. The integration of
AI performers built through a model trained on the decisions
made in previous performances by agents, and 3. A structured
evaluation of how performers engage with these VR adaptations.
For this evaluation, studies will be conducted with musicians
from diverse musical backgrounds including those familiar with
experimental notation and those from traditional performance
practices. The evaluation will examine several key dimensions:
the intuitiveness of score interaction, the impact of networked col-
laboration on performance decisions, how VR mediation affects
musical interpretation compared to traditional score reading, and
Collaborative Musical Expression Through Interactive VR Scores NIME ’25, June 24–27, 2025, Canberra, Australia
the overall experience of musical collaboration in virtual environ-
ments. This will involve both qualitative methods (semistructured
interviews, think-aloud protocols during performance) and quan-
titative measures (such as analysis of interaction patterns and
musical outcomes). It is hoped that such an evaluation will pro-
vide critical insights into how these systems function not just
technically, but as tools for genuine artistic expression and col-
laboration, potentially revealing aspects of the design that could
be refined to better support diverse performance practices.
As work on this project has progressed, the concept of the mu-
sical score as an instrument with its own potential and agency
has become more significant. In this framework, the score is
not merely a static set of instructions but an interactive tool
that musicians engage with and which in turn can help shape
that engagement through its design. This performance model
also highlights the score’s agency in the musical process as it
actively influences the performer’s decisions, providing a frame-
work through which collaboration is mediated, and becoming an
integral part of the creative act and collaborative experience.
6 Ethical Standards
This research involved the development of VR adaptations of
musical scores for collaborative performance but did not involve
direct human subject testing at this stage of development. The
research received no specific grant from any funding agency,
however the VR equipment used in this project was provided
by The University of Sydney. Future evaluation with human
performers will be conducted following appropriate institutional
ethics approval and informed consent procedures.
References
[1] Andrea Agostini and Daniele Ghisi. 2012. Bach: An Environment for Computer-
Aided Composition in Max. In Proceedings of the International Computer Music
Conference (ICMC2012) . 373–378. http://hdl.handle.net/2027/spo.bbp2372.
2012.068
[2] Chris Bartlette and Mark F. Bocko. 2006. Effect of Network Latency on
Interactive Musical Performance. Music Perception 24, 1 (2006), 49–62. https:
//doi.org/10.1525/mp.2006.24.1.49
[3] P. Burt. 2006. The Music of Toru Takemitsu . Cambridge University Press,
Cambridge, U.K.
[4] Cornelius Cardew. 2008. Cornelius Cardew: A Reader . Copula Press, Harlow,
U.K.
[5] Nick Didkovsky and Georg Hajdu. 2008. MaxScore: Music Notation in
Max/MSP. In Proceedings of the International Computer Music Conference
(ICMC2008). http://hdl.handle.net/2027/spo.bbp2372.2008.034
[6] Katerina El Raheb, Marina Stergiou, Akrivi Katifori, and Yannis Ioannidis. 2020.
Symbolising Space: From Notation to Movement Interaction. Proceedings of
the International Conference on Movement and Computing (2020), 91–99.
[7] Christopher Fox. 1987. Music as Social Process: Some Aspects of the Work of
Christian Wolff. Contact 30 (1987), 6–15.
[8] José L. Gómez-Sirvent, Francisco López de la Rosa, Roberto Sánchez-Reolid,
Rafael Morales Herrera, and Antonio Fernández-Caballero. 2024. Musical
Instruments in Extended Reality: A Systematic Review. International Journal
of Human–Computer Interaction (2024). https://doi.org/10.1080/10447318.2024.
2431352
[9] Cat Hope. 2017. Electronic Scores for Music: The Possibilities of Animated
Notation. Computer Music Journal 41, 3 (2017), 21–35. https://doi.org/10.1162/
comj_a_00427
[10] Yuk Hui. 2016. On the Existence of Digital Objects . University of Minnesota
Press, Minneapolis, MN.
[11] David Kim-Boyle. 2023. Immersive Musical Notations in AR/VR. InProceedings
of the International Computer Music Conference (ICMC 2023) . International
Computer Music Association, Shenzhen, China.
[12] David Kim-Boyle. 2023. The Reactive Score. In Proceedings of the 2023 In-
ternational Conference on Technologies for Music Notation and Representation
(TENOR2023). https://www.tenorconference.org/proceedings.html#2023
[13] Anders Lind. 2021. MmmUMmmbling - Networked Animated Notation for
Telematic Choir. InProceedings of the 2021 International Conference on Technolo-
gies for Music Notation and Representation (TENOR2021 . Hamburg, Germany.
[14] William Marotti. 2014. Challenge to Music: The Music Group’s Sonic Politics.
In Tomorrow is the Question: New Directions in Experimental Music Studies ,
Benjamin Piekut (Ed.). University of Michigan Press, Ann Arbor, MI, 109–138.
[15] Jeff Nichter. 2024. Oculus Quest 2 Speaker Impulse Responses. http:
//jeffnichter.weebly.com, Last accessed on 2024-1-24.
[16] Paul Roe. 2007. A Phenomenology of Collaboration in Contermpoary Com-
position and Peformance . Ph. D. Dissertation. The University of York, York,
U.K.
[17] Katie Salen and Eric Zimmerman. 2003. Rules of Play . M.I.T. Press, Cambridge,
MA.
[18] Stefania Serafin, Cumhur Erkut, Juraj Kojs, Niels C. Nilsson, and Rolf Nordahl.
2016. Virtual Reality Musical Instruments: State of the Art, Design Principles,
and Future Directions. Computer Music Journal 40, 3 (2016), 22–40. https:
//doi.org/10.1162/COMJ_a_00372
[19] Gilbert Simondon. 2017. On the Mode of Existence of Technical Objects . Univer-
sity of Minnesota Press, Minneapolis, MN.
[20] Toru Takemitsu. 1972. Corona.
[21] Craig Vear. 2019. The Digital Score - Musicianship, Creativity and Innovation .
Routledge, New York, NY.
[22] Christine Webster and Sophia Kourkoulakou. 2022. Composing in virtual
immersion: avatar and representation. Hybrid: Revue des arts et médiations
humaines 9 (2022). https://doi.org/10.4000/hybrid.2968
[23] Iannis Xenakis. 2019. Formalized Music . Pendragon Press, Stuyvesant, NY.
[24] Karitta Christina Zellerbach and Charlie Roberts. 2024. A Framework for
the Design and Analysis of Mixed Reality Musical Instruments. International
Conference on New Interfaces for Musical Expression (2024).