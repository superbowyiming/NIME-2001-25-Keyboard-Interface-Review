Exploring the (un)ambiguous Guitar: A Qualitative Study
on the use of Gesture Disambiguation in Augmented
Instrument Design
Adan L. Benito Temprano
Centre for Digital Music
Queen Mary University of
London
London, UK
a.benitotemprano@qmul.ac.uk
Teodoro Dannemann
Centre for Digital Music
Queen Mary University of
London
London, UK
t.dannemann@qmul.ac.uk
Andrew P . McPherson
Dyson School of Design
Engineering
Imperial College London
London, UK
andrew.mcpherson@imperial.ac.uk
ABSTRACT
Some of the performer’s gestures, despite corresponding to
different physical interactions, might produce a similar sonic
output. This is the case of upward and downward string
bends on the guitar where stretching the string shifts the
pitch upwards. Bending represents an expressive resource
that extends across many different styles of guitar playing.
In this study, we presented performers with an augmented
electric guitar on which the gesture-to-sound relationship of
downward bending gestures is changed depending on how
the instrument is configured. Participants were asked to ex-
plore and perform a short improvisation under three differ-
ent conditions, two augmentations that correspond to dif-
ferent auditory imagery and a constrained scenario. The
different sessions of the experiment were recorded to con-
duct thematic analysis as an examination of how gestural
disambiguation can be exploited in the design of augmen-
tations that focus on reusing performer’s expertise and how
the gesture-to-sound entanglement of the different modali-
ties supports or encumbers the performer’s embodied rela-
tionship with the instrument.
Author Keywords
Augmented Instruments, disambiguation, auditory imagery,
multimodal sensing, subtlety
CCS Concepts
•Applied computing → Sound and music computing; Per-
forming arts; •Information systems→ Music retrieval;
•Hardware → Sensor devices and platforms;
1. INTRODUCTION
From its origin at the beginning of the 20th century the
electric guitar has been embraced as a tool for musical ex-
perimentation by different musical traditions [3, 6, 14]. As
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’23, 31 May–2 June, 2023, Mexico City, Mexico.
a result, different idiomatic playing styles and expressive
techniques have emerged contributing to the development
of a series of gestures and interactions that convey both
musical meaning and articulation and are able to produce
a recognisable signature for genres and even particular per-
sonal styles and instruments [21].
Plucking, tapping, bending, fretting, sliding, etc are ex-
amples of combinations of excitation and modification ges-
tures that performers use as expressive resources and that
when honed over years of practice, contribute to the embod-
ied relationship between musicians and their instruments.
Experienced guitarists are not only able to use these ges-
tural resources on demand to achieve a specific sonic effect
but can rapidly adapt to unexpected reactions and unfamil-
iar sounds thanks to their ability to recreate and anticipate
sounds in their minds, a phenomenon referred to asauditory
imagery [12].
This acquired imagery often encompasses gestures that,
despite being associated with different physical interactions
might have similar, even identical, sonic results and there-
fore be virtually indistinguishable from this perspective, re-
sulting in similar auditory feedback. This opens a possi-
bility for designing augmentations based on the analysis of
such actions so that their sonic effect is differentiated. We
refer to this process as disambiguation.
Here we aim to explore how these augmentations might
challenge the performer’s imagery and whether this allows
them to repurpose their existing skills by accessing their
existing gestural vocabulary to control new interactions.
We presented nine experienced guitarists with an aug-
mented guitar under different modalities of interaction de-
signed around the disambiguation of bending gestures. Each
modality alters the imagery of gesture differently, which
might allow us to draw further insights into which augmen-
tations are a better fit for this approach.
2. BACKGROUND
2.1 Disambiguation in augmented instruments
We define ambiguous gestures as those sound-generating
gestures which produce a similar sound despite presenting
different interactions to the performer.
The electric guitar is no stranger to ambiguity: for exam-
ple, a vibrato effect can be produced by rocking the fingertip
and stretching the string longitudinally (axial vibrato) or by
bending and pulling it transversally (radial vibrato) and the
direction in which the string is plucked does not have an im-
mediate obvious on the sound of the instrument. Many of
the existing techniques result in a sound that, although not
always identical, can be hard to distinguish [25].
We propose that by focusing on disambiguating specific
gestures from the guitarist’s vocabulary we can help dis-
entangle gesture-to-sound relationships and motivate aug-
mentations that provide a great level of control intimacy
while repurposing performer’s expertise, allowing them to
quickly adapt to these and engage in new forms of musical
expression.
However, this is not a new paradigm within NIME. Sev-
eral augmented DMIs have been designed over the years
that reuse performers’ skills for augmentation which have
specific relationships with gestural ambiguity.
TouchKeys [17] allows performers to create new control
mappings for the position on which the fingers are located
on a key, creating the possibility of disambiguating key
presses that occur in different locations for a single key.
The Svampolin [19] detects stick and slip states of bow-
ing gestures and bowing direction, using this data to create
a simplified representation of bow-string interaction. Ac-
tions are then projected through a velocity model to obtain
sound features related to gestures which are unambiguous
from each other. Morreale et al. [18] present an augmented
guitar pick that extracts signals related to the movement
of the device relative to the magnetic pickups of the guitar.
Although Magpick can capture plucking and strumming di-
rection, the designers decided to not create disambiguated
augmentations, but instead use the integrated signal in one-
dimensional mappings that control effect parameters.
Our proposal differs from these approaches in that we
conceptualise disambiguation as a design paradigm rather
than an implicit result in the scope of interaction. We
suggest that a bottom-up approach, where designers anal-
yse specifically-ambiguous gestures and how they relate to
performers’ auditory imagery, and design interactions over
their differentiating features could provide a rich experience
while providing minimal disruption.
2.2 Motivation: a subtle sabotage
The following question remains unanswered: how do we de-
sign interactions that are minimally intrusive if these di-
rectly challenge the performer’s auditory imagery?
Guidi and McPherson [11] present a study where expert
guitar players were able to accurately control a sound ef-
fect with the use of Magpick [18] while at the same time
subconsciously adapting their playing to compensate for be-
haviours that were designed to disrupt their interaction by
changing the sensitivity of the augmented plectrum over
time. This supports the idea that experimented performers
might be able to repurpose sensorimotor skills when pre-
sented with augmented instruments that challenge their ex-
pected gesture-sound relationships.
Moreover, Guidi et. al [12] showcase how auditory im-
agery can support skill transfer in the adoption and em-
bodiment of modified instruments by putting a violin with
transposed notation in the hands of professional performers.
The results suggest that when musicians struggle to identify
a specific sound event as part of their auditory imagery, the
motor program to control this is unavailable and the per-
formance disrupted. However, musicians can still perform
fluently when the auditory feedback is unfamiliar but they
can access their auditory imagery and anticipate the related
motor program.
2.3 Case study: electric guitar string bending
String bending is a modification gesture and a common id-
iomatic resource guitar players employ on demand to exert
precise, continuous control over pitch. It can be used to cre-
ate melodic ideas, accentuate specific notes and even access
microtonality (as in the case of the blue notes).
The physics behind string stretching [10], makes bend-
ing ambiguous: the pitch of the played note will always
be raised regardless of the bending direction. This offers
an opportunity for designing augmentations where auditory
feedback changes with respect to bend quantity and bend
direction.
3. THE (UN)AMBIGUOUS GUITAR
An Augmented guitar for bending disambiguation.
We developed an augmented electric guitar - the
(Un)ambiguous guitar - which allows us to extract infor-
mation on string displacement for all six strings aligned to
hexaphonic audio, and a processing unit that analyses both
data streams simultaneously to infer gestural information
and create mappings to process the hexaphonic output in
real-time. The hardware and software components of the
instrument are open-source and available on the supporting
website 1
3.1 Technical details
3.1.1 Guitar and sensors
The guitar was hand-built from individual parts to resem-
ble a familiar Stratocaster but showcases a fixed bridge and
lacks any controls on its surface (see Figure 1). Instead of
the traditional electromagnetic pickups found in most elec-
tric guitars, the instrument is equipped with an active hexa-
phonic pickup2 which can be connected through a Roland
GK-compatible 13-pin DIN connector [1] and a multichan-
nel bend-sensor adapted from the work presented in [ ?] to
sense direction and quantity of bending. This version was
developed as a drop-in replacement for humbucker pickups
and breaks out six channels of horizontal string displace-
ment data to another 13-pin DIN connector.
The apparatus presented in [ ?] senses variations in mag-
netic flux produced by the horizontal displacement of the
string and was employed to showcase how such measure-
ments can capture gestures associated with left- and right-
hand techniques in real-time, and to characterise them in
terms of pitch-contour to accurately estimate pitch-shifting
produced by bending.
3.1.2 Processing unit
A processing unit was developed to take the signals from
the hexaphonic pickup and the multichannel bend-sensor.
Three Bela units [16] are employed to process these signals
such that each receives two adjacent string outputs from
the hexaphonic pickup and the corresponding analog signals
from the bend-sensing apparatus synchronously. The line
output of each unit is then summed with an analog mixer
to present a single line output to the user.
A Pure Data patch was developed to exchange MIDI mes-
sages through USB with the unit in order to change the
parameters of the algorithms running on it (see Figure 2).
1https://instrumentslab.org/research/exploring-the-
unambiguous-guitar.html
2https://www.cycfi.com/product/nu-multi-6/
BACK
FRONT
BEND SENSOR
HEXAPHONIC PICKUP
DIN-13 CONNECTORS
FRONT
GUITAR
PROCESSING UNIT
Figure 1: Picture of the augmented guitar used for the study (on the left) and the processing unit containing 3 Bela minis and
analog conditioning circuitry (on the right).
Figure 2: Capture of the Pure Data interface that controls
the behaviour of the instrument
3.1.3 The B- and G-bender parallelism
The B and G strings are mostly associated with bending
gestures during solo performance, but they also relate to
a well-known mechanical augmentation designed to contin-
uously manipulate the pitch of a string through external
action: the Stringbender [20] (widely identified as G- and B-
bender). Therefore, we only employ the bend-sensing setup
corresponding to these strings to restrict the focus of the
experiment while offering a familiar metaphor.
3.2 Isolating bending gestures
Since we want to focus on disambiguation bending gestures,
it is important that these are isolated from other excitation
and modification gestures.
The bending sensor employed for tracking the movement
of the string (Section 3.1.1) does not provide a direct mech-
anism for separating plucking and bending gestures so a
multimodal approach was followed for further disambigua-
tion. Sensor data is employed together with a transient
envelope and pitch estimates from a YIN detector [7] to ex-
tract different states of the bending gesture in real-time (see
section 3.2.2).
3.2.1 Calibration
Since the mapping between displacement from the bend sen-
sor and the pitch-shift produced by a bend gesture changes
from fret to fret, we followed the procedure suggested in [2]
for calibration. Several downward bends were captured for
each fret and least-squares linear regression was used to ob-
tain an approximate characterisation for latter mappings.
Boundaries of the steady string for upward and downward
bends were also captured for each fret. This neglects hys-
teresis in the sensing setup but provides a sufficient approx-
imation for mapping as shown in [2].
3.2.2 Disentangling plucking and bending
To facilitate separation between plucking and bending ges-
tures we conceptualised a simple model of the interaction of
the string that divided a note into 5 different possible states:
note transient, note on, note off, bend on and bend off which
worked in parallel with an ASR (Attack Sustain Release)
model for bending gestures. A transient envelope consist-
ing of the difference between two envelope detectors with
the same release time but different attack times was used
to filter the transient produced from plucking the string.
Three different thresholds were adjusted to determine the
beginning of the transient, its end (and the start of the note)
and the release of the note.
Bending direction (upwards or downwards) was inferred
by thresholding a hysteresis model of displacement with re-
spect to the values corresponding to the steady string (no
bend). Attack and release states of the bending gestures
were then extracted by measuring peaks and their direction
over bend velocity which was computed via decimation and
differentiation of the displacement variable.
3.2.3 Pitch correction and fret estimation
Since YIN and other pitch detectors are prone to errors
[15], we leveraged our simple string state model and the
data from bend calibration to regulate its predictions. Since
we are only interested in estimating pitch during bend ges-
tures, we accumulated predictions during the transient state
of our model to obtain the best estimate candidates (based
on YIN’s confidence) during the initial attack of the note.
Once a good estimate (or the end of the transient) was
reached, we computed all the possible frets that could lead
to each candidate (without bending and assuming a bend
of up to 5 semitones) and, for each of these, obtained the
estimated pitch corresponding to the string displacement
following our calibration polynomials. The predicted fre-
quency was matched against all fret candidates and esti-
mated fret (and corresponding pitch estimate) was chosen
by measuring the shortest distance between YIN’s estima-
tion and the prediction based on string displacement.
3.3 Modalities
Having developed a control mechanism to extract string-
bend direction and quantity and the general mappings of
pitch-bends across the fretboard, we designed two new map-
ping strategies for downward bends as a way to challenge
the existing ambiguous sound-to-gesture relationship.
3.3.1 Disambiguated Pitch Control
In this scenario, the pitchbend quantity parameter is em-
ployed to control a realtime monophonic pitchshifter as
proposed in [ ?], where a scalar sets the amount of pitch-
shift produced by a downward bend. A scaling factor of
−1x compensates for the natural pitch shift, effectively can-
celling the effect of the bend - configuration to which we re-
fer as reduced (or constrained) bend control - whereas
an augmented behaviour can be achieved by using a fac-
tor with an absolute value greater than 1. The augmented
bend control modality uses a factor of −2x on the down-
ward bends to invert the pitch-shifting rule so that they
produce a downward pitch shift of the same quantity as an
upward pitch but in an opposite direction.
This modality is however still conceptually tied to the
original gesture-to-sound relationship of bending as both
manipulate the pitch of the instrument (effectively ’re-
tuning’ the downward bending gesture to a different range)
and therefore remains linked to the original imagery of the
bending gesture.
3.3.2 Feedback Control
We introduce a new mapping modality where the interac-
tion of bending is disentangled from the guitarist’s imagery.
Here the bending amount is mapped to an effect that, while
still using pitch information, does not manipulate pitch di-
rectly but adds a new sonic interaction on top of the sound
of the bent string.
We built this interaction on a real-time virtual acoustic
feedback (VAF) generator adapted from [9] that simulates
the idiosyncratic ’howling’ sound produced when an electric
guitar is close to the speaker through which the instrument
is being amplified at high-gain settings. This sound, widely
associated with the rock genre and derived playing styles,
has been appropriated by players outside of this area [22],
[8]. We employ the same frequency estimation as the previ-
ous modality to set the frequency of the nonlinear oscillator
and create feedback that follows pitch changes. The pitch-
bend quantity parameter related to downward string bends
is re-mapped to a value in decibels to control the gain of
the oscillator so that the amount of feedback raises with the
amount of pitch-bending produced by a downward bend.
We expect that using the same features to create the map-
pings for both modalities will allow us to analyse the effects
of sound manipulation and not the differences in mapping
related to the analysis of bending
4. QUALITATIVE STUDY
4.1 Motivations
A qualitative study was designed aroundthe (un)ambiguous
guitar to analyse how guitarists react to the disambiguation
of bending gestures and how different augmentations affect
their performance.
We pose the following questions related to how the modal-
ities affect the mental imagery of the performer:
• Is one augmented modality generally preferred to the
other two? And if so, why? Are any of them easier to
adapt to and incorporate into the performer’s gestural
repertoire?
• What do participants focus on when trying to perform
on the augmented version of the instrument?
• Are guitar players able to anticipate the sonic results
produced by the different modalities after having fa-
miliarised themselves with the instrument?
• Are there particular patterns of interaction that recur
across different musicians for a certain modality, or
across modalities?
We hypothesise that physically bending the string down-
ward or upward are mostly equivalent in the performer’s
imagery, since they both raise the pitch of the string, and
thus the choice of one gesture over the others is not linked
to specific auditory feedback but to ergonomics. We also
speculate that modalities not linked to the existing imagery
of bending (i.e. feedback control) are easier to adopt by
performers and that the constrained behaviour will be less
preferred to the other two.
4.2 Methodology
We invited 9 experienced guitar players with different levels
of expertise and backgrounds to explore the possibilities of
the (un)ambiguous guitar through the execution of a series
of exercises and improvisation.
4.2.1 Participants
All participants have more than 14 years of experience play-
ing electric guitar and five of these consider themselves ac-
tive performers. With the exception of P7, participants are
affiliated with a research group in music and audio tech-
nology and four are NIME practitioners. As such, their
expectations of music technology might be different from
that of players with no contact with music technology re-
search. Participants play in a wide range of styles ranging
from experimental music to metal, progressive rock, funk,
folk, blues, jazz, bossa-nova, synth-pop and post-punk.
4.2.2 Protocol
Participants were invited to take part in an experiment that
spans two sessions of 30-60 minutes held in a controlled
studio environment. Voice recordings were taken using a
microphone for annotation and analysis, and the guitar’s
processing unit gathered synchronous data corresponding
to the bend-sensor and the raw and processed recordings of
the hexaphonic pickup.
During the sessions, a think-aloud [13] protocol was fol-
lowed in which participants were asked to verbalise anything
they found interesting, surprising or encumbering during
their interaction with the instrument.
4.2.3 First session
In the first session, participants were presented with the
(un)ambiguous guitar connected to an effect processor and
amp-simulator unit which could be adjusted by the player
to their liking. The guitar’s processing unit acted as a black
box that was configured by the researcher for the different
augmented modalities.
The session started with the instrument configured on its
original behaviour with no specific interaction programmed
so that participants could familiarise themselves with the
guitar itself.
Following this, the guitar was reconfigured by the re-
searcher to the first augmented modality described in Sec-
tion 3.3 (augmented bend control (ABC)) and, after a phase
of free exploration, participants were asked to perform three
exercises to further familiarise themselves with the new be-
haviour including upwards and downward bends across the
fretboard, vibrato and pre-bends (where the string is bent
before being excited). This procedure was then repeated
for the second modality ( feedback control (FBC)).
4.2.4 Second session
The second session puts modalities into the context of a
simple improvisation over a minor blues backing track. A
blues style was chosen due to the bending gesture being
widely associate with it and because it tends to belong to
the repertoire of many electric guitar players, regardless of
their background.
The session began with a refamiliarisation with the in-
strument in the original modality followed by an impro-
visation over the backing track. Three more improvisa-
tions were recorded afterwards, two using the augmented
behaviours and one with a modality which has not yet
been introduced to the performer, the constrained bend con-
trol (CBC) where downward bends are effectively cancelled.
This modality was added in order to analyse whether play-
ers were consciously disrupted by their use of downward
bending or were able to ignore its effect.
4.2.5 Interview and MPX-Q questionnaire
At the end of the second session, participants were asked
to complete a questionnaire (see Appendix A) reflecting
on specific aspects of their experience with each modality,
which served to structure a short interview lead by the re-
searcher (guitar player and designer of the augmentation).
The questionnaire in Appendix A is a slightly more con-
densed version of theMusician’s Perception of the Experien-
tial Quality of Musical Instruments Questionnaire (MPX-
Q) [24, 23] in which a bottom-up process was taken over the
course of three iterative studies to generate a series of crite-
ria for assessing the quality of musical instruments based on
psychometric analysis. Our adaptation of MPX-Q reduces
the number of items to 27, eliminating many associated with
materiality, ergonomics, playing comfort and visual aesthet-
ics, since these are shared across modalities.
Participants rated each of the 3 disambiguated modalities
from 1 to 3 in ascending order depending on how well they
perceived each of them to satisfy the items in the question-
naire (1 corresponding to the modality that better adjusts to
a specific statement, and 3 to the one that fits it the least).
Ratings were used to instigate a discussion on the inter-
related aspects which might have influenced participants’
experiences and preferences. The interview concluded with
an open prompt for any further comments or suggestions
regarding the instrument.
4.2.6 Analysis
We analysed the transcriptions of the recordings following
a reflexive thematic analysis (TA) approach [4, 5]. The
raw recordings were divided into excerpts of interests and a
series of preliminary codes drawn from common threads and
relationships on these. A second researcher was then invited
to review and refine these codes over different rounds of TA
and to help conceptualise the final theme structure that
we believe describes the patterns of interaction with the
instrument. We consider our approach deductive despite
not using an initial codebook since part of the material from
the interviews was framed by the reflection on the MPX-Q
questionnaire.
5. FINDINGS
We identified a layered theme structure that shows different
threads amongst participants. Themes are organised under
topics that link them together. These relate to ideas around
the following concepts:
• Auditory Imagery – how the augmentation changes
the relationship between sound and sensorimotor pro-
grams[26].
• Embodiment – whether the augmentation elicits con-
scious patterns of interaction or disrupts existing pat-
terns.
• Engagement – participant’s willingness to explore the
augmentation.
• Appropriation – performer’s interest in developing a
further relationship with the augmentation,
Moreover, we recognise three main themes and five fur-
ther subthemes that complement them.
ENGAGEMENT
EMBODIMENT
AUDITORY 
IMAGERY
APPROPRIATION
RECOGNITION AND
UNDERSTANDING OF SUBTLE
ASPECTS OF AUGMENTATION
PERCEPTION OF CONTROL
CHANGES WITH MODALITY
AUGMENTATION GENERATES
DIFFERENT LEVELS OF
DISRUPTION
ADOPTION THROUGH
PRACTISE
MODALITIES PRESENT
DIFFERENT DIFFICULTIES
FOR EXPRESSING MUSICAL
IDEAS
MODALITIES LINKED TO
IDIOMATICITY & CONTEXT
EXPECTATIONS ARE
CHALLENGED BY THE
AUGMENTATION
TOPICS
THEMES
SUBTHEMES
Figure 3: Theme map result of the Thematic Analysis described in section 4.2.6. Dotted lines represent connections between
themes and subthemes (red) or topics and subthemes (blue).
5.1 Understanding subtlety of interaction
Being able to understand the mechanism of the augmenta-
tion and its subtleties and adapting to this is critical for the
embodiment of the interaction [18].
During the first part of the study, participants were able
to quickly recognise the sonic effect of the two augmented
modalities and their possibilities. At least 7 participants
(P1-6, P8) recognised the augmented disambiguation within
the first 2 minutes of interaction, whereas for the con-
strained behaviour at least two participants ( P3, P6) could
still not figure out what the modification was after explor-
ing and improvising, but felt that their performance was
hindered by it.
Participants were able to identify many of the limitations
of the bend-sensing mechanisms without these being dis-
closed to them and, in most cases, to quickly elaborate
mechanisms to navigate them.
P1, P3 and P8 identified differences in pitch-shifing range
for the first modality and found whereas P2-4, P8 and P9
noticed that changing the speed of the bend would affect
the response of the augmentation, while another five ( P3-6,
P8) noticed that control was reduced for the lower frets and
quickly moved to explore the response of the guitar on the
higher frets. More interestingly, 8 out of 9 participants high-
lighted a discontinuity in the interaction with the downward
bend before the effect of any of the augmented modalities
was noticeable.
This lack of continuity was signalled as one of the primary
sources of disruption, even when compared to range incon-
sistency or the inversion of pitch direction. P9 mentions the
following for theABC modality“Okay, so I need to stop do-
ing vibrato, where I would normally do it, because... Yeah,
it’s not predictable, because sometimes it feels like there’s
a step.” whereas P7 said (regarding the FBC modality):
“I feel like you’re bending up into this high note and then
just transforms it. It’s almost like a wah, it’s like we need
to cross the threshold”. This suggests that participants are
able to draw quick expectations of the sonic results of the
augmentation and react to this, which links to topics of
embodiment and auditory imagery. However several par-
ticipants (P2, P4-6, P8) suggested that their expectations
would need to be re-evaluated in order to embody this new
interaction. P6 mentions (regarding the ABC modality):
“So, instantly, I’ve worked out what’s going on (...) There’s
like a new technique to practice, I’m trying to sort of con-
struct something that I can hear in advance in my head,
and what I think it’s gonna sound like (...) I was trying to
adjust my playing in order to incorporate this way of doing
something”.
5.2 Different participants, different modalities,
different levels of disruption
We identified that the levels of disruption would change
across participants and modalities which would suggest dif-
ferent kinds of engagement with the augmentations. We
identified four levels of disruption from this perspective:
1. Unable to play (highest disruption)
P6 mentions regarding FBC modality: “(...) I’m sort
of missing the boat each time (...) I’m struck, yeah,
(...) I’m feeling like I can’t really play the song now” .
Similarly, for the ABC modality, P1 says “I can’t re-
ally do much with this apart from doing some unre-
quested sitari-thing. I can’t really use it much on the
first two strings.”
2. Turn off on demand (medium-high disruption)
Talking about the FBC modality, P4 mentions “(...)
although it’s very interesting, and I feel it’s fun to play,
I wouldn’t have it on all the time” . Which might sug-
gest a certain level of engagement but a desire to be
able to recall the interaction on demand.
3. Downward bends can be avoided (medium-low
disruption)
Four participants (P1-3, P5) mention that they could
easily avoid undesired effects by playing the guitar
without bending downwards unless they want to recall
the specific interaction. P1: “I think as long as you
avoid the downward stuff, it seems to behave okay” .
P6 suggests something similar for the ABC modal-
ity where the participant mentioned that when play-
ing jazz, they can just avoid bending down to have
control over which notes are hit (and then proceed
to demonstrate): “(...) if we were doing a jazz stan-
dard or something, I could probably just play, and it
wouldn’t have got in the way (...).” .
4. I can play as I normally do (low disruption)
Participant P7, on the other hand, when talking about
the FBC modality mentions: “I’m exploring my ele-
ment, I could just play the guitar without getting that
effect until I want to do it. (...) I don’t really mind
having to just pull it all the way down.” which suggests
low disruption and level of engagement and embodi-
ment of the augmentation on that modality higher
than other peers. On the other hand, P7 comes from
a more experimental background where the sonic ef-
fects might be more relevant than a specific control
of pitch, in contraposition with the expectations of
P6, rooted in jazz, where phrasing and melody are
of most importance. This relationship, among others,
might support the idea that context and idiomaticity
play an important role in the auditory imagery of dif-
ferent performers and therefore in their embodiment
of specific interactions.
5.3 Modalities and control
One recurrent theme across participants relates to their
ability to control the effect of the different modalities and
the different mechanisms that emerge from this interaction.
At least five participants (P1-P4, P8) agreed that modal-
ity CBC offered the least options for enacting any kind of
meaningful musical action. However, there was no obvious
division between the controllability offered by the two aug-
mented modalities. Performers P1, P3 and P5 seemed to
indicate that they preferred the mapping of the FBC and
that it was easier to express musical ideas with it, how-
ever, participants P4, P6 and P7 saw in the augmented
bend modality an opportunity to explore melodic ideas. It
was generally agreed however that the feedback modality,
despite being easier to control, had fewer options. P5 for
example mentions “I think because of the qualities of feed-
back like you can do feedback in different places, but it’s al-
ways going to sound kind of similar” whereas P3 said: “(...)
the pitch one has more options that I can use rather than
the feedback one that one is kind of just, like, a sound (...)
whereas, the pitch one, I feel like it kind of made me think
about new licks, and new melodic ideas.” .
Another appreciation with respect to the control offered
by modalities was that, during the exercises, at least 3 par-
ticipants (P3, P6 and P8) commented that the augmented
behaviours were forcing them to put more sensitivity on the
bending gesture and to try to control it more precisely, es-
pecially with the ABC modality. P7 on the other hand,
embraced the “glitches” caused by the limitations of the
heuristic mapping process for the ABC modality and pre-
ferred that as a nuanced expressive resource to the idea of
control and precision in the execution of bends.
Moreover, participants P2-6 and P8 mentioned that they
would like to spend more time with the ABC modality to
be able to learn how to control it to develop new ideas.
P6 mentions “I can see myself you know, in the fullness of
time, spending more time playing like this” , and P3 said “I
feel like maybe if I practised a bit more with the first and
second one I could start to really more precisely control the
actual notes. They would get a lot easier to express, like,
express, like, music using that” .
Yet another aspect related to control was the desire that
several participants (P3, P5 and P8) showed for being able
to adjust the mapping of the disambiguation to control dif-
ferent effects and parameters to the ones presented in the
study or to be able to adjust aspects of the augmentation.
In particular P3 said“ I can imagine using that to control all
kinds of stuff to be really cool (...). It’s a new dimension of
control over the guitar, so you could in theory, I guess, use
that to control anything, not just like guitar-specific stuff,
but even stuff outside of that” . These appreciations align
with the idea of appropriation of the disambiguated gesture
and how performers embrace this new mode of interaction.
6. CONCLUSIONS
In this paper, we propose using a disambiguation paradigm
as a technique to frame new augmentations in terms of per-
formers’ auditory imagery for repurposing expertise and cre-
ating rich interactions.
To test this hypothesis, we designed an augmented guitar
on which we created different mappings tied and disentan-
gled from performers’ original imagery of bending gestures
and analysed participants’ reactions to these during a study
of recognition and improvisation.
Among the themes that were conceptualised during our
analysis, we see some salient ideas. Firstly, it was confirmed
how expert players can easily adapt to disruptions created
by disambiguation and that this can help raise awareness
of the subtleties of interaction, especially when the existing
imagery is challenged, but that special attention should be
put to continuity of gesture-to-sound mappings.
We observed how augmentations that do not disrupt the
existing imagery might be quicker to adapt to and, in gen-
eral, easier to control, but that they offer limited interac-
tion when compared to those that do provoke it. Moreover,
attention was drawn to how different participants might en-
gage with modalities that contradict their auditory imagery
and to how disruption varies across both modalities and par-
ticipants and is linked to idiomaticity.
Lastly, we saw how several participants engaged with the
concept of gestural disambiguation and started appropriat-
ing the augmentation during the session.
We acknowledge the limitations of the study regarding the
number of participants, duration and the qualitative aspects
of our analysis and suggest further investigation through a
longitudinal exploration and the development of continuous
mappings that do not bound gesture to discrete events.
7. ACKNOWLEDGEMENTS
The authors would like to give special thanks to Professor
Marcelo M. Wanderley and the people from the Input De-
vices and Music Interaction Laboratory (IDMIL) at McGill
University for hosting the first author of this paper and pro-
viding useful feedback during part of the development of the
(Un)ambiguous Guitar used for this study.
8. ETHICAL STANDARDS
Participants were given an information sheet explaining the
nature and demands of the research and signed a consent
form to take part in the study so that data from their perfor-
mances could be collected and used for research purposes.
The study presented in this publication has been reviewed
and approved by the first author’s university’s ethics board.
We observe no potential conflicts of interest.
9. REFERENCES
[1] E. Bates, D. Furlong, and D. Dennehy. Adapting
polyphonic pickup technology for spatial music
performance. In ICMC, 2008.
[2] A. L. Benito Temprano and A. McPherson. A TMR
Angle Sensor for Gesture Acquisition and
Disambiguation on the Electric Guitar. In Audio
Mostly 2021, pages 256–263. ACM, 2021.
[3] A. Bennett and K. Dawe. Guitar Cultures. Routledge,
2001.
[4] V. Braun and V. Clarke. Using thematic analysis in
psychology. Qualitative research in psychology,
3(2):77–101, 2006.
[5] V. Braun and V. Clarke. Reflecting on reflexive
thematic analysis. Qualitative research in sport,
exercise and health, 11(4):589–597, 2019.
[6] G. Carfoot. Acoustic, electric and virtual noise: The
cultural identity of the guitar. Leonardo Music
Journal, pages 35–39, 2006.
[7] A. De Cheveign´ e and H. Kawahara. Yin, a
fundamental frequency estimator for speech and
music. The Journal of the Acoustical Society of
America, 111(4):1917–1930, 2002.
[8] M. Frengel. The Unorthodox Guitar: A Guide to
Alternative Performance Practice. Oxford University
Press, 2017.
[9] L. Gabrielli, M. Giobbi, S. Squartini, and
V. V¨alim¨aki. A nonlinear second-order digital
oscillator for Virtual Acoustic Feedback. In IEEE
International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pages 7485–7489, 2014.
[10] D. R. Grimes. String Theory - The Physics of
String-Bending and Other Electric Guitar Techniques.
PLoS ONE, 9(7):e102088, 2014.
[11] A. Guidi and A. McPherson. Quantitative evaluation
of aspects of embodiment in new digital musical
instruments. In International Conference on New
Interfaces for Musical Expression, 2022.
[12] A. Guidi, F. Morreale, and A. McPherson. Design for
auditory imagery: Altering instruments to explore
performer fluency. In International Conference on
New Interfaces for Musical Expression , 2020.
[13] M. W. Jaspers, T. Steen, C. Van Den Bos, and
M. Geenen. The think aloud method: a guide to user
interface design. International journal of medical
informatics, 73(11-12):781–795, 2004.
[14] O. L ¨ahdeoja. An Approach to Instrument
Augmentation: The Electric Guitar. In International
Conference on New Interfaces for Musical Expression ,
pages 53–56, 2008.
[15] M. Mauch and S. Dixon. pYIN: A fundamental
frequency estimator using probabilistic threshold
distributions. In IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP),
pages 659–663, 2014.
[16] A. McPherson and V. Zappi. An environment for
submillisecond-latency audio and sensor processing on
beaglebone black. In Audio Engineering Society
Convention 138. Audio Engineering Society, 2015.
[17] A. P. McPherson. TouchKeys: Capacitive
Multi-Touch Sensing on a Physical Keyboard. In
NIME, 2012.
[18] F. Morreale, A. Guidi, and A. McPherson. Magpick:
An augmented guitar pick for nuanced control. In
International Conference on New Interfaces for
Musical Expression, 2019.
[19] L. S. Pardue, K. Buys, M. Edinger, D. Overholt, and
A. McPherson. Separating sound from source: Sonic
transformation of the violin through electrodynamic
pickups and acoustic actuation. In International
Conference on New Interfaces for Musical Expression ,
pages 278–283, 2019.
[20] G. V. Parson and C. J. White. Shoulder strap control
for string instruments. US Patent 3,512,443, 1970.
[21] A. Pat´ e, B. Navarret, R. Dumoulin, J.-L. Le Carrou,
B. Fabre, and V. Doutaut. About the electric guitar:
A cross-disciplinary context for an acoustical study.
In Acoustics Conference, 2012.
[22] R. Perks. Fretless Architecture: Towards the
Development of Original Techniques and Musical
Notation Specific to the Fretless Electric Guitar.
Music & Practice, 4, 2019.
[23] P. J. C. Reimer and M. M. Wanderley. Embracing
Less Common Evaluation Strategies for Studying User
Experience in NIME. In International Conference on
New Interfaces for Musical Expression , 2021.
[24] G.-M. Schmid. Evaluating the Experiential Quality of
Musical Instruments. Springer, 2017.
[25] T.-W. Su, Y.-P. Chen, L. Su, and Y.-H. Yang. TENT:
Technique-embedded note tracking for real-world
guitar solo recordings. Transactions of the
International Society for Music Information Retrieval ,
2(1), 2019.
[26] R. J. Zatorre, J. L. Chen, and V. B. Penhune. When
the brain plays music: auditory–motor interactions in
music perception and production. Nature reviews
neuroscience, 8(7):547–558, 2007.
APPENDIX
A. MODIFIED MPX-Q QUESTIONNAIRE
Our adaptation of the MPX-Q Questionnaire as it was
handed to the participants before the interview.
Evaluation of an Augmented Electric Guitar Prototype          Participant: _____________   
 - 1 - 
 Modality A  Pitch bend control Modality B  Feedback control Modality C  Reduced bend control    A B C [Sample answer] 2 1 3 The instrument allows me to learn new things.    The instrument offers me new possibilities of things to do    The instruments expands my experience of musical interaction    The instrument offers me new facets of playing    I perceive the instrument as offering a lot of variety    The instrument feels like I can go beyond myself    The instrument offers me interesting possibilities to manipulate sound    The instrument offers me a good variety of sounds to evoke    I can continually discover new things by using the instrument    The instrument fosters my creativity    The instruments supports me in creating new music in any style    The instrument offers new possibilities to express myself musically    I perceive the instrument as challenging in a positive way    Playing the instrument allows me to further develop my musical skills    The instrument keeps me interested    The instrument allows me to be engaged when I am playing it    The instrument allows me to focus on sound generation    It is easy for me to get into a flow of playing with the instrument    
Evaluation of an Augmented Electric Guitar Prototype          Participant: _____________   
 - 2 - 
Modality A  Pitch bend control Modality B  Feedback control Modality C  Reduced bend control  Modality    A B C [Sample answer] 2 1 3 I feel in control of the instrument    I can play precisely on the instrument    I can control the sound appropriately    The instrument does what I want it to do    I can use the instrument intuitively    The instrument responds well to my actions    I feel like I am initiating, executing and controlling the behaviour of the instrument    The instrument works the way I expect it to    I perceive the instrument as allowing small and efficient movements    The instrument feels like an extension to my body     