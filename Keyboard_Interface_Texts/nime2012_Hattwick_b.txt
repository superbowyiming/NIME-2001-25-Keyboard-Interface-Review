Approaches to Collaboration in a Digital Music Ensemble
Ian Hattwick
Centre for Interdisciplinary Research in Music
Media and Technology
Input Devices and Music Interaction Lab
Music Technology Area
McGill University, Canada
ian@ianhattwick.com
Kojiro Umezaki
University of California, Irvine
303 Music and Media Bldg., UCI
Irvine CA 92697-2775 USA
kumezaki@uci.edu
ABSTRACT
The Physical Computing Ensemble was created in order to
determine the viability of an approach to musical perfor-
mance which focuses on the relationships and interactions
of the performers. Three performance systems utilizing ges-
tural controllers were designed and implemented, each with
a diﬀerent strategy for performer interaction.
These strategies took advantage of the opportunities for
collaborative performance inherent in digital musical instru-
ments due to their networking abilities and reconﬁgurable
software. These characteristics allow for the easy implemen-
tation of varying approaches to collaborative performance.
Ensembles who utilize digital musical instruments provide
a fertile environment for the design, testing, and utilization
of collaborative performance systems.
The three strategies discussed in this paper are the pa-
rameterization of musical elements, turn-based collabora-
tive control of sound, and the interaction of musical sys-
tems created by multiple performers. Design principles,
implementation, and a performance using these strategies
are discussed, and the conclusion is drawn that performer
interaction and collaboration as a primary focus for system
design, composition, and performance is viable.
Keywords
Collaborative performance, interaction, digital musical in-
struments, gestural controller, digital music ensemble, Wii
1. INTRODUCTION
The Physical Computing Ensemble (PCE) was formed at
the University of California Irvine in Fall 2010 in order to
explore the potential of collaborative performance in a dig-
ital music ensemble . The hypothesis behind the formation
of the PCE was that one approach to a successful DME
performance is through highlighting performer relationships
and interaction. During the creation of the PCE considera-
tions which would normally be the primary focus of a per-
formance, such as compositional intent and the expressive
facility of individual performers, were de-emphasized in or-
der to focus on the development of collaborative strategies
which the performers would be able to conﬁdently employ.
Careful attention was given to the clarity of performer’s in-
strumental gestures, and to the correlation between these
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’12,May 21 – 23, 2012, University of Michigan, Ann Arbor.
Copyright remains with the author(s).
gestures and the musical result. Our hope was that this
approach would culminate in a performance that was un-
derstandable, engaging, and enjoyable. This paper discusses
the guiding principles behind the PCE, the implementation
of these principles in three compositions, and a performance
of the compositions.
This examination of the collaborative potential of digi-
tal musical instruments in a performance context is greatly
inﬂuenced by the work of musicologist Christopher Small.
Small argues that “the act of musicking establishes in the
place where it is happening a set of relationships, and it is in
those relationships that the meaning of the act lies. They
are to be found not only between those organized sounds
which are conventionally thought of as being the stuﬀ of mu-
sical meaning but also between the people who are taking
part, in whatever capacity, in the performance”[16]. Talk-
ing about the Princeton Laptop Orchestra, Dan Trueman
notes that “[o]ne of the most exciting possibilities aﬀorded
by the laptop orchestra is its inherent dependence on people
making music together in the same space”[19]. The Phys-
ical Computing Ensemble was formed for the purpose of
exploring these possibilities.
1.1 Collaborative affordances of DMIs
We refer to Miranda & Wanderley’s deﬁnition of a digital
musical instrument (DMI) consisting of interface > map-
pings > synthesis algorithm[15]. Commonly both mapping
and sound synthesis take place in software. This creates op-
portunities for collaboration due to two factors — the pos-
sibility of sharing information with other performers over
a network, and the reconﬁgurability of mapping strategies
and synthesis algorithms.
While the possibilities of network-based information shar-
ing in musical performance has been addressed [21] [22],
the reconﬁgurability of DMIs for collaborative performance
is equally important. Reconﬁgurability means that a sub-
stantial part of the instrument can change in the course of
a performance. This has the beneﬁt that instrument de-
sign can becomecontext-speciﬁc, and can depend on the
existence of performers relating to each other in speciﬁc
ways. While reconﬁguring DMIs is not always seen as a
good thing, as noted in Perry Cook’s Principle“Programma-
bility is a curse”[6], Cook also notes “[more] can be better!
(but hard)”[7]. It opens up the possibility for certain con-
ﬁgurations of instruments that depend on each other, or on
certain aspects of the performance environment.
In this paper we refer to a digital music ensemble (DME)
as an ensemble of musicians performing using DMIs. This
restriction of instrumentation is important because it allows
for an approach to collaborative performance that takes ad-
vantage of the characteristics of DMIs described above.
1.2 Previous Work
The Hub, as the most prominent example of a DME which
explicitly focuses on collaborative performance, is one of the
primary inﬂuences for the PCE.Laptop orchestras, and the
PLOrk in particular, have also been important primarily
for their use of instruments which are developed by com-
posers and directors [17] [4], in contrast to ensembles like
The Hub and Sensorband in which each performer provides
and performs with diﬀerent DMIs [5] [2].
The Tooka [10] and Soundnet [2] are examples of instru-
ment in which collaborative performance is designed into
the hardware. These instruments demonstrate that collab-
orative control of an interface is a viable approach, although
collaboration through software may prove to be more prac-
tical in certain contexts and has the advantages that the
mode of collaboration may change during performance, and
DMIs may also be used in non-collaborative contexts.
2. FOUNDATIONS OF THE PCE
Considering how humans express themselves physically refers
to more than just the use of expressive gestures such as
hand movements. It also includes the ways in which we
position ourselves in space — whether we face each other,
move closer and further away from each other — and how
this aﬀects the ways in which we use eye contact and sub-
tle physical cues. These physical expressions can be used
as the conceptual frameworks for computer-mediated forms
of human communication. In this scenario the focus moves
away from human-computer interaction and towards human
interaction as mediated by a computer.
As the Physical Computing Ensemble took shape it de-
veloped the following attributes:
• The performer interface should rely on gestures which
would be meaningful to the performer, fellow musi-
cians, and audience.
• Performers should each have their own speaker, which
should be positioned on stage as to localize each per-
formers’ sound in a diﬀerent place. However, the per-
formers themselves should not be tied down to a spe-
ciﬁc location and should use a wireless interface. One
corollary of this decision is that performers must not
use sheet music, as this would tie them to a location
on stage.
• The performers’ attention should be on their fellow
performers, with interaction being the focus. The per-
former’s instruments should not require visual feed-
back.
• The role of the computer, and its physical presence,
should be minimized in order to direct attention to
the performers.
• Each composition should use a diﬀerent software in-
strument which utilizes a diﬀerent approach to per-
former interaction.
2.1 Technical Notes
Each performer used a Nintendo Wii remote as a gestural
controller. The three-axis accelerometer and trigger button
were the only sensors used. OSCulator was used to route
the controller data into Max/MSP.
The compositions were programmed in Max/MSP and
each composition consisted of multiple sections, each with
speciﬁc parameter settings. Vibrotactile cues using the Wii
remotes built-in vibroactuators were given to the perform-
ers in order to assist them in navigating the compositions.
Three kinds of cues were given: start/stop playing; section
change; and speciﬁc performance instructions. At the be-
ginning of each section performers were cued as to whether
they were playing in a section or not. If they were play-
ing, they received 16 rapid pulses. If they were not they
received a single long pulse. Each section was cued with a
vibrotactile count-in consisting of 8 eighth-notes, followed
by the appropriate start/stop cue at the downbeat of the
new section. In “Just Continue to Move” performers also
were given speciﬁc cues in the form of 1, 2, or 3 short pulses
indicating speciﬁc musical gestures.
Since there was no visual direction given to the performers
in the form of sheet music or visual cues, they were expected
to memorize the compositions. In practice, the performers
used visual communication with each other to help remem-
ber the content of the compositions. The tactile cues also
proved to be indispensable. While the Wii remote’s vibroac-
tuator is limited to on/oﬀ messages the cues were eﬀective
in conveying necessary information. The performers had
occasional diﬃculty with distinguishing between diﬀerent
pulse patterns, but this was solved largely through the re-
striction of cues to certain contexts. There were also some
problems with performers not feeling cues, which stemmed
from the masking of vibrotactile cues by vigorous physi-
cal motion. This did not pose too much of a problem in
this context since the tactile cues were primarily used as
reminders, and visual communication with other perform-
ers easily compensated for missed cues, but it does point to
larger issues with the use of vibrotactile systems to provide
feedback and guidance during performance.
3. 3 APPROACHES TO INTERACTIVITY
Behind each PCE composition is a diﬀerent concept of in-
teractivity. The concepts in the compositions examined be-
low are: the parameterization of musical elements, where
diﬀerent musicians are in control of diﬀerent elements of
the same musical event; turn-based collaborative control of
sound, where performers share control of a sonic element se-
quentially rather than simultaneously; and the interaction
of systems set in place by each performer. To the degree
which these forms of interaction depend upon the capabili-
ties of a computer they are unique to a digital music ensem-
ble. There are other more traditional forms of interaction
in these compositions as well, but the success of each piece
is dependent upon the qualities of the forms of interaction
described above. Full documentation of the compositions is
available on the ﬁrst author’s website, ianhattwick.com.
3.1 Triangulation
“Triangulation” explores the parameterization of musical el-
ements as utilized by The Hub in “The Minister of Pitch”[5].
There are three pairs of musicians; in each pair one musi-
cian deals primarily with pitch and timbral material and
the other musician with rhythmic material. Both musicians
use 3-axis accelerometers to write into multiple data buﬀers,
which are then used as 1) wavetables and 2) amplitude val-
ues sampled at 16th notes, respectively. Data is written into
their buﬀers as long as they depress their trigger button.
Since the pitch musician is writing data into a wavetable
there is no audible result until the end of their gesture.
In contrast, the rhythm musician’s gestures are stored and
heard simultaneously. In practice this means that their ges-
tures are sequential and meet at the moment of sound gen-
eration, which requires visual coordination between the mu-
sicians.
3.2 Just Continue to Move
“Just Continue to Move” uses the motions of throwing a
ball back and forth as its primary performance gesture. The
Figure 1: A pitch/rhythm pair performing in “Tri-
angulation”
concept of playing catch has many associations (cooperative
play, interaction with the environment, skill-based perfor-
mance, etc.). Throwing a ball is an expressive act with an
inﬁnite number of variations, and is easy to perform but
with room for virtuosity. There is a common desire for a
form of computer musicianship that is easy for the beginner
to grasp but that rewards expert performance[19][1][23]; in
some ways catch is a simple example of this.
In the PCE implementation, the virtual ball represents
control over a long sample of a spoken anecdote. Performers
grasp the ball by holding the trigger button; while grasped,
acceleration controls the amplitude of the sample. When
the ball is thrown, the momentary acceleration and angle of
release at the moment the trigger is released are measured.
A short section of the sample whose end is the playback
position of the sample at the moment of release is then
looped. The release angle determines the total length of the
loop; acceleration determines the intial speed of the loop.
The speed slows to a stop over the course of a few seconds,
resulting in a pseudo-doppler eﬀect which aurally conveys
the trajectory of the ball. The receiving player “grabs” the
ball at the appropriate point in its trajectory.
3.3 Skipping Stones
In “Skipping Stones” individual musicians create musical
events whose qualities are derived from the metaphor of
skipping stones on a lake. The musician makes a single mo-
tion — picking up a stone by pressing the trigger button,
throwing the stone by moving their hand perpendicularly
to the ground, and releasing the stone at the proper place
in the throw by letting go of the trigger button. This single
motion creates a miniature musical system whose charac-
teristics are determined by the acceleration and angle at
the moment of the stone’s release. How hard the stone is
thrown determines the speed, amplitude, and number of
repetitions, or ‘skips’, of a note. The angle of the stone’s
release determines the length of the sonic event which con-
stitutes each skip. There is a metric pulse and each skip
is one of eight rhythmic subdivisions of the basic pulse,
from a 32nd note to a half note. While the subdivisions
are quantized, the moment of release is not, which allows
for considerable rhythmic ﬂexibility.
The primary form of interaction in this composition is in
the creation of systems with diﬀerent rhythmic subdivisions.
Depending on how many musicians are playing at once this
takes the form of a duet with easily discernible interlocking
rhythms or it can take the form of a complex composite
of many diﬀerent rhythms. In contrast to the processes
in a typical algorithmic composition, whose parameters are
set before the composition begins, in “Skipping Stones” the
parameters of the process are set by a gesture extremely
similar to a traditional performance gesture. This allows
performers to set into motion musical processes which are
a reaction in real-time to the processes created by other
musicians.
4. IN PERFORMANCE
Since one of the goals of the PCE was to highlight the phys-
ical relationships between performers, the staging of each
composition was important consideration. The stage setup
consisted of six speakers in a semi-circle behind the ensem-
ble, and a large open space for the performers to inhabit.
Each performer had a dedicated speaker which served as
their home base. This inﬂuenced the performers’ location
left-to-right more than front-to-back, in an attempt to lo-
cate each performer in the correct location in the ‘stereo
ﬁeld’.
Each composition employed varying ensemble conﬁgura-
tions ranging from duets to tutti sections. Speciﬁc stagings
were established in order to highlight the interaction of each
conﬁguration. This helped to convey the focus of the com-
position to the audience and facilitate visual communica-
tion between performers. Diﬀerent stagings also served to
suggest diﬀerent kinds of performance gestures. For exam-
ple, in “Just Continue to Move” duets in which performers
were located at opposite sides of the stage caused the per-
formers to throw ‘long bombs’, while stagings in which the
performers were close more often instigated volleying. The
ﬂuidity of the staging was a hugely important factor in the
performance, with the open space allowing the performers
considerable latitude in physical expression.
The April 22 performance was to an audience of around
80 people who were largely unfamiliar with electro-acoustic
music. Once the performance began it quickly became ap-
parent that they were drawn in by the rapport between the
performers. By the end of the concert it was apparent that
our ﬁrst two hopes, that it be understandable and engag-
ing, were fulﬁlled. Anecdotal evidence gathered over the
next week suggests that the third hope was fulﬁlled as well.
5. CONCLUSIONS
The hypothesis asserted in this paper is that one approach
to a successful DME performance is through highlighting
the relationships and interaction of the performers. Prin-
ciples for DME performance based on this hypothesis were
presented, three diﬀerent systems for collaborative perfor-
mance were described, and we analyze the use of these sys-
tems in concert.
While it is diﬃcult to quantify precisely, it is our belief
that the principles laid out in this paper were instrumen-
tal to the concert’s success. We would also like to empha-
size that the reconﬁgurability of digital musical instruments
provides an opportunity for modes of collaborative perfor-
mance practice to be implemented on a wide variety of in-
struments. In the concert described above, the use of dif-
ferent collaborative approaches to give each composition a
distinct character was greatly beneﬁcial.
6. ACKNOWLEDGMENTS
Thanks to the members of the Physical Computing Ensem-
ble: Yunxiang Gao, Chris Lavender, Josh Ottum, David
Figure 2: Performers playing catch at either end of the stage
Resnick, Randall Smith, and Kevin Zhang; to Chris Do-
brian and the ICIT faculty at UC Irvine; and to Marcelo
Wanderley at McGill University.
7. REFERENCES
[1] T. Blaine and S. Fels. Contexts of Collaborative
Musical Experiences. In Proceedings of the 2003
Conference on New Interfaces for Musical Expression ,
volume 3, pages 129–134, Montreal, Canada, 2003.
National University of Singapore.
[2] B. Bongers. An interview with Sensorband. Computer
Music Journal, 22(1):13–24, 1998.
[3] B. Bongers. Physical Interfaces in the Electronic Arts:
Interaction Theory and Interfacing Techniques for
Real-time Performance. In M. M. Wanderley and
M. Battier, editors, Trends in Gestural Control of
Music, volume 6, pages 41–70. IRCAM - Centre
Pompidou, Paris, France, 2000.
[4] I. I. Bukvic, T. Martin, E. Standley, and
M. MAtthews. Introducing L 2 Ork: Linux Laptop
Orchestra. In Proceedings of the 2010 Conference on
New Interfaces for Musical Expression , number Nime,
pages 170–173, 2010.
[5] J. Chadabe. Electric Sound: The Past and Promise of
Electric Music. Prentice Hall, New York, 1996.
[6] P. Cook. Principles for designing computer music
controllers. In Proceedings of the 2001 conference on
New Interfaces for Musical Expression , pages 1–4,
Seattle, Washington, 2001. National University of
Singapore.
[7] P. Cook. Re-Designing Principles for Computer Music
Controllers: A Case Study of SqueezeVox Maggie. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , pages 218–221,
Pittsburgh, USA, 2009. Carnegie Mellon University.
[8] J. Croft. Theses on liveness. Organised Sound,
12(01):59–66, Apr. 2007.
[9] C. Dobrian and D. Koppelman. The ”E” in NIME :
Musical Expression with New Computer Interfaces. In
Proceedings of the 2006 conference on New interfaces
for musical expression, pages 277–282, Paris, France,
2006. IRCAM - Centre Pompidou in collaboration
with Sorbonne University.
[10] S. Fels, L. Kaastra, S. Takahashi, and G. McCaig.
Evolving tooka: from experiment to instrument. In
Proceedings of the 2004 Conference on New Interfaces
for Musical Expression, pages 1–6, Hamamatsu,
Japan, 2004. Shizuoka University of Art and Culture.
[11] S. Gresham-Lancaster. The Aesthetics and History of
the Hub : The Eﬀects of Changing Technology on
Network Computer Music.Leonardo Music Journal,
8:39–44, 1998.
[12] I. Hattwick and M. M. Wanderley. A Dimension
Space for Evaluating Collaborative Musical
Performance Systems. Unpublished, 2012.
[13] T. Igoe. The FAQs of Physical Computing, 2004.
[14] M. McLuhan. The Gutenburg Galaxy . University of
Toronto Press, Toronto, Ontario, 1962.
[15] E. R. Miranda and M. M. Wanderley. New Digital
Musical Instruments: Control And Interaction Beyond
the Keyboard. A-R Editions, Middleton, WI, 2006.
[16] C. Small. Musicking. Wesleyan University Press,
Hanover, New Hampshire, 1998.
[17] S. Smallwood, D. Trueman, and P. Cook. Composing
for laptop orchestra. Computer Music Journal ,
32(1):9–25, 2008.
[18] A. Tanaka and B. Bongers. Global String: A Musical
Instrument for Hybrid Space. In Proceedings of the
1999 Conference on Artistic, Cultural and Scientiﬁc
Aspects of Experimental Media Spaces., pages
299–304, Bonn, Germany, 2001.
[19] D. Trueman. Why a laptop orchestra? Organised
Sound, 12(02):171, July 2007.
[20] M. Wanderley and P. Depalle. Gestural Control of
Sound Synthesis. Proceedings of the IEEE,
92(4):632–644, Apr. 2004.
[21] G. Weinberg. Interconnected musical networks:
Toward a theoretical framework. Computer Music
Journal, 29(2):23–39, 2005.
[22] G. Weinberg, R. Aimi, and K. Jennings. The Beatbug
network: a rhythmic system for interdependent group
collaboration. In Proceedings of the 2002 conference
on New interfaces for musical expression , pages 1–6.
National University of Singapore, 2002.
[23] D. Wessel. Problems and prospects for intimate
musical control of computers. Computer Music
Journal, 26(3):11–22, 2002.