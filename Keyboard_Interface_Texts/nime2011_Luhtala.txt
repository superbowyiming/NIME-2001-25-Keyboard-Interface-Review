Designing a Music Performance Space  
for Persons with Intellectual Learning Disabilities 
 
 
Matti Luhtala 
VTT Technical Research Centre 
 of Finland 
P.O. BOX 1300, 
 33101 Tampere, Finland 
matti.luhtala@vtt.fi 
 
   Tiina Kymäläinen 
VTT Technical Research Centre 
of Finland 
P.O. BOX 1300,  
33101 Tampere, Finland  
tiina.kymalainen@vtt.fi 
 
Johan Plomp 
VTT Technical Research Centre 
of Finland 
P.O. BOX 1300,  
33101 Tampere, Finland  
johan.plomp@vtt.fi 
 
ABSTRACT 
This paper outlines the design and development process of the 
‘DIYSE Music Creation Tool’ concept, by presenting key 
questions, the used methodology, the music instrument 
prototype development process and user research activities. The 
aim of this research is to study how music therapists (or 
instructors) can utilize novel technologies and study new 
performing opportunities in the music therapy context, with 
people who have intellectual learning disabilities. 
 The research applies an action research approach to develop 
new music technologies by co-designing with the music 
therapists, in order to develop in situ and improve the adoption 
of novel technologies. The proof-of-concept software utilizes 
Guitar Hero guitar controllers, and the software allows the 
music therapist to personalize interaction mappings between the 
physical and digital instrument components. By means of the 
guitars, the users are able to participate in various musical 
activities; they are able to play prepared musical compositions 
without extensive training, play together and perform for 
others. User research studies included the evaluation of the tool 
and research for performance opportunities. 
 
Keywords 
Music interfaces, music therapy, modifiable interfaces, design 
tools, Human-Technology Interaction (HTI), User-Centred 
Design (UCD), design for all (DfA), prototyping, performance. 
 
1. INTRODUCTION 
The Do It Yourself Smart Experiences (DIYSE) project 1 aims 
at enabling ordinary people to easily create setup and control 
applications in their smart living environments as well as in the 
public Internet-of-Things space, allowing them to leverage 
aware services and smart objects for obtaining highly 
personalized, social, interactive, flowing experiences at home 
and in the city. The development of the ‘DIYSE Music 
Creation Tool’ and the user research studies were based on a 
preliminary study within the DIYSE-project. The study 
outlined the everyday life of people with intellectual learning 
disabilities2 concerning new technologies. Based on this 
 
1 http://www.dyse.org 
2 People who have a mild or moderate intellectual learning 
disability (Diagnosis ICD-10). 
preliminary research, the music therapy context was chosen for 
the research framework. 
 Learning to play a traditional musical instrument requires 
long-term training, and consequently many beginners never 
succeed to develop the necessary fine-motor skills to play 
music. This is especially the case with the end-user group of 
this study; people with intellectual learning disabilities. This 
user group needs musical interfaces that are extremely easy to 
understand and to adopt: the paradigm is also found in the 
studies of Machover [6] and Benvenieste [1]. Therefore, the 
aim of this study has been to design easy-to-learn interactive 
music instruments and develop alternative methods for music 
creation. This paper presents the challenges of interaction 
design related to the music creation context, and describes the 
prototype development and the user-centred design research 
processes [5]. 
 
2. INTERACTION DESIGN  
FOR A MUSIC CONTEXT 
In the field of interaction design research, there is a demand for 
new design tools that enable creativity by means of explorative 
interaction, as opposed to limited executive and mission-based 
interaction (e.g. [3], [5] & [6]). Petersen et al. have proposed 
that the aesthetical interaction perspective offers an alternative 
to traditional interaction ideals [6].  In aesthetic interaction, the 
user is seen as an improvisator and the interaction between the 
human and the technology is a situation of play. According to 
Petersen, aesthetic interaction is found in the concept of 
intrigue that is connected to experience, surprise and 
ser end ip ity in th e us e o f inte rac t iv e sy stem s ( ib id p . 27 4) .  I n 
the light of Petersen’s theory, equal attention should be paid to 
the players’ cognitive skills, emotional values and bodily 
capabilities in the design of creativity-supporting music tools. 
A music-playing learning situation should enable the player to 
imagine, create, play, share and reflect on musical actions [7]. 
The playing situation involves an interaction feedback loop 
between the participants, their instruments and produced 
sounds. In an ideal state, a playing situation should encourage 
players to improvise and express themselves through playing 
and experiencing immersion. 
 
3. METHODS AND TOOLS 
3.1 Prototyping 
In the pursue of finding means to support the musical activities 
of persons with intellectual learning disabilities, we began by 
simplifying the music creation process and concentrated on 
finding interactive technologies that were easily available and 
easy to use. According to the preliminary research, we had 
learned that the target group end-users had various, and often 
multiple, disabilities and that they were enthusiastic about 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
NIME’11, 30 May–1 June 2011, Oslo, Norway. 
Copyright remains with the author(s). 
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
429
music. In the initial research phase, various sensor technologies 
were tried out and observed with the end-users. The 
prototyping phase was carried out through an iterative co-
design process between the designers and a music therapist. 
The co-operation with the professional music therapist was an 
essential part of developing the prototype. For developing the 
digital user interface we used the Max MSP graphical 
programming language [9]. Nintendo Wii Remotes [10] and 
Guitar Hero controllers were chosen for our physical controller 
framework. Both of the technologies offered good 
technological support for realizing proof of concept prototypes 
because of their reliability and active open source and sharing 
communities. 
 
3.2 Music Therapy Context 
The use of the ‘DIYSE Music Creation Tool’ was observed and 
evaluated in a natural music therapy context (see figure 1), in 
order to gather information about the adoption and usability of 
the software and the instruments. Rinnekoti Foundation, a 
service provider for disabled people and partner in the project, 
provided the facilities for the evaluation of the ‘DIYSE Music 
Creation Tool’: a computer, three guitars and the software, 
were brought to the music therapy studio. The therapist chose 
the players based on their capability to benefit from the new 
means to make music and based on their availability for the 
whole observation period. On proposal of the music therapist, 
the observation period culminated into a final concert, in which 
the participants performed the music piece for an audience with 
the instruments accompanied by an acoustic drum kit. The 
concert was part of the DIYSE project research consortium 
meeting (see video link in the appendices section). 
 
  
 
 
Figure 1. ‘Music therapy session: learning to play and 
practicing for a performance. 
 
3.3 Prototype Evaluations 
The ‘DIYSE Music Creation Tool‘was evaluated in two phases. 
The first evaluation session was arranged in August 2010, at the 
Rinnekoti Foundation, Espoo, Finland. The participants were 
26 – 58 years of age. All of the interviewees knew each other 
beforehand and were accustomed to participate in music 
therapy sessions. The research methods included observations 
and semi-structured interviews [4] and there were two 
objectives for the evaluations. Firstly, the initial goal was to 
determine technical requirements by utilizing co-design, and 
therefore the music software was introduced to the music 
therapist. Secondly, the acceptance and the user experience 
were evaluated with the players. At the end of the evaluation 
session, there was a short ‘Sonic Sketching’ workshop that was 
aimed to encourage participants to innovate surprising and 
inspiring ideas for novel music instruments.  
The second evaluation phase was held between 
October/November 2010, at the Rinnekoti Foundation and the 
p a r t i c i p a n t s w e r e m o s t l y t h e s a m e a s i n t h e f i r s t p h a s e . T h e 
observation framework was arranged for 1.5 weeks observation 
period, and the music therapist was responsible for the therapy 
context within the given framework. The therapist carried out 
most of the therapy sessions individually. The video 
observation period lasted ten days, and seven music therapy 
sessions were video-recorded in that time scale. The recorded 
video material was analyzed based on the ‘interaction analysis 
lab’ method [2]. In the method, the observers comment about 
the context of the video material, create a hypothesis about 
what is occurring in the recording, and discuss about the 
context [8]. During the analysis, the material was observed 
according to four topics: supporting creativity, learning, user 
frustration and independent playing.  
 
4. RESULTS 
4.1 Prototype 
The software features the following three functionalities: 1. 
Composing and restoring music tracks in the software. 2. 
Design of interaction mapping strategies between the guitar’s 
interface elements and played sounds. 3. Choose sounds for the 
guitar. Figure 2 presents the software’s interface layout. 
 
 
Figure 2. ‘DIYSE Music Creation Tool’ software’s main 
window: functionalities for recording, mapping interactions 
and choosing sounds. 
 
4.1.1 Prototype in Use 
The music therapist prepared the therapy sessions by recording 
song arrangements into the software using a midi keyboard. 
The music in the first evaluation session was a general 12 bar 
‘blues’ theme. For the second session, the therapist chose a 
song composed called ‘Egyptian Reggae’, by Richman 
Jonathan. The first song was used for practicing purposes and 
the latter was rehearsed to be performed in the concert. 
According to the therapist, the chosen genres – the blues and 
the reggae – were stated to provide a ‘good groove’ and were 
therefore suitable for the therapy group. In addition, the songs’ 
musical elements were easy to arrange for the three guitars. The 
therapist arranged the musical elements as follows: 1. bass 
guitar, 2. rhythm guitar and 3. solo guitar.  
 The software assisted to map the arranged sound elements to 
the three guitars interface elements. The bass guitar was played 
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
430
using the controller’s strum switch. The switch triggered single 
notes from a step-sequencer’s timeline in sequential order. The 
bass guitar was meant to be the easiest instrument to learn as it 
produced meaningful musical structures through simple switch 
triggering. The rhythm guitar and the solo guitar were played 
by pressing the color buttons attached on the controller’s neck. 
The rhythm guitar’s idea was to challenge the player to play 
chords in the right order and time. The solo guitar was designed 
to support an idea of free playing and expression. Using only 
harmonic notes, each mapped to the guitar’s colored buttons, 
the audible result was designed to be pleasing as there were no 
dissonant notes. 
 
4.2 Interviews and Observations 
According to the interviews and observations, the most 
satisfactory attribute of the ‘DIYSE Music Creation Tool‘ was 
the experience itself;  the joy of creating and generating music 
and the feel of accomplishing something in a short period of 
time, even if the players lacked the skills to play musical 
instruments. This sense of easiness was consequence of the fact 
that some music pieces were composed beforehand and thereby 
there were “no wrong notes” i.e. if the player pressed the bass 
guitar’s strum, the music flowed and sounded pleasantly. 
According to the preliminary observations, it seemed to be 
important that the instruments resembled real instruments, 
guitar and bass, so that its affordances were easy to perceive 
[2]. For the music therapist, it was important that there were 
many alternatives to choose from the sound library, relating to 
music genres, instruments, sounds and tones. The most 
significant finding was the fact that performing to an audience 
seemed to be important for this user group. Generally, the 
threshold to perform and try out new things seemed to be quite 
low. 
 
4.3 Interaction Analysis Lab 
The music therapist used much effort in trying to provide a 
creative atmosphere, so that the therapy situation would not be 
just about pressing buttons and learning rhythm. For example, 
he accompanied the players by playing traditional instruments 
and encouraged the players to communicate with him through 
musical expressions such as tempo variations and pauses. In 
addition, he made occasional polyrhythmic textures in order to 
increase the complexity level of playing. Many times his efforts 
disturbed the participants, as finding the rhythm took all their 
attention. Otherwise, the playing situation was quite static; it 
appeared that there was not much improvisation or 
experimental playing during the practise. An incentive to 
support creativity with the ‘DIYSE Music Creation Tool’ was 
the promised performance for an audience.   
The observations indicated that the appearances, the shape 
and sound of the instrument, were important and that the 
instruments must support the player’s identity. For example, 
one of the players mentioned that because his brother played 
the guitar in a band, he liked to play it too. However, the guitar-
like shape also provided challenges: it was difficult to detect 
the colour buttons and it was challenging to decide how to hold 
the instrument, as it seemed to be uncomfortable to hold it ‘like 
a guitar’. Some participants even did not have enough motor 
coordination to play the instrument like a guitar. This was an 
important observation, because the way to hold the instrument 
influences the way feedback is received. Preferably, the 
interaction with the instrument should be as intuitive as 
possible. Observations indicated also, that it seems to be more 
important for the players to press the right button at the right 
time, than to have a subjective playing experience and feel 
comfortable in the role of an improviser. 
The music therapist himself learnt to prepare the system on 
the third observation day; connecting the guitars and the 
computer, uploading the sounds and creating personalized 
mapping strategies for the players. The most significant 
observed difficulty of the learning experience was related to 
learning the rhythm. If the players could not find the rhythm, it 
became difficult to perceive a mental map of the overall 
situation, and the users were disappointed and frustrated. In 
general, the players of this user group needed a lot of support 
from the therapist i.e. the level of independency was low. The 
music therapist guided the participants e.g. by instructing the 
colour keys of the instrument: “red-green-yellow” (see figure 
3). On the third observation day, there was a new player 
attending the music therapy sessions. He practiced playing the 
instruments only once and was therefore an excellent subject to 
study. At first, he played the bass and was able to learn the first 
three notes of the rhythm pattern, but learning the whole 
rhythm structure seemed to be quite demanding for him too. 
Yet when he finally had learned the rhythm, it seemed to be 
extremely rewarding. 
 
 
 
Figure 3. Practicing to operate the instruments: music 
therapist giving instructions – red, green, yellow... 
 
During the observations, there were specific moments when 
players seemed to be quite frustrated. For example, in the 
second observation day one of the players was notably 
disturbed. His playing of the bass was already fluent and 
therefore his gaze wondered towards other interests. One of the 
play ers stated to be tired of the chosen piece of music, and he 
wanted to play something else. Frustration was apparent 
especially when the participant’s ability to learn was not 
properly taken into account. There seemed to be a delicate 
balance between patronising the player and providing too much 
information and encouragement for independent playing. 
 
5. DISCUSSION 
The ‘DIYSE Music Creation Tool’ was intended to be a design 
tool for the music therapist. During the design process, the 
therapist utilized the system for planning the sessions for his 
customers, and the end-users utilized the system for playing 
music and performing. By co-designing the system and using it 
in a real therapy situation, it was possible to create and develop 
new music playing experiences for music therapy clients in 
si tu. C rea t iv ity w as c ho sen to be a c ritic a l is sue o f the st udy .  
Based on the theoretical background and the results attained 
through the user evaluations, it was perceived that the Guitar 
Hero controller is not an ideal controller for playing music. The 
controller’s interface elements mainly support point and click 
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
431
interaction style, which is suitable for playing rhythm games as 
indicated by Machover [5]. Supporting only the rhythm is not 
nearly enough; rhythm, timbre, pitch and time should all be 
considered equally important when designing interactive music 
instruments. In the light of Petersen et al [6], the Guitar Hero 
controller can be mainly seen from the mechanistic tool 
perspective, thus having distance to dialogue, media and 
aesthetic views of interaction. In search of the aesthetic 
experience, we emphasize experimental aspects of the four 
music elements presented above. Therefore interaction design 
of the instrument should encourage the player to explore and 
playfully appropriate the musical dimensions through the 
instrument. However, it must be acknowledged that the point 
and click interaction is one considerable alternative when 
designing music instruments for persons with learning 
disabilities. A significant finding of the research was that it is 
important to minimize the possibilities to fail (or the feeling of 
failure) by keeping the control of the instrument simple. On the 
other hand, it is important that the playing situation challenge 
the player in the five learning phases that Resnic [7] presents: 
imaging, creating, playing, sharing and reflecting. 
 In future research, we intend to develop instruments that 
enable explorative human-computer interaction. This allows the 
players to concentrate on the creative process of music making 
and creating in a performance space. Performing on stage and 
training for the performance were stated to be very important. 
Some of the challenges for future design phases include 
providing support for two or more players and for the co-
playing concept as a whole. Social media could support in 
developing the music performance space by offering a tool for 
publishing music and providing a place for recording music or 
performing. In an ideal situation, digital and physical tools help 
users to enhance their everyday life; to think, to design and 
create art, experiment with new technology and technological 
gadgets and become stakeholders in public projects. 
 
6. ACKNOWLEDGMENTS 
T h i s w o r k w a s d o n e a s a p a r t o f t h e E u r e k a / I T E A 2 D I Y S E 
project in a cooperation between the Technological Research 
Center of Finland (VTT), the Rinnekoti Foundation and Laurea 
University of Applied Sciences. We gratefully acknowledge the 
financial support by the Ubicom programme of Tekes. 
 
7. REFERENCES 
[1] Benvenieste, J. Jouvelot, P., Lecourt, E. and Renaud, M. 
Designing Wiiprovisation for Mediation in Group Music 
Therapy with Children Suffering from Behavioral 
Disorders, IDC 2009, Como Italy. 
[2] Jordan, B. & Henderson, A., 1995. Interaction analysis: 
Foundations and practitice, The journal of the learning 
sciences 4 (1), 39-103. 
[3] Krippendorf, K. 2006. The semantic turn, a new 
Foundation for design, Taylor & Francis. 
[4] Kuniavsky, M., 2003. Observing the user experience: a 
practitioner's guide to user research, Morgan Kaufmann. 
[5] Machover, T. 2009. "Beyond Guitar Hero - Towards a 
New Musical Ecology." RSA Journal (London), January–
March 2009. 
[6] Petersen, M. Iversen, o. Krogh, P and Luvigse, M. 
Aesthetic Interaction – A pragmatist’s Aesthetics of 
Interactive Systems. DIS2004, Cambridge, Massachusetts, 
USA. 
[7] Resnic, M, N/A, All I Really Need to Know (About 
Creative Thinking) I Learned (By Studying How Children 
Learn) in Kindergarten, Mitchel Resnick: kindergarten 
approach to learning, MIT Media Lab, Cambridge. 
[8] Ylirisku, S., Buur, J., 2007.  Designing with video: 
Focusing the User-centred design process. Springer. 
 
Links: 
[9] Max MSP, Web site (read April 26, 2011): 
http://www.cycling74.com 
[10] Nintendo Wii Remote, Web site (read April 26, 2011): 
http://www.nintendo.com/wii/console/controllers 
 
Video 
http://www.youtube.com/HTIforWelbeing 
 
 
 
 
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
432