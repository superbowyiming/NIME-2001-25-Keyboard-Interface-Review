‘A Hapless But Entertaining Roar’:   
Developing a Room Feedback System through   
Artistic Research and Aesthetic Reflection
John Bowers
Independent Artist-Researcher
Visiting Scholar, SARC
Queen’s University, Belfast, UK
john.m.bowers@gmail.com
ABSTRACT 
This paper presents a room feedback system which the author has 
been developing and performing with for nearly three years. The 
design emerged from an artistic research process which emphasises 
multiple explorations coexisting around a research topic while having 
a sensitivity to the practicalities of a customary gig (short set-up time, 
unpredictable acoustics). Typically enabled by a stereo room-mic and 
a pair of speakers, many algorithms have been explored in the loop 
with some being tributes to historical feedback works. An overall 
design is offered where all feedback pathways are simultaneously 
available and mutually interfere via the room. Each algorithm is 
designed to have one significant performable parameter but how this 
is mapped to sensors or widgets is itself performable with various 
behaviours available, including some explorations of self-
programming and ‘intra-active’ ideas. Concert experience in solo and 
small ensemble formats is discussed and a number of contributions 
are identified in how the work: extends room feedback research to 
explore multiple parallel processes of varied spectro-morphological 
character, offers connections to historical work in a pedagogically 
interesting fashion, demonstrates several novel algorithms, while 
exemplifying a characteristic artistic research method. The paper 
closes with a speculative ‘feedback aesthetics’ to help configure 
future work. 
Author Keywords 
NIME, feedback, room feedback, interaction, intra-action, artistic 
research, performance ecology 
CCS Concepts 
• H.5.5 [Information Interfaces and Presentation] Sound and 
Music Computing. 
“…the hapless but nevertheless entertaining roar of feedback…” 
Roy Brassier 
1. INTRODUCTION 
This paper reports on nearly three years of artistic research, 
technical development, and performance with a room feedback 
system. Feedback has a long musical history with often-cited 
contributions including the electronic circuits of Bebe and Louis 
Barron stimulated into unpredictable self-oscillation [2], the electric 
guitar of Jimi Hendrix heavily overdriven and amplified, and the 
matrix mixing and related techniques that can be found throughout 
David Tudor’s music [3, 4]. Feedback is ubiquitously employed in 
modular synthesizer patches and many current commercial  
synthesizers build in feedback paths to, for example, overdrive an 
analogue filter. Many artists have found feedback to be a valuable 
aid in extending or repurposing the capabilities of commercial 
devices as in, for example, Toshimaru Nakamura’s no-input mixing 
boards.  
In NIME and allied research worlds, we have seen a number of 
instruments and interfaces built around interactive feedback. This 
includes: the feedback cellos and self-resonating vibrotactile 
instruments of Eldridge, Kiefer and colleagues [15, 16], the hybrid 
resonant assemblages of Bowers and Haas [5], Paul Stapleton’s 
VOLA [9], Halldór Úlfarsson’s augmented cello [6], Adam Pultz 
Melbye’s feedback actuated augmented double bass (FAAB) [13, 
14], Ward Slager’s Pandora’s Box [7], amongst others. 
Several writers have begun to reflect on the overall character of 
feedback music categorising the different ways in which feedback 
is implemented [8], analysing interviews with feedback musicians 
[12], and speculating on the philosophical and aesthetic issues that 
feedback connects with, including an examination of contemporary 
cybernetic and posthuman thinking [14]. 
2. DESIGN METHOD 
The research reported here was initiated in the early days of the 
COVID-19 pandemic as a personal response to lockdown conditions 
in the UK. Housebound, I reflected on the character of enclosed 
spaces [17] and the experiences of those confined to them, from 
prisoners [19] to mystics [18]. In this setting, it seemed appropriate to 
develop a room feedback system but one which was capable of many 
different ways of creating room sound to, as it were, enliven the room 
rather than accept its fixed modes, thereby creating an interesting 
aesthetic contrast to, say, Alvin Lucier’s I Am Sitting In A Room . 
While the gently modulating, contemplative work using microphone 
feedback and long tape delays of Éliane Radigue in Vice-
Versa a n d  Feedback Works 1969-1970 was part of my lockdown 
soundtrack, I also sought more dynamic ways of creating and 
intervening in the room’s sonic confinement, perhaps to please 
restless prisoner Jean Genet as much as contemplative mystic Julian 
of Norwich. For this reason, Di Scipio’s [21] insistence that the 
“sound is the interface” and the ever changing feedback roomscapes 
of Collins’ Pea Soup [23] were valuable influences. 
Within this aesthetic framing, I adapted the artistic research methods 
I and colleagues have previously worked with [24, 25, 26] and 
engaged in a proliferation of different ways of creating and working 
with room feedback, with the intention not so much of finding ‘the 
best’ or ‘the most innovative’ but of exploring the design space of 
room feedback through many different ‘samplings’. This included 
novel approaches to be sure but also incorporated my own attempts 
at replicating techniques from room feedback’s history. 
In common with [25, 26, 5, 9], I worked with an assemblage idea 
whereby the different algorithms I explored could all be brought into 
contact with each other in an open, incrementally developing system. 
In this, the room came to have an extra status as a kind of design 

metaphor. I saw the system I began to develop as a kind of room, one 
which could accommodate many different participants (algorithms 
and guest instruments) and their encounters, and be tolerant of their 
comings and goings. 
I worked with computationally frugal algorithms so that the system 
could run on one processor of a contemporary laptop or, in a cut-
down but still recognisable version, on a microcontroller-based 
environment such as Bela [10]. These were the resources available to 
me, locked down. I did not explore methods for pre-processing or 
detailed analysis of, say, room acoustics. I preferred that the 
behaviour of the system should emerge in performance and through 
how its behaviour is configured by the room, the algorithms which 
process room sound, and how the performer works with/in the 
system. 
There was also an early commitment to develop with a conventional 
MIDI controller in mind and to support the gestures of a player at 
such a device. While it is easy to imagine alternative controllers 
finding a use and, say, hybrid devices which combine movable 
microphones or speakers and sensors, this is deferred to a later stage 
of exploration. I discuss the controllers I had available to me later in 
this paper. They all had the format of a series of channels, each with a 
fader and a small number of knobs on buttons. Their build gave a 
number of hard design constraints which I was happy to work with 
from the start. As we will see, I explored algorithms for sound 
processing with only a few controllable parameters (knobs) or modes 
(buttons) in an overall design which mixed their amplitude (faders). 
3. THE FEEDBACK SYSTEM 
The system has been in continuous development for nearly three 
years with many different algorithms explored, several in many 
different versions. Throughout this time the system has been 
performed with, starting during lockdown with online streamed 
solo and collaborative performances with Paul Stapleton and Adam 
Pultz Melbye (as the trio 3BP), and more lately in traditional gigs. 
My performance experience is discussed later in the paper . Here, I 
described the state of the system as of 7th April 2023, the 
publication deadline for NIME 2023, but also the day of a solo gig 
in which it will be played. 
Overall Organisation. Figures 1 and 2 depict the overall 
organisation of the system by way of a screenshot and a functional 
block diagram. Twelve different algorithms are present, all 
implemented in Pure Data (PD, http://puredata.info/). A software 
gain control acts globally on the input, post [adc~]. All twelve 
algorithms send their output to two summing busses. After passing 
through a gain adjustment stage, these busses are output to [dac~] 
which communicates with the audio interface, ultimately sending 
the sound to the room. Eleven of the algorithms receive the same 
two channel input. The twelfth is an internal feedback loop 
containing a variable long delay and an optional convolution 
reverb. This internal loop receives input from the summing busses. 
Input Saturation and Output Limiting. While the confines of 
COVID-19 lockdown shaped the work, I wanted to develop 
something that was readily gigable when such opportunities 
returned. Many feedback musicians [e.g. Alice Eldridge, personal 
communication] have stories to tell about the fragility of systems, 
the sensitivity of their gain structures, and how beautiful effects at 
soundcheck get absorbed by the bodies of an audience when they 
arrive. By contrast I wanted something that was quick and easy to 
set up, was not overly sensitive to microphone and loudspeaker 
placement, and would not be liable to unwanted distortions, 
explosions or flatlinings to unbreakable silence. After much 
experimentation, I use a saturation function on the input to each 
algorithm: 
[ expr~ (if ($v1!=0, $v1/abs($v1), 0))*(1 - exp(-1*abs($v1*$f2))) ] 
a PD implementation of the equation specified in Reiss and 
McPherson [27]. The parameter ($f2) is set with a default for each 
algorithm individually to manage the saturation character 
appropriately. The defaults have emerged after years of 
      Figure 1. Screenshot of the Pure Data implementation of the feedback system described in this paper.      
experimentation and vary across the algorithms. For those  
algorithms whose output levels are unpredictable, a Hilbert 
transform-based limiter is placed on the output to give delay 
artefact-free amplitude limiting by default to 83dB (where, by PD 
convention, digital full-scale is 100dB). For this, I developed a two 
channel version of Katja Vetter’s vcompander~ [28] set to perform 
signal limiting.  
3.1.Algorithms 
In this section, I describe each algorithm in the depicted version of 
the system and give some sketches of others which have been 
experimented with. 
Short Feedback Delay. A variable delay is available of up to 12.7ms. 
Interpolation of delay times takes place if values are changed. There 
is an internal feedback loop to give comb filter effects with a 
coefficient of +/-0.91 determined by judgement. The sign on the 
feedback can be changed so as to obtain octave shifts. 
Ring Modulation (Vink). This algorithm draws on the work of Jaap 
Vink [29]. Vink designed a very flexible analogue feedback system 
where the feedback signal was, in order, tape delayed, ring 
modulated with an oscillator, put through a voltage controlled 
amplifier (VCA), an artificial reverberator, and then a third octave 
filter bank before being looped back to the tape delay. The signal’s 
amplitude was measured post-filter bank and inverted to control the 
VCA to avoid distortion by giving more amplification to quiet signals 
and less to loud ones. My version contains a digital feedback routing 
inspired by Vink’s design. It can be fed by a mix of room signal and 
internal feedback, passing this to, in order, an interpolating digital 
delay, a digital approximation of a ring modulator by means of signal 
multiplication with a sine wave, a Schroeder reverberator [30], and a 
10-band resonant filter bank. The coefficients of the filter bank 
randomly walk. The output of the filter bank is fed to both the overall 
output mixer and the feedback loop internal to the algorithm. The 
delay time (up to 2000ms) and the modulating frequency (8Hz to 
6000Hz) can be set. A button press randomises the room size, 
damping, and wet component of the reverberator. Another button 
press switches the reverberator in or out. In this way, reverberation 
can be obtained from the room or artificially or both. 
Resonant Filter. This is a simple resonant filter (PD’s reson~) with a 
fixed Q of 80 and a centre frequency up to 12.5k. 
Granular Streams. T h e  r o o m  s o u n d  i s  s a m p l e d  i n t o  a  2 0 s  b u f f e r .  
Sixteen streams of grains are extracted from this buffer with random 
length between 0.1ms and 5000ms. Grains can be pitched up or 
down 2 octaves, and are randomly panned. 
Granular Delay. An adaptation of Johannes Kreidler’s patch [31] is 
used with delay times variable between 100ms and 30s, and +/- 3 
octaves of transposition. On a button press, a delay/transposition pair 
can be randomly selected. 
Spectral Accumulator and Pitch Shift. The room sound is analysed 
by an FFT into 1024 bins. The signal representing these results is 
passed through an infinite impulse response (IIR) filter with the 
previous frame being weighted W and the current frame weighted 1-
W. W can be thought of as the ‘weight of the accumulated past’ or a 
control of spectral ‘smear’ over time.  
  Figure 2. Functional diagram of the feedback system described in this paper, showing the sound processing 
algorithms and their routings. 
The spectrum emerging from this calculation is combined with an 
FFT of white noise. The resynthesised signal is effectively a noise 
with a spectral profile that is an accumulation of the past with, at the 
extremes, W=1 freezing the analysed spectrum and W=0 updating it 
every frame, with values in between giving various flavours of 
pseudo-reverb. This synthesised spectral noise can then be pitch 
shifted +/- 2 octaves using an algorithm which simulates the tape-
head rotation technique. 
Spectral Sample and Hold. The room sound is analysed by FFT into 
256 bins. This spectrum is then sampled and held driven by two 
metronomes. One of these beats quickly - varying between one 
trigger every 1ms and every 20ms. Sixteen of the bins are selected at 
random on a trigger. The amplitude of these bins is normalised and 
the other 240 bins are set to have zero gain. This spectrum is then 
cross-synthesised with pink noise, the roll-off of which gave less 
uncomfortable results in this algorithm than using white noise. The 
other metronome beats more slowly - between one trigger every 
50ms and every 7620ms. All 256 bins are sampled on this trigger, 
normalised and cross-synthesised with pink noise. In this way, two 
noises are created, derived from different rates of sampling from and 
holding the room spectrum. Two buttons turn the samplings on or off 
- when off, the associated spectrum is frozen to a static noise texture. 
Oscillator Bank. PD’s sigmund~ algorithm is set to identify ‘notes’ in 
the room sound. Large analysis windows (up to 16384 samples) and 
analysis reporting (8192) intervals are selected to maximise 
frequency domain accuracy and make the rate of reporting 
manageable. The most recent 16 different note values are stored in a 
FIFO (first in, first out) stack. On a button-press, these values are sent 
to a bank of 16 sine wave oscillators. A control can transpose this 
bank +/- 3 octaves. A press on another button resets the transposition 
to 0.  
AllTheNotes. While Oscillator Bank k e e p s  a  r e c o r d  o f  t h e  l a s t  1 6  
different note values detected in the room sound, AllTheNotes keeps 
a time-ordered record of all values since the system was launched or 
the algorithm was last initialised. A control navigates through these 
data to select the note value to play. In this way, the pitch history of a 
performance can be played by sweeping the control. A wavetable 
oscillator is used with frequency and table values derived from 
another control. This technique is described in greater detail below 
(see SPK: The Self-Programming Knob). 
Dynamic Tonality. This algorithm is inspired by suggestions of 
Sethares and colleagues for scales which can dynamically vary in 
response to ongoing sound [32]. In addition to finding notes, 
[sigmund~] is set to look for three frequencies which correspond to 
the three strongest partials in a sinusoidal model of the sound. Call 
these, in ascending order of amplitude, f1, f2, f3. The ratios f2/f1 and 
f3/f1 are used to generate a scale by repeatedly iterating each ratio up 
and down, taking modulus 2 of results to preserve a sense of octaves. 
Accordingly, each iteration adds 4 scale degrees. Up to 5 iterations of 
this calculation are repeated every time sigmund~ detects a new note. 
On a button-press, the most recently detected note is taken as a root 
and the derived degrees (plus root) are used to tune a bank of 21 
waveguides made of tuned delay lines with high gain feedback. The 
whole tuning can be shifted +/- 3 octaves. The output from the 
waveguides is passed through a one pole low pass filter with 
adjustable frequency. In this way, partials present in the room sound 
can be reinforced or pitch-shifted and/or other spectrally related 
partials can be given the chance to emerge if they resonate with one 
of the tuned waveguides. 
Square Wave Delay Modulation. This algorithm is a PD 
implementation of the signature technique developed by guitarist 
Henry Kaiser [33] initially for the Lexicon PCM-42 digital delay 
whose clock time can be modulated by a square wave. Kaiser sets the 
frequency and depth of the square wave modulation of a long delay 
line so that repeats occur time (pitch) shifted up and down (down and 
up) by the same ratio. In the early 1980s, Kaiser proposed this as an 
alternative to the long fixed delays employed by Terry Riley and in 
Robert Fripp’s Frippertronics. The algorithm here uses a simulation 
of the tape-head rotation technique in PD (rather than forcing PD’s 
clock speed to change!) with a nominal delay set to 4800ms (i.e. 
2400ms an octave up, 9600ms an octave down), the maximum in the 
original Lexicon device. A control makes available a 5-limit 
pentatonic just intoned scale (plus octave) with ratios selected so that 
(with the exception of the octave) inversions do not also appear in the 
scale: 1/1, 5/4, 4/3, 3/2, 5/3, 2/1. This is used to determine time/pitch 
shifts. For example, selecting 2/1 will give pitch-shifts an octave up 
and down (half and double delay) while 3/2 will give pitch-shifts a 
just fifth up and down (2/3 and 3/2 times the nominal delay, 3200ms 
and 7200ms respectively). There is no feedback internal to the 
algorithm. Any further repeats will be via the room.  
Internal Feedback Loop and Convolution Reverb. A s  s h o w n  i n  
Figure 2, receiving its input from the bus which sums the output of 
all algorithms is an internal feedback loop containing, first, a variable 
delay with a maximum value of 20 seconds, this being selected in 
tribute to Di Scipio’s Background Noise Study [ 2 2 ] .  A  c o n t r o l  i s  
available to set or modulate the delay time. Following the delay is a 
convolution reverb which made use of William Brent’s [convolve~] 
object [38] which can be wet/dry mixed. While the system’s primary 
use is to explore room feedback in the very room in which the system 
is located, the possibility to load Impulse Responses (IRs) from 
different rooms or imagined spaces was conceptually relevant to 
some performances. For example, in one networked performance of 
the trio 3BP, IRs from the locked down home studios of my 
collaborators were loaded into the system’s internal feedback loop. 
Others. Many other algorithms have been experimented with and 
several of the above have gone through different versions. For 
example, a simpler Ring Modulator in the loop was tried but it did 
not produce the variety of the Vink-inspired design. Other algorithms 
are, as-it-were, in the repertoire and could be favoured for particular 
performances. Crusher is an aggressive reduction of the room signal 
to a square wave with a switchable Schmitt-trigger with variable 
thresholds. Switching in the Schmitt-trigger reduces noise and setting 
a large separation between thresholds can turn the room sound into 
bursts of clicks. Anti-Signal puts an inverted and variably delayed 
room sound back into the room. Quaternion Oscillator uses an 
oscillator design of Miller Puckette where the room sound, rather 
than a synthesised impulse, drives the oscillator [34]. Frequency Shift 
uses an implementation of the single side band (SSB) technique. 
Amplitude Modulation amplitude modulates the room sound with a 
sine wave whose frequency can be adjusted over a wide range. 
3.2. Inter- and Intra-Action 
As was remarked earlier, development was done with conventional 
MIDI controllers (with a selection of sliders, knobs, and buttons) in 
mind and a variety have been explored including inexpensive ones 
such as the Korg Nanokontrol (8 channels each with a fader, a 
knob, and 3 buttons) and the Akai MidiMix (8 channels with a 
fader, 3 knobs, and 2 buttons, together with a master channel fader 
and 4 more buttons). These have both been experimented with and 
are small enough to fit in a gig bag. Preference though is given to a 
Faderfox MX12 which offers 12 channels each with a fader, 2 
knobs, and 2 buttons with high quality components and lightweight 
long-throw faders, comfortably spaced, enabling dexterous 
movement, fast if needs be. The constraints of this device, and 
indeed of the ‘MIDI universe’, create design challenges which have 
been interesting to pursue.  
[25], [36] and [49] report on a number of strategies for extracting 
much playability out of simple control surfaces by, for example, 
layering different mappings in few-to-many designs. In contrast, 
here, I have preferred a design strategy where the algorithms are 
typically implemented to pick out one or at most two key controls 
which have a clear performative consequence (together with a fader 
to control the amplitude of the algorithm’s output). However, 
exactly how these key performance controls work is itself 
performable. 
This approach builds upon a philosophical perspective associated 
with Karen Barad [37] and introduced into NIME by Nyström [11]. 
Developing Niels Bohr’s writings on quantum physics, Barad 
argues that objects and their properties, and phenomena and their 
character, emerge in encounters rather than pre-exist them. In her 
terms, objects intra-act rather than inter-act. Developing this, [11] 
presents some experiments where gestures, control devices, 
parameter-mappings, and sound synthesis all mutually configure 
each other. For example, a fast sweep of a fader might be 
interpreted differently from a slow sweep and sound synthesis may 
vary on the basis of the accumulated history of gesture rather than 
predicted on the basis of a single controller position. 
Behaviour Mixer 
For several of the algorithms, one knob is devoted to being a 
‘behaviour mixer’. This affects how the second knob (call it the 
controller) will be mapped to the algorithm. Seven behaviours were 
identified.  
•  Direct: the controller value, given by its position, is passed 
without change. 
•  Gray: the controller is transformed by a Gray code. In a Gray 
code successive values, when expressed in binary, differ only in one 
bit. However, as the significance of that bit varies, the jumps 
between successive values are distributed as a power law with small 
jumps most frequent and larger jumps being progressively rarer. 
This gives an interesting texture to a sweep of the controller knob. 
•  Collins: a random mapping function is computed at launch time 
- with all available output numbers selected without replacement, 
‘urn’-style. This technique is used to map the valve positions in Nic 
Collins’ !trumpet [41]. It provokes the exploration of the mapping 
in performance, the playing of local ‘sequences’, alongside larger 
‘sample and hold’-style gestures. 
•  Triangle: a triangle LFO sweeps through all the values with the 
period of oscillation, P, set by three successive presses of a 
designated button. The controller serves to set the LFO’s phase. 
•  Envelope: the amplitude of the room sound is measured with 
the same period, P. This is normalised in overlapping windows, 
scaled and output. In this way, the amplitude of the room sound can 
affect sound transformation, as amplitude affects phase-delay in 
Collins’ Pea Soup [23]. The controller is ignored. 
•  Smooth: random values are selected and smoothly interpolated, 
ramping with period P. The controller knob value, given by its 
position, is passed instantly when it is moved but new smooth 
random values appear when the controller hasn’t changed in P. 
•  Stepped: random values are selected with period P but without 
interpolation. The controller knob behaves as with smooth. These 
last two methods of obtaining random values echo the classic 
design decisions in Buchla’s Source of Uncertainty synthesizer 
module. 
Sweeping the behaviour mixer knob moves from one behaviour to 
another through a zone where the output of two is mixed. In this 
way, for example, the triangle LFO behaviour can fade to the 
envelope behaviour or smooth random can become stepped. This 
overall design allows a number of behaviours and mappings to be 
selected from and performed. Slow moving modulations in the 
manner of Radigue, amplitude driven delay times in the manner of 
Pea Soup, random sample and holds in the style of early electronic 
music, amongst different mappings of manual gesture are all 
available. 
SPK: The Self-Programming Knob 
The idea of a method of intra-action where how significant 
performance controls work is itself performable is carried to an 
extreme with the SPK, named in partial tribute to the Australian 
industrial noise band. This takes the 7-bit [0,127] value from a knob 
and writes it to a table (of size 128) at a given index. The index is 
then incremented by 1 and wrapped around to lie in the range 
[0,127] if needed, ready for the next value. Accordingly, the table 
fills with 7-bit values, holding the last 128 received. This table is 
construed as the mapping function from which the output value is 
derived. Just before the new input is written to the table, its value is 
taken as the index from which the stored value is to be read. This is 
then output. In this way, the SPK writes its own mapping function.  
A switchable modification to this inserts the output, rather than the 
input value, at the current index in the table. This creates a variety 
of bifurcations and discontinuities in the table, adding to the range 
of behaviours that can emerge from the SPK. Finally, the mapping 
function can be iteratively sampled without taking new knob input. 
The output is used as the index to the table, the value stored there is 
output. This is then used as the next index. And so on. In this way, 
the SPK can be used as a kind of arpeggiator-sequencer, sometimes 
with short repeating patterns, sometimes with long periods, 
seemingly random. This behaviour can be modified further if the 
output is also switched to be stored in the table at the current index. 
This tends to cause the table, and hence the output, to settle to a 
small number of values, often just one constant. In the current 
design, to keep with the SPK p h i l o s o p h y ,  t h e  t i m i n g  f o r  t h e  
metronome that governs the iterations is given by intervals between 
direction changes in the knob. In this way, the knob determines not 
only its own mapping function but also the timing of any process 
which iteratively uses the function. In AllTheNotes, one of the 
knobs is used as an SPK t o  g e n e r a t e  o u t p u t  w h i c h ,  s c a l e d ,  g i v e s  
sample values for a wavetable. Its output combines with the output 
of the other knob to retrieve note values from the performance 
history. These note values play the wavetable oscillator with timing 
data taken from the SPK. In this way, AllTheNotes creates sounds 
which are an intra-active emergent of room analysis, gestural data, 
self-programmed mappings, timings, and sample data.  
Direct Interaction  
Where possible I have tried to implement intra-active concepts in 
how the control knobs and buttons engage with the algorithms. 
However, sometimes the algorithm cannot be happily reduced to 
just one essential control, now matter how ingeniously multiple 
parameters might be derived from this. On these occasions, the 
algorithm’s playability is typically promoted by keeping two 
parameters independent and directly manipulable in a traditional 
inter-active fashion. The Vink-inspired Ring Modulator a n d  t h e  
Granular Delay  b o t h  s e e m  m o r e  p l a y a b l e  w i t h  a  d i r e c t  
manipulation of two significant parameters each. 
4. PERFORMANCE EXPERIENCE 
I have performed with this feedback system on over 20 occasions in 
the last three years. This included live streamed performances 
during COVID-19 lockdown in solo, duo, and trio formats [e.g. 50, 
51] and a number of performances at international arts festivals  
both solo and in small ensembles (e.g. with 3BP at NIME 2021 and   
the IF 2021 improvisation festival, Guelph, Canada, and at Piksel 
2022, Bergen, Norway in the trio HPB with Kerry Hagan and 
Miller Puckette). In the early stages of development, I added the 
system to a performance setup which included many other elements 
(e.g. modular synthesizer, field recordings, effects units, a zither). 
Over the last year, however, I have done a series of performances 
where the system is effectively my only musical resource - one as 
part of a curated feedback music concert [52] a live recording of 
which has subsequently been released [53]. The system has also 
been used in studio recording contexts. Most recent to the time of 
writing, I performed a 4 hour long durational improvisation to mark 
the 2023 Northern Hemisphere Vernal Equinox using exclusively 
room feedback sounds [54].  The reader may wish to check 
citations [50-54] to gain an impression of how the system has been 
  Figure 3. John Bowers and Owen Green performing The Brazen Head at Sonorities 2022, Belfast, UK.  
A DIY binaural head picks up the room sound. Photo courtesy of Sonorities Festival.
  Figure 4. John Bowers performing Khôra For Slapstick And Room Feedback at the Feedback Musicianship Network 
Concert, The Meeting House, University of Sussex, Brighton, UK, 2022. A slapstick interacts with room feedback.   
A Røde NT4 stereo condenser microphone is on the boom stand above the shot. 
Photo by Dimitris Kyriakoudis.
used and as a background to the discussion I now give. 
The system is easy to set up. The inclusion of saturation and 
limiting components make gain structure a less critical issue than 
with many feedback systems. It is easy to adjust to the difference an 
audience makes when I have sound checked to an empty room. It 
behaves differently in different environments, and with different 
microphones and different placements (including in a DIY binaural 
head in The Brazen Head, a performance with Owen Green at the 
Sonorities 2022 Festival, Belfast, see Figure 3), but the algorithms 
are rarely mute, do not explode, and it is uncommon that interesting 
effects are unobtainable. 
I tend to select a different set of algorithms per performance. I 
prepare them so that their left-to-right organisation on the Faderfox 
M12, for example, suggests ‘trajectories’ and supports ‘adjacencies’ 
that might be explored. In Khôra For Slapstick And Room 
Feedback [52, 53], the feedback was first processed with the 
algorithms I had placed to the left of the device (e.g. Short 
Feedback Delay), spreading to the right as the performance 
unfolded to halfway, but then with much to-ing and fro-in when 
interesting interactions had been discovered. In this way, the system 
is primed to help find interesting ‘modulations’ with the layout of 
the controller itself helping shape performance. However, my 
performances are strongly improvised, both by preference and in 
recognition that the emergent effects of feedback cannot be 
properly explored otherwise. I typically search out ‘sensitive zones’ 
where one feedback mode or behaviour slips into another in critical 
regions of some control or where the feedback flickers 
autonomously. I also search out combinations of algorithms which 
entangle with each other in interesting ways. The loss of human 
control that many feedback musicians celebrate [12] can be actively 
sought - a paradox I will return to at the end of this paper. 
The algorithms have great spectro-morphological [42] variability 
between them, in part by design, but also through their 
responsiveness to room conditions and behaviour mixing. This 
makes it possible to organise performances by spectro-
morphological contrast and similarity, to find layers and transitions, 
to vary intensities. I feel that the system is capable of supporting 
performances of an unusually dynamic character for work 
exploring feedback. This also helps responsivity to others in group 
improvisation formats. While I can generate drones and textures 
which form a ‘base’ or a ‘canopy’ to other musicians, it is also 
possible to swiftly react. For example, in the trio 3BP I commonly 
‘duel’ the Short Feedback Delay  a l g o r i t h m  w i t h  A d a m  P u l t z  
Melbye’s double bass played arco. 
For me, perhaps the most satisfying feature of the system is its 
flexibility in terms of the contexts and ensembles it can fit in with, 
whether these work with a sparse responsive improvisation ethic or 
a full on noise assault, are acoustic or electronic in character, prefer 
scruffy pub-gigs or concerts in cathedrals, while also providing 
ample resources for solo work. This open character is discussed 
further below. 
5. CONTRIBUTION AND FUTURE WORK 
In this paper, I have presented a room feedback system which has 
been developed out of a process which combines artistic research, 
technical development, and performance practice. In terms of 
research in NIME, I think this work makes a number of 
contributions. 
•  It describes a system where many algorithms are made 
available simultaneously and can be mixed in performance and 
explored in how they entangle via the room. Di Scipio’s systems 
often explore several feedback routes and processes [43]. For 
example, in Background Noise Study [22, Figure 4], there are four 
(delay, filter, resample, granularise). The current work develops that 
interest to offer a multitude of paths (here as many as 12). 
•  The work extends the spectro-morphological variation that is 
typical in a feedback system by offering multiple algorithms and 
varied behaviours and mixes of them to map (or disrupt or ignore) 
performer gesture. 
•  Some of the algorithms are novel in their application in 
feedback scenarios (for example, tuning waveguides through an 
application of dynamic tonality). The paper also describes some 
further experiments in ‘intra-action’ where how aspects of the 
system respond emerges in performance [11]. 
•  The system incorporates tributes to several historically 
important feedback works. This gives the system a kind of 
pedagogical potential, as well as building a sense of historical 
development into the artefact in a literal sense. This, together with 
the long-term performance practice associated with it, engages with 
Marquez-Borbon and Martinez-Avila’s [44] call for an alternative 
performance pedagogy in NIME that is concerned with longevity as 
much as innovation, see also [55]. 
•  The work has been carried out within a tradition of artistic 
research that emphasises the proliferation of design alternatives 
which are then assembled performatively [26, 25, 24, 55]. These 
projects typically involve collective exploration. The current system 
is an example of how this approach can be applied to creating an 
‘assemblage’ system within the practice of an individual artist-
researcher. 
•  The system has an open character and can accommodate other 
performers and their sound-makers. It can help ‘fold in’ the 
contributions of multiple performers into a shared acoustic 
environment, giving a kind of augmentation to what a room does 
anyway. As such it helps create ‘performance ecologies’ [45, 46] 
where different musical resources are gathered and interplay. 
In future work, I anticipate adding more algorithms to the system’s 
repertoire and exploring more complex routings between them. 
Currently, the algorithms get to feed each other via the room. While 
this has a certain coherence and elegance to it, there is much scope 
for creating networks of algorithms [35] and, perhaps, making their 
topology ‘intra-actively’ configurable in performance.  I have also 
begun explorations feeding back the room sound to modulate 
synthesis rather than, as in most of the algorithms discussed here, 
for the room sound to be processed. This works well in 
combination with the approach described here [54]. Most of my 
work to date has used quite simple set-ups with a pair of 
microphones and a pair of loudspeakers. Clearly there is much 
scope for the exploration of multi-speaker, multi-microphone arrays 
in more carefully considered physical architectures [cf. 39]. I have 
done some preliminary experiments with hand-held microphones 
and mobile loudspeakers, together with sensors or tracking 
technologies to capture movement data. Clearly, this offers a 
different kind of ‘instrumentality’ from a MIDI control box and 
suggests a different performance aesthetic, perhaps one more staged 
and focussed on the performer than the more modest presence that 
the wok currently manifests. 
6. CONCLUSION:  
A FEEDBACK AESTHETICS 
Magnusson and colleagues [12] write: “Rather than being a style or 
a genre, feedback is a technique”. However, it is a technique that 
lends itself to certain kinds of musics and is in play with a bundle of 
related values and commitments, in what I would call, in short, a 
kind of aesthetic. Indeed, on the basis of a number of interviews 
with practitioners, [12] document some of these values and 
commitments under the headings of: 
•  agency -  e . g .  h o w  f e e d b a c k  c r e a t e s  c i r c u m s t a n c e s  w h e r e  
performers can lose control and devices can exhibit autonomy 
•  complexity - how multiple factors can impinge on the feedback 
instrument or system and affect its behaviour 
•  coupling -  h o w  f e e d b a c k  c o u p l e s  p e r f o r m e r  a n d  s y s t e m  i n  
mutually transformative ways 
•  design - e.g. the exploration of design strategies to promote the 
emergence of autonomous systems 
•  play -  t h e  d i f f e r e n t  f o r m s  o f  i n t e r a c t i v i t y  t h a t  p e r f o r m e r s  c a n  
explore with feedback 
•  post-humanism -  h o w  s o m e  p r a c t i t i o n e r s  l i n k e d  f e e d b a c k  
music to forms of thought in which human/non-human 
relationships are rearticulated. 
For many respondents, their position on these themes was 
developed in opposition to ideas of traditional musical and 
instrumental practice. While it should be clear that the new work I 
have presented can speak to all of these themes, I want to develop 
an aesthetic which does not set feedback music in opposition to 
other forms nor sees it emerging as a new genre [1]. Rather my 
experience in developing and performing the room feedback 
system is that it creates an exploratory arena in which different 
framings of agency, complexity, and the rest can be put in contact 
with each other. I t  i s  n o t  s o  m u c h  t h a t  f e e d b a c k  m u s i c  e x p r e s s e s ,  
represents or materialises prior commitments but that room is 
(literally) given for their formation and juxtaposition in the duration 
of the performance. 
Sometimes I just let the system be. Sometimes I search out for 
interesting phenomena. Sometimes I engage in vigorous fader-
flipping, knob-yanking and button-pressing, which has a direct 
effect and sometimes a bizarrely mapped one. Sometimes the 
system can approximately return to a prior state, sometimes it has 
reprogrammed itself to make that effectively unfindable. My 
situation in this as a performer is profoundly variable. Sometimes it 
seems as if my (fader, knob, button) gestures are transduced and 
exert control over algorithms. Sometimes it seems that I am 
implicated in a kind of correspondence as multiple streams of sound 
and action become entangled. (On this contrast between 
transduction and correspondence, see Ingold [40]). To use Karen 
Barad’s phrase, there are many and varied ‘agential cuts’. And all 
this can change on a moment by moment basis, worked up 
improvised from within the performance, that is, immanently. 
In his writings on the history of cybernetics, Pickering [47] argues 
that its various projects stand as ‘ontological theatre’ - that is, as 
means to help us reimagine what the world consists of. When 
writers in cybernetics tamed their fascination with complexity and 
saw ways to simplify and manage the world, ‘control’ sometimes 
worryingly approximated ‘domination’ [48]. In contrast, for 
Pickering, it is a ’cybernetics of uncontrol’ that keeps an ‘ontology 
of unknowability’, without a desire for domination, alive. 
I intend these room feedback experiments as a kind of ontological 
theatre, a musical one, where what music, action, and space consist 
in can be reimagined. I do not wish to tame their complexity and so 
I see ‘control’ as one instance in a sea of multiple possibilities. 
Accordingly, the system I have described I treat, not as an 
instrument, but as a playable design space w h e r e  d e s i g n s  c a n  b e  
introduced and juxtaposed with each other and with other goings-on 
in the room.  
And all this to create a hapless but nevertheless entertaining roar. 
7. ACKNOWLEDGMENTS 
I wish to thank Queen’s University, Belfast, UK for a visiting 
position at SARC during which I have deepened my musical 
engagement with feedback.  
My friends, colleagues and bandmates in 3BP, Paul Stapleton and 
Adam Pultz Melbye, have been especially supportive in the 
development of this work theoretically, technically, and artistically.  
I am also grateful to The Feedback Musicianship Network which 
was funded by the UK Arts and Humanities Research Council, and 
organised by Chris Kiefer (Experimental Music Technologies Lab, 
University of Sussex, UK) and Dan Overholt (Augmented 
Performance Lab, Aalborg University Copenhagen, Denmark) to 
whom I presented an early version of this work. 
8. ETHICAL STANDARDS 
The work reported here was self-funded by the author. It did not 
involve the participation of any human subjects. I have no conflicts 
of interest to report. 
9. REFERENCES 
1.      Brassier, Ray. (2007). Genre is Obsolete. Multitudes, No. 28, 
Spring 2007. 
2.      Greenwald, Ted (1986). Keyboard Magazine February 1986: 
54-65. Available at: https://www.effectrode.com/knowledge-
base/the-self-destructing-modules-behind-revolutionary-1956-
soundtrack-of-forbidden-planet/ [visited 11.01.2023] 
3.      Nakai, You. (2021). Reminded by the Instruments: David 
Tudor’s Music. New York, NY: Oxford University Press. 
4.      Nakai, You. (2022). "Late Realizations." ECHO, a journal of 
music, thought and technology 3. doi: 10.47041/WXPP3029 
5.      Bowers, John and Annika Haas. (2014). Hybrid Resonant 
Assemblages: Rethinking Instruments, Touch and Performance 
in New Interfaces for Musical Expression. Proceedings of the 
International Conference on New Interfaces for Musical 
Expression, Goldsmiths, University of London, pp. 7–12. http://
doi.org/10.5281/zenodo.1178718 
6.      Úlfarsson, Halldór. (2018). The halldorophone: The ongoing 
innovation of a cello-like drone instrument. Proceedings of the 
International Conference on New Interfaces for Musical 
Expression, Virginia Tech, pp. 269–274. http://doi.org/10.5281/
zenodo.1302579 
7.      Slager, W. J. (2021). Designing and performing with Pandora’s 
Box: transforming feedback physically and with algorithms. 
NIME 2021. https://doi.org/10.21428/92fbeb44.61b13baf 
8.      Sanfilippo, D., & Valle, A. (2013). Feedback Systems: An 
Analytical Framework. Computer Music Journal, 37(2), 12–27. 
http://www.jstor.org/stable/24265464 
9.      Stapleton, Paul. uncertain rhythms. Music Proceedings of the 
International Conference on New Interfaces for Musical 
Expression NIME’19, June 3-6, 2019, Porto Alegre, Brazil. 
10.    Bela. https://bela.io/ [visited 11.02.2023] 
11.    Nyström, Erik. (2020). Intra-Actions: Experiments with 
Velocity and Position in Continuous Controllers. Proceedings of 
the International Conference on New Interfaces for Musical 
Expression, Birmingham City University, pp. 367–368. http://
doi.org/10.5281/zenodo.4813420 
12.    Magnusson, T., Kiefer, C., & Ulfarsson, H. (2022). Reflexions 
upon Feedback. NIME 2022. https://doi.org/
10.21428/92fbeb44.aa7de712 
13.    Melbye, Adam Pultz and Halldor A Ulfarsson. (2020). 
Sculpting the behaviour of the Feedback-Actuated Augmented 
Bass: Design strategies for subtle manipulations of string 
feedback using simple adaptive algorithms. Proceedings of the 
International Conference on New Interfaces for Musical 
Expression, Birmingham City University, pp. 221–226. http://
doi.org/10.5281/zenodo.4813328 
14.    Melbye, A. P. (2021). Resistance, Mastery, Agency: 
Improvising with the feedback-actuated augmented 
bass. Organised Sound, 26(1), 19–30. 
15.    Eldridge, A., & Kiefer, C. (2017). Self-resonating feedback 
cello: interfacing gestural and generative processes in 
improvised performance. NIME, 25–29. 
16.    Eldridge, Alice, Chris Kiefer, Dan Overholt, and Halldor 
Ulfarsson. (2021). Self-resonating Vibrotactile Feedback 
Instruments: Making, Playing, Conceptualising. Proceedings of 
the International Conference on New Interfaces for Musical 
Expression. http://doi.org/10.21428/92fbeb44.1f29a09e 
17.    Bachelard, Gaston. (1964). The Poetics of Space. Orion Books. 
18.    Julian of Norwich. (c. 1373/1998). Spearing, Anthony Colin 
and Spearing, Elizabeth (eds.). Revelations of Divine Love. 
London, New York: Penguin Books. 
19.    Jean Genet. (1949/1963). Our Lady of the Flowers. Bantam, 
Mass Paperback Edition. 
20.    Di Scipio, Agostino. (2022). A Relational Ontology of 
Feedback. in ECHO, a journal of music, thought and 
technology 3. doi: 10.47041/TKUL7223 
21.    Di Scipio, A. (2003). ‘Sound is the interface’: From interactive 
to ecosystemic signal processing. Organised Sound, 8(3), 269–
277. https://doi.org/10.1017/S13557718030 00244  
22.    Di Scipio, Agostino. (2011). Listening to Yourself through the 
Otherself: On Background Noise Study and other works. 
Organised Sound. 16. 97 - 108. 10.1017/S1355771811000033.  
23.    Collins, N. (2011/2020). The History of Pea Soup. Web 
publication, 2011, updated 2020. https://
www.nicolascollins.com/texts/peasouphistory.pdf [visited 
11.02.2023] 
24.    Bowers, J., T. Shaw, S. Bowen (2016). Many Makings: 
Entangling Publics, Participation and Things in a Complex 
Collaborative Context. In Proceedings of Designing Interactive 
Systems (DIS 2016), Brisbane, June 2016. New York: ACM. 
Pages 1246-1257. 
25.    Bowers, John, & Green, Owen. (2018). All the Noises: 
Hijacking Listening Machines for Performative Research. 
Proceedings of the International Conference on New Interfaces 
for Musical Expression, 114–119. https://doi.org/10.5281/
zenodo.1302699 
26.    Bowers, John, Richards, John, Shaw, Tim, Frieze, Jim, Freeth, 
Ben, Topley, Sam, Spowage, Neal, Jones, Steve, Patel, Amit, & 
Rui, Li. (2016). One Knob To Rule Them All: Reductionist 
Interfaces for Expansionist Research. Proceedings of the 
International Conference on New Interfaces for Musical 
Expression, 433–438. https://doi.org/10.5281/zenodo.1175996 
27.    Reiss, Joshua D.  and Andrew McPherson. (2014). Audio 
Effects: Theory, Implementation and Application Hardcover. 
CRC Press. 
28.   Vetter, Katja. (2010). vcompander~ https://www.katjaas.nl/
compander/compander.html [visited 11.02.2023] 
29.   Sonology, Mr. Ring-Modulated Feedback in BEA5. https://
www.youtube.com/watch?
v=X_Bcr_HS9XM&ab_channel=MrSonology [visited 
11.02.2023] 
30.    Schroeder, M. R.. (1962). Natural-sounding artificial 
reverberation,'' Journal of the Audio Engineering Society, vol. 
10, no. 3, pp. 219-223, 1962. 
31.    Kreidler, Johannes. (2013). loadbang: Programming Electronic 
Music in Pure Data. 2nd edition. Wolke Verlag. 
32.    Sethares, William A.; Milne, Andrew J.; Tiedje, Stefan; Prechtl, 
Anthony and Plamondon, James (2009). Spectral tools for 
Dynamic Tonality and audio morphing. Computer Music 
Journal, 33(2) pp. 71–84. DOI: https://doi.org/10.1162/
comj.2009.33.2.71 
33.    Kaiser, Henry. (2014). https://www.youtube.com/watch?
v=gbJFlX_L6To&ab_channel=GuitarPlayerMagazine [visited 
11.02.2023] 
34.    Bowers, J. and K. Hagan (2019). Improvisation at the Edge of 
Chaos: A Worked-Through Design and Performance Practice 
for Electronic Improvisation. In Proceedings of the 
International Computer Music Conference, ICMC 2019, New 
York, USA. 
35.    Thomasi, Ricardo. (2022). Patterns of emergence and feedback 
topology in Ecos Study: glimpses of a performance ecosystem 
model. in ECHO, a journal of music, thought and technology 3. 
doi: 10.47041/ADJW7276 
36.   Mudd, Tom, Simon Holland, and Paul Mulholland. (2019). 
Nonlinear dynamical processes in musical interactions: 
Investigating the role of nonlinear dynamics in supporting 
surprise and exploration in interactions with digital musical 
instruments. International Journal of Human-Computer Studies, 
128, pages 27-40. 
37.   Barad, Karen. (2007). Meeting the Universe Halfway, London: 
Duke University Press.  
38.   Brent, William. https://github.com/wbrent/convolve_tilde 
[visited 11.02.2023] 
39.   Eckel, Gerhard. https://users.iem.at/eckel/art/Stele/Stele.html 
[visited 10.01.2023] 
40.   Ingold, T. (2020). Correspondences. Wiley. 
41.   Collins, N. https://www.nicolascollins.com/texts/Collins_!
trumpet.pdf [visited 11.02.2023] 
42.    Smalley, D. (1986). Spectro-morphology and Structuring 
Processes. In: Emmerson, S. (eds) The Language of 
Electroacoustic Music. Palgrave Macmillan, London. https://
doi.org/10.1007/978-1-349-18492-7_5 
43.   Di Scipio, Agostino. 2022. "A Relational Ontology of 
Feedback." ECHO, a journal of music, thought and technology 
3. doi: 10.47041/TKUL7223 
44.   Marquez-Borbon, A. and J. P. Martinez-Avila. 2018. The 
Problem of DMI Adoption and Longevity: Envisioning a 
NIME Performance Pedagogy. In Proc NIME 2018. 
45.   Bowers, J. (2003). Improvising Machines: Ethnographically 
Informed Design for Improvised Electro-Acoustic Music. In 
ARiADATexts 4 www.ariada.uea.ac.uk/ariadatexts/ariada4/ 
ariada4_text.html now available at http://citeseerx.ist.psu. edu/
viewdoc/download?doi = 10.1.1.219.1699&rep = rep1& type = 
pdf.  
46.   Waters, S. (2007, June 12–15). Performance ecosystems: 
Ecolog- ical approaches to musical interaction. Proceedings of 
EMS: Electroacoustic Music Studies Network ‘07. http://
www.ems- network.org/spip.php?article278  
47.   Pickering, Andrew. (2010). The Cybernetic Brain: Sketches of 
Another Future. London and Chicago: The University of 
Chicago Press. 
48.    Curtis, Adam. (2011). All Watched Over by Machines of 
Loving Grace. BBC Two. Original broadcasts 23 May – 6 June 
2011. 
49.   John Bowers and Sten-Olof Hellström. (2000). Simple 
interfaces to complex sound in improvised music. In CHI '00 
Extended Abstracts on Human Factors in Computing Systems 
(CHI EA '00). Association for Computing Machinery, New 
York, NY, USA, 125–126. https://doi.org/
10.1145/633292.633364 
50.    http://www.paulstapleton.net/portfolio/with-john-bowers 
[visited 06.04.2023] 
51.    http://www.paulstapleton.net/portfolio/3bp  [visited 
06.04.2023] 
52.    Feedback Musicianship Network Concert, The Meeting House, 
University of Sussex, Brighton, UK, 6-9pm, 12th May, 2022 
https://feedback-musicianship.pubpub.org/pub/
fmnmeetinghouse/release/6 [visited 06.04.2023] 
53.    Live at the Meeting House. https://www.emutelab.org/label/
fmn_liveathemeetinghouse [visited 06.04.2023] 
54.    Equinox Roar by John Bowers. https://www.youtube.com/
watch?v=e2_N4B1F-1k&t=12318s&ab_channel=JohnBowers 
[visited 06.04.2023] 
55.   Bowers, John, John Richards, Tim Shaw, Robin Foster, and 
Akihiro Kubota. (2023). Raw Data, Rough Mix: Towards an 
Integrated Practice of Making, Performance and Pedagogy. To 
appear in Proceedings of the International Conference on New 
Interfaces for Musical Expression 2023. 