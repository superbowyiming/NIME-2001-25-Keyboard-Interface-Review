A Comparative User Study of Two Methods of Control on a
Multi-Touch Surface for Musical Expression
Blake Johnston
New Zealand School of Music
Victoria University of
Wellington, New Zealand
blake.r.jo@gmail.com
Owen Vallis
New Zealand School of Music
Victoria University of
Wellington, New Zealand
ovallis@calarts.edu
Ajay Kapur
California Institute of the Arts
24700 McBean Pkwy
Valencia, CA 91355
akapur@calarts.edu
ABSTRACT
Mapping between musical interfaces, and sound engines, is
integral to the nature of an interface [3]. Traditionally, mu-
sical applications for touch surfaces have directly mapped
touch coordinates to control parameters. However, recent
work [9] is looking at new methods of control that use rela-
tional multi-point analysis. Instead of directly using touch
coordinates, which are related to a global screen space, an
initial touch is used as an ‘anchor’ to create a local coor-
dinate space in which subsequent touches can be located
and compared. This local coordinate space frees touches
from being locked to one single relationship, and allows for
more complex interaction between touch events. So far, this
method has only been implemented on Apple computer’s
small capacitive touch pads. Additionally, there has yet to
be a user study that directly compares [9] against mappings
of touch events within global coordinate spaces. With this
in mind, we have developed and evaluated two interfaces
with the aim of determining and quantifying some of these
diﬀerences within the context of our custom large mutli-
touch surfaces [1].
Keywords
Multi-Touch, User Study, Relational-point interface
1. INTRODUCTION
The use of mutli-touch surfaces for musical applications has
a well-developed history, with work such as Toshi Iwia’s
“Composition on the Table” [4], and applications like the
AudioPad [8], the reacTable [6, 5], and multiple applica-
tions on the Bricktable [1, 2]. Many of these instruments
use fuducials, or objects that provide X-Y location, point
acceleration, unique IDs, rotation, and rotational accelera-
tion. While these objects provide more data than is avail-
able from a single touch event, and allow for more complex
mapping schemes, it is possible to gain similar additional
data from touch events by leveraging the relationships be-
tween an initial point and subsequent points [9]. The aim
of this research is to determine if this type of relational con-
trol can aﬀord musicians’ greater creativity with respect to
multi-touch interfaces.
This paper describes two software interfaces developed
during the course of this research, and reports on the user
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’12,May 21 – 23, 2012, University of Michigan, Ann Arbor.
Copyright remains with the author(s).
study used to evaluate the interfaces. Following this, the
experiments are described, including the process, partici-
pants, and results. These results are then discussed in a
broader context, and will show that although the increased
complexity of the relational interface was more challenging
to learn, it allowed participants to be more creative while
at the same time promoting greater exploration of the sonic
space.
2. XY AND ANCHOR POINT
The applications and user study were run using the Brick-
table, a 50”rear diﬀuse illuminated (DI) custom-built multi-
touch table. The ﬁrst of the two interfaces is designed to
allow for polyphonic control of a basic sine oscillator syn-
thesizer using a global coordinate system. This interface
provides similar control to existing single point X-Y sur-
faces, for which a touch event provides values for its X and
Y position. The second interface is designed to control the
same single oscillator synthesizer, however, control values
are derived from the relationship between an anchor point
(initial point), and the location of satellite points (subse-
quent points). This second interface creates a local coor-
dinate space and provides an increased number of control
data sources that can be used for expressive mappings to
parameters. Furthermore, these control data streams are
interdependent of one another, allowing for all parameters
to be modiﬁed simultaneously in an organic manner.
2.1 Mapping
2.1.1 Mapping using global XY position
This ﬁrst interface allows the user to control two parame-
ters using the position of their ﬁngers. Each ﬁnger placed
on the table creates a note with the global X position con-
trolling the pitch of the oscillator, and the global Y position
controlling the volume of the oscillator. As the X position
increases from left to right the pitch ascends, and as the Y
position increases from top to bottom, the volume increases.
The interface visually conveys this relationship by display-
ing a circle at the location of the touch event, and drawing
rectangle between the top left corner of the screen (0,0 in
the global coordinate space) and the location of the touch
event (See ﬁgure 1)
2.1.2 Mapping using a local Anchor Point
The second interface also allows for the control of two pa-
rameters, however, this time local relationships between an
anchor point and subsequent satellite points are used as
control sources. The angle and distance between a satel-
lite point and the anchor point control a note, with angles
mapping to pitch, and distances mapping to volume. With
respect to the anchor point, the pitch has a range of four
octaves, with the lowest note directly underneath the an-
chor point, and the starting octave being determined by
Figure 1: XY, and anchor point interfaces
the location of the anchor. The pitch ascends as the satel-
lite point is rotated clockwise around the anchor point, and
eighty percent of the volume range is controllable within the
average span of a person’s hand.
This local relationship between the anchor point and satel-
lite points can provide new control data streams. For exam-
ple, the average angle and average distance of all satellite
points to the anchor point, as well as the maximum angle
and maximum distance of all satellite points to the anchor
point. These additional control sources were not used dur-
ing the user study in order to minimize the variables when
comparing the two interfaces.
The interface visually represents this relationship by dis-
playing a circle where a ﬁnger is placed. These circles dif-
ferentiate the anchor/satellite relationship through colour,
green representing a satellite point and red representing
the anchor point. A circular diagram surrounds the anchor
point to show the pitch increments in angle.
2.2 Software
The interfaces use the Java based language Processing, with
TUIO [7], and OSC [10] providing the communication be-
tween various applications. TUIO communicates with the
open source multi-touch tracker CCV, and OSC sends syn-
thesis control data to Reaktor.
Figure 2: Data communication
3. EV ALUATION
The study had participants freely exploring each interface
for up to two minutes, and then completing four simple
tasks designed to test speciﬁc aspects of each interface. Af-
ter completing these tasks, participants were asked about
their experiences with the two interfaces.
3.1 Participants
The user study consisted of twelve participants compris-
ing a mix of students and lecturers from both music and
computer science backgrounds. Eleven of the twelve par-
ticipants played some form of musical instrument. Addi-
tionally, while nearly all participants had had at least some
prior experience with multi-touch interfaces, only ﬁve par-
ticipants had used them to make music. All participants
were unpaid volunteers.
3.2 Method
3.2.1 Pre-Survey Questionnaire
The pre-interview questionnaire conﬁrmed the participants
consent to the experiment, as well as personal questions
about their age, level of understanding, prior experience
working with touch-table surfaces, and familiarity with mu-
sical concepts and instruments. These questions were de-
signed to provide information about the participant’s po-
tential understanding of the interfaces.
3.2.2 Interaction with Interfaces
Firstly, each participant was asked to freely explore the in-
terface without any speciﬁc task. After approximately two
minutes, the interface interaction was explained to the par-
ticipant with the experimenter demonstrating each param-
eter. The participant would then be asked to complete four
tasks. The ﬁrst task was to make a chord on the table. The
second task was to create a chord on the table using both
hands, and then remove both hands and attempt to make
the same chord again. The third task was to hold a chord in
the left hand while playing a melody in the right hand. The
ﬁnal task was to have a free improvisation on the table. The
participant then discussed the two interfaces and completed
the questionnaire. Additionally, the order of the interfaces
was alternated between each participant in an eﬀort to try
and eliminate any bias this may have added to the results.
3.2.3 Post-Interview Questionnaire
The post-interview questionnaire asked the participant to
critically compare the two interfaces. These questions ex-
amined eleven diﬀerent aspects of the interfaces such as in-
tuitiveness, learnability, control, mapping, creativity, visual
reference, repeatability, exploration, applications and fun.
Each participant was asked to rate the two interfaces on
these aspects using a scale of 1 to 10, 1 being barely/not
very and 10 being a lot/very. They were then asked to
discuss any diﬀerences between the two interfaces and the
reasons for their answers.
3.3 Results
Figure 3: Overview of results
3.3.1 Intuitiveness
Participants were asked how natural and organic each in-
terface felt, and to describe any diﬀerences they discerned
between the two? Most participants found both interfaces
to be quite intuitive, with the average response of 7.6 for
the XY interface and 6.4 for the Anchor Point interface. Of
the two, the XY interface was described as more familiar
and transparent, with participants attributing this to sim-
plicity of control and an easy learning curve. The Anchor
Point interface was found to be slightly less intuitive as it
took some time for most people to learn how to control the
parameters. The relationship between an angle and a pitch
was something that most participants hadn’t encountered
before. The requirement of placing an anchor point before
sound could be made also required understanding of an ex-
tra parameter.
3.3.2 Learnability
Participants were asked how challenging each interface was
to learn, and to describe the main diﬀerence between the
two? The average rating for XY was 8.2, while the Anchor
Point interfaces averaged 7.0. Most people found the con-
trols of the XY interface were very simple to learn whereas,
the Anchor Point interface proved to be more complex, re-
quiring an understanding of the relationships between satel-
lite points and a relative anchor point. Even though the
Anchor Point interface had a signiﬁcantly lower average,
this rating was still high and both interfaces proved to be
relatively easy to learn.
3.3.3 Control
Participants were asked to rate the ease of control for each
interface, and to describe the main diﬀerence between the
two. The ease or diﬃculty of controlling the sound on each
interface highlights pronounced diﬀerences between the two.
The participants’ scores were quite even with the average for
the XY interface scoring 7.6 and the Anchor Point Interface
scoring 6.9; however, the reason why the interface was easy
to control was diﬀerent for each. The XY interface was
easy to control because it had simple parameters that were
familiar and intuitive. However, most people found it hard
to control the pitch precisely, with the degree for error being
very high and each pitch only occupying a small, ﬁxed space
along the X-axis. In contrast the Anchor Point interface was
found to be harder to control for some people as the physical
action of rotating the hand “was useful but not easy to do.”
However, as people explored the interface more, they used
the full range of the space, which allowed them to have much
more control of the angle. As they moved the satellite points
further away from the anchor, they were able to control the
pitch a lot more precisely. This is because the distance
between note increments becomes larger as a satellite point
moves further away from an anchor point.
3.3.4 Mapping
The participants were asked if it felt as though the controls
from each interface were mapped to the sounds being pro-
duced, and which mapping they preferred? Both interfaces
scored similarly, with the preferred interface split equally
and the XY and Anchor Point interfaces scoring 7.5 and 7.6
respectively. Most participants who preferred the XY inter-
face’s mapping liked it because of its simplicity. “It was a
lot easier to know harmonically what it was going to do.”
Whereas, participants who preferred Anchor Point’s map-
ping cited its freedom to move the anchor point, as well as
it being interesting “because you could improvise and come
up with things you didnˆ a˘A´Zt expect.” This parameter came
down to personal choice and a clearer division might have
been seen if the participants were given more time, as the
ease of learning would not have impacted as much on the
results.
3.3.5 Creativity
The participants were asked how much creative expression
each interface allowed for, and to describe any diﬀerence
between them? The XY interface had an average of 6.4 and
the Anchor Point interface had a slightly higher average of
6.8. The reasons why participants found each interface to
be creative were quite diﬀerent. Participants found the XY
interface to be easier to control, and because of this they
could be immediately creative with the sounds they were
making. In contrast, the Anchor Interface was found to
be creative because it “oﬀered a bigger range of things”. It
provided more freedom as the relational point was moveable
and gave unexpected results. This freedom was felt to be
essential for some people to be creative with one participant
saying “I ﬁnd that when your improvising its when some-
thing unexpected happens and you have to react is when
your most creative.”
3.3.6 Visual Reference
The participants were asked how eﬀectively the visuals from
each interface represented the relationship between interac-
tion and sound, and if one interface provided a stronger
visual references? The XY interface had an average of 6
and scored signiﬁcantly below the Anchor Point interface,
which had an average of 7.1. Most participants found the
visual reference for the XY interface to be either confusing
or unnecessary. The visual reference did not hinder their
understanding of the interface but was deemed unnecessary
due to the simplicity of the interaction. However, the visual
reference for the Anchor Point interface was felt to help rein-
force understanding of the interaction between touch events
and sound.
3.3.7 Repeatability
The participants were asked how easy it was to reproduce a
sound on each interface? Both interfaces scored quite low,
with the XY interface having an average of 5.6 and the An-
chor Point interface having an average of 5.5. Many people
found that the placement of the anchor point made repeat-
ing a sound harder than the individual points of interface
XY; however, some people did ﬁnd the Anchor Point easier
to repeat a sound due to the larger touchable area occupied
by each pitch.
3.3.8 Exploration
The participants were asked how compelling each interface
was, and if one interface prompted greater exploration?
Both interfaces scored quite highly with the XY interface
having an average of 7.3 and the Anchor Point interface hav-
ing an average of 7.8. The simplicity of the XY interface
seemed to make people lose interest quick; “Once I learnt it,
it was fun to try and make some sounds, but because its lim-
itations are so easily apparent it becomes a bit bland.” On
the other hand, the Anchor Point interface proved harder
to control for most people, which made them want to ex-
plore and experiment with the interface more. Additionally,
the method of control for most people was something with
which they were unfamiliar, leading them to ﬁnd that the
anchor interface was “more interesting as you [could] create
shapes and see how they relate.”
3.3.9 Application
The participants were asked what sort of settings each inter-
face might be used in. Many participants thought that both
interfaces could be used in installation settings, or be quite
eﬀective as a teaching tool for both simple synthesis as well
as melodic and chordal theory. Some participants also felt
that both interfaces, especially the Anchor Point interface,
could be used in live performance and studio work.
3.3.10 Fun
Lastly, the participants were asked which interface they
found to be more fun, and why? The participants were
divided regarding this question, and the reasons given were
mostly ease of use and expressivity. Many people found the
XY interface to be easier to use, and therefore spent more
time exploring the controls. In contrast, while the Anchor
Point was harder to learn, it aﬀorded greater expression
once the methods of interaction were understood.
4. DISCUSSION AND CONCLUSIONS
Before discussing these results further, it is necessary to
consider the validity of these results in the context of the
study that was performed. A shortcoming of this user sur-
vey is that there’s a novelty factor that may inﬂuence the
responses of the participants. In an attempt to minimize
this, the interface that was to be used ﬁrst by a participant
was alternated throughout the survey. Another limitation
of this survey may be the length of interaction with each
interface. The Anchor Point interface requires some time
to understand how it works, while the XY interface was un-
derstood almost immediately. This may adversely aﬀect the
user’s interaction experience if they only allowed a short pe-
riod of time to work with each interface. However, even with
these limitations, the two interfaces have proven to be very
similar. Both interfaces scored highly across all categories,
and general conclusions can be made from the statistical
results as well as the comments of the participants.
The XY interface has proven to be more intuitive and
easier to learn. Most participants said that this was due to
the simplicity of the parameters and their familiarity with
an X-Y relationship. The Anchor Point interface is slightly
harder to learn and slightly less intuitive. Most participants
thought that the more complex relationship of rotation and
relative position of the anchor point made the Anchor Point
interface harder to learn and they were also less familiar
with these relationships than the simplistic XY relation-
ship. Both interfaces rated highly on ease of control, how-
ever, this question shows an important diﬀerence between
the two interfaces. The XY interface’s simplicity was the
main reason given for why the interface was easy to control
whereas, the Anchor Point interface has a unique feature
that aﬀords more precise control. As a satellite point is
moved further away from the anchor point, the touchable
area for each pitch division increases. This in turn leads to
a smaller degree of error in pitch control for the user.
This feature also links into the creativity and exploration
categories. Most people found that the Anchor Point in-
terface allowed them to be more creative and encouraged
greater exploration, with participants generally using more
of the space during the free section. The Anchor Point in-
terface also provided more organic control as many pitches
could be played quietly to create a chord while a melody
could simultaneously be played with accuracy by dragging
a point away from the anchor point. In contrast, while
people found the XY interface to be initially interesting,
participants seemed to quickly become bored with its limi-
tations. Once the user had worked out the limitations, they
were quick to tire of interacting with the same relationship.
Interestingly, most people found it hard to repeat the
same chord on both interfaces. This issue can be attributed
partly to the lack of haptic feedback provided by multi-
touch screens. This could be mitigated by stronger visual
references for pitch divisions for these types of interface.
The visual reference for the Anchor Point interface was
found to be more essential to understanding its method of
control, while the XY visual reference was felt to be distract-
ing as the relationship quickly became self-evident when in-
teracting with the interface.
With practice, the Anchor Point interface may allow more
precise control as the user learns the angular relationships
between the anchor point and subsequent satellite points.
This would allow for greater control as well as more intu-
itive harmonic control as a chord shape could be inverted
to create related chords. The shape of a triad can be played
on the Anchor Point interface with one hand, and could be
learnt and then transposed around the table. This provides
an interesting alternative to the spacing of notes on the XY
interface, especially when the range is large and requires
multiple hands.
These results seem to indicate that although the Anchor
Point interface is more complex and harder to learn, it af-
fords more creative expression and prompts more explo-
ration than the XY interface. The Anchor Point interface
is closer than the XY interface in these aspects, to a tra-
ditional instrument, as instruments like the guitar or piano
take some time to learn how to use but once learnt can be
very expressive.
Both interfaces could be well suited for use on an iPad or
similar surface, although the smaller screen would inhibit
some of control aﬀorded in the Anchor Point interface. The
portability and popularity of these devices could promote
many uses however, with use of both the XY and Anchor
Point interfaces as musical pedagogical tools for aural train-
ing and recognition.
5. ACKNOWLEDGMENTS
We would like to thank all the participants of the user sur-
vey for their time. Jordan Hochenbaum, whose work with
Owen Vallis on building the ‘Bricktable’ made this paper
possible. Jim Murphy, for helping with calibration and
setup. Thanks to Victoria University of Wellington URF
Grant for supporting this project and the New Zealand
School of Music for their support.
6. REFERENCES
[1] J. Hochenbaum and O. Vallis. Bricktable: A musical
tangible multi-touch interface. In The Berlin Open
Conference, Berlin, Germany, 2009.
[2] J. Hochenbaum, O. Vallis, D. Diakopoulos,
J. Murphy, and A. kapur. Designing expressive
musical interfaces for tabletop surfaces. In The
conference on new interfaces for musical expression,
Sydney, Australia, 2010.
[3] A. Hunt, M. Wanderley, and M. Paradis. The
importance of parameter mapping in electronic
instrument design. Journal of New Music Research,
32L(4):429–440, 2003.
[4] T. Iwai. Composition on the table. In ACM
SIGGRAPH 99 Electronic art and animation catalog,
page 10. ACM, 1999.
[5] S. Jorda, G. Geiger, M. Alonso, and
M. Kaltenbrunner. The reacTable: exploring the
synergy between live music performance and tabletop
tangible interfaces. In Proceedings of the 1st
international conference on Tangible and embedded
interaction, pages 139–146, 2007.
[6] S. Jorda, M. Kaltenbrunner, G. Geiger, and
R. Bencina. The reactable*. In The International
Computer Music Conference, pages 579–582, 2005.
[7] M. Kaltenbrunner and R. Bencina. reacTIVision: a
computer-vision framework for table-based tangible
interaction. In The 1st international conference on
Tangible and embedded interaction, pages 69–74, 2007.
[8] J. Patten, B. Recht, and H. Ishii. AudioPad: a
Tag-Based interface for musical performance. In
NIME, pages 148–153, 2002.
[9] K. Schlei. Relationship-Based instrument mapping of
Multi-Point data streams using a trackpad interface.
In NIME, pages 15–18, Sydney, Australia, 2010.
[10] M. Wright and A. Freed. Open sound control: A new
protocol for communicating with sound synthesizers.
In ICMC, pages 101–104, 1997.