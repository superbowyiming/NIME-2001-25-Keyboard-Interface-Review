The World Wide Web in an Analog Patchbay
Don Derek Haddad, Joseph A. Paradiso
MIT Media Lab
75 Amherst Street
Cambridge, MA 02142
[ddh, joep]@media.mit.edu
ABSTRACT
This paper introduces a versatile module for Eurorack syn-
thesizers that allows multiple modular synthesizers to be
patched together remotely through the world wide web.
The module is conﬁgured from a read-eval-print-loop en-
vironment running in the web browser, that can be used to
send signals to the modular synthesizer from a live coding
interface or from various data sources on the internet.
Author Keywords
Networked instruments, Modular synthesizers, Remote col-
laboration
CCS Concepts
•Hardware →Analog and mixed-signal circuits; Digital
signal processing; •General and reference →Design;
1. INTRODUCTION
The renaissance of modular synthesizers in this age of dig-
ital music making raises fundamental questions about the
connection between electronic musicians and machines [15].
The concept of sound synthesis using symbolic representa-
tions of information, whether in the physical world or on
the computer screen, presented new ways of thinking about
electronic music composition in the past century [10]. Even
when hidden from plain sight, this symbolic representation
in music making does exist. For instance, a live coding
improviser constructs a mental model of their composition
while invoking their musical expression in front of an au-
dience. On the other hand, communication has long inﬂu-
enced electronic music. In the age of telephony, operators
would manually connect calls across lines using patch cords,
similarly to how sonic artists today route signals on software
and/or hardware synthesizers. This paper showcases the in-
tegration of modular synthesizers with the world wide web,
as presented in a Eurorack module called the 20N02, while
also demonstrating the concept of controlling the modu-
lar synthesizer from a read-eval-print-loop (REPL) environ-
ment embedded in the web browser. Moreover, this paper
introduces an online patchbay that allows multiple modu-
lar synthesizers to broadcast signals to each other over the
internet, or receive data from various sources that are also
fed through the network, such as sensor data.
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’19,June 3-6, 2019, Universidade Federal do Rio Grande do Sul Porto
Alegre, Brazil.
2. RELATED WORK
2.1 Networked Instruments
In 1967, before the ubiquity of networked systems, Maryanne
Amacher’s pioneering work City Links transmitted sound
from urban environments to other locations [11]. Networked
systems as a musical medium started to leverage remote col-
laboration among electronic musicians and sonic artists with
the development of digital communication, and dates back
to the late 1970s [5]. In the mid 1980s, computer networked
ensembles like “The Hub” started to emerge. They decided
to use a network hub, hence their name, instead of relying
on a typical ad-hoc wired connection, resulting in a more
robust networked collaboration at the time [3]. With the
expansion of the world wide web, and its adoption as a tool
for music collaboration, many systems were developed to
connect performers, composers, and audiences around the
world [21]. Network latency demotivated the creators of
such systems from emulating traditional music performance,
therefore pushing the boundaries of experimental sound art
[5]. New collaborative tools were developed in the early
2000s and used typical client-server conﬁgurations, like the
daisy phone [7] and the networked laptop ensembles [8].
Figure 1: Musical patches running inside the virtual
world of Doppelmarsh are driven by streams of data
coming from a sensor network deployed in a wetland
[12].
The ramiﬁcation of the internet in everyday life, through
social media, also opened a new horizon for experimental
music collaboration. The massively multiplayer online drum
machine (MMODM) for instance used the social platform
Twitter as an interface for musical collaboration [19]. Al-
though controlling electronic music instruments from the
internet has been long explored in academia, the internet of
musical things is on the rise (IoMusT), and that is due to the
deployment and commercialization of ubiquitous sensing in
our daily life [20]. In 2012, a system called Patchwork, by
407
B. Mayton et. al, allowed the control of a massive modular
synthesizer patch from within a web-interface [13]. Access-
ing streams of internet-based slow-control and audio data is
standard practice in the world of PCs, handhelds, and IoT,
but has yet to appear in the world of modular synthesizers.
This paper expands on prior work by facilitating the con-
nection of modular synthesizers through the internet, plus
enabling them to connect to ubiquitous sources of online
data and audio (both cached and streaming), augmenting
the modular paradigm with data and sound sources coming
from everywhere.
Figure 2: Two WiFi powered Eurorack modules in
market as of today. A - Developed by Rebel Tech-
nology, allows sending and receiving osc messages,
and B - by SDS Digital, does only MIDI output on
8 diﬀerent channels.
2.2 Modular Versatility
Advances in digital embedded systems in combination with
analog synthesizers ﬂooded the market of modular synthe-
sizers with interesting hybrid and versatile modules. Var-
ious manufacturers embrace the ﬂexibility of digital tech-
nologies in designing their Eurorack modules today. The
Disting mk4 by Expert Sleepers [2], for example, can morph
into more than 60 diﬀerent modules with diﬀerent function-
alities. ALM’s PAM module does more than a traditional
clock/gate module [4]; it includes multiple low-frequency
oscillators, envelopes generators, Euclidean sequencers, ran-
dom voltage sources and more, and is programmed with a
single rotary encoder and a tiny display.
From the halls of academia came a hybrid module called
“Salt” that also embodies this duality of analog and digital,
and is powered by the Bela.io platform [14] and Pure-Data
(PD) [16]. This module enables exporting PD patches right
into a modular synthesizer, turning digital signals from the
computer into control voltages or audio sources, and there-
fore extending the possibilities of a given patch.
Similarly, the modular synthesizer emulator VCV Rack,
in combination with an audio interface like the ES-8 by Ex-
perts Sleepers, can also be used to send signals back and
forth to a modular synthesizer, putting us in the age of hy-
brid physical and virtual modular synthesis [18]. On the
other hand, digital audio workstations have also integrated
with hardware interfaces and symbolic patching. Namely,
Max for Live that enables the creation of Max/MSP patches
from within Ableton Live, to facilitate composing and im-
provising with other hardware and software synthesizers [1].
2.3 Data Soniﬁcation
Turning data into sound in musical compositions has been
a subject of research since the 1980s. Much remains to be
learned about how soniﬁcation works in the scientiﬁc ﬁeld.
In order to extract meaning from sound, listeners need to
learn and adapt to a“sonic legend”as well as have some kind
of visual guidance in a performance [6]. Today, mapping
ubiquitous real-time streams of data into sound presents a
burgeoning new medium for musical expression, for exam-
ple soniﬁcations done on particle collisions from the ATLAS
detector at CERN by various composers and electronic mu-
sicians using digital technologies [9]. More recently, data
gathered from plasma fusion research from MIT’s Alcator
C-Mod Tokamak, were soniﬁed on a massive analog synthe-
sizer [17].
3. DESIGN
3.1 Hardware Design
At the core of the 20N02 module resides the esp-8266, a
low-cost WiFi chip manufactured by Espressif. The chip
can be purchased as a surface mount device (SMD) module,
packaged with other required components like an antenna,
level shifters, capacitors, pull-up resistors and protective
diodes. The inclusion of a second microcontroller on board
turns the esp8266 into an IOT device capable of connecting
to sensors and actuators and engage with streams of data
through the internet.
Figure 3: This picture shows the two-layers printed
circuit board of the ﬁrst revision of the 20N02 mod-
ule. Photo-credit: Gabriela Bila
The ﬁrst revision of the module requires 3.3V to operate,
therefore a voltage regulator is needed to transform the in-
coming 5V from Eurorack power supplies into a stable 3.3V.
The incoming stream of data through WiFi is converted into
control voltages (CV) by an external single channel 12-bit
digital to analog converter (DAC) that communicates with
the esp-8266 module via the I2C ports. The output of the
DAC is ampliﬁed and buﬀered with an op-amp, powered
by the -12V and 12V rails of the Eurorack power bus, into
3 identical outputs that in-turn are connected to envelope
followers with LEDs used as signal indicators. The esp-8266
module includes a single analog input, and can only accept
1V signals. A voltage divider was used to turn CV sig-
nals coming from the modular synthesizer into the allowed
range. Lastly, an FTDI module is required to ﬂash the esp-
8266 chip via its RS232 serial ports, which could be done
using the Arduino IDE. Once ﬂashed, the module can al-
low over the air updates (OTA), making swapping programs
and installing updates an easier task.
408
3.2 Software Design
The preliminary program uploaded to the 20N02 module
runs a Websocket client that accepts streams of data from
other connected clients. Network latency could be notice-
able especially that the Websocket protocol runs over TCP,
not to mention networked latency over WiFi. This will not
aﬀect the integrity of the signals being sent or received, as
the program waits until the entire signal is in memory be-
fore writing to the DAC. This approach pushes composers
away from replicating conventional instruments. Unlike the
Open Sound module by Rebel Technology that promotes
such replicas. (Example: TouchOSC app that sends mes-
sages from a virtual piano running on an iPad over WiFi
into a Eurorack synthesizer). Multiple 20N02 module could
be connected and conﬁgured from within a REPL environ-
ment running on a web-browser. A live-coding-like interface
is used to generate digital signals, that in turn are streamed
into the module over WiFi. These signals could take var-
ious forms and shapes. For instance, a simple linear at-
tack/decay envelope could be implemented through a sim-
ple script that draws an ascending and descending line on
a 2D X-Y plane. Moreover, many more complex waveform
could be computed by using the Javascript built-in Math
object. Figure 4, shows an example of a couple of complex
waveforms generated using trigonometric functions. Many
types of signals could be generated this way: attack, decay,
sustain, release, complex oscillators, pitch sequences, and
random numbers to name a few.
Figure 4: Various waveforms generated from the
20N02 REPL environment using Javascript.
The esp-8266 is equipped with 80 KiB (81.92 KB) of user
data, the incoming stream of data is cached and saved onto
the chip, and could be looped based on user’s input or un-
til overridden by a new stream. The web server in use is
implemented with Node.js and runs a Websocket and an
HTTP server. The Websocket server is used to route the
incoming streams of data to their appropriate destinations,
whereas the HTTP server is simply used to serve the REPL
environment. The 20N02 module could be also conﬁgured
to accepts other types of data through application program
interfaces (APIs). It was tested with historical sensor data
coming from sensors deployed in an outdoor environment,
sonifying the history of slowly-changing temperature, hu-
midity and pressure over a year, accelerated into a com-
plex envelope waveform lasting just a few minutes. In other
terms, analog sensor readings are converted from voltages
to digits, sent over the network to be converted back into
voltages, then used to drive a patch of a modular synthe-
sizer, either in real-time or cached and output with a varying
timebase.
Figure 5: A live coding interface is presented in
the web-browser using Google Chrome’s developer
console. The theme of the web-app matches the
colors of the console in dark mode.
3.3 Interface Design
The face-plate mounted on top of the module is also manu-
factured with FR-4 PCB material. By design, certain areas
on the face-plate were left without the silk-screen overlay
and without the copper-layer, allowing light coming from
the LEDs to diﬀuse in an ambient fashion while indicating
signals. The module is 8HP (1.6’) wide and matches the Eu-
rorack format with 3 rack units of height (3U). The design of
the REPL environment extends the developer console found
on modern web-browsers as shown in ﬁgure 5.
Figure 6: A picture of the 20N02 Eurorack module.
4. PROTOTYPE
An early prototype of the 20N02 module has been made,
with a single analog input and 3 buﬀered outputs. It was
manufactured and tested by a handful of electronic musi-
cians and sonic artists. The feedback of this short survey
will highly inﬂuence the future features that will be added
to the module.
5. FUTURE WORK
A second revision of the module is in the works, capa-
ble of handling multiple inputs and outputs up to audio
rates, as well as adding an audio CODEC chip allowing
409
Figure 7: A brief annotation of the 20N02 module.
streaming samples to be provided into a modular synthe-
sizer over WiFi. The web-platform is also getting a reno-
vation, as more functions will be added to the REPL en-
vironment to improve readability, also allowing a quicker
access to common operations. A basic security layer will be
also added to prevent users from getting unwanted signals
through their synthesizers. Ultimately, a REST API could
be developed to facilitate the integration of the 20N02 with
common IoT standards, while inviting other developers to
contribute with creative applications that could be deployed
on what can resemble an app store for smart modular syn-
thesizers.
6. CONCLUSION
This paper extends the ﬁeld of networked instruments into
the world of modular synthesizers. A Eurorack module
called 20N02 was developed to connect modular synthesiz-
ers together through the world wide web as well as to pro-
vide outputs that produce control voltages and audio from
internet sources (real-time or cached). Moreover, multiple
use cases were presented to show the beneﬁts of connecting
an analog synthesizer to the internet, like facilitating data
soniﬁcation of various sources through APIs. Finally, this
module made it possible to perform remote live coding op-
erations on a modular synthesizers from around the world,
through a web interface using Javascript.
7. ACKNOWLEDGMENTS
This project wouldn’t be possible without the help and men-
torship of Mark Feldmeier. We would also like to thank
two electronic music composers and modular-synth builders:
Mr. John Debo, and Mr. Joseph Junior Sfeir who have
helped tremendously in the early development of the project,
and who’s feedback will be incorporated in future revisions
of the 20N02.
8. REFERENCES
[1] Abelton live, a software music sequencer and digital
audio workstation for macos and windows.
URL: https://www.ableton.com/.
[2] Experts sleepers disting mk4 many-in-1 multifunction
module.
URL: http://www.expert-sleepers.co.uk/disting.html.
[3] The hub: computer network music ensemble.
URL: en.wikipedia.org/wiki/The Hub (band).
[4] Pam: compact programmable clocked modulation
source for your eurorack.
URL: http://busycircuits.com/alm017/.
[5] ´A. Barbosa. Displaced soundscapes: A survey of
network systems for music and sonic art creation.
Leonardo Music Journal, pages 53–59, 2003.
[6] S. Barrass and G. Kramer. Using soniﬁcation.
Multimedia systems, 7(1):23–31, 1999.
[7] N. Bryan-Kinns. Daisyphone: the design and impact
of a novel environment for remote group music
improvisation. In Proceedings of the 5th conference on
Designing interactive systems: processes, practices,
methods, and techniques, pages 135–144. ACM, 2004.
[8] J. Freeman and A. V. Troyer. Collaborative textual
improvisation in a laptop ensemble. Computer Music
Journal, 35(2):8–21, 2011.
[9] E. Hill and S. Goldfarb. Atlas data soniﬁcation: a
new interface for musical expression and public
interaction. Technical report,
ATL-COM-OREACH-2016-018, 2016.
[10] V. Lazzarini. The development of computer music
programming systems. Journal of New Music
Research, 42(1):97–110, 2013.
[11] A. Licht. Sound art: Origins, development and
ambiguities. Organised Sound, 14(1):3–10, 2009.
[12] E. F. Lynch. SensorChimes: musical mapping for
sensor networks toward augmented acoustic
ecosystem. PhD thesis, Massachusetts Institute of
Technology, 2016.
[13] B. D. Mayton, G. Dublon, N. Joliat, and J. A.
Paradiso. Patchwork: Multi-user network control of a
massive modular synthesizer. In NIME, 2012.
[14] G. Moro, A. Bin, R. H. Jack, C. Heinrichs, A. P.
McPherson, et al. Making high-performance
embedded instruments with bela and pure data. 2016.
[15] J. A. Paradiso. The modular explosion-deja vu or
something new? In Presented at the Voltage Connect
Conference, Berklee College of Music, Boston MA,
2017.
[16] M. S. Puckette et al. Pure data. In ICMC, 1997.
[17] P. Rivenberg. Spinning data into sound: An
interdepartmental collaboration brings out the music
of nuclear fusion.
URL: http://news.mit.edu/2018/mit-collaboration-
uses-nuclear-fusion-data-to-create-music-paradiso-
resynthesizer-0509,
2018.
[18] Synthhead. How to create a hybrid modular system
with vcv rack.
URL:
http://www.synthtopia.com/content/2018/02/16/how-
to-create-a-hybrid-modular-system-with-vcv-rack/,
2018.
[19] B. Tome, D. D. Haddad, T. Machover, and J. A.
Paradiso. Mmodm: Massively multiplayer online
drum machine. 2015.
[20] L. Turchet, C. Fischione, and M. Barthet. Towards
the internet of musical things. In Proceedings of the
Sound and Music Computing Conference, pages
13–20, 2017.
[21] G. Weinberg. Interconnected musical networks:
Toward a theoretical framework. Computer Music
Journal, 29(2):23–39, 2005.
410