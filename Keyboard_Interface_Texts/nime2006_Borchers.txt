MICON A Music Stand for Interactive Conducting
Jan Borchers 
RWTH Aachen University 
Media Computing Group 
52056 Aachen, Germany 
+49 (241) 80-21050 
borchers@cs.rwth-aachen.de 
Aristotelis Hadjakos 
TU Darmstadt 
Telecooperation Division 
64289 Darmstadt, Germany 
+49 (6196) 902520 
thadjakos@gmx.de 
Max Mühlhäuser 
TU Darmstadt 
Telecooperation Division 
64289 Darmstadt, Germany 
+49 (6151) 16-3709 
max@informatik.tu-darmstadt.de 
 
 
ABSTRACT 
The MICON is an electronic music stand extending Maestro!, 
the latest in a series of interactive conducting exhibits that use 
real orchestral audio and video recordings. The MICON uses 
OpenGL-based rendering to display and animate score pages 
with a high degree of realism. It offers three different score 
display formats to match the user’s level of expertise. A real-
time animated visual cueing system helps users with their 
conducting. The MICON has been evaluated with music 
students. 
Keywords 
Music stand, score display, exhibit, conducting. 
1. INTRODUCTION 
Conducting is a well-established and rich metaphor when 
interacting with a musical body such as an orchestra. Some 
people even enjoy conducting alongside a classical recording at 
home. Personal Orchestra [3], an interactive exhibit for public 
spaces, was the first system to let museum visitors actually 
control tempo and volume of an audiovisual recording via 
conducting gestures. 
Visitors can also emphasize an instrument section by 
conducting towards it. This gives visitors, albeit limited, 
opportunity to change the musical expression and play a more 
active part. Personal Orchestra has been an exhibit at the 
HOUSE OF MUSIC VIENNA  since 2000 [3]. Two follow-up 
systems with new gesture recognition and audio time-stretching 
algorithms have been developed since: You’re The Conductor  
opened at the Children’s Museum Boston in 2003 [6], and the 
latest, Maestro!, at  the Betty Brinn Children’s Museum in 
Milwaukee in 2006 [7,8]. 
These exhibits provide a previously unavailable interaction to 
people who are not professional conductors: the experience of 
conducting an orchestra. To make this experience more 
realistic, we wanted to provide the visitor with a music stand as 
an extension to Maestro!. To this end, the MICON ( Music 
Stand for Interactive Conducting Systems) was created. 
 
Figure 1. A visitor conducting the Vienna Philharmonic in 
the Personal Orchestra  exhibit at the HOUSE OF MUSIC 
VIENNA (http://www.hdm.at). The music stands were still 
merely decorative here. 
  
2. DESIGN CONSIDERATIONS 
The functional goals of the MICON were: 
• To display the musical score to Maestro! visitors while 
they are conducting, and 
• To indicate the current position in the score and 
automatically advance the pages following the music, to 
help visitors with their conducting. 
The key constraints in creating the MICON were: 
• Production quality.  Since the Maestro! system featured 
professional orchestras, its look and feel had to fulfill high 
standards to be accepted by the museum and orchestra in 
question. The MICON had to look and behave as 
professional as the rest of the exhibit, which required 
excellent visual quality of the score display and fluid, non-
distracting interaction with it. 
• Visitor profile. Typical visitors using the system would be 
one-time users with a short dwelling time. The system had 
to provide for this through a particularly simple, self-
explanatory, and obvious interface that required little or no 
interaction apart from the conducting itself. 
• Musical knowledge. Some visitors might be amateur or 
even professional conductors, but  most would have no 
prior experience in conducting. The MICON had to 
provide these beginners with alternatives to the complexity 
of a full orchestral score document. Hopefully, by 
interacting with the system, visitors would learn a little 
 
 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies 
are not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, or republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
NIME 06, June 4-8, 2006, Paris, France. 
Copyright remains with the author(s). 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
254
more about conducting and experience some of its 
challenges and rewards. 
• Listener architecture. The MICON had to extend the 
Maestro! system; to minimize dependencies between these 
two co-evolving projects, their communication interface 
had to be kept as narrow as possible, with the MICON 
essentially listening to the timing information that was 
already being generated by the Maestro! gesture 
recognition engine. 
Additional guidelines for interactive music exhibits that we 
followed in this design can be found in [2]. 
3.  RELATED WORK 
There has been a wealth of research aimed at recognizing 
conducting gestures, which we will not cover here as it is not 
the focus of this paper. Similarly, a variety of systems have 
been developed previously that offer a more or less “complete” 
conducting experience—often limited to audio or video only, 
and frequently using synthetic (MIDI or VRML, for example) 
data as opposed to real audio and video material for playback. 
We refer the interested reader to [5] and [7] for a more detailed 
overview.  
MOODS (Music Object Oriented Distributed System) is a 
synchronous real-time cooperative editor for music scores [1]: 
Every change is immediately made visible to all users. It is 
intended for orchestra musicians during rehearsal. MOODS 
consists of different types of lecterns for the instrumentalists, 
the conductor, and the orchestra's archivist. Editing in MOODS 
is based on different permissions for these groups. MOODS 
supports semiautomatic page-turning. The score on the 
instrumentalists’ lecterns is separated horizontally; the page that 
is currently being played is shown below a separator, the 
following page appears above it. As the music advances, the 
separator moves downwards. The score on the conductor's and 
archivist's lectern is separated vertically between the current 
and next page. MOODS assumes a constant tempo for a piece; 
tempo variations have to be adjusted manually by a human 
operator during the performance, making it unsuitable for our 
purposes. 
muse is a digital music stand for symphony orchestras [4]. It 
consists mainly of a portable display and a matching stand with 
integrated metronome and a pitch-generating tuner. It allows 
on-screen annotation and intrasymphonic wireless 
communication. Pages are turned automatically or manually. In 
automatic mode, an attached microphone captures the incoming 
sound, and the muse compares it against the score to turn pages 
at the appropriate moment. Instrumentalists load pieces from an 
archive over an encrypted connection to prevent copyright 
violation. muse was presented to the Pittsburgh Symphony 
Orchestra. However, it does not highlight the current score 
position, and its page-turning requires per-instrument 
microphones.  
The commercial eStand (www.estandmusic.com) consists of a 
tablet PC and footswitch for manual page-turning. The system 
is optimized for low noise. The software displays the score, 
which has to be downloaded from the Internet or created with 
note-setting software. The musician can annotate the score with 
the provided pen. The eStand has a built-in metronome, tuning, 
music library management, and networked annotation sharing 
for ensembles. eStand does not highlight the current position in 
the score and does not advance the score automatically.  
  
Figure 2. Typical conducting exhibit setup. 
4. DESIGNING THE MICON 
We will start with our envisioned usage scenario. Fig. 2 shows 
the layout of a typical conducting exhibit installation. The user 
stands in front of a large screen. Two loudspeakers are directed 
towards her. The computer hardware is hidden. In front of the 
user stands the music stand. A sensor tracks the baton and sends 
its position to the computer. 
First, the user sees a list of music pieces on the large screen, 
points the baton towards the desired item and pushes the button 
on the baton. In the same way she selects the representation of 
the musical material on the music stand. She has three choices: 
full score, piano part score, or piano roll. In either case, the 
MICON shows the pulse notation at the top of the selected 
representation. After the selection, the orchestra appears, the 
user begins to conduct, and the orchestra starts playing, with the 
score display advancing automatically on the MICON. 
A full score is an assembly of all the instruments' voices and the 
standard format that conductors use. There is a lot of 
information present in a full score: the notes for every 
instrument, dynamic markings, etc., and it requires very good 
music-reading skills. An extract of the full score for the piano is 
easier to read, as there are only two note systems, left hand and 
right hand. The piano-roll and the pulse notation do not require 
any score-reading abilities. 
4.1 Score Animation and Highlighting 
Fig. 3 shows the first page of the “Blue Danube” by Johann 
Strauss as it is presented on the MICON. The score is enhanced 
with additional information: An orange bar cursor marks the 
position of the music. While music plays, the cursor moves to 
the right. Above the cursor is a ball jumping up and down. This 
ball marks the beats in the music. The beats occur when the ball 
hits the “ground” (Fig. 4). The user can emphasize an 
instrument section by conducting towards it. This section is 
then highlighted on the music stand by coloring the 
corresponding lines red. The pages on the MICON do not have 
a flat appearance but are rendered more like naturally flexible 
paper. When the cursor reaches the last beat of the right page, 
the page lifts up (Fig. 5), turns (Fig. 6), and the next two pages 
become visible (Fig. 7). 
When the cursor moves to another note system, it fades out 
smoothly. After it vanishes from the previous note system, it 
smoothly fades in at the new note system. The same happens to 
the jumping ball and the instrument group highlight during 
transition. When the jumping ball fades out completely at the 
end of the note system’s last bar, it is located at the highest 
point of its trajectory. In the next note system the ball reappears 
at the highest point and moves downward while fading in 
(Fig. 8). 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
255
Figure 3. The “Blue Danube” on the music stand. 
 
 
 Figure 4. The jumping ball: (a) and (b) before the beat, 
(c) at the beat, (d) after the beat.  
 
 
 
 
Figure 5. Page turning begins. 
 
 
 
Figure 6. Page is halfway turned. 
 
 
 
 
Figure 7 Page turning ends. The bending behavior of the 
page in the above panels aims to closely resemble physical 
paper. 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
256
 
 
Figure 8. The cursor moves to another note system. 
4.2 Piano Roll Notation 
The piano roll notation represents notes as boxes of uniform 
height. Box width represents the length of a note, the vertical 
position represents its pitch, and the horizontal position its onset 
time. Music software such as MIDI sequencers frequently uses 
piano roll notation to represent musical material, so that some 
users of the MICON may already be familiar with this notation. 
Fig. 9 shows the piano roll representation of bars 45–49 of the 
“Blue Danube” as it is presented on the MICON. 
The notes that are currently played by the orchestra are in the 
center of the screen. In addition, they are highlighted in a 
brighter color. As time proceeds, the boxes move to the left, and 
the highlight moves to the following notes. The highlight moves 
rhythmically, mimicking the rhythm of the music. A user 
without prior experience with the piano roll notation can thus 
figure out the connection between this notation and the music.  
4.3 Pulse 
The pulse notation consists of circles representing the beats of 
the music. They are horizontally aligned. The more time there is 
between two beats, the longer is the distance between the two 
corresponding circles. Tempo changes lead to differing 
distances between the circles: the pulse notation outlines the 
tempo changes of the piece: It shows the metrical landscape of 
the music around the current beat, giving the user an indication 
of the recently passed and the upcoming tempo. Fig. 10 shows a 
metric landscape for a steady tempo, Fig. 11 shows a tempo 
decrease (ritardando). 
 
Figure 9. Bars 45–49 of the “Blue Danube” in piano roll 
notation. The beginning of the theme is still recognizable. 
 
Figure 10. Steady tempo. 
 
 
Figure 11. Tempo change (in a ritardando). 
 
The circles move to the left as time proceeds. Coming from the 
right and approaching the center of the screen, they grow in 
size. Far from the center they grow only slowly, but as they 
approach the center, they grow at a higher rate. They reach their 
maximum size in the center of the screen, which marks the beat. 
Afterwards, they shrink again, first rapidly, then slowly, to their 
original size (Fig. 12, 13, and 14). Mathematically speaking, 
circle size is computed as the absolute value of a modified 1/ x 
function, with x=0 at the center, and clipping the size to a 
maximum size at that point. 
 
 
Figure 12. The circle approaches from the left 
(still original size). 
 
 
Figure 13. The circle is in the center (maximal size). 
The beat occurs. 
 
 
Figure 18. Circle in the middle barely visible. 
The other circles begins to move. 
 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
257
These animations are hard to describe on paper; therefore, we 
have created a screen capture that shows the system in use. See: 
http://media.informatik.rwth-aachen.de/micon.html . 
 
5. IMPLEMENTATION 
5.1 Preparing Music For The MICON 
To add a music piece to the MICON requires to create four 
types of  files: 
• A MIDI file, 
• A beats file, 
• Page scans of the full score and the piano part, and 
• ScoreInfo files for the full score and the piano part. 
The piano roll and the recorded (digital audio) music have to be 
synchronized. Therefore, MIDI files were produced that closely 
resemble the tempo changes of the original recording. We 
created these files by playing alongside the orchestral recording 
on a MIDI keyboard and recording this performance to a MIDI 
file. Manual post-processing was done to correct minor errors 
and to achieve a better synchronization. In a second manual 
post-processing step, this synchronized MIDI file was refined 
under aesthetic considerations: The notes were quantized to a 
fixed raster and aligned so that notes belonging to a logical 
compound begin and end in the correct position. When, for 
example, a chord is played, the notes constituting the chord 
should all start and end at the same horizontal position. For 
legato passages, neighbouring notes should end respectively 
start at exactly the same horizontal position.   
A beats file contains a list of time stamps indicating when each 
beat occurs in the orchestral recording. This allows the MICON 
to compute a mapping between the elapsed time (in seconds) 
and the position in the music (in beats). This mapping is 
required for the score and pulse representations. The beats file 
for a new piece can be created with Midi2Beats, a program we 
developed. Midi2Beats extracts the rhythm of a MIDI-file: 
Every Note-On in the MIDI file is stored as a beat event in the 
beats file. Therefore, a MIDI file has to be created that has 
exactly one Note-On on every beat. By deleting notes from and, 
sometimes, adding notes to the previously created MIDI file, it 
can be transformed into such a file. Using this file, the beats file 
is created using MIDI2Beats. 
The ScoreInfo file provides graphical information about the 
score layout on the page. This is mainly: 
• The x/y position of every beat, 
• The position and extent of each note system and 
• The position and extent of each instrument group on the 
score page (full score only). 
We developed the ScoreMarker application (Fig. 19) to easily 
specify this information. First, the developer loads the graphical 
page scans into ScoreMarker. Using the mouse, he defines the 
note systems, beats and instrument groups in the score. 
ScoreMarker then creates the corresponding ScoreInfo file. 
 
 
Figure 19. The ScoreMarker application. 
5.2 Communication 
Maestro! and the MICON communicate via a UDP-based 
protocol. Communication is one-way: Maestro! sends messages 
to the MICON which then updates its internal state. During the 
initial user selections, Maestro! informs the MICON about what 
piece and score representation the user chooses. During the 
piece, Maestro! continuously sends the current position in the 
piece to the MICON: every few seconds Maestro! sends the 
current instrument emphasis. 
5.3 Rendering 
MICON uses OpenGL for its graphical output and creates 
realistic-looking, curved score pages resembling physical paper 
more closely than a normal “flat” 2-D rendering would. Fig. 19 
shows a curved score page. To create these pages, each page is 
sliced vertically into 100 equidistant pieces, which are then 
reconnected with their two neighbors to form the curved page. 
The angles between these neighboring slices were defined 
beforehand for several key frames of the page-turning 
animation. We experimentally chose values for these 99 inter-
slice angles at each key frame. Rendering the slices for a given 
key frame is then straightforward: Starting at the origin, a slice 
is drawn along the x axis (the coordinate system is shown in 
Fig. 20). The origin is then translated along the x axis so that 
the origin now points to the right end of the drawn slice. Now, 
the origin is rotated around the y axis with the predefined angle, 
and the rendering of the next slice begins. 
 
 
 
Figure 19. Score from the side. 
 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
258
 
Figure 20. Reference coordinate system for rendering the 
above page. 
As the page turns, it changes its form: At the beginning (0°) and 
end (180°) of the page turn, the page has the “normal” shape 
shown in Fig. 19. In addition to these two key-frames, a 
configuration of the 99 angles was specified for a page turned 
90 degrees. These angles were again chosen experimentally. 
For all other frames, the 99 inter-slice angles smoothly 
transition between these key frame configurations using linear 
interpolation. 
6. EVALUATION 
We tested advanced prototypes of the MICON and Maestro! 
with music students at the University for Music and Performing 
Arts (“Hochschule für Musik und Darstellende Kunst”) in 
Frankfurt, Germany. The goal was to get feedback about the 
Maestro! system in general, and the MICON in particular. Ten 
students participated in the test: four pianists, four other 
instrumentalists (violinist, cellist, flautist, guitarist), and one 
composer.  
Page turning speed originally only depended on the tempo of 
the music. It would start when the last beat of the right page 
was reached, and end with the first beat on the new page. When 
users conducted very slowly, this made page turning 
unnaturally slow, as two students criticized. MICON now 
completes page turning in two seconds maximum—or less if 
the tempo is above 30 bpm. 
Many students were uncertain how to start conducting, for 
example, whether to conduct quarter or half notes. To help with 
this, the pulsating circle described in section 4.3 was added. 
The students liked the appearance of MICON. Especially the 
curved pages and the animated page turning were appreciated. 
7. SUMMARY 
We presented the MICON, a music stand for Maestro!, an 
interactive conducting exhibit. The MICON displays musical 
material in various formats: full score, piano extract score, 
piano roll, and pulse notations. This enables a broad public to 
use the MICON, while still allowing expert music score readers  
to benefit from their abilities. Several carefully designed 
animation techniques help users with their conducting. The 
MICON renders its output via OpenGL to create natural-
looking curved pages and a realistic-looking page-turning 
mechanism. The MICON was tested successfully with music 
students, and their feedback incorporated into the final design. 
8. FUTURE WORK 
We intend to conduct more formal user studies to evaluate the 
MICON, and to make content creation less tedious. In 
particular, a (semi-) automatic way to create the piano roll 
MIDI files would greatly simplify this very time-consuming 
manual process. 
9. ACKNOWLEDGEMENTS 
The authors would like to thank Henning Kiel and Eric Lee for 
their help with integrating the MICON with Maestro!. 
REFERENCES 
[1] Bellini, P., Nesi, P., and Spinu, M. B. Cooperative visual 
manipulation of music notation. ACM Trans. Comput.-
Hum. Interact., 9, 3 (2002), 194–237. 
[2] Borchers, J. A Pattern Approach to Interaction Design.  
John Wiley & Sons, Chichester, UK, 2001. 
[3] Borchers, J. O,, Samminger, W., and Mühlhäuser, M. 
Engineering a realistic real-time conducting system for the 
audio/video rendering of a real orchestra. IEEE Fourth 
International Symposium on Multimedia Software 
Engineering (Newport Beach, CA, Dec. 11–13, 2002). 
[4] Graefe, C., Wahila, D., Maguire, J., and Dasna, O. muse: a 
digital music stand for symphony musicians. Interactions, 
3, 3 (1996), 26–35. 
[5] Kolesnik, P. Conducting Gesture Recognition, Analysis and 
Performance System. M.Sc. Thesis, McGill University, 
2004.  
[6]  Lee, E., Nakra, T. M., and Borchers, J. You're the 
Conductor: A Realistic Interactive Conducting System for 
Children. NIME 2004 International Conference on New 
Interfaces for Musical Expression  (Hamamatsu, Japan, June 
2004), 68–73. 
[7] Lee, E., Karrer, T., and Borchers, J. Toward a Framework 
for Interactive Systems to Conduct Digital Audio and Video 
Streams. Computer Music Journal, 30,1 (Spring 2006), 21–
36. 
[8] Lee, E., Kiel, H., Dedenbach, S., Grüll, I., Karrer, T., Wolf, 
M., and Borchers, J. iSymphony: An Adaptive Interactive 
Orchestral Conducting System for Digital Audio and Video 
Streams. CHI 2006 Extended Abstracts (Montréal, Apr. 22–
27, 2006), ACM Press (in print). 
 
 
 
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
259