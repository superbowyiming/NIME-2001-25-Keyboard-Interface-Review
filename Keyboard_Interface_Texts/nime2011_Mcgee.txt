BioRhythm: a Biologically-inspired Audio-Visual
Installation
Ryan McGee
PhD Student
Media Arts and Technology
University of California,
Santa Barbara
ryan@mat.ucsb.edu
Yuan-Yi Fan
PhD Student
Media Arts and Technology
University of California,
Santa Barbara
dannyfan@mat.ucsb.edu
Reza Ali
PhD Student
Media Arts and Technology
University of California,
Santa Barbara
syedali@mat.ucsb.edu
ABSTRACT
BioRhythm is an interactive bio-feedback installation con-
trolled by the cardiovascular system. Data from a photo-
plethysmograph (PPG) sensor controls soniﬁcation and vi-
sualization parameters in real-time. Biological signals are
obtained using the techniques of Resonance Theory in Hemo-
dynamics and mapped to audiovisual cues via the Five Ele-
ment Philosophy. The result is a new media interface utiliz-
ing sound synthesis and spatialization with advanced graph-
ics rendering. BioRhythm serves as an artistic exploration
of the harmonic spectra of pulse waves.
Keywords
bio-feedback, bio-sensing, soniﬁcation, spatial audio, spa-
tialization, FM synthesis, Open Sound Control, visualiza-
tion, parallel computing
1. INTRODUCTION
Hemodynamics is the study of blood ﬂow and circulation.
Resonance Theory in Hemodynamics (RTH) [12, 7] pro-
vides scientiﬁc evidence of the relationship between har-
monic peaks of blood volume change signals and visceral or-
gans. The spectra and frequency selectivity of arterial beds
in organs were found to change proﬁles following speciﬁc
patterns with ligations of diﬀerent arteries [7]. Three pri-
mary concepts summarize RTH. First is the measurement
of a subject’s physiological condition by palpation sensors
and harmonic analysis of the resulting pulse waveform using
objective signal processing techniques. Second is the per-
spective that there exists a direct relationship between the
eﬃciency of the cardiovascular system and the development
of meridians within a species. Biologically, meridians are
pathways for the ﬂow of qi (pronounced “chi”), the Chinese
term for psychophysical energy. Finally, animal and clinical
studies show the speciﬁc relations between visceral organs
and pulse harmonics [7].
Five Element Philosophy (FEP) [11] provides a map-
ping from visceral organs to musical pitch, color, and car-
dinal direction. Table 1 combines Resonance Theory in
Hemodynamics with FEP to create the mappings used in
BioRhythm. We use FEP only as a metaphor for creat-
ing the artistic vocabulary and bio-audio-visual mappings
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’11,30 May–1 June 2011, Oslo, Norway.
Copyright remains with the author(s).
Table 1: Summary of RTH and FEP
Harmonic 0 1st 2nd 3rd 4th
Organ Heart Liver Kidneys Spleen Lungs
Color Red Green Black Yellow White
Pitch G E A C D
Direction South East North Center West
within this work. BioRhythm is the ﬁrst known attempt to
establish a relationship between RTH and FEP.
1.1 Background
While the soniﬁcation of biological data for artistic purposes
has a long history, the majority of projects have focused on
electroencephalographic (EEG), electrocardiographic (EKG),
electromyographic (EMG), or some combination of several
sensors [10, 9]. In addition to aesthetic exploration, other
studies have focused on biological soniﬁcation as a tool for
diagnosis [5]. With BioRhythm the goal was to extract
as many audio-visual mapping parameters as possible us-
ing a single ﬁngertip photoplethysmograph (PPG) sensor.
The unobtrusive PPG interface is also more conducive to
audience interaction than other sensors.
1.2 Biological Sensor
A photoplethysmograph (PPG) is an optical sensor that
measures blood volume changes by illuminating the skin
with an LED and detecting the amount of light transmitted
or reﬂected to a photodiode. The PPG used in BioRhythm
takes measurements on the index ﬁnger and is used as the
primary source to drive audiovisual generation. The spec-
trum of a PPG signal is characteristic of the harmonic spec-
tra used in RTH. In addition, the optical PPG has the ad-
vantage of being easy to use for public installations.
Figure 1: PPG Sensor (BIOPAC Systems, Inc.) [1]
1.3 Harmonic Analysis of the PPG Waveform
The harmonic modulus is deﬁned as ratio of amplitude of
the harmonic to that of the fundamental frequency. BioRhythm
uses RTH and FEP to map the harmonic moduli of a PPG
signal (Figure 2) into ﬁve frequencies, colors, and direc-
tions that serve as the basis for soniﬁcation and visualiza-
tion techniques.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
80
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
0
0.2
0.4
0.6
0.8
1
Frequency (Hz)
Amplitude
Figure 2: Spectrum of typical PPG Signal
1.4 System Integration
Real-time physiological signal acquisition to soniﬁcation and
visualization is accomplished with parallel computing be-
tween three laptops via Open Sound Control (OSC) [13].
One laptop captures and processes the raw PPG data using
BIOPAC software [1] then uses Max/MSP to send the raw
data along with spectral information via OSC. Two other
laptops receive OSC data and generate the soniﬁcation and
visualization respectively.
BIOPAC PPG Sensor
(Real-time physiological 
data acquisition)
BIOPAC AcqKnowledge
(Signal processing 
software for processing 
raw data)
Max/MSP
(Create OSC Streams)
Bio-feedback System
Sonication System
(Max/MSP)
Visualization System
(openFrameworks)
Multi-channel
Audio Output Video Projector
Figure 3: System Integration
2. SONIFICATION
The soniﬁcation for BioRhythm is composed of 3 separate
sonic layers using an intricate combination of FM synthe-
sis, spatialization, ﬁltering, and delay lines implemented in
Max/MSP. Parameters received via OSC are the raw PPG
signal, heart rate (in beats per minute), interbeat interval
(time between heart beats in milliseconds), and the ampli-
tudes (0-1) of the ﬁve PPG harmonics. The soniﬁcation
software also computes each user’s average heart rate, thus,
there is a brief learning phase for before the soniﬁcation be-
gins for each new user. Figure 4 provides and overview of
the soniﬁcation in BioRhythm.
OSC Parameters:
Heart Rate, Interval, 
Raw PPG, PPG 
Harmonics
Resonated 
Heart Beat
Additive FM 
Synthesizer
Multiple Carrier
FM Synthesizier
Subwoofer
Static 
Spatialized
Outputs
Dynamic
Spatialized
Output
Computed 
Parameters:
Average Heart Rate, 
Tempo, Rate in Hz, 
Average Interval
Pentatonic Scale and 
Spatialization 
Information from Five 
Element Theory
(Table 1)
Parameters
Synthesis
Time-Varying
Delay Line
Figure 4: Soniﬁcation in BioRhythm
2.1 Heartbeat Layer
The ﬁrst layer takes an iconic approach to soniﬁcation [6]
by representing the user’s heartbeat with a sound sample
of a heartbeat triggered at each peak of the PPG signal.
The sample is equalized with frequency peaks in the 40-
80hz range corresponding to G, E, C, D, and A musical
notes as deﬁned by FEP. There is no sound synthesis or
spatialization at this layer, but the heartbeat layer provides
the user with a simple, clear biofeedback response while the
other two layers contain more depth.
2.2 FM Synthesis
The second and third layers of sound use a unique approach
to soniﬁcation that combines model-based and parameter-
based methods [6]. If we think of the soniﬁcation software
as an instrument, then the incoming data not only plays the
instrument, but also deﬁnes and reshapes the instrument.
This is accomplished through the use of frequency modula-
tion (FM) sound synthesis. The basic elements of FM syn-
thesis are a carrier frequency (the fundamental frequency),
a modulation frequency (the rate at which the carrier fre-
quency will vary), and the modulation index (the amount
of frequency deviation from the carrier which directly cor-
responds to the number of resulting partials). When the
ratio of the carrier to modulator frequency is an integer a
harmonic sound results. For non-integer ratios the sound is
inharmonic.
2.3 Additive FM Layer
The foundation of the second sonic layer sums ﬁve simple
FM synthesizers, a technique known as additive FM syn-
thesis. Each of the carrier oscillators is set to a frequency
corresponding to one of the ﬁve notes of the FEP penta-
tonic scale speciﬁed in Table 1. The modulator frequen-
cies begin at a 1:1 ratio with the carrier. The modulators
continuously adjust themselves so that the ratio of the av-
erage heart rate to current heart rate matches the carrier
to modulator ratio. Thus, the modulator frequency changes
with each heartbeat. Due to the properties of FM synthe-
sis, the sounds become more harmonic as the user’s heart-
beat closely matches their computed average. Large changes
from the average heart rate will result in more inharmonic
sounds. The amplitudes of the 5 harmonic ﬁlters are scaled
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
81
to a modulation index between 0 and 25 for their respective
modulators. Thus, strong presence of a particular harmonic
in the PPG signal produces a high modulation index that
results in a harsher sound with more high frequency compo-
nents. The output of each FM synthesizer is given a static
position corresponding to a cardinal direction speciﬁed in
Table 1.
2.4 Multiple Carrier FM Layer
The third layer of sound implements multiple carrier FM
synthesis (MCFM), multiple carriers sharing a single mod-
ulator). Again, each of the carrier frequencies corresponds
to a note in the FEP pentatonic scale. However, in this layer
the user’s current heart rate is converted to Hertz and used
as the single modulation frequency. The raw PPG signal
is scaled to an index between 0 and 25 for the modulator.
Higher amplitudes of raw PPG data indicate higher blood
pressure for the user and will raise the modulation index
of the sound, resulting in more high frequency components.
Likewise, users with lower blood pressure will experience a
calmer sound with less high frequency components.
2.5 Spatialization and Movement
Further interpretation of the third layer lies in the timing
and spatialization of the synthesized sounds. The output of
the MCFM synthesizer connects to a delay line with a vari-
able delay time set by the interbeat interval. Thus, slower
heart rates produce longer delays that echo the dry sound.
If the heart rate suddenly increases it will be echoed by
several short time-delayed versions of the sound. The time
varying delay lines shift the frequency of the sound, which
produces an eﬀect similar to Doppler shift. This delay line
implementation makes apparent subtle changes in heart rate
that cannot be interpreted by simply listening to the heart-
beat of the ﬁrst layer. Lastly, this layer is highly spatialized
as a single point source moving rapidly around the user.
A direction (azimuth) and distance is computed from the
weighted average of harmonic levels that correspond to car-
dinal directions. The panning algorithm used is original
but similar to distance-based amplitude panning (DBAP)
techniques [8].
2.6 Soniﬁcation Summary
To summarize the soniﬁcation, we have a simple heart beat
sound providing the underlying rhythmic interpretation and
deep bass frequencies, a second layer that represents change
through tonal timbre and chord formation, and a third ﬂut-
tering treble layer that focuses more on time delays and
dynamic spatialization to represent change. Due to the
extreme sensitivity of the PPG, a static sound cannot be
achieved even in the user’s most restful state. Thus, users
are not required to elevate their heart rate or dramatically
change their physiological state to hear interesting results
(though many have fun doing so). Each individual produces
their own unique choreography of sounds due to parameters
of their unique heart beat or biorhythm.
3. VISUALIZATION
The visualization consists of a single abstract organic form
produced by algorithmic methods focused on distorting of
a perfect sphere. As with the soniﬁcation, the incoming
bio-signals are mapped according to RTH and FEP, which
leads to an extremely coherent synchronization between au-
ditory and visual cues in the installation. The visualization
receives the same parameters as the soniﬁcation via OSC
and runs as a C++ OpenFrameworks [4] application.
Figure 5: BioRhythm Visualizaton
3.1 Aesthetic
The development of an organic aesthetic was pursued be-
cause of the biological nature of the research. This organic
form steers away from traditional data graphs and plots, so
to engage the installation’s audience in a deeper and more
anthropomorphic manner. The blob-like extrusions in the
visual aesthetic help to emphasize the human body, its or-
gans and their ﬂuctuations, as described in RTH.
3.2 Mapping
The base radius of the sphere reﬂects the amplitude of the
raw PPG data and thus the overall form appears to ”thump”
in unison with the user’s heard beat and soniﬁcation. A 3D
Perlin noise function distorts the vertices of a sphere as the
user’s heart rate departs from equilibrium and the soniﬁ-
cation produces more inharmonic sounds. If the user can
steady their heart rate, then they will be able to replicate
a pseudo-perfect sphere along with a harmonic soniﬁcation.
Otherwise, as with the sound, the form will ﬂuctuate and
warp according to the blood pressure in the user’s ﬁnger.
Four lights add color to the visual scene. Green, red,
black (absence of light), yellow, and white lights are placed
according to the cardinal directions given by FEP. The pres-
ence of any color varies with the amplitude of its harmonic
along with the presence of a FM carrier frequency in the
soniﬁcation.
4. PUBLIC INSTALLATIONS
BioRhythm has been publicly exhibited at MindShare Los
Angeles [3] and at the Media Arts and Technology End of
Year Show at the University of California, Santa Barbara
(UCSB) [2]. Both events regularly draw hundreds of artists,
engineers, scientists, and others interested in new media at
intersection of art and technology.
4.1 Hardware
The original BioRhythm installation at UCSB used a video
projector and accompanying array of 32 speakers in an upwards-
pointing semi-circle on the ﬂoor around the user. A stereo
version has also been implemented for venues where larger
surround setups are not possible. The ﬁngertip PPG sensor
hangs from the ceiling by a thin wire.
4.2 Interactivity and Feedback
The public feedback we receive is generally positive, and
users are often comment on how well the sounds match
the visuals. Typical behavior after waiting for the 15 sec-
ond learning phase is that people either attempt to remain
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
82
Figure 6: 32 Channel Installation at UCSB
calm to settle the system, attempt to elevate their heart
rate through movement to provoke dramatic changes, or at-
tempt some “hack” of the system. For instance, realizing
that blood ﬂow is being measured in the ﬁnger, some users
trigger audio-visual reactions by clenching their ﬁnger or
ﬁst. In fact, one man attempted to cut oﬀ circulation in his
girlfriend’s hand, and when he released her wrist there was
indeed a dramatic change in timbre and spatialization with
an explosive warping of the visual form (similar to Figure
7). Other users realize the extreme sensitivity of the PPG
sensor and squeeze or rub the sensor to produce extreme
eﬀects. Though these hacks are quite interesting, we ﬁnd
that each individual produces interesting time-varying re-
sults when remaining still. The sensitivity of the system
is such that the user would have to be laying down nearly
unconscious to achieve a constantly harmonic sound with
spherical shape.
5. CONCLUSIONS
BioRhythm explores the use of a biofeedback sensor for an
interactive audio-visual installation. The simple velcro ﬁn-
gertip sensor makes BioRhythm suitable for public instal-
lations with hundreds of users. The soniﬁcation involves
dynamic changes in pitch, timbre, rhythm, and spatializa-
tion most notably through the use of FM synthesis, delay
lines, and multichannel panning. The visualization projects
concurrent movements of shape and color. Users are able
to observe audio-visual reactions in the installation corre-
sponding their unique physiological states.
Future work involves improved sensor calibration, search-
ing for patterns within pulse spectra, and the use of alter-
native sound synthesis methods. RTH and FEP have pro-
vided one mapping from biological data to sound and visual
domains, but they are only a starting point, and we are ex-
cited to explore newly proposed mappings from artists and
scientists alike.
6. ACKNOWLEDGMENTS
We are grateful to JoAnn Kuchera-Morin (UCSB) and Alan
Macy (BIOPAC Systems, Inc.) for hardware support and
to Dan Overholt (Aalborg University) for software support.
Figure 7: Dramatic Change in BioRhythm
7. REFERENCES
[1] BIOPAC Systems, Inc. http://www.biopac.com/.
[2] End of Year Show 2010.
http://www.mat.ucsb.edu/show/.
[3] Mindshare Los Angeles. http://www.mindshare.la/.
[4] openFrameworks. http://www.openframeworks.cc/.
[5] M. Ballora, B. Pennycook, P. C. Ivanov, L. Glass, and
A. L. Goldberger. Heart Rate Soniﬁcation: A New
Approach to Medical Diagnosis. Leonardo,
37(1):41–46, 2004.
[6] T. Hermann. Taxonomy and Deﬁnitions for
Soniﬁcation and Auditory Display. Proc. of the 14th
ICAD, Paris, 2008.
[7] W.-K. Lin Wang, Yuh-Ying; Hsu, Tse-Lin; Jan,
Ming-Yie; Wang. Review: Theory and Applications of
the Harmonic Analysis of Arterial Pressure Pulse
Waves. Journal of Medical and Biological Engineering,
30(3):125–131, 2010.
[8] T. Lossius, P. Baltazar, and T. de La Hogue.
DBAP-Distance-Based Amplitude Panning. In
Proceedings of 2009 International Computer Music
Conference, Montreal, Canada, 2009.
[9] Y. Nagashima. Bio-sensing Systems and Bio-feedback
Systems for Interactive Media Arts. Conference on
New Interfaces for Musical Expression, pages 48–53,
2003.
[10] D. Rosenboom. Biofeedback and the Arts: Results of
Early Experiments. Aesthetic Research Centre of
Canada, 1974.
[11] I. Veith. Introduction to the Nei Ching (The Yellow
Emperor’s Classic of Internal Medicine). University of
California Press, 1966.
[12] Y. Wang, S. Chang, Y. Wu, T. Hsu, and W. Wang.
Resonance, The Missing Phenomenon in
Hemodynamics.Circulation Research, 69(1):246–249,
1991.
[13] M. Wright and A. Freed. Open Sound Control: A
New Protocol for Communicating with Sound
Synthesizers. In Proceedings of International
Computer Music Conference, pages 101–104, 1997.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
83