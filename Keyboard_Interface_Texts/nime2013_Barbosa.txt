Illusio: A Drawing-Based Digital Music Instrument   Jerônimo Barbosa, Filipe Calegario, Veronica Teichrieb, Geber Ramalho Centro de Informática Universidade Federal de Pernambuco (UFPE), Brazil {jbcj,fcac,vt,glr}@cin.ufpe.br   
Giordano Cabral Departamento de Estatística e Informática Universidade Federal Rural de Pernambuco (UFRPE), Brazil giordanorec@gmail.com 
ABSTRACT This paper presents an innovative digital musical instrument, the Illusio, based on an augmented multi-touch interface that combines a traditional multi-touch surface and a device similar to a guitar pedal. Illusio allows users to perform by drawing and by associating the sketches with live loops. These loops are manipulated based on a concept called hierarchical live looping, which extends traditional live looping through the use of a musical tree, in which any music operation applied to a given node affects all its children nodes. Finally, we evaluate the instrument considering the performer and the audience, which are two of the most important stakeholders involved in the use, conception, and perception of a musical device. The results achieved are encouraging and led to useful insights about how to improve instrument features, performance and usability.  Keywords Digital musical instruments, augmented multi-touch, hierarchical live looping, interaction techniques, evaluation methodology 1. INTRODUCTION A digital musical instrument (DMI) “consists of a control surface or gestural controller, which drives the musical parameter of a sound synthesizer in real time” [12]. They can be separated in three parts: (a) the input module - that transforms a value from nature into a computable number; (b) the output module – responsible for the sound synthesis; and (c) the mapping module – a set of strategies responsible for mapping the input into the output module.   Although the DMI may have a simple model, analyzing its user experience (UX) is a complex task. Attempting to refine this UX analysis, experiments by designing, evaluating and analyzing DMIs were performed based on potential user's feedback [1,2], This led us to consider aspects beyond the traditional input, output and mapping ones, such as: (d) its body - e.g. ergonomics, appearance and portability of the device's physical body; (e) adhesion - any reason that would lead someone to be interested in using this instrument, like price, references of virtuous players; (f) and user profile - eg. how much suitable is the instrument to the musical style it plays.   Traditional aspects have been well explored: new interface technologies are opening a wide range of possibilities to new 
DMIs inputs [12], the great diversity of technologies related to sound synthesis [16] bring valuable opportunities to be applied to DMIs outputs and tools are concerned with turning the mapping more efficient [5,7]. However, new DMIs that are focused on exploring aspects like body and adhesion are far insufficient and, if we want to build more engaging instruments, all these UX aspects should be considered in the design process.   Regarding this subject, Norman [14] suggests an interesting approach to increase user's engagement with systems: the positive affect. The "positive affect arouses curiosity, engages creativity, and makes the brain into an effective learning organism". Incorporating this idea to our design process and aiming to explore both body and adhesion aspects, we set the following guidelines to the creation of a new DMI: • Playfulness & Visual aesthetics - related to the adhesion aspect, the DMI should resemble a playful environment where the user is encouraged to freely explore musical ideas. It should be visually expressive in a live performance, aiming to impact the audience; • Flexibility - related to the body aspect, the DMI should be easily customizable by users concerning their context and intention.  As a result, we propose the Illusio (Figure 1), an innovative DMI which is based on new interaction concepts - the sketch, the mockup and the navigating - that allow users to draw their own graphical interface (GUI) by sketching on an empty surface and by relating these sketches with real-time recorded loops during the performance (the mapping module). For that, it uses an augmented multi-touch interface as input module (that mixes a multi-touch surface with a device often used in the musical context, the guitar pedal), and the hierarchical live looping concept as output module (that extends the traditional live looping technique)1.  
 Figure 1. User performing with the Illusio  Finally, we evaluated Illusio considering the perspective of performers and audience. We have collected good preliminary                                                                     1 Detailed information about how the system works is available on: http://vimeo.com/25641586 
 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. NIME’13, May 27-30, 2013, KAIST, Daejeon, Korea. Copyright remains with the author(s).  
results as well as insights for future experiments and for future improvements of the instrument.  2. BACKGROUND As mentioned before, input, output and mapping aspects of DMI design and implementation have been well explored by the literature [7,12,16].  Although these works does represent an important and necessary advance in building DMI, they do not seem to be sufficient. Feedback collected from users in experiments related to DMI design [1,2] points out that the so-called body and adhesion aspects should be better investigated. Of course, these two aspects have already been indirectly addressed in previous approaches, but, as they were not intended to explicitly target these aspects in the DMI, results are not conclusive.   Concerning the body aspect, examples include classical Moog synthesizers, more recently, Mutantrumpet2 and Tod Machover's hyperinstruments [11]. These works gave good hints about how instruments can be played by inheriting affordances of traditional instruments. As a consequence, this approach does not work with instruments that do not match the category of "augmented instruments".   Concerning the adhesion aspect, some instruments provided several insights. The most notable of them are the Reactable (that is also an interesting body aspect example, which will be explained in the following section) [10] and the Laser Harp3 that reached relative popularity outside the academic context and was successfully incorporated in artistic performances.  2.1 Augmented Multi-touch Multi-touch technologies have emerged since last decade as a powerful tool for developing interactive user-friendly applications and have been successfully used throughout several areas, including the musical context [6]. Despite its advantages, this technology has shown some sensitive drawbacks when is musically applied. One of them is the lack of haptic feedback, which in some cases may decrease the accuracy of a musical performance [13].  Aiming to overcome a similar issue, the game industry has recently bet on an interesting solution: mixing multi-touch with traditional approaches already consolidated in the game context, like keys and buttons. Two remarkable examples are the Nintendo Wii U and the PlayStation Vita.  In this work, we call augmented multi-touch technologies the ones whose lack of haptic feedback was overcome by using auxiliary technology that needs to be physically manipulated and that was inspired by traditional approaches already consolidated in musical context. One practical example is the previously mentioned Reactable [10], which mixes a multi-touch surface with the use of physical cubes, each one containing symbols on its faces, which can be controlled like real knobs. 2.2 Hierarchical Live Looping Live looping is a technique used for creating complex musical structures by using delay effect and real-time sampling, through continuous repetition of layers of sounds recorded by the performer at the moment of the performance, providing an "one-man-band" experience.  The popularization of this technique has resulted in commercial development of several live looping tools (eg. Ableton Live, SooperLooper and several Boss products, like the RC-300). Besides new DMIs are being developed based on                                                                     2 http://www.benneill.com/about/ 3 http://www.harpelaser.com/ 
the creative use of live looping as their output modules. Two examples are the BeatBugs [19] and the SoundCatcher [18].  A common problem in this kind of systems is that they are frequently based on linear structures, so that audio manipulations can be only applied to single loops - or, otherwise, to all of them at the same time.  Aiming to overcome this problem, Berthaut et al. have developed a concept called Hierarchical Live Looping (HLL) [4] that allows performers to group live loops, by using a musical tree in which any music operation applied to a given node affects all its children (instead of only single loops), extending traditional live looping.  They also developed a new DMI to test the concept, the DRILE [4], but no other attempts have been done in literature to explore it since then. 3. ILLUSIO Considering that body and adhesion aspects should be more explored in order to design more effective DMIs, we designed a new instrument that tried to focuses upon them: the Illusio - a new digital musical instrument that allows users to perform by drawing sketches and by associating them with live loops.  As we believe that augmented multi-touch is a powerful concept yet to be fully explored, we chose it for Illusio's input module by combining a traditional multi-touch surface with a device similar to a guitar pedal. Due to the same reason, we chose HLL for Illusio's output module.   The Illusio's mapping module allows performers to control hierarchical live loops by drawing sketches and by associating them with sounds. It was designed to encourage people to freely explore and prototype new musical ideas by allowing users to draw their own interface to control real-time recorded loops through the HLL musical tree, aiming to provide a one-man-band experience. It is focused on multi-instrumentalist musicians already experienced. Thus, its mapping module is based on drawing rough sketches on an interactive surface. After drawn, these sketches can be edited, grouped, removed and subjectively associated to live loops - recorded with one or more instruments connected to a input mixer - by using the pedal. In the final step, users can freely manipulate these sketches through the interactive surface. 3.1 User Experience Illusio’s user experience was created to allude to a child painting on blank paper - mixing dreams, reality, images and sounds - allowing users to draw their own user interface. The fundamental goals are: • To resemble a playful environment where the user is encouraged to freely explore musical ideas; • To be visually expressive in a live performance aiming to impact the audience; • To provide an environment where the users are free to experiment their own interface, building elements with shape and size that seem appropriate to their intentions. In order to achieve this, its mapping module is based on three concepts: sketches, mockups and navigation. Each one is further described in the following subsections. 3.1.1 Sketches A sketch is a rough drawing made by the user and is responsible for storing live loops. It is the main concept behind Illusio and could be considered a leaf in the HLL musical tree.  Users may create sketches by pressing and moving their fingers against the multi-touch surface as shown in Figure 2. A sketch is considered finished when the shape is closed.  
Thereafter, it can be selected by touch. In this case, they can also be freely moved by dragging the finger. 
 Figure 2. User drawing a sketch  After created, the sketch is ready to be associated with any loop. This can be achieved through its selection and by recording a new loop using the pedal. Sketches that are associated with loops have a small timer inside it, so the user can distinguish from sketches not yet associated.  When this association is completed, it is possible to play or stop loops by using the pedal - that also allows users to delete any sketch at any time. While a spinning line in the center of the sketch is used to represent playing loops, a point is used to represent stopped loops, as shown in Figure 5. 3.1.2 Mockups Mockups are a subtype of sketch that, instead of live loops, stores other sketches (including as well as other mockups). Thus, any music operation applied to a given mockup will affect all sketches stored inside of it, playing the role of a node in the HLL musical tree. 
 Figure 3. Grouping two sketches into a mockup  Mockups aim to gather different loops into a single structure, triggering them together - by playing or stopping. Besides, it allows reducing the visual complexity of sketches. There are two ways for creating them: • By selecting sketches already created and using the pedal afterwards, like shown in Figure 3; • By opening an empty sketch - thereby, not associated with any loop - and then creating a new sketch inside of it (concept to be explained in the next section). 3.1.3 Navigation Sketches and mockups are organized in a tree structure (the HLL musical tree). Thus, navigation is the concept that allows users to navigate through this structure and to edit sketches and mockups in real-time.  For navigating, users should open or close objects. Both can be achieved by applying pinch gestures on the surface. To open a sketch, users should apply a pinch gesture inside the sketch area. To close a sketch, the gesture should be applied in an area where there are no sketches.  When a sketch associated with a loop is open, it is possible to visualize the loop’s waveform and then change it by drawing a new waveform. Besides, it is also possible to apply sound effects.  When an empty sketch is open (with no loop associated) a new stage is shown. There, it is possible to create new sketches, which will automatically become children of the former sketch – that, in turn, will be transformed into a mockup.  Finally, when a mockup is open, its content (sketches and mockups inside the mockup) is displayed on the screen. These objects can once again be navigated as described above, until reaching the leaves. 
3.2 Technical Description Technically, Illusio comprises three components: the pedal, the interactive surface and the software.  The pedal component is responsible for triggering which functionality should be activated. It was built using a QWERTY USB keyboard whose keys were all removed but three and afterwards covered with black tape, as shown in Figure 4.  
 Figure 4. The pedal  The interactive surface component is responsible for allowing multi-touch interaction. It was built from a DIY multi-touch table, based on the Frustrated Total Internal Reflection (FTIR) approach [13] (using Community Core Vision4 as tracker). It was approximately 1 meter high and its superior structure consists of a rectangular white board made of acrylic and waxed paper. Its structure was made of a projector responsible for visual feedback and cheap components like PVC tubes, tapes, mirrors, swabs. 
 Figure 5. Illusio’s software, composed by playing and stopped sketches  The software component is the core of the instrument and can be separated in two different modules: (a) the black & white visual interface (illustrated in Figure 5), developed using Processing, responsible for handling user input gestures and represented by an empty screen containing rough sketches; and (b) the sound looper, developed using Openframeworks/C++, responsible for dealing with the audio output. Both modules communicate via Open Sound Control (OSC) messages. 4. EVALUATION According to O’Modhrain's [15], a complete DMI evaluation should cover different points of views: (a) The performer's view - How effective is the relationship between performer and device in a manner that the second allows the first to concretize all his musical intentions; (b) The audience's view - How effective is the relationship between performer and device in a manner that could affect sensitively the ones who watch the performance? (c) The manufacturer's view - How effective is the system under a commercial perspective?  In the present work, the Illusio prototype was tested and evaluated by the two first stakeholders – the performer and the audience. As we are interested in iteratively improving the prototype, our main goal here was to analyze Illusio's UX aspects, aiming to collect insights about how to improve instrument features, performance and usability. All material collected is open and available for consultation5.                                                                     4  http://ccv.nuigroup.com/ 5 http://www.cin.ufpe.br/~jbcj/illusio-evaluation 

4.1 Performer’s View Aiming to evaluate the performer’s view, a qualitative experiment was conducted based on previous work [1].  The experiment was performed with 4 people that matched the profile desired for Illusio users. They were aged 24-29 and all had some familiarity with technology and a strong background in music: 2 professional musicians (users 2 and 4) and 2 amateur musicians (users 1 and 3), all playing at least two instruments for at least 6 years). Concerning this, they were asked to bring their favorite instruments in order to use them as Illusio’s sound input.  The process was divided into two stages: the data collection and the data analysis. 4.1.1 Data Collection During data collection, each participant had two different moments to test Illusio, one free - in which they had to explore the system without receiving any information about how it works - and another guided - in which they were told in details how the system works. They were also asked to have in mind that these moments should be considered rehearsals for a public presentation that would happen in a third moment so that they would have to be concerned about preparing a short performance using Illusio.    A semi-structured interview followed each rehearsal. Its structure was based on the UX aspects already presented, plus some questions concerning user profile (background in technology and music):  • Input – Questions related to the actions required for the performer to interact with the device and his experience with the input technology used for this purpose; • Output – Questions related to the sound result produced by the instrument, including its versatility, expressivity and suitability to the genre of music the participants were used to play; • Control – Questions related to how the performer played the instrument and the mapping between input and output; • Body – Questions related to the physical body of the device, including ergonomics, appearance and portability; • Adhesion – Questions related to the reasons that would lead someone to play this instrument, including price, motivation, repertory and others. • General – Questions that could not fit any of the previous categories.  It was stressed to participants that their answers should regard their own personal context (eg. the genre of music and kind of instruments they are used to play, etc.) and not abstract generalizations. This stage took in average 40-50 minutes per solo session for each participant, in which 20-30 minutes were dedicated to semi-structured interviews, totalizing around 8 hours. 4.1.2 Data Analysis During the data analysis, all collected material was analyzed using Discourse Analysis (DA) - a technique that allows the analysis of the discourse by finding patterns across texts, as well as social and cultural contexts in which the texts occur. As different approaches to DA are possible, an already successful approach was adopted as used in [17].   4.1.2.1 User 1 User 1 was the youngest (24 years) and the one who had less experience with music (6 years) between the participants. He 
had limited experience with touch technologies (“rarely”) and had never used guitar pedals.  The user did not easily understand the instrument and gave generic and inconclusive answers during free exploration. Handling multiple inputs (the tablet, the pedal and the instruments) in a small place was also reported as a problem.   During the guided exploration, his main complaints concerned the pedal hardware and the fact that it was “hard to put” loops “into the time he wanted”. He also hesitated about answering if it would be feasible to play songs from his repertoire using the prototype because his “songs are more conventional and are not very repetitive”. 4.1.2.2 User 2 User 2 was an experienced musician that has been studying music for 12 years. Although he had no previous experience with guitar pedals or multi-touch technologies, he had a strong background in technology.  He defined the pedal as “bad and not usable” due to problems like its high latency, its bad design (“some keys were bigger than others”) and the difficulty of “pressing a key without pressing others”.  During the free exploration, for him, “there was no feedback at all” and the system did not make sense (“sometimes I do the same thing and get different results”), what made him feel “angry and frustrated”. However, he changed his opinion during the guided exploration, when he was able to understand the system “completely” (“100%”).  The sound output was considered “transe music” with “limited expressivity” but he felt excited about using it in one of his works (“it’s suitable”). 4.1.2.3 User 3 User 3 described himself as an amateur musician that loves percussive instruments. He said he uses technology in his leisure time but hardly has experience with touch technologies and none with guitar pedals.  His inexperience with the technology strongly influenced his performance. Despite of it, he was the fastest in learning how it worked in the free exploration moment.  The prototype was considered versatile and its sonority was praised, but the user criticized his “low expressivity” because of the complex controls (“I would mix things up”). For him, such control could allow more powerful possibilities (like “controlling volume and effects”).  During the guided moment, the user explored the system in a musical way and perceived problems with synchronizing loops (“to put everything to play on right timing”). 4.1.2.4 User 4 Among all participants, User 4 was most experienced in music, playing in several bands for more than 20 years. He had experience in guitar pedals and in looper stations.  During free exploration, he thought “it was hard to understand the concept” because the system did not presented any help guide. After having an overview, he described the system as easy to understand but not ready for new users as “it was not instructive”.  As soon as he started to understand how it worked, he started to get bored. He scored the shortest time on experimenting the prototype but also was the one who showed more intimacy with it.   He said the instrument was versatile but it “was not organic” (as he could not change the original tempo) and always transformed his music into “mantra music”, “not designed to allow improvisation” (due to the repetition).   The pedal was described “as highly problematic” as he could not easily synchronize his loops (he could not understand if it 
was his or the keyboard’s fault) and the hardware used was not suitable to be used with feet, as it was “too sensitive”. 4.2 Audience’s View The process of perceiving a musical performance is a complex phenomenon that is intrinsically influenced by social, cultural, technical, perceptual and emotional background [2]. Thus, we decided to focus the present work on the audience's understanding of how the DMI works - as well as the kind of interaction it employs - since: (a) it engages with communicative and cognitive issues, which are understood to be sensitive in this context; (b) we believe that it can be objectively measured, as suggested by previous attempts [8].  The process employed for that was already described in detail in a previous work [2]. It consists of three steps: (a) audience profiling – which collects information about candidates participating in the experiment and compares it to the target audience profile; (b) data collection – which collects data from the target audience; and (c) data visualization – which aims to show the information to helps us to further analyze the results. The evaluation is based on the human-human communication aspects presented by Gurevich and Cavan Fyans [9] and Bellotti et al. [3], as follows:  • Cause comprehension - "Which part of the performer's body (or yet, which technological device) was used to interact with the system?"; "How understandable are the actions made by the user for interacting with the system?”; • Effect comprehension - "Did the system provide enough audiovisual information for the audience to understand what is happening between the user and it?”; • Mapping comprehension - "How clear is the relationship between the user's actions and the resulting sound?”; • Intention comprehension - "How successful was the user to express himself using the system?"; "Was the user's intention well understood?”; • Error comprehension - "Were the system's errors perceived (e.g. technical problems and software bugs)?"; "Were the user's errors noticeable?”. 4.2.1 Audience Profiling Regarding the audience profiling stage, 80 participants were contacted by e-mail and were asked to answer a profile test. Among them, 47 were selected due to their accordance with the target profile: people with some relation with technology and music (scored 3, 4 or 5 in a 1 to 5 scale) and who play musical instruments. 4.2.2 Data Collection and Visualization In the data collection step, the selected participants were then contacted by e-mail, asked to watch a video of a performance with the Illusio6 and answer an online questionnaire.  Concerning the cause comprehension degree, 46% of the participants marked 4 and 35% marked 5 in a scale from 1 to 5 (where 1 is "Did not understand" and 5 is "Completely understood"). Besides, taking into account a list of body parts and also a list of interaction devices in the questionnaire, the majority indicated the actual body parts and devices used during the performance, indicating a match between perceived and actual understanding. The calculated average related to this axis was 3,83 in a scale from 0 to 5.                                                                     6 http://youtu.be/CAiVWvVFaqI 
 In respect of the mapping comprehension degree, 41% of the participants marked 4 and 35% marked 5 (considering a scale from 1 to 5, where 1 is "Did not understand" and 5 is "Completely understood"), which shows that the mapping was considered well understood by the majority of the audience. We have also used an open question: “Describe in few words how does the system work”. Only a few participants mentioned what the user did for reaching system’s outputs, fact that has hindered the accuracy measure of mapping results. The calculated average value related to this axis was 3,8.  Considering the audience's understanding of which output the system is generating, 68% of the participants marked 3 or 4 (35% answered 3 and 33% answered 4) in a scale from 1 to 5 (where 1 is "I do not agree" and 5 is "I completely agree") and only 13% marked 5. This result shows that the system's output effects were not evaluated by the audience as well as the user’s actions. The calculated average value related to the effect axis was 2,91. We believe that functionalities implemented only as stubs (which had no effect when the performer tried to use them on the video) could be a possible reason for this result.   When the issue was the intention comprehension degree, 79% of the participants marked 4 or 5 in a scale from 1 to 5. However, once again, the usage of open questions did not help to verify the accuracy of these results, as the answers were very abstract and confusing, hindering any attempt to match positively or negatively perceived and actual understanding. The calculated average value related to this axis was 3,87.  Concerning the error comprehension degree, 30% of the participants marked 5 and 59% marked 4 in the 1 to 5 scale, what seems suitable as the system and the performer actually presented only a few errors during the performance. However, once again the usage of auxiliary questions did not help to verify the accuracy of these results, as 74% of the participants mentioned that they have not perceived any error, which may indicate that the system does not highlight occurrences of errors. The average value related to the error axis was 2,67.  According to these results, the Illusio datasheet was created, as shown in Figure 6. 
 Figure 6.  Illusio’s datasheet 5. RESULTS Regarding the performer view, all participants enjoyed the prototype and said to be excited about exploring it in the future (except User 4). It presented good results regarding adhesion, what could signalize that our design guidelines were useful and the instrument could be powerful in attracting new users. Regarding this, it would be important to improve initial feedbacks so that they could guide novices - as this was the most commented point concerning the control aspect.  The guidelines proposed were also proved to be useful regarding part of the body aspect, as the graphical user interface received very good reviews. However, the same did not happen with its physical body, which received bad reviews regarding 

the hardware (eg. "ugly", "not usable"), mainly concerning the pedal.   Some other aspects were also proved to be sensitive and should be considered in later improvements. One example is the input. Although considered intuitive to use, the pedal - once again - was heavily criticized due to its fragility and the fact that sometimes it was hard to put loops in the right time (what could have been caused by the algorithm used for synchronizing them).  Another aspect that deserves attention is the output, described as limited (“mantra music”, “not organic”, “does not allow improvisation” - mainly among the most experienced musicians). In addition, as no further controls (like volume control) were given, it sounded like a simple loop station - but much more expensive. Regarding the audience view, the effect aspect (the audience's understanding of which output the system is generating) and the error aspect (understanding of mistakes made by the user and the system) seemed to be the most sensitive and should be considered in a future redesign of the instrument.  Another sensitive point does not concern the DMI itself but the evaluation method used. Although the open questions used in the questionnaire provided good parameters for reducing the gap between perceived and actual understanding it did not properly work for all cases (specially the intention axis) due to the fact that some answers were superficial, which did not give any hint about how to match both understandings. This could have introduced some noise into the achieved results. 6. CONCLUSION We presented here the Illusio - a new innovative digital musical instrument that allows users to perform by drawing sketches and by associating them with live loops. These loops are manipulated based on a concept called hierarchical live looping, which extends traditional live looping through the use of a musical tree, in which any music operation applied to a given node affects all its children nodes. Illusio has an augmented multi-touch interface that combines a traditional multi-touch surface and a guitar pedal like device. It works through interaction techniques based on 3 main concepts: sketches, mockups, navigating. Finally also we evaluated the instrument considering the performer view and the audience view, these evaluation provided important information that can be used on next development cycles.  As future work, we hope to improve the system by using these results and then re-evaluating the new prototype with new users. We believe that this approach – a cycle of evaluation processes in which user feedback is constantly used to improve the system, always concerning all DMI's UX aspects – could be a promising way to build more effective and contextualized DMIs. 7. ACKNOWLEDGMENTS Special thanks to the Wouwlabs group, the MusTIC group, Francisco Magalhães, Patrick McGlynn and all participants who kindly accepted to take part of the experiments. Illusio was developed with the partial support of Rumos Itaú Cultural Cybernetic Arts. 8. REFERENCES [1] Barbosa, J., Calegario, F., Magalhães, F., Teichrieb, V., Ramalho, G., and Cabral, G. Towards an evaluation methodology for digital music instruments considering performer’s view: a case study. Proceedings of 13th Brazilian Symposium on Computer Music, (2011). 
[2] Barbosa, J., Calegario, F., Teichrieb, V., and Ramalho, G. Considering Audience’s View Towards an Evaluation Methodology for Digital Musical Instruments. NIME  ’12 Proceedings of the 2012 conference on New interfaces for musical expression, (2012). [3] Bellotti, V., Back, M., Edwards, W.K., Grinter, R.E., Henderson, A., and Lopes, C. Making sense of sensing systems: five questions for designers and researchers. CHI ’02 Proceedings of the SIGCHI conference on Human factors in computing systems, (2002), 415–422. [4] Berthaut, F., Desainte-Catherine, M., Hachet, M., and others. DRILE: an immersive environment for hierarchical live-looping. NIME  ’10 Proceedings of the 2010 conference on New interfaces for musical expression, (2010), 192–197. [5] Bevilacqua, F., Müller, R., and Schnell, N. MnM  : a Max / MSP mapping toolbox. NIME  ’05 Proceedings of the 2005 conference on New interfaces for musical expression, (2005), 85–88. [6] Buxton, B. Multi-Touch Systems that I Have Known and Loved. Microsoft Research 56, 2007, 1–11.  [7] Cont, A., Coduys, T., and Henry, C. Real-time Gesture Mapping in Pd Environment using Neural Networks. NIME  ’04 Proceedings of the 2004 international conference on New interfaces for musical expression, (2004), 39–42. [8] Fyans, A. and Gurevich, M. Spectator understanding of error in performance. Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, (2009), 3955. [9] Gurevich, M. and Cavan Fyans, A. Digital Musical Interactions: Performer–system relationships and their perception by spectators. Organised Sound 16, 02 (2011), 166–175. [10] Jordà, S., Geiger, G., Alonso, M., and Kaltenbrunner, M. The reacTable: exploring the synergy between live music performance and tabletop tangible interfaces. Proceedings of the 1st international Conference on Tangible and Embedded interaction, ACM (2007), 139–146. [11] Machover, T. Hyperinstruments: A Progress Report, 1987-1991. 1992. [12] Miranda, E.R. and Wanderley, M.M. New Digital Musical Instruments: Control and Interaction Beyond the Keyboard. A-R Editions, 2006. [13] Montag, M., Sullivan, S., Dickey, S., and Leider, C. A Low-Cost, Low-Latency Multi-Touch Table with Haptic Feedback for Musical Applications. NIME  ’11 Proceedings of the 2011 conference on New interfaces for musical expression, June (2011), 8–13. [14] Norman, D.A. Emotional Design: Why We Love (or Hate) Everyday Things. Basic Books, 2004. [15] O’Modhrain, S. A framework for the evaluation of digital musical instruments. Computer Music Journal 35, 1 (2011), 28–42. [16] Roads, C. The Computer Music Tutorial. MIT Press, 1996. [17] Stowell, D., Robertson, A., Bryan-Kinns, N., and Plumbley, M.D. Evaluation of live human–computer music-making: Quantitative and qualitative approaches. International Journal of Human-Computer Studies 67, 11 (2009), 960–975. [18] Vigliensoni, G. and Wanderley, M. Soundcatcher: Explorations in audio-looping and time-freezing using an open-air gestural controller. Proceedings of the International Computer Music Conference (ICMC), (2010), 100–103. [19] Weinberg, G. The Beatbug – evolution of a musical controller. Digital Creativity 19, 1 (2008), 3–18. 