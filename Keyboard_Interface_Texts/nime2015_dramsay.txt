GroupLoop: A Collaborative, Network-Enabled Audio
Feedback Instrument
David B. Ramsay
Responsive Environments
MIT Media Laboratory
20 Ames St.
Cambridge, MA 01239
dramsay@media.mit.edu
Joseph A. Paradiso
Responsive Environments
MIT Media Laboratory
20 Ames St.
Cambridge, MA 01239
joep@media.mit.edu
ABSTRACT
GroupLoopis a browser-based, collaborative audio feedback
control system for musical performance.GroupLoopusers
send their microphone stream to other participants while
simultaneously controlling the mix of other users’ streams
played through their speakers. Collaborations among users
can yield complex feedback loops where feedback paths over-
lap and interact. Users are able to shape the feedback
sounds in real-time by adjusting delay, EQ, and gain, as
well as manipulating the acoustics of their portion of the au-
dio feedback path. This paper outlines the basic principles
underlyingGroupLoop, describes its design and feature-set,
and discusses observations ofGroupLoopin performances.
It concludes with a look at future research and reﬁnement.
Author Keywords
Audio feedback, internet browser, WebRTC, laptop music,
audio streaming, audio networks, collaborative instrument
1. INTRODUCTION
Audio feedback occurs when the output of a speaker is ream-
pliﬁed by the microphone that is driving it. In other words,
feedback occurs whenever there is a loop by which an audio
signal will repeatedly be combined with a delayed copy of
itself.
Most people associate audio feedback with an undesir-
able, piercing tone. However, feedback has an illustrious
history as a tool for musical expression. Pioneered in the
1960’s by the likes of Pete Townshend, Jimi Hendrix, and
Pink Floyd, feedback quickly became an integral part in
the rock guitar lexicon. Outside popular music, composers
like Steve Reich (Pendulum Music, 1966), laid the frame-
work for innovative feedback architecture [1]. Recent works
by David Lee Myers (i.e. ”Feedback Chains”) as well as
Christian Carriere and Toshimaru Nakamura (icons of the
’no-input’ mixer genre) drive the ﬁeld forward [2].
Several musicians have designed instruments speciﬁcally
for the creation of feedback music. Andrew McPherson is
known for feedback designs based on pre-existing acoustic
instruments [3]. Composers like Je↵ Morris and Nicolas
Collins have created platforms that inject a range of e↵ects,
manage the mixing of multiple acoustic paths, and, in some
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’15,May 31-June 3, 2015, Louisiana State Univ., Baton Rouge, LA.
Copyright remains with the author(s).
instances (i.e. Collins’ ”Pea Soup”), actively monitor and
regulate feedback behavior [4][5].
Experimental network music also gained momentum start-
ing in the 1950’s with eary cybernetic artwork. As telecom-
munication infrastructure has improved, networked music
performance (NMP) has become one of its dominant cur-
rent incarnations. Laptop orchestras and high-speed Na-
tional Research and Education Networks (NRENs) are now
common platforms for experimentation in collaborative and
emergent network music generation. The web browser has
also seen growth in the collaborative music space, with ap-
plications such as Plink, Jam with Chrome, and Soundtrap.
These platforms and applications are not typically de-
signed to create feedback music, however. The intersection
of networked audio and feedback music has been explored
in a handful of isolated work. Ritsch’s ”I am playing in one
netroom” (2010) and Davis (et al.)’s ”The Loop” (2012) are
two notable examples of internet based feedback designs.
GroupLoopﬁts in the tradition of these feedback systems,
with several notable innovations.GroupLoopis a browser-
based feedback performance system that connects multiple
acoustic spaces from anywhere in the world. It was de-
signed to easily enable collaboration between multiple users
across skill level and geography.GroupLoop’s decentralized
architecture allows rapid growth in system complexity while
maintaining its real-time conﬁgurability.
GroupLoopis available atfeedback.davidbramsay.com.
2. PLAYING AND CONTROL
Grouploop’s software connects to the local computer’s de-
fault soundcard and forms streaming peer-to-peer audio con-
nections with otherGroupLoopusers over the internet. Par-
ticipants control their output by mixing of the incoming
microphone streams. Any audio transmitted through the
speakers is recaptured by a user’s microphone and sent back
out over the network to collaborators. The number of simul-
taneous users– and thus the number of available speakers
and microphones– is only limited by the processing power
of the host computers and network speed.
The networked design ofGroupLoopa↵ords players con-
trol over the creation, alteration, and interaction of multi-
ple simultaneous feedback paths through multiple acoustic
spaces. The real-time, distributed control of this evolving
process– allowing the user to selectively turn on or o↵ an
incoming stream and adjust the volume accordingly– is the
fundamental user interaction within the instrument.
Users can vary the sound of the instrument both before
and during performance. Real-time controls on the outgo-
ing audio include a highly-responsive graphic EQ and vir-
tual knobs for delay, microphone gain, and EQ strength.
Users can manipulate the feedback sound by increasing the
gain (up to 20 dB) or adding up to two seconds of delay to
251
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
Figure 1: GroupLoop UI
their microphone stream. The EQ features nine adjustable-
Q, resonant bandpass ﬁlters. The maximum gain of these
ﬁlters is plus/minus 40 dB of gain, with the option to add
an additional 80 dB.
Users can further manipulate their sound by altering mi-
crophone/speaker selection, external signal processing (i.e.
limiters), system geometry, and environmental acoustics.
Advanced users can go beyond the use of built-in com-
puter microphone and speakers to set up complex and time-
varying acoustic systems like those described in Reich and
Morris. Moving, covering, touching, or otherwise modifying
the acoustic elements (e.g. speakers, microphones) during a
performance are simple but e↵ective ways to interact with
the instrument. In [6], the inventors of Laptap provide a
thorough overview of acoustic interventions to ’play’ feed-
back loops for a ﬁxed laptop geometry.
Finally,GroupLoopincludes a built-in MIDI synthesizer
to inject source material into the feedback process. MIDI-
enabled participants may also use their MIDI modulation
wheel to control the volume of incoming audio streams,
or automatically mute/play each stream in synchrony with
synthesizer notes.
2.1 Source Material
There are four types of input signals that drive the feedback
process: environmental sounds, recorded audio, embedded
synthesis, and self-noise.
The most basic input is from players shouting, singing,
clapping, or otherwise introducing self-made (i.e. environ-
mental) sounds into their feedback paths using the micro-
phone. Audio recordings can also be used by playing them
on theGroupLoopcomputer through the system speakers.
Recordings can be routed directly into the outgoing micro-
phone streams with high ﬁdelity using services like Sound-
Flower [7].
The embedded MIDI synthesizer, which takes advantage
of the Web MIDI API (an experimental feature only avail-
able in Chrome) [8], is another option for input. The user
can add/remove oscillators, modify their harmonic relation-
ships, and change the volume, attack, decay, and porta-
mento for each. Sine, square, triangle, and saw-tooth waves
are available, and oscillators can be mapped to MIDI input
notes in a variety of novel ways. For instance, each oscillator
can be assigned– based on chord voicings– to only the low-
est sounding note, the second lowest, the highest, etc. This
output is directly mixed into the user’s microphone stream,
with an option to sustain the audible notes indeﬁnitely.
With enough gain,GroupLoopwill begin feeding back
without an apparent input. In this case, the ampliﬁcation of
the noise ﬂoor of the system is enough to result in a growing
feedback state with each loop iteration. This method of
feedback is easily controlled with EQ.
GroupLoop’s EQ gain scale was chosen to make it easy to
achieve self-noise feedback across all frequencies on a 2013
MacBook Pro laptop. There is additional equalization up-
stream of the UI to bias the system towards a more even
self-feedback response over frequency by boosting the bass
and attenuating the high end.
252
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
2.2 Visual Design
The features described above are laid out in three visual
sub-sections, as shown in Figure 1. The top two panels
a↵ect audio leaving the computer, while the last section
controls incoming connections.
The top panel is hidden unless a MIDI device is plugged
in. It reveals theGroupLoopsynthesizer, divided into an os-
cillator bank on the right and control parameters on the left.
The microphone/synthesizer output stream is visualized in
the second section, with a real-time spectrum analyzer, a
conﬁgurable EQ, and other associated controls.
The last block shows all available incoming streams with
on/o↵ and volume controls. Whenever a new user logs into
the service, they automatically appear as an input in this
section of the UI. A chat feature is included to help coordi-
nate performances and encourage collaboration.
Figure 2: Potential GroupLoop networking topolo-
gies. (A) represents the current implementation,
(B) shows a computationally expensive alternative,
and (C) introduces a future, centralized server.
3. AUDIO NETWORKING
Networking is at the core of theGroupLoopplatform. Be-
cause of this,GroupLoopwas developed for the Google
Chrome browser using Node and Javascript. It takes ad-
vantage of HTML5 and other advanced browser function-
ality, including Web MIDI (which is only implemented in
Chrome), WebRTC, and Web Audio APIs. Webrtc.io, Web-
MIDIAPIShim, jQuery, jQuery Knob, and jQuery RangeS-
lider open source libraries are also used.
3.1 WebRTC and its Limitations
While there are recent examples of collaborative perfor-
mance over private, high-speed NRENs, public internet la-
tency still renders traditional real-time ensemble perfor-
mance impractical [9][10]. NMP research typically focuses
on strategies to either cope with this latency or incorporate
it into a network-based e↵ect (like reverb) [11]. In the con-
text of feedback performance, however, 60-300ms of delay
is tolerable and often desirable.
WebRTC is a relatively new W3C standard [12], with
working desktop implementations in Google Chrome, Mozilla
Firefox, and Opera. This API o↵ers simple, browser-based,
peer-to-peer media streaming. Connections based on the
Opus codec and a customizable Session Description Pro-
tocol o↵er full-band (48k sampling rate) and sub-100ms
latency audio performance, subject to network speed con-
straints. If the connection slows, Opus is capable of transi-
tioning to a lower sampling rate in real-time, preserving the
stream but temporarily reducing bandwidth [13].
Early adoption of any technology has certain drawbacks.
WebRTC implementations in Firefox and Chrome di↵er sub-
stantially, constantly evolve, and lack reﬁned documenta-
tion. One notable feature– the ability to process incom-
ing network peer audio connections through the Web Audio
API before playing them out of the speakers– is currently
unsupported in Chrome [14].
3.2 Network Topologies and Control
Several of theGroupLoopdesign choices follow naturally
from the Chrome WebRTC implementation. Control for
equalization and delay is placed on the outgoing connection,
as shown in (A) of Figure 2. To instead map the UI to a↵ect
the audible, incoming connections would require duplicating
the audio processing of (A) on every upstream device, with
control parameters sent remotely over a data socket link
(B). The current implementation already approaches the
limit of in-browser computation, making (B) impractical.
Grouploopcreates a true peer-to-peer, fully connected
mesh network, which provides the most conﬁgurable, lowest-
latency topology. However, this also means that forN users,
each device hasN-1 bi-directional full-band connections.
Tests have shown that up to ten users can operateGrou-
pLoopin the fully connected conﬁguration without perfor-
mance degradation. For larger networks, a central rout-
ing server, called an MCU (Multipoint Control Unit), could
drastically reduce the number of streaming connections at
the cost of increased latency [15]. Solutions currently exist
that o↵er basic WebRTC MCU routing services. With ad-
ditional e↵ort to port Web Audio functionality to the MCU
environment, audio processing might also be o✏oaded to
the MCU (Figure 2-C).
4. PERFORMANCE
GroupLoopwas debuted in December 2014 with a live per-
formance by three trained musicians at the MIT Media Lab.
Four laptops runningGroupLoopwere conﬁgured with ex-
ternal soundcards, speakers, and microphones, and placed
around a large shared performance space. An additional
machine was set up in a remote location.
This model of expert collaboration in a shared space was
chosen to demonstrate advanced performance technique. To
shape an audio stream without knowing where in the room
or how loud it will be played demands careful listening and
group coordination. The additional remote computer rep-
resents how a novice might collaborate. The extra node was
exploited by the experts as an e↵ects processor might be–
selectively pulled into their feedback paths to change the
sound quality. It is evocative of a many-to-few performance
model, in which several novice users remotely collaborate
with a handful of centralized, expert musicians.
Performance withGroupLoopis unrepeatable and di -
cult to control, and composition for the platform is a form
of process music. In group settings,GroupLoopdemands a
high level of skill and understanding to play, with narrow
margins for error. It remains accessible, however, for novice
users interested in simpler contributions.
5. FUTURE WORK
In its current design,GroupLooplends itself to two system
topologies: (1) experienced players using the platform in
a shared space together collaboratively, and/or (2) novices
around the world setting up simple remote systems that the
experts may exploit.
Iterations ofGroupLoopthat granted MIDI-enabled users
additional control over their output stream were sonically
limited and unintuitive to use. Fundamental changes in the
balance of control or network topology are more likely to
generate compelling new instrument designs. One example
is a master/slave topology- in which one central user has
253
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
Figure 3: GroupLoop in use during a three musician
live performance. Notice the external speaker and
microphone feedback elements, as well as the MIDI
controller.
complete control over a star or mesh network. Performance
with this design could include the ability to send di↵erent
streams out through each feedback loop, splitting individ-
ual notes in a synthesizer chord (or other inputs) between
downstream users.
These concepts generally share the assumption of a cen-
tralized performance space with remote contributors. One
impediment to this design is the lack of a monitoring so-
lution for remote participants. Monitoring requires an ad-
ditional audio stream from the performance space to each
user and signiﬁcant additional setup. It represents a trade-
o↵ between ﬂexibility and ease of use, and forGroupLoopa
low barrier to entry was paramount. However, for perfor-
mances featuring a small set of experienced remote users,
monitoring would be important.
Furthermore, this system is suggestive of simultaneous,
linked, remote performances. To enable this type of collab-
oration, a solution that tightly couples the user controls to
the local aural experience is required. Updates to Chrome’s
WebRTC implementation may make this an easy modiﬁca-
tion in the near future– otherwise, a change in platform or
a sophisticated control paradigm will be required.
There are other areas for improvement in the core plat-
form. A more sophisticated visualization of the network
would be useful to manage complex loops in real-time. An
MCU server would enable support for more simultaneous
connections with a small increase in latency. Additional
signal processing for modifying and controlling the feedback
path could also be beneﬁcial, although the current design
is close to the limit of real-time browser computation. Of-
ﬂoading part of the processing to a powerful MCU could
address this limitation, though it would require a signiﬁ-
cant investment in custom software architecture.
6. CONCLUSIONS
GroupLoopwas created to enable the collaboration of users
across all skill levels and geographies. Performance with the
platform suggests success, as it is simple enough to start by
opening a browser on a laptop, but extensible enough to
invite complex acoustic design and virtuosic mastery. As
an instrument, it presents the player with challenges that
are both technical and artistic. It is capable of diverse and
unexpected sounds, immeasurable reconﬁgurability, and in
some cases, unrepeatable complexity.GroupLoopencour-
ages a high level of collaboration, and leverages new tech-
nologies to become one of the ﬁrst full-band, real-time col-
laborative music platforms available on the internet.
GroupLoopcreates new topologies for collaboration in
performance, and invites thoughtful reﬂection on future topolo-
gies for real-time music collaboration over any distance.
Technology is quickly driving toward ubiquitous, internet-
based collaboration.GroupLooprepresents a step towards
that connected, musical future.
7. ACKNOWLEDGMENTS
The authors would like to acknowledge Tod Machover and
the participants of the MIT Media Lab ’Future of Music’
class– particularly Spencer Russell for his continued guid-
ance. Special thanks also goes to theGroupLoopperform-
ers: Charles Holbrow and the aforementioned Mr. Russell.
8. REFERENCES
[1] Steve Reich.Writings About Music. New York
University Press, 1974.
[2] Todd Jenkins.Free Jazz and Free Improvisation: An
Encyclopedia, Volume 2. Greenwood Press, 2004.
[3] Andrew McPherson. The magnetic resonator piano:
Electronic augmentation of an acoustic grand piano.
Journal of New Music Research,3 9 ( 3 ) : 1 8 2 – 2 0 2 ,2 0 1 0 .
[4] Je↵rey M Morris. Feedback instruments: Generating
musical sounds, gestures, and textures in real time
with complex feedback systems. InInt. Computer
Music Conference, Copenhagen, Denmark, pages
469–476, 2007.
[5] Nicolas Collins. The history ofPea Soup.
www.nicolascollins.com,2 0 1 1 .
[6] Dae Ryong Hong and Woon Seung Yeo.Laptap:
Laptop Computer as a Musical Instrument using
Audio Feedback; Proceedings of the International
Conference on New Interfaces for Musical Expression,
pages 233–236. 2013.
[7] Soundﬂower, http://rogueamoeba.com/freebies, 2015.
[8] J. Kalliokoski and C. Wilson, editors.Web MIDI
API. W3C Working Draft (work in progress),
http://www.w3.org/TR/webmidi, 2013.
[9] Carlo Drioli, Claudio Allocchio, and Nicola Buso.
Networked performances and natural interaction via
LOLA: Low latency high quality A/V streaming
system.Information Technologies for Performing
Arts, Media Access, and Entertainment,
7990:240–250, 2013.
[10] Nathan Schuett. The e↵ects of latency on ensemble
performance. Undergraduate honor’s thesis, CCRMA,
Stanford University, 2002.
[11] J.P. C´ aceres and A. Renaud. Playing the network:
the use of time delays as musical devices. In
Proceedings of International Computer Music
Conference, pages 244–250, 2008.
[12] A. Bergkvist, D. Burnett, C. Jennings, and
A. Narayanan, editors.WebRTC 1.0: Real-time
Communication Between Browsers. W3C Working
Draft (work in progress),
http://www.w3.org/TR/webrtc, 2013.
[13] J. M. Valin, editor.Deﬁnition of the Opus Audio
Codec. Internet Engineering Task Force (IETF),
http://tools.ietf.org/html/rfc6716, 2012.
[14] Issue 241543: createMediaStreamSource does not
work for remote peer’s stream, 2015. Chromium Bug
Tracker,
code.google.com/p/chromium/issues/detail?id=241543.
[15] Justin Uberti and Sam Dutton. Real-time
communication with WebRTC. InGoogle I/O,2 0 1 3 .
254
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 