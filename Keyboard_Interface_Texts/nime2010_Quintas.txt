GLITCH DELIGHTER:  Lighter’sdFlamedBasedHypersInstrumentdfordGlitchdMusicddindBurning The SounddPerformanced d  RudolfodQuintasdengageLabdddUniversitydofdMinhordCCGdˆêvvsv˜êdGuimarãessPTdLabcomdddddddddddddddddddddddddUniversitydofdBeiradInteriordRuadMarquêsdDmÁviladedBolamadÁ'vysvvydCovilhãsPTdrudolfotquintas@gmailtcomdd
ddd
ABSTRACT Glitch DeLighter is a HyperInstrument conceived for Glitch music, based on the idea of using fire expressiveness to digitally distort sound, pushing the body and primitive ritualism into a computer mediated sound performance.  Glitch DeLighter uses ordinary lighters as physical controllers that can be played by creating a flame and moving it in the air. Droned sounds are played by sustaining the flame and beats by generating sparks and fast flames. The pitch of every sound can be changed moving the flame vertically in the air. This is achieved by using a custom computer vision system as an interface which maps the real-time the data extracted from the flame and transmits those parameters to the sound generator. As a result, the flame visual dynamics are deeply connected to the aural perception of the sound - ‘the sound seems to be burning’. This process establishes a metaphor dramaturgically engaging for an audience. This paper contextualizes the glitch music aesthetics, prior research, the design and development of the instrument and reports on Burning The Sound– the first music composition created and performed with the instrument (by the author).  Keywords Hyper-Instruments, Glitch Music, Interactive Systems, Electronic Music Performance.  1. INTRODUCTION “The musician's sensibility, liberated from facile and traditional Rhythm, must find in noises the means of extension and renewal, given that every noise offers the union of the most diverse rhythms apart from the predominant one.”                       Luigi Russolo (1913)  
Glitch DeLighter is an Hyperinstrument conceived for Glitch  music - a gender of electronic music emerged in the early 90’s. It’s aesthetics is characterized by the use of everything that can result from digital distortion such as CD skipping, system errors, bugs, crashes, hardware noise as the base of its music vocabulary. The term post-digital was used by Kim Cascone to report on the different experimentations related to glitch aesthetic (Cascone 2000). Although Glitch music is relatively recent, its roots can be found back to Modernism with Luigi Russolo’s Futurist Manifesto “The Art of Noises” (Russolo 1913). Almost 100 years ago, he demands for new sounds and instruments that could open a completely new pallet for music performance, production and listening. One of glitch music founders were the Oval, a band formed in Germany in the beginning of the 1990’s that used the technique of damaging CDs by writing on them with pens, then using the distorted sounds as the base of their music vocabulary. The sound quality of their technique was quite unpredictable. Nowadays, with the increasing interest for these sounds, there is a lot of music software that allows musicians to create and shape the exact “glitched” sound they are looking for, such as: Reactor, FLStudio or Abelton Live among other.   1.1 First Experiments  “New techniques are often discovered by accident or by the failure of an intended technique or experiment...”  (Cascone 2000)  The ‘discovery’ of this instrument started as an accidental error.  When working on one other project, also involving a computer vision system and a sound generator, I picked up from my pocket a lighter to test the infra-red tracking.  When striking the lighter the sound sample that was supposed to play got  “frozen” producing a “glitched” effect. What got my attention was the fact that this “glitched” effect could be manipulated and didn’t crashed my computer. I immediately felt it as an interesting audiovisual metaphor and its sound was already expressive.  As pointed by Perry Cook “Musical interfaces that we construct are influenced greatly by the type of music we like” (Perry Cook 2001). This quote applies very well to this research as it expresses so well the motivation and design issues surrounding the construction of this instrument. 
 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.  To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. NIME2010, 15-18th June 2010, Sydney, Australia Copyright remains with the author(s). 
Being interested in the potential of its audiovisual metaphor, and being the controller already an expressive element, I got motivated to make further research that could lead to the develop hyperistrument for gitch music performance based on the following design issues:  - That increased the body expressiveness in live performance;  - That made possible an endless combination of expressive gestures and sounds; - That had explored deep relation between the controller and sound generator;      - That was both engaging for the performer and an audience.    2. RELATED WORK In this section I consider prior research that influence the development of this instrument (1) in which computer vision techniques are used as interfaces for live music performance; (2) in which hand controllers are used to manipulate sound samples; (3) in which glitch sound is live performed using the controller as a visual metaphor. 2.1 Computer Vision Interfaces Glitch DeLighter uses a computer vision system to track the flames position in space.  One of the most influential works applying computer vision is the David Rokeby Very Neurvous System (1986-1990). That system uses video cameras, image processors, computers, synthesizers and a sound system to create a space in which the movements of one's body create sound and/or music. Douglas Cooper describes it as a piece that “makes something out of you. It turns you into a symphony. Or a jazz song. Or a samba. After determining where you are and how you're moving, Very Nervous System takes this information and turns it into music”. (Cooper 1995).   
 Figure 1. David Rokeby in Very Neurvous System (1986-1990)  This project is very relevant to my work as it probes the capabilities of using a video camera as a sensor for a music controller. But a significant difference is that musically it doesn’t address a particular gender, being more influential as technologically system rather than an instrument.      2.2 Gesture Control One of the most influential Hyper-Instrument related to the Glitch DeLighter is the The Hands (1984-2005) MIDI controller by Michel Waisvisz (1949-2008) developed at STEIM. This controller it is one of the first interfaces to give 
gestural control and play of sound samples using MIDI protocol. Figure 2 shows an image from 2005 version. This instrument was very influential in my research because it explores the expressiveness of having in the hands the direct control of the sound being live produced and manipulated.   
 Figure 2. The Hands Controller (2005)  2.3 Controllers as Visual Metaphors  The history of electronic music instruments goes back to the beginning of the XX century with the Theremin build in the late 1920s by Leon Theremin (1986-1996). The instrument was mastered by Clara Rockmore which developed a method to play with it (Rockmore 1998). Nowadays, several versions, some of them integrated in synthesizers are used by hundreds of music bands. In the actual scene of live performance, musicians have been adopting a large variety of MIDI controllers and DIY Circuit Bending instruments to enhance expressiveness in live electronic music performance. But to the best of my knowledge, I am unaware of any Hyperinstrument conceptually oriented for the purpose of glitch music performance in which live elements like fire are used to digitally distort sound, where the controller emits a visual metaphor expressed in the sound generator – in this case, the flame generated by the lighters cause digital distortion causing the perception of sound as being burned. The instrument metaphor not only is engaging for an audience as for the performer, and it pushes the body and primitive ritualism to computer mediated sound performances.  3. INSTRUMENT DEVELOPMENT This section describes the instrument: how it works, the elements involved, its set-up, controller, generator, calibration and expressiveness issues. From these elements, the relation between controller and generator is one of the most important issues when creating a new instrument - as pointed by Serji Jordà its final expressiveness and richness depends on the generator involved and the mapping applied between them (Jordà 2001). This relation was deeply explored by this instrument: when a flame is made the sound seems to be burning. This synesthesic relation is explored as an audiovisual metaphor as the controller emits a visual impulse aurally expressed by the sound generator.  3.1 Instrument Overview Glitch Delighter uses ordinary BIC® lighters as physical controllers to digitally distort sound samples in real-time by creating a flame and moving it in the air. This is achieved using a custom computer vision system interface that tracks the 

flame’s position in real-time as parameters to the sound generator. Figure 3 illustrates this process (using one lighter):  
  Figure 3. Instrument Process Overview  1) The infra-red camera looks towards the lighter direction. 2) Its video signal is connected to the computer where some image processing is applied to filter the incoming image such as CCD noise. Additional image processing is applied to produce a binary image where the lighter’s flames appear as a solid white shape in a black background (Blobs). 3)  The flame’s shape (Blobs) are tracked by the tracking system that outputs ‘X,Y’ coordinates from the flame position. 4) This variables (coordinates) are then filtered and mapped to the sound generator as input parameters. Figure 4 illustrates this process in a performance set-up situation from the camera view.  
 Figure 4: Instrument Set-Up in Performance Situation  The Figure 4 also illustrates how the performer should position in the space to calibrate de instrument: being centered towards the camera, he can see the video being captured in the computer screen. This visual feedback allows him to position himself in relation to the camera and find the calibration point. This point is where he can move his arms freely to play the lighters inside the captured video signal.  
Figure 5 illustrates this issue in detail. Obviously he can also move backwards, but moving forward and staying inside the image depends on the camera lens. Using a Creative© Web Camera the performer ‘safe space’ is approximately 9 sq meters. This space is enough to move freely the body and produce expressive gestures. In both figures the video image is represented as being sliced vertically in four areas – A, B, C, and D. These areas represent four individual sound samples (Sound Sample A, B, and D) placed in the ‘air’ (image area). To activate the corresponding sound sample, the horizontal flame coordinate is used as a parameter for this function. This means that by continuously moving a flame horizontally a across the space (camera image) the four sound samples will be used. This issue is described in detail in the following subsection.    
 Figure 5: Performer moving his arms in the calibration point  3.2 Mappings  The mapping “design” of this instrument was crucial to its final expressiveness.  Choosing how <one> controller will be mapped to <one> synthesis parameter (sound generator) is a matter of sensibility. No math or general technique is involved, no right or wrong, just more or less expressive it can result. Usually the most common way is to assign <one> controller output to <one> synthesis parameter (sound generator), like the breath pressure values of a sensor to the volume parameter of a synthesized sound. In this instrument the flame’s vertical position is assigned to the pitch: moving it up increases the sound pith and moving it down decreases the pith.  This was mapped so that when a flame travels from down (near the floor) to the top (with the arms up) the pitch travels from low to high. This makes the instrument to be felt more expressive both to the performer and audience that receives a visual metaphor for the sound pitch transformation. Table n.1 describes the general mapping occurred between the Controller Outputs and the Sound Generator.  

Table 1. Mappings Controller  OUTPUTS Sound Generator MIDI OUT Flame Vertical Position Pitch; 0-127 Flame Horizontal Position Sound Selection; Sound Panning; 0-127 
Flame on/off (Boolean)  Plays/Stops the sound Note on/off (HOLD) Flame Velocity Filter Parameter   Four sound samples can be played and distorted. They are positioned along four vertical areas in the image. The Flame horizontal position is the variable that chooses which sound sample to be used. It also affects the sound panning. The flame on/off  is a (Boolean) variable that works just like a key pressed function. The Flame velocity affects a filter in the sound generator giving extra expressiveness to the performer gestures.  Additionally, the controller outputs are mapped to MIDI so they can be routed to other instruments, controllers or effect processors with MIDI input. This was particularly useful in the first performance developed with this instrument described in the results section. 3.3 Sound Generator The sound generator is a custom MAX/Msp patch that loads and plays four sound samples in each pre-set according to the lighters’ flame. This pre-sets can be dynamically changed which is particularly useful is a performance situation.  The glitch effect is generated when a flame is turned on. The values of the sound sample are read and outputted to the sound card being repeatedly played and interpolated from the buffer starting point. The frequency of this loop is given by the rate of the video image capture, approximately 30hz.  The sound pitch changes with the flame vertical position that increases or decreases the interpolation value.  This distortion occurs to the four sound samples. Technically there could be as many sound samples as vertical areas. This means that if the camera is capturing at 320 x 240, 320 columns could be used to map 320 corresponding samples, though most likely it would be too hard to master. Just like if the key of a piano was 3 times smaller, a piano could have the triple keys, but it would be almost impossible to play since the keys size are ergonomic correspondent to the size of human fingers. The same principle is applied to this instrument. The arm has a minimum and maximum distance from the center of the body to its extremity. Two areas were defined for both the left and right arm, one near to the body center and another areas at a “natural” distance to the body. In a performance situation this can be perceived as two areas for each side if the body and becomes very intuitive for the performer to know where each sound is, because the correspondent A, B, C and D areas (figure 5) become natural.   3.3.1 Sound Expressiveness Both droned sounds and beats can be played and mixed live. Droned sounds can be played and manipulated by sustaining and moving a flame. Beats by generating sparks and fast flames. When a flame is turned, its horizontal position assigns which a sound sample will be distorted and its vertical position gives it correspondence pitch distortion. To better understand how this works Figure 6 illustrates the production of a Droned sound that travels from area A and ends in area D, passing through B and C changing its pitch continually.  
 
 Figure 6. the production of a droned sound   The figure gives attention to five different moments in time, expressed in the illustration as m1,m2,m3,m4 and m5. The m1, is the first moment and the m5 is the last one. Together they form a curve that expresses changes occurred to the droned sound: When the flame is created (m1) the sound sample activated is the one corresponding to area A. The flame vertical position affects its pitch. Along the curve the pitch is being increased until m3 and then starts to decrease until m5. The pitch value is particular useful because when the sound sample changes in m2, m3, and m4 one can notice the sound changing but because the pitch is maintained, it gives the sound continuity. In other words we can think that along the droned curve the sound timbre changes but its pitch maintains.  This is also becomes a very expressive feature as the performer can play continuously crossing one area to the other producing a “rhythmic drone” effect.    4. TESTS AND FIRST RESULTS Burning The Sound was the first composition to be live performed with Glitch DeLighter instrument that probe its expressiveness and flexibility. This composition was based on a structured improvisation set. The interactive sound performance was inspired in the nature of rituals, power and control. It used the fire from the instrument to subvert patterns of rhythm, using technologically mediated computer sound to exorcise the sound as a spiritual strategy. The performer's gestures in relation to the instrument not only shows the performer's emotional state, but it brings the instrument to life. In this action, it is explored and established as a synaesthesic symbolic metaphor in the sense that it is from the flame that the sound is shaped. This intensifies the synaesthesic quality of the sound being perceived as burned by the flame. Fire was probably the first technology to exist and is knowledge based and ritualistic. Within "Burning The Sound", digital, new media and ancestral technologies fuse to question contemporary strategies of invisible control. The performance is timeline structured guided by gestural improvisation based on pre-established ‘rituals’. It has aproximattely 13 minutes, set to be live performed using massive sound speakers. It is sonically ‘aggressive’ from the beginning, growing from droned to rhythmic sculptured sounds, 

from free improvisation to pattern sequencing until its subversion.  I perform with the feeling that I am “exorcising the sound”, this is for me, a spiritual attempt in finding the moments were the “noise” produced by digital distortion becomes warm and beauty, almost like the fire itself, is not good or evil, just needs to be in the right place. Figure 7 shows the instruments being used in live performance.    
 Figure 7. Glitch Delighter instrument in Burning The Sound Performance, live at CTM -Transmediale 2009, Berlin.   The performance has been played live in the context of media art festivals and electronic music events. It was awarded the Transmediale Distiction Award in 2009. The following jury quote serves an example of how the relation between the instrument and the performance is felt by the audience:   "Any sufficiently advanced technology is indistinguishable from magic." This quote by Arthur C. Clarke applies well to Burning the Sound, a performance by Rudolfo Quintas combining high technology with one of the earliest tools used by humans – fire. Over the thousands of years this element has not lost any of its magical, mesmerizing qualities. With all our current knowledge the behavior of flames is still beyond our control and understanding. The performance amplifies this chaotic energy, taking us back in time to a moment when we would gather around a fireplace to witness to shamans. The custom software instrument developed by  Quintas is so well designed that all of the involved high technology seems to disappear, bringing into focus the live performer and his skill of 'playing with fire'. The work is both compositional and performative – both technical and expressive. Quintas’s own presence in the work drawing the audience into the light of the flame leads to a kind of exchange – a kind of visual and physical ritual. The lighter functions as a kind of paintbrush that can carve out sounds from the air that fire is fire is constantly eating'. Transmediale Jury Statement (2009)   As a result of the instrument expressiveness and flexibility the audience often refers to my gestures as choreography. .   5. CONCLUSION AND FUTURE WORK Practice-Based Research is a key subject to discover and explore new possibilities.  The starting point of this instrument was born by ‘failure’. Failure has been one on the key issues on 
the art of the cast XX century and in computer creativity, discovering by practice is one of the key issues as the reality often doesn’t show the potential of this medium. Burning the Sound performance demonstrated the potential of the instrument and since November 2009 it has been used in the concerts of CRISIS a electronic music band where the author plays live electronics. The use of live elements that produce synesthesic metaphors is a subject still to explore in the relation between controller and generator in the context of live electronic music.  Currently I am starting to explore a new instrument that focus on the precise manipulation of sparks in a Tesla Coil as an electronic music controller.   6. ACKNOWLEDGMENTS  I would like to thank Pedro Branco from engageLab for the revision of this paper. The NIP artist-in-residence at STEIM (NL) and the grant from DGartes/Ciencia Viva (PT) under the first edition of the program “Experimentação: Arte, Ciência e Tecnologia” that supported the development of this project.  7. REFERENCES  [1] Russolo, L (1987). The Art of Noises. New York: Pendragon Press. (Originally published in 1913.) [2] Cascone, Kim (2000) THE AESTHETICS OF FAILURE: 'Post-Digital' Tendencies in Contemporary Computer Music, Computer Music Journal 24:4 Winter 2000 (MIT Press) [3] Cook, P. (2001) “Principles for Designing Computer Music Controllers”, Proceedings of the 2001 New Instruments for Musical Expression Workshop. Seattle: CHI (NIME) 2001 [4] Douglas Cooper, "Very Nervous System: Artist David Rokeby adds new meaning to the term interactive", Wired Issue 3.03 (Mar 1995)Lamport, L. LaTeX User’s Guide and Document Reference Manual. Addison-Wesley, Reading, MA, 1986. [5] Rockmore, Clara (1998). Method for Theremin. Edited by David Miller & Jeffrey McFarland-Johnson. Made publicly available at http://www.electrotheremin.com/claramethod.html [6] Jordà, Sergi (2001) New Musical Interfaces and New Music-making Paradigms, Proceedings of the 2001 New Instruments for Musical Expression Workshop. Seattle: CHI 2001 [7] Trasmediale -International Festival for Contemporary Art and Digital Culture. In Jury statement: Transmediade Award 2009 [ http://www.transmediale.de/en/node/3121 ] last visit 22 November 2009   [8] CRISIS music on Myspace: [www.myspace.com/CrisisCrisisCrisis] last visit 20 Abril 2010    
