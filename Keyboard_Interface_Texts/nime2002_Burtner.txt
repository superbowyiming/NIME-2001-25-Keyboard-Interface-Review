Noisegate 67  for Metasaxophone 
Composition and Performance Considerations of a New Computer Music Controller 
 
Matthew Burtner 
Virginia Center for Computer Music (VCCM) 
Department of Music, University of Virginia, Charlottesville 22903, USA 
mburtner@virginia.edu 
http://www.burtner.net
ABSTRACT 
Noisegate 67 was the first fully interactive composition 
written for the Computer Metasaxophone, a new computer 
controller interface for electroacoustic music. The 
Metasaxophone is an acoustic tenor saxophone retrofitted 
with an onboard computer microprocessor and an array of 
sensors that convert performance data into MIDI control 
messages. While maintaining full acoustic functionality the 
Metasaxophone is a versatile MIDI controller. This paper 
discusses the compositionally driven technical and 
aesthetic concerns that went into building the 
Metasaxophone, and the resulting aesthetic 
implementations in Noisegate 67 . By juxtaposing the 
compositional approach to the saxophone before and after 
the electronic enhancements an attempt is made to expose 
working paradigms of composition for metainstruments. 
 
 
Figure 1 - The Metasaxophone: Front and Back Views 
INTRODUCTION 
New Control Parameters for an Old Interface 
Since its first appearance in public in 1842 (Rascher 1970), 
the saxophone has proven a highly flexible performance 
interface with acoustic characteristics that have allowed it 
to flourish in a wide range of musical styles and aesthetics.  
 The young instrument builder Adolphe Sax 
intended his instrument to have the dexterous flexibility of 
the strings, the coloristic diversity of the woodwinds, and 
the dynamic power of the brass. An instrument designed to 
unite instrumental elements, the saxophone, has also 
proven stylistically flexible, continually being adapted to 
new performance needs. Styles as diverse as the orchestral, 
band, jazz, rock, improvised and electroacoustic music 
traditions have embraced it.  
 Electroacoustic music raises new possibilities for 
extending the timbral range of acoustic instruments. Very 
often, however, the instrumental interface is not suited for 
direct performer control of the new timbral opportunities. 
This paper discusses how a project involving music for 
electronics and acoustic saxophone drove the development 
of a human computer interface project extending the 
expressive performance possibilities of the saxophone.   
 The Metasaxophone is classified in the field of 
human-computer interaction as an augmented traditional 
instrument. It is part of a growing trend in instrument 
design that uses traditional instrumental performance 
interfaces as input devices for computer instruments (Cook 
and Morrill, 1993; Hunt, Wanderley and Kirk, 2000; Orio, 
Schnell and Wanderley, 2001; Paradiso, 1997).  
 Previous notable attempts at augmenting the 
saxophone have sacrificed the actual acoustic instrumental 
sound for MIDI controller capabilities. The first MIDI 
saxophone, the Synthophone, is a versatile MIDI controller 
marketed by Softwind Instruments (Softwind, 1986). The 
developers of the Synthophone were interested in 
preserving the tactile interface of the saxophone but not its 
acoustic sound. The Synthophone therefore produces no 
sound of its own, the saxophone body being only a housing 
for the electronics. Retaining the true sound of the 
saxophone has been of primary importance in developing 
the Metasaxophone. 
 
FORMATIVE WORK  
The Metasaxophone grew out of an ongoing project 
exploring the saxophone as an electroacoustic instrument. 
The project simultaneously pursues extended performance 
practice and the expansion of the instrument through 
electronics. Compositions such as Incantation S4 (1997), 
Split Voices (1998) and Portals of Distortion (1998) were 
fundamental in redefining the performance practice of the 
saxophone and suggesting the Metasaxophone controller. 
Performance technique took on new meaning in these 
pieces, becoming a means of opening the saxophone 
acoustically, bringing out its hidden resonant 
characteristics, and allowing it to speak on its own. All 
three of these pieces were recorded and released by Innova 
Records on the 1999 CD, Portals of Distortion: Music for 
Saxophones, Computers and Stones (Burtner, 1999). These 
compositions for saxophone are characterized by the 
fundamental aesthetic assumptions described below.  
1) The Instrument as Complex Acoustic Filter 
The saxophone was conceptually redefined as a complex 
acoustic filter and preconceptions of traditional notions of 
tone, intonation, fingering, and embouchure were 
discarded and replaced with a more open conception of the 
sound possibilities of the instrument. This reconception of 
the instrument was based on an observation that notions of 
saxophone performance practice were highly biased 
towards the aesthetics of traditional musics such as jazz 
and classical traditions. 
 A more open approach to the instrument suited 
the world of electroacoustic music well. It is characteristic 
of the way composers approach digital audio synthesis 
systems, with open ears and a desire to explore. This is 
most notably the case in Portals of Distortion for nine 
tenor saxophones, in which the ensemble is treated as a 
network of signal processors, mixed together into a 
complex signal.  
In place of the traditional performance practice a 
new approach evolved based on continuous and variable 
pressure in the air column of the horn, changing the 
complex properties of the tube by applying various key 
combinations, and embouchure changes designed to both 
sustain the resonance and control the spectral properties of 
the signal.  
2) Signal  Processing as a Metaphor for 
Extended Instrumental Performance Practice 
In order to enhance the timbral relationship between the 
saxophone and electronics, techniques of digital audio 
synthesis used in the composition of the electronic parts 
were applied analogously to the saxophone. These included 
techniques such as granular synthesis, spectral mutation, 
convolution, digital distortion, ring modulation, and 
spectral resonance. Each signal processing technique was 
applied acoustically, through the use of extended 
techniques, to the performance of the acoustic instrument 
and refined into a controllable performance practice. In 
general an attempt was made to form a greater unity 
between the electronic and acoustic instruments, allowing 
them to occupy a similar, extended timbral space. 
3) Continuous timbral evolution of the 
instrumental sound 
The repertoire of techniques that evolved included 
sonorities that could be modified greatly over time through 
subtle embouchure changes. Circular breathing was 
necessary in this context to sustain the changes 
indefinitely. Symmetries of the horn began to function 
almost motivically as observations of certain harmonic 
coincidences became apparent. Figures 2 and 3, excerpts 
from  Incantation S and Split Voices, show ways this music 
was notated for the performer. 
 
Figure 2: Excerpt from the Score of Incantation S4  
 
 
Figure 3: Excerpt from the Score of Split Voices 
 
 
Figure 4: Metasaxophone Bell  
REDEFINING THE FUNCTION OF A KEY 
While performing compositions such as Incantation S4 , 
Portals of Distortion and Split Voices it became clear that, 
in the context of these slowly evolving musical textures, 
much of the performer's tactile sensitivity was being 
unused. In each of those pieces, entire minutes may pass 
with the performer holding down one basic fingering. In 
the second part of Split Voices, for example, the front five 
keys are held down for over 5 minutes while the 
performer trills other keys and changes the embouchure 
and air pressure. 
 A perceived limitation of the manual interface 
gradually appeared: while the saxophone allows for 
continuous control over embouchure changes and 
changing air pressures, the fingers of the performer have 
very little direct continuous control over the instrumental 
sound.  
 For all practical purposes, a saxophone key is 
either open or closed. Half keying is an extended 
technique of some promise, and using very rapid, 
changing trills can give the impression of a continuously 
changing sound, but these both involve substantial 
changes in the air column that could disrupt other key 
work in progress. What was needed was a new level of 
key control that would not disrupt normal playing but 
could be used to substantially modify the sound. 
 It occurred that by giving the keys pressure 
sensitivity or "aftertouch", a feature common on MIDI 
keyboard controllers, direct tactile control over the 
electronic signal processing could be given to the 
performer. This computer interface could be placed easily 
in the expressive zone left unused by the instrument, 
namely finger pressure on the keys. In essence, the 
saxophone keys which normally execute only on and off 
changes of the air column, could be converted to 
continuous control levers. 
 
TECHNICAL SPECIFICATIONS  
Hardware 
An approach was developed for retrofitting the acoustic 
Selmer tenor saxophone with sensors and a 
microprocessor that could convert the performance data 
into a continuous control data stream. A great deal of 
thought went into how and where the sensors would be 
attached to the instrument, and important performance 
considerations were contributed by Christopher Jones, 
Brian Ferneyhough, and Gary Scavone who also advised 
technically on the project. It was finally decided that the 
microprocessor would gather performance data from eight 
continuous voltage force sensing resistors (FSR), five 
triggers, and an accelerometer.   
 The FSRs (by Interlink Electronics) are located 
on the front B, A, G, F, E and D keys, and beside each of 
the thumb rests. Three triggers (also by Interlink) are 
located on the bell of the instrument, and two are 
positioned on the back, below each of the thumb rests. An 
Analog Devices ADXL202 accelerometer IC chip on the 
bell measures the position of the saxophone on a two 
dimensional axis - left/right and up/down.  
 The data from these sensors are collected via a 
26 pin serial connector by a Parallax Inc. Basic Stamp 
BIISX microprocessor fixed to the bell of the instrument. 
Analog pressure data from the performer is converted to a 
digital representation by passing each analog signal 
through a resistor/capacitor (RC) circuit into the input 
pins on the BIISX (Figures 5 and 6). Trim potentiometers 
calibrate the input sensitivity of each sensor.  
Figure 5: Block Diagram of the Metasaxophone 
Software 
The BIISX is programmed in Parallax Basic (PBASIC) 
and the software converts the sensor data into MIDI 
messages. Analog to digital conversion is accomplished 
using the PBASIC RCTIME (Parallax inc, 1999) function 
that measures the charge/discharge of the RC circuit over 
time. The Metasax program loops thro ugh the input pins 
reading the RCTIME counter of each pin.  
 Multiple programs can be loaded into the 
BIISX’s EEPROM for a variety of applications. The 
standard Metasaxophone software sends MIDI control 
change messages 20-27 on channel 1 for the FSRs, MIDI 
note-on 1-5 on channel 1 for the triggers, and the 
accelerometer sends MIDI note-on messages 6-10 as the 
performer crosses certain thresholds of left/right, up/down 
tilt, and control change messages 28 and 29 for 
continuous control.  
 
Figure 6: Metasaxophone Circuit Board 
 The continuous controller MIDI messages sent 
from the Metasaxophone are used to control digital signal 
processing and synthesis algorithms. Originally an 
interactive interface programmed in Max/MSP (Ziccarelli, 
1989) was used. Current developments continue to use 
Max/MSP but also are exploring interface 
implementations in SuperCollider, RTCMIX, Scanned 
Synthesis and Pd.   
 The technical development of the 
Metasaxophone drew on a growing body of important 
alternate controller work. The technology used is a 
variation on a theme by Gary Scavone at Stanford 
University (Scavone, 1999), and Perry Cook at Princeton 
University (Cook, 1992). 
 
MUSICAL APPLICATIONS AND NOTATION 
The earliest applications of the Metasaxophone involved 
using the after-touch capabilities to control  real time 
signal processing of the saxophone sound. An interface 
and set of signal processing networks in Max/MSP 
allowed the possibility of modifying the timbre of the 
saxophone in many ways simultaneously. For example, 
reverb can be controlled by finger pressure on one key, 
distortion can be assigned to a second, frequency 
modulation to a third, etc. In and of itself, this made the 
Metasaxophone a useful tool for the computer music 
performer. Figure 7 shows the Max/MSP interface for 
Noisegate 67. 
 
Figure 7: Max/MSP Performance Interface for 
Noisegate 67 
 
Notation 
Notational issues quickly arose due to the lack of a 
standardization for notating multidimensional continuous 
control changes over time. The glissando is a useful 
notational paradigm for continuous frequency change, and 
dynamic markings can express continuous changes in 
amplitude satisfactorily; but communicating to the 
performer how multiple key pressures would evolve in the 
context of saxophone music presented a compositional 
problem. The notation needed to be specific enough to 
show pressure changes for each finger, but it could not be 
too specific for the performance capabilities of the 
instrument. For example, while it is idiomatic to specify 
polyphonic pressure curves over specified time periods, it 
is not reasonable to notate very precise polyphonic 
controller values.  
 A system was devised in which each finger was 
given its own pressure staff, the total pressure of each 
finger occupying a space from pressure 0 (minimum) to 
pressure 1 (maximum) on the X axis. Contours for each 
finger could be drawn into the space and the performer 
could then follow the contours, approximating the types 
of changes over time. Above the pressure staff the 
traditional saxophone music is written.. Below the 
pressure staff, a third staff containing other controller 
information such as saxophone position and triggers was 
combined with a composite graphic representation of the 
sounding electronic part. Figure 8 illustrates a page of the 
new notation from Noisegate 67. 
 
Noisegate 67 
The ability to control real-time interactive electronics 
from the saxophone opened entirely new compositional 
and performance possibilities. The Metasaxophone allows 
the possibility for performer-controlled modular form, in 
which the electronics can track exactly the modulation 
between sections of the piece, allowing the performer 
great flexibility in time.  
 Noisegate 67  takes advantage of the interactive 
nature of the instrument by exploring controlled open 
form. The beginning and end of the piece are notated 
completely in time. The middle section, however, is a 
network of possible paths through which the performer 
can freely move, dramatically shaping the time/energy 
structure of the composition. 
 The score of Noisegate 67  is in the form of a 
Triptych. The left and right panels of the score present the 
beginning and end of the piece and are notated in clock 
time. The performer plays the left panel first. After 
completing the left panel of the score, the performer folds 
open the two panels and enters the inner section of the 
music.  
 The inner four panels present 21 systems and a 
network of 25 paths for moving between them. The 
duration of each system differs depending on the 
performance. In this way, large-scale expressive control 
over the inner section of the piece is given to the 
performer. The duration and expressive potential of this 
section can vary greatly. Certain paths lead to a music of 
drama and intensity while other paths reveal a calm and 
reserved music.  
  In terms of computer applications, Noisegate 67 
explores the saxophone as a real-time, expressive noise 
controller. Each of the eight keys are connected to noise 
generators and filters. By applying pressure to the key, the 
amplitude of each noise generator is increased, creating 
an amplitude gate for the noise. By carefully controlling 
the finger pressure, the performer plays shifting bands of 
noise that are performed in counterpoint to the saxophone 
sound. The amplitude of the saxophone sound itself 
controls a ninth layer of noise. As the amplitude of the 
saxophone sound increases, the amplitude of the noise 
generator increases and key pressures control filter 
parameters.  
 In this manner the dynamic of the noise system 
is divided into two layers: 1) a noise part independent of 
the saxophone audio, formed of 8 key pressures, each 
with fixed filter coefficients, and 2) a noise part 
shadowing the saxophone's audio amplitude with 
continuously changing filter characteristics. 
  Additionally, certain keys continuously control 
modulation of the saxophone audio signal. The E key has 
a fixed modulation rate of 40Hz, and by adding pressure, 
the depth of the modulator is increased. The modulation 
rate of the D key on the other hand is determined by the 
saxophone's audio signal amplitude, and ranges from 1 to 
100Hz. Additional keys are used to control delay lines, 
and to trigger samples from the computer. 
 
Figure 8: Metasaxophone Notation Excerpt from Noisegate 67 
FUTURE DIRECTIONS 
Current work with the Metasaxophone involves 
exploration of extended techniques for physical models. 
In an ongoing project with Stefania Serafin 
(Burtner/Serafin 2000 and 2001), the Metasaxophone has 
been used as a controller for  bowed string physical 
models. By controlling the string from within the gestural 
space of a wind instrument, new expressive potentialities 
of the model are opened. The disembodied nature of 
physical models becomes a means of recombining it with 
other interfaces, creating extended techniques for physical 
models that would not be possible for the real instrument. 
 Another project with Max Mathews involves 
developing real-time interactive applications for Scanned 
Synthesis algorithms (Mathews/Verplank/Shaw, 2000). 
As in the work with physical models, the Metasaxophone 
controls a variety of parameters of a computer-modeled 
string. The keys act as complex hammers and change the 
damping, length and stiffness of the string. 
 
Figure 8: Excerpt from the Score of Noisegate 67 
 
CONCLUSION 
The computer Metasaxophone represents a further step 
towards formulating an integrated and meaningful 
electroacoustic performance practice. Through the 
development of imbedded systems and sensor technology, 
and through the use of general communication protocols 
such as MIDI, direct control of digital signal processing 
and electronic processes can be given to the performer. 
The Metasaxophone has proven a useful tool for opening 
new possibilities of real time integration of instrumental 
and computer-generated music. 
 In contrast to the earlier work for acoustic 
saxophone and electronics, Noisegate 67 reveals insights 
into how the use of metainstruments can shape a 
compositional approach to computer music. Notation,  
performer control of timbre,  and musical form were all 
radically reshaped in Noisegate 67 as a direct result of the 
enhanced saxophone interface.  
The possibilities of new applications for 
metainstruments are virtually infinite, and this 
enhancement of the saxophone has pushed the practice of 
saxophone performance and composition into new 
expressive areas.  
 
REFERENCES 
• Burtner, M., and Serafin, S.. Extended Techniques for 
Physical Models Using Instrument Controller 
Substitution. Proc. ICMA, Perugia, Italy, 2000. 
• Burtner, M., and Serafin, S. Real time Extended 
Physical Models for the Performer and Composer. Proc. 
ICMC, Havana, Cuba, 2001. 
• Burtner, M. Portals of Distortion, Innova Records, 
AMC, St. Paul, Minnessotta, USA, 1999.  
• Cook, P. A  Meta-Wind-Instrument Physical Model, and 
a Meta-Controller for Real Time Performance Control. 
Proc. ICMC, San Jose, USA 1992. 
• Cook, P. Principles for Designing Computer Music 
Controllers. Proc. of NIME-01, Seattle, USA, 2001. 
• Cook, P.R., Morrill, E., and Smith, J.O., A MIDI 
Control and Performance System for Brass Instruments. 
Proc. ICMC, Tokyo, Japan, 1993. 
• Felts, R. The Synthophone MIDI Saxophone. Saxophone 
Journal, vol.17 #2, 1992. 
• Hunt, A., Wanderley, M.M. and Kirk, R. Towards a 
Model for Instrumental Mappings for Expert Musical 
Performance. Proc. ICMC,  Berlin, Germany, 2000.  
• Mathews, M., Verplank, B., and Shaw, R. Scanned 
Synthesis, A New Synthesis Technique. Proc. ICMC, 
Berlin,  Germany, 2000. 
• Orio, N., Schnell, N., Wanderley, M. Input Devices for 
Musical Expression: Borrowing Tools from HCI. Proc of 
the NIME-01, Seattle,  USA, 2001. 
• Paradiso, J. New ways to play: Electronic Music 
interfaces. IEEE Spectrum 34, 1997. 
• Parallax Inc. BASIC Stamp Programming Manual. 
Version 1.0. www.paralaxinc.com. 1999.  
• Rascher, S. M. The Story of the Saxophone. 
http://www.classicsax.com . 1972. 
• Scavone, G. The Holey Controller. http://www-
ccrma.stanford.edu/~gary. 1999. 
• Softwind Instruments, “The Synthophone Manual” 
http://home.att.net/~synthophone/manual/index.htm, 
Switzerland, 1986. 
• Ziccarelli, D. An Extensible Real-Time Signal 
Processing Environment for Max, Proc. ICMC, Ann 
Arbor, USA, 1998.