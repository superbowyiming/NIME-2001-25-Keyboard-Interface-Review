Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-228
Dual-Use Technologies for Electronic Music
Controllers: A Personal Perspective
Joseph A. Paradiso
Responsive Environments Group
MIT Media Laboratory
1C a mbridge Center, 5FL
Cambridge, MA 02142
(617) 253-8988
joep@ media.mit.edu
ABSTRACT
Several well-known alternative musical controllers were
inspired by sensor systems developed in other fields, often
comingt ot heir musicala pplication via surprising routes.
Correspondingly, work on electronic music controllers has
relevance to other applications and broader research themes.
In this article,I give at our though several controller sys tems
that I have been involved with over the past decade and
outline their connections with other areas of inquiry.
1. FR OM PHYSICS TO INSTRUMENTS
People devote an amazing amount of energy into developing
newm odeso fm usical expression. There's nothing quite like
the satisfaction that one gleans after building and playing a
newi nstrument, feeling its response, andh earing sounds that
have never been produced before. Although most of the NIME
audience is quite familiar with the technical literature in
computer music (e.g.,Computer Mu sic J ournal , Journal of
New Music Research , Leonardo Music Journal , Organized
Sound , etc.), the periodical Experimental Musical Instruments ,
and Bart Hopkins' books [1,2] give an excellent survey of a
wider grassroots movement where artisans of all sorts bend
their abilities into crafting new ways to create and shape
sound. Indeed, people heralding from many daytimecallings
cross-fertilize all sorts of ideas and approaches from many
fields into musical instruments.
When growing up, I was hardly immune to this muse; like
many of my colleagues coming of age in the generation of
consumer electronics, I essentially learned circuits by
building various devices that mades ounds, often buying old
gear left over from the Boston area's extensive high-tech,
military-industrial R&D at local surplus houses and hacking it
tomakem usic. Perhapsi nm y case, thee xpression got a little
extreme in the 140-module homebrew patchable synthesizer
that evolved in my basement during the 70’s and early 80’s
[3]. In addition to being a source of unusual sounds, it is very
much an intimate musical controller. Despite the drawbacks of
being too closely wedded to the world of atoms, with a knob
and patchcord on every signal, modular synthesizers provide a
highly fine-grained, tangible, and parallel interface into sonic
structure. Althoughit's a little rusty now, I'm not ready to
surrender that axe to pasture…
Figure 1: The homebuilt modular in my former basement
Since electronic music systems by defin ition rely on a fresh
supply of ideas and technology to keep things current,
instrumenti nventorsa nd developers often tap the accessible
edge of Moore’s Law. Some fascinating stories can be f ound
where this trend is pushed to its extremes, e.g., the in itiative
by North American Rockwell to push large-scale integrated
circuit technology directly from the space program into
musical instruments, resulting in the Allen Digital Organ, the
world’s first real-time dig ital wav etable synthesizer, which
appeared on the marketw ay back in 1971 [ 4,5]. This example
illustrates how a mixture of different perspectives can lead to a
disruption in an established field. Innovation seldom comes
out of comfort; it often arises from a cultural clash [6], which
frequently manifested testy circumstances as Allen engaged
with Rockwell [5].
Onew ouldt hink that experimental high-energy physics
would have little effect on electronic music controllers, but
indeed it has, through several avenues. Since Bob Bowie had
worked with Veljko Radeka's Instrumentation Group at
Brookhaven National Laboratory, he was well aware of
capacitive pickup electronics for cathode-strip drift chambers
(standard charged-particle detectors) [7]. This proved to be the
inspiration for the sensor system that he designed with Max
Mathew's fort he RadioB aton [8], one of today'sb est-known
alternative controllers. As both Bob and Max knew Neil
Gershenfeld through BellLabs, these ideas propagated further
into the Media Lab's cello bow controller [9] used in Tod
Machover's Hyperstring performances [10]. At that time, I was
also using capacitive sensing technology, but in high-energy
physics applications at Draper Laboratory, this time using a
stretched-wire to sense the precision alignment of drift
chamber packages for the muon system of the proposed GEM
detector at the Superconducting Supercollider (SSC) [11].
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-229
Upon joining the Media Lab in 1993, I pushed these
technologies into a wireless violin bow tracker and a free-
gesture controller for ourSensor Chair [9]. When designing
the sensor suites for the Brain Opera performance interfaces
[12], I again adapted technologies that we had developed
earlier for aligning high-energy physics detectors. In
particular, theDigita lB a t on [12,13] used an optical tracker
based around a position-sens itive photodi ode (PSD) that we
had evaluated at Draper for GEM's optical straighness
monitoring [14], and the laser rangefinder design that I turned
into a hand tracker and musical interface for large projection
walls [15,16] was inspired by a rangefinder that we had
intended to use for dynamic detector surveying [17].
Figure 2: Wireless sensors in a star topology
2. HIGH-DENSITY WIRELESS SENSING
Although interfaces for electronic music face some very
interesting research challenges on their own turf [18], this
section will provide a few examples that illustrate how
particular controller designs that we've pursued address
broader research issues - essentially taking an opposite tack to
the previous discussion. In particular, the goals of Ubiquitous
Computing [19], which envisions sensors, processing, and
communication moving into everyday objects and
environments, form a good match to technical research in
many avenues of musical controller design.
The sensor topology described in the next two sections is
the centralized “star” with a heavy basestation, as portrayed
in Figure 2. This topology is well suited, for example, to
a wearable sensor array used in a dance performance, where
one needs to rapidly acquire all information from every
sensor cluster on the stage without the laten cy that would
be incurred in a peer-peer network as shown in Figure 6.
Figure 3: The final version of the Expressive Footwear shoe
When I first conceived of the Expressive Footwear project
[20] in 1997, I wanted it to be a wireless sensor tour-de-force.
Knowing nothing about dance, I threw every sensor that would
fit and seemed even vaguely useful onto a dance sneaker, with
awireless d atalink coming directly off the shoes. In the end,
we put 16 diverse sensors on each shoe to measure many
parameters of contact and free gesture together with position.
We developed a series of such shoes between 1997 and 2000
[21].
As the first devices were deployed before compact sensor
packages, such as the Motes [22,] became established, it was
somewhat of a radical statement, an early case of what I call
"sensing as commodity", partly inspired by the various
dexterous glove interfaces developed at STEIM [23].
Traditional sensing applications have been based on
measuring only parameters of direct relevance. When
designing an artifact needing measurement, sensors are
traditionally placed exactly where they’re needed to provide
primarily the information required. Now that sensors are
becoming so inexpensive and small, however, we can look at
pursuinga not her, less stringe nt strategy that involves
packing as many sensor measurements as possible into the
object’s form factor. If there’s any suspicion that a
measurement can be at all relevant, and if it can fit into the
package constraints, just include it as a member of a large
embeddeds ensors uite.T hisw ay,a hosto fm ultimodal sensor
readings catch many features o f activity and expression –
instead of “sharpshooting” particular parameters of interest
with explicit sensors, this approach catches a wide range of
phenomena with multisensorary “buckshot”, allowing one to
reconstruct a variety of features and states by fusing the data
in software. This allows an instrument designer or player to be
more open to serendipity – the rich sensory stream produced
by such a heavily instrumented controller captures many types
of gesture, enabling a user to map an effective response to
many types of activity and usage modalities that weren’t
anticipated when the device was designed. In the case of the
Expressive Footwear,t h i sw a s indeed the case – after
perfecting a compact circuit card to do such dense wireless
sensing and survive on the foot of a dancer (a major challenge
in itself [24]), the data stream was sufficiently rich to map
expressive response onto many different styles of dance across
the wide range of dancers that we worked with in this project.
We have since min iaturized this instrument package further,
producing a device that we call the sensor “ Stack”[ 25] that is
composed of circuit cards roughly an inch and a quarter on a
side.M ating at small connectors on t heir perimeter, different
such cards can be vertically layered, allowing a designer to
stack up a suite of sensing devices into a compact form factor,
roughly the area of a large wrist watch. One card contains a 22
MIPs processor and RF transceiver; subsequent cards
encapsulate different sensing modalities. At the moment, we
have develope dt wo sensor car ds (a 3-axis inertial
measurement unit [IMU], and a tactile i nput dev ice that
interfaces to pressure [FSR and piezo], bend, and cap acitive
sensors), and a sonar card is under development. Our current
applicationo ft hisp latformi si n medicalb iomotiond iagnosis
and therapy, where we’re trying to use a h eavily instrumented
shoe to enable some of the function of a high-infrastructure
gait laboratory at a hospital to be accommodated in a small
doctor’s office or home environment [26]. We are also
planning to use this platform as a research tool to investigate
state-driven processing and resource allocation in sensor
nodes. As energy, computation, and communications
bandwidth tend to be quite limited in b attery-powered
systems, sensor nodes have to take careful account of what
sensors are used, what features are extracted, and what data is
transmit [27]. Accordingly, appropriate processing at each
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-230
node can extract a limited amount of local c ontext in order to
dynamically adjust this resource balance. Instead of blindly
andw astefully dumping all measured bits all of the time, a
more efficient sensor node will send only relevant features at
appropriate times.
Figure 4: The currently working version of the Sensor Stack
In the near future, we intend to explore the application of our
Stack in ensemble dance, where we instrument the hands and
feet ofas mall troupe of dancers. By upgrading the 115
kbit/second RF transceiver that we’re using to a 1-2
Mbit/second capacity and running a simple TDMA protocol,
weanticipateb einga blet om aintaina 100 Hz full state update
from each node of this system for 4-5 dancers, effectively
capturing many features of real-time dance performance. In
addition to just building an architecture to acquire the data,
this system will confront significant technical challenges in
real-time data fusion in order to produce a prompt and relevant
media response to the 300-500 parameters streaming in with
each measurement update. There are likewise issues involved
in content mapping here – we can no longer map our data
directly at the sensor level, as is now conventional in MIDI
mapping packages like MAX, since there’s just too much
dissimilar data streaming in to deal with by hand.
Metavariables defined at a higher level, reflecting information
relevant to the performer (perhaps inferred affect [28],
synchronicity and deviation, energy, learned or entrained
parameters, etc.), will need to be defined in order to effectively
author content on top of these systems.
Figure 5: Low cost “jerk” sensor to instrument large crowd
3. FEAT HERWEIGHT SENSORS
We have also been pushing another dimension in high
density wireless sensing. Instead of making heavy nodes that
each host many degrees of sensing freedom, we have
developeda system that supports huge numbers of extr emely
lightweight nodes that each measure only one coarse
parameter. This system has been targeted at interactive
entertainment for large groups. Whereas Loren Carpenter’s
camera-driven Cinematrix [29] effectively and ec onomically
enables a large group to be instrumented with passive optical
targets, kinetic musical expression, such as interactive dance,
can have difficulty with the line-of-sight and lighting
constraints that video-based approaches require. Accordingly,
we have developed [30] an extremely compact wireless sensor
that sends a narrow RF pulse out when it’s jerked. As the
active duty-cycle is so brief and since the circuit needs no
complex components, a small, onboard watch battery lasts
years of regular use. The device, manufactured in large
quantity, is so inexpensive that it can be given out at sports
gameso rd ance ravesa sa party favor with the ticket, enabling
participants to contribute some level of group control over
interactive media. We have derived a set of real-time statistics
from the data stream that indicate the level of activity, mean
tempo, and significant events with many coincident hits, and
have used thesef eaturest od efinep arameterse xploited by an
interactive music system for MIT dance parties [31]. Alt hough
the results were intrigui ng, the area of i nteractive
entertainment for large groups is still quite open –
maintaining some degree of collective consonance and causal
engagement with scores of participants is a difficult, if not
impossible challenge [32].
These minimal wireless “featherweight” sensors have many
applications in other areas. We will soon deploy them in
“smart home” environments that monitor overall patterns of
activity for elder care– as ignificant and growing problem,
sinces om anys eniors are living alone and unattended. Much
more noninvasive than a camera or microphone, and
potentially more reliable, these minimal sensor packages can
be affixed to doors, furniture, cabinets, etc., where they will
produce a wireless response to associated activity. By
monitoring patterns evident in the wireless signals, deviations
in habits can be detected, potentially indicating an evolving
medical problem.
Figure 6: Dense peer-peer sensor network
4. ELECTRONIC SKINS
Anotheri nteresting frontieri nd ense,m ultimodal sensing is
posed by the concept of sensate electronic skins. Applications
abound in areas like robotics, telepresence, medical
diagnostics, and prosthetics for very dense tactile arrays that
approach the sensory capabilities of biological skin.
Similarly, significant technical challenges are posed here in
fabrication, microelectronics, and signal processing [33].
Today’s tactile arrays (e.g., FSR [34] and fiber opticmatrices
[35], “smart skin” for aircraft wings [36], etc.) are all heavily
multiplexed; a dedicated processor essentially scans all sensor
cells and looks at each piece of data. Accordingly, these
centralized systems have difficulty scaling up to large arrays
because of the mass of wiring and data involved. In order to
feasibly build such systems, processing must be blended
smoothly into the sensing substrate. A rough inspiration can
be taken fromb iology, where signals from tactile and other
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-231
sensor receptors are combined and preprocessed in the ner vous
system, often before reaching the brain [37]. Hence, a possible
manifestation of electronic skin involves a peer-peer, ad-hoc
sensor network, much as hasb een proposed for ba ttlefields,
cities, and buildings, but shrunk down to a mm node spacing.
In this scenario (Figure 6), a processor manages a group of
local sensors (a mix of different types can be included to
enable multimodal sensing – e.g., pressure, temperature,
proximity, etc.), collecting and processing the resultant data,
and communicating with its neighbors. When a stimulus
occurs, the processors will cl uster, character ize, and i solate it,
thereupon routing the resultant high-level features out node-
node to an external portal, suppressing the granular detail.
Such electronic skins could provide a very promising
technology for advanced musical interfaces, as they possess
both a high-resolution, multimodal, tactile sensing capab ility
together with the possibility of local optical, tactile, and
possibly acoustic display via actuators connected to each
processort hata re driven viaa distributed controls cheme.
Musicalp erformance or installation applications p lace tight
requirements on the latency of response (depending on the
instrument or interface, roughly 1-100 ms of delay can be
tolerated), hence routing and internode communications
protocols and topologies must be appropriately constrained.
Figure 7: 100 Pushpin nodes pushed into their substrate
Since the challenges here are considerable, we have
developeda fewh ardware testbedsw ith which we can conduct
experiments in dense sensor networks and begin to explore
applications of such electronic skins. The first, “Pushpin
Computing ,” [38] is composed of a large, sandwiched
conductor/insulator power plane and an array of small
processors with configurable communication and
sensing/actuation capabilities (via a set of layered boards, as
in theStack described above). As the bottom layer of the
Pushpin sports a pair of unequal-length insulated pins
connected to the local power lines, Pushpins can be pushed
into the power plane at any position, where they pull power
from the conductors and establish communication (currently
via IR) with their neighbors. Accordingly, the Pushpin system
ishighlyc onfigurable andh as been used to test dynamic
routing in sensor nets [39].
Another testbed now nearing completion is called the
“Trible ”( “Tactile Reactive Interface Based on Linked
Elements”) [40].S howni nF igure8 ,i ti se ssentially a soccer
ball tiled with 32 Circuit card “patches”, each hosting a 22
MIPs processor and an array ofu pt o1 8s e n s o r s ,including
pressure transducers, piezoelectric cantilevers bonded to
fibrous “whiskers” that protrude from holes in thes urface,
microphones, temperature monitors, and light sensors. As
each card also supports a small audio speaker, a vibrator, and
an RGB LED, all nodes are capable of providing a direct,
multimodal response. There is no central control in this
system –t he patches onlyt alkt ot heir neighbors, hence, as in
Figure 6, they collectively proces st he sensor information and
coordinate their local responses and/or route the processed
features out to an external c onnection. Although we have yet
to exploit its musical potential, with 516 channels of
multimodal sensing and local actuation, theTrible promises
to open up some interesting avenues of music control and
distributed sound generation.
Figure 8: The Trible,b e f o r ei n stallation of its whiskers
Figure 9: A few assembled Z-Tiles under test
The last device in this category is a collabor ation between
the Interaction Design Group at the University of Limerick
and the Media Lab’s Responsive Environments Group called
the “Z-Tiles ”[ 41]. Partially shown in Figure 9, it is an array of
interlocking, puzzle-shaped floor tiles, each of which hosts an
arrayo ff ivep rocessors anda seto ff orce-sensitive resistors,
each roughly 3 cm in diameter. Whe nt he tiles are interlocked,
a mating connector routes both power and digital data tile-tile,
hence a sensor network is built up as the floor is assembled.
Contrary to the previous sensate floors on which it was based
(e.g., ourMagic Carpet [16] and Limerick’s LiteFoot [42]),
which involved heavy cabling infrastructure that limited their
span, theZ-Tiles are intrinsically scalable. Upon d etecting
pressure, neighboring tiles will communicate to isolate and
characterize footsteps, then route the resulting featuresnode-
node to an attached computer that can provide an appropr iate
response. As the Z-Tiles were designed for interactive dance,
the routing and processing routines need to be sufficiently
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-232
prompt to avoid introducing excessive delay when passing
messages across the maximum span of tiles in a given
installation (and with a given amount of foot traffic).
Although prototype tests of a half-dozen linked tiles have
been completed, this system is currently under development.
The resultant floor is planned to be used not just in
entertainment, but alsoi n“ smart home” applications, where
gait can be characterized and occupants tracked [43]
throughout a responsive space.
Figure 10: The Musical Trinkets engaging a Crowd in Milan
5. OT HER  EXAMPLES
Many other technologies that have made their way into the
worlda t large have started fromo rb een inspired by musical
controllers. Force-sensitive resistors (FSR’s), common
components used for moderate-resolution pressure sensing in
many applications, were perfected by a founder of Interlink
[44] for sensing aftertouch on keyboard interfaces. The first
conceptual implementation of spread-spectrum
communication, posed by actress Hedi Lamarr and the
composer ofBallet Mechanique ,G e o r g eAntheil, was based on
the sequencing principles of a player piano [45].
I’veb een able to participatei n pushing af ew otherm usical
controller designs into a range of applications. The swept-
frequency tag reader that I designed for theMusicalT rinkets
installa tio n[ 46] wasi nspiredb y Electronic Ar ticle
Surveillance (anti-shoplifting) systems [47]. The Trinkets
hardware is now evolving further into a 3D volumetric tracker
for passive tags [48]. Although this has many potential
applications in augmented and virtual reality (e .g., various
control points on objects, fingers, etc. can be wirelessly tagged
andt racked), this incarnation was inspired by the need to tag
and precisely track the position of a tumor on a patient
undergoing radiation therapy [49].
The Sensor Chair [9]i sa nother controller that has had
particular success outside of the musical realm. It began its
life in 1994 as a transmit-mode capacitive sensing system to
track free gesture at the arms and legs of a seated occupant, in
this case, the magicians Penn and Teller, who used it to
perform a mini-opera by Tod Machover together with a
comedic séance [50]. Two attendees took special notice of this
device in its performance debut at MIT’s Kresge Auditorium
that summer. One was the current agent for the Artist formerly
known as Prince. After a convoluted series of events that is
difficult to summarize, this connection culminated in one of
the strangest musical interfaces that I’ve ever built, theSensor
Mannequin [9], an electric-field-sensing monstrosity probably
stored somewhere deep in Paisley Park now. The other
interested attendee at this event was from the North American
division of NEC Automotive. He saw theSensor Chair as a
potential solution to a persis tent problem in automotive
safety, namely a sensor system that could determine whether or
notto fire a car’s airbag duringa collision based on the status
of the facing seat’s occupant (several infants had recently been
killed by airbag deployments when their car seat was not
properly oriented). After adapting some of the innards of the
Sensor Chairsystem, then prototyping and testing many
layouts for sensate seats, they have moved to product with the
ElesysSeat Sentry [51], now a feature on several cars in current
production. Closing the circle, Motorola has recently r eleased
a9 -channel capacitive-sensing chip for this system, the
MC33794 [52]. Originally inspired by the electronics in our
chair,t hisd evice is au seful buildingb lock for musical
controller buildersw antingt ow orkm ultichanne l capacitive
proximity sensing into their interaction portfolio.
Figure 11: Bono enjoying the Sensor Chair at MLE, Dublin
6. CONCLUSIONS
Electronic Music Controllers have absorbed tec hnology,
ideas, and innovators from man yf ields of inqui ry and practice.
Conversely, developments in musical interfaces have also
contributed concepts, inspiration, and products to entirely
different areas of application. The field is very much amelting
pot,w here artists andt echnologists hailing from many
different backgrounds come together to exchange
perspectives. Such environments are fertile incubators for new
and disruptive concepts. Musical controllers also can provide
excellent testbeds and challenges though which to explore and
demonstrate ideas in areas like Ubiquitous Computing. Yes, at
the end of the day in this field,t he show is what counts the
most. But along the way, interesting tributaries lead to
territories that could never have been imagined beforehand.
It’s been aw ild ride,a nd there’sp lentyo fw ater still out there,
so hold onto the hull and keep exploring!
7. ACKNOWLEDGEMENTS
I’ve touched on several projects in this paper that many
people have contributed to, hence they all deserve
acknowledgement. My past and present students in the Media
Lab’sResponsive Environments Group have been instrumental
in most of these efforts; in particular, Kai-Yuh Hsiao, Ari
Benbasat, Josh Lifton, Mike Broxton, Eric Hu, and Stacy
Morris have been principal in many of the projects mentioned
here. My early work on violin bows, sensor chairs, and the
Brain Opera is what got me started in this area, thanks very
much to a longtime collaboration with Tod Machover.
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-233
Similarly, Neil Gershenfeld was the first to extend me the
invitation to switch from my w orld of physics detectors and
sonar systems at Draper Lab to the universe of bows and
gesture controllers at the Media Lab (as this article entails, it’s
hard to keep both feet in any one place!). Several alumni were
vital to some of the early projects noted here, particularly Ed
Hammond, Pete Rice, and Josh Smith, who hung on thr ough
the Sensor Chair and Brain Opera .A nd, of course, many other
students, faculty, and researchers at the Media Lab contributed
to the efforts described here and are thanked for making the
place the cutting edge that it is. I’ve delighted in exchanging
ideas with my many colleagues doing musical interfaces at
other institutes. In particular, Mikael Fernstrom from the
University of Limerick has been a resource and friend in many
projects beyond just the Z-Tiles. And, of course I give special
thanks to Max Mathews for not only being a pioneer and
inspiration to us all, but for also being perhaps the field’s
greatest boundary-breaker and cross-fertilizer as he brought
disparate talent and strong ideas together to push music deep
into the future.
8. REFE RENCES
[1] Hopkin, B., Gravikords, Whirlies & Pyrophones:
Experimental Musical Instruments, Ellipsis Arts, NY,
1996.
[2] Hopkin, B., Orbitones, Spoon Harps & Bellowphones ,
Ellipsis Arts, New York 1998.
[3] Paradiso, J.A., “Diary of a Teenage Synth Hacker,” Forward
to Kettlewell, B.,Electronic Music Pioneers ,P r o M usic
Press, Vallejo, CA, pp. 4-9, 2002. See also:
http://www.media.mit.edu/~joep/synth.html
[4] Carson, B., “The World’s First Digital Sample-Playback
Synthesizers,”Keyboard ,M arch 1995, pp. 38-46.
[5] Markowitz, J., Triumphs and Trials of an Organ Builder ,
Allen Organ Publishing, Macungie, PA, 1989.
[6] Paradiso, J.A., "From Tangibles to Toolkits and Chaos to
Convection - Management and Innovation at Leading
Design Organizations and Idea Labs," Presented at the
Workshop onManaging as Designing: Creating a
vocabulary for management education and research ,
Weatherhead School of Management, Case Western
Reserve University, Cleveland OH, June 14-15, 2002. To
be Published, Stanford University Press.
[7] Fernow, R., Introduction to Experimental Particle
Physics, Cambridge University Press, 1986.
[8] Mathews, M.V., "Three Dimensional Baton and Gesture
Sensor", US Patent No. 4980519, Dec. 25, 1990.
[9] Paradiso, J., Gershenfeld, N. "Musical Applications of
Electric Field Sensing",Computer Music Journal , 21(3),
1997, pp. 69-89.
[10] Machover, T., Hyperstring Trilogy ,O x ingale Records,
April, 2003.
[11] Paradiso, J., "New Technologies for Monitoring the
Precision Alignment of Large Detector Systems,"Nuclear
Instruments and Methods in Physics Research A386,
1997, pp. 409-420.
[12] Paradiso, J., "The Brain Opera Technology: New
Instruments and Gestural Sensors for Musical Interaction
and Performance,"Journal of New Music Research , 28(2),
1999, pp. 130-149.
[13] Marrin, T. and Paradiso, J., ``The Digital Baton: A
Versatile Performance Instrument,''in Proc. Int. Computer
Music Conf. (ICMC'97) , pp. 313-316.
[14] Paradiso, J., "Testing and Development of Extended
Range Straightness Monitor Systems", GEM
Collaboration Report (SSCL), GEM-TN-93-331, May
1994.
[15] Paradiso, J., et al.," Sensor Systems for Interactive
Surfaces," IBM Systems Journal ,V o lume 39, Nos. 3 & 4,
October 2000, pp. 892-914.
[16] Paradiso, J., et al., "New Sensor and Music Systems for
Large Interactive Surfaces," Proceedings of the
International Computer Music Conference (ICMC 2000),
pp. 277-280.
[17] Hashemi, K.S., Hurst, P.T., and Oliver, J.N., “Sources of
Error in a Laser Rangefinder,”Review of Scientific
Instruments 65, No. 10, 3165-3171 (1994).
[18] Paradiso, J.A., and O’Modhrain, S., “Current Trends in
Electronic Music Interfaces,”Journal of New Music
Research ,t ob e published, July 2003.
[19] Weiser, M., "The Computer for the Twenty-First Century,"
Scientific American, pp. 94-10, September 1991.
[20] Paradiso, J. and Hu, E., "Expressive Footwear for
Computer-Augmented Dance Performance," inProc. of the
First International Symposium on Wearable Computers ,
Cambridge, MA, IEEE Computer Society Press, Oct. 13-14,
1997, pp. 165-166.
[21] Paradiso, J., et al., "Design and Implementation of
Expressive Footwear," IBM Systems Journal ,V o lume 39,
Nos. 3 & 4, October 2000, pp. 511-529.
[22] See: http://webs.cs.berkeley.edu/tos/
[23] Blaine, T. (Bean), “Tech: A Soft Touch,” Electronic
Musician ,J une 1998, pp. 106-109.
[24] Paradiso, J., "FootNotes: Personal Reflections on the
Development of Instrumented Dance Shoes and their
Musical Applications," in Quinz, E., ed., Digital
Performance,Anomalie, digital_arts Vol. 2, Anomos,
Paris, 2002, pp. 34-49.
[25] Benbasat, A., Morris, S., Lovell, D., Paradiso, J., “A
Wireless Modular Sensor Architecture and Application in
On-Shoe Gait Analysis,” Submitted to theIEEE Sensors
Conference, 2003, Toronto, CA.
[26] Morris, S.J. and Paradiso, J.A., “A Compact Wearable
Sensor Package for Clinical Gait Monitoring,”Offspring
Vol. 1, No. 1, pp. 7-15, January 31, 2003.
[27] Raghunathan, V., et al., “Energy Aware Wireless
Microsensor Systems,” IEEE Signal Processing Magazine,
March 2002, pp. 40-50.
[28] Camurri, A., Ricchetti, M., Trocca, R., “EyesWeb - Toward
Gesture and Affect Recognition in Dance/Music
Interactive Systems,”ICMCS,V ol. 1, 1999, pp. 643-648.
[29] Carpenter, L., “Cinematrix, Video Imaging Method and
Apparatus for Audience Participation,” US Patents
5210604 (1993) and 5365266 (1994).
[30] Feldmeier, M. and Paradiso, J., “Ultra-Low-Cost Wireless
Motion Sensors for Musical Interaction with Very Large
Groups,” Presented at theUBICOMP 2001 Workshop on
Designing Ubiquitous Computing Games ,A C M
UBICOMP Conference Proceedings, Atlanta GA, Sept.
2001.
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
NIME03-234
[31] Feldmeier, M., Malinowski, M., Paradiso, J., “Large Group
Musical Interaction using Disposable Wireless Motion
Sensors,” in theProceedings of the ICMC 2002
Conference, International Computer Music Association,
San Francisco CA, pp. 83-87, September 2002.
[32] Ulyate, R. and Bianciardi, D., “The Interactive Dance Club:
Avoiding Chaos in a Multi-Participant Environment,”
Computer Music Journal,V ol. 26, No. 3, Fall 2002, pp.
40-50.
[33] Lumelsky, V., Shur, M.S., Wagner, S., “Sensitive Skin,”
IEEE Sensors Journal,V ol. 1, No. 1, pp. 41-51 (2001).
[34] Papakostas, T., Lima, J., and Lowe, M., “A Large Area Force
Sensor for Smart Skin Applications,”in Proc. of the IEEE
Sensors 2002 Conference ,V ol. 2, pp. 1614-1619.
[35] See: http://www.tactex.com/
[36] Udd, E. (ed.), Fiber Optic Smart Structures, Wiley, 1995.
[37] Kandel, E.R., Schwartz, J.H., and Jessell, T.M., Principles
of Neuroscience ,4 th Ed., McGraw-Hill, 2000.
[38] Lifton, J., Seetharam, D., Broxton, M., Paradiso, J.,
“Pushpin Computing System Overview: a Platform for
Distributed, Embedded, Ubiquitous Sensor Networks,” in
F. Mattern and M. Naghshineh (eds):Pervasive 2002 ,
Proceedings of the Pervasive Computing Conference,
Zurich Switzerland, 26-28 August 2002, Springer Verlag,
Berlin Heidelberg, pp. 139-151.
[39] Lifton, J., et. al.,“ AS ensor Network Connectedness
Determination Algorithm and Implementation,”
submitted to the ACM Sensor Network Conference
(SenSys ), 2003.
[40] Lifton, J., Broxton, B., and Paradiso, J., “Distributed
Sensor Networks as Sensate Skin,” Submitted to theIEEE
2003 Sensors Conference ,T o ronto CA.
[41] McElligott, L., et al., “‘ForSe FIElds’ – Force Sensors For
Interactive Environments,” in Borriello, G. and
Holmquist, L.E. (Eds.):UbiComp 2002 ,S p r inger-Verlag
Berlin Heidelberg, LNCS 2498, pp. 168-175, 2002.
[42] Griffith, N. and Fernström, M., “LiteFoot: A Floor Space
for Recording Dance and Controlling Media,”
Proceedings of the 1998 International Computer Music
Conference,I nternational Computer Music Association,
San , CA (October 1998), pp. 475-481.
[43] Orr, R.J. and Abowd, G.D., “The Smart Floor: A Mechanism
for Natural User Identification and Tracking,” in
Proceedings of the CHI 2000 Conference on Human
Factors in Computing Systems: Extended Abstracts,A C M
Press, New York (2000), pp. 275-276.
[44] See: http://www.interlinkelec.com/
[45] Braum, Hans-Joachim, "Advanced Weaponry of the Stars,"
American Heritage of Invention and Technology,V o l. 12,
No. 4, Spring 1997, pp. 10-17.
[46] Paradiso, J.A., Pardue, L.S., Hsiao, K., and Benbasat, A.,
“Electromagnetic Tagging for Electronic Music
Interfaces,” To appear in theJournal of New Music
Research ,J uly 2003.
[47] Lichtblau, G.J. Resonant Tag and Deactivator for use in
Electronic Security System, US Patent No. 4,498,076, Feb.
5, 1985.
[48] Paradiso, J.A., Hsiao, K., "Multiple-axis tracking of
passive resonant structures," US Patent No. 6,404,340,
June 11, 2002.
[49] Dr. Paul G. Seiler, Paul Scherr Institute (PSI), Villigen,
Switzerland, personal communication, 1999.
[50] Machover, T ,M e dia Medium (musical score), Ricordi,
Milan/Paris, 1994. Debut performance at the Digital
Expression Symposium ,M I TK r e s g eAuditorium, October
20, 1994.
[51] http://www.elesys.co.jp/
[52] Ohr, S., “Non-contact sensor discerns passenger size for
airbags,” EE Times, February 6, 2003.