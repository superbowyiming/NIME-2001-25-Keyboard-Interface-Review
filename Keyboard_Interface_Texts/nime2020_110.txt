The Appropriation and Utility of Constrained ADMIs
Joe Wright
Integra Lab, Royal Birmingham Conservatoire
Birmingham City University
Millennium Point, Curzon St.
Birmingham, UK, B47XG
joe.wright@bcu.ac.uk
ABSTRACT
This paper reﬂects on players’ ﬁrst responses to a con-
strained Accessible Digital Musical Instrument (ADMI) in
open, child-led sessions with seven children at a special
school. Each player’s gestures with the instrument were
sketched, categorised and compared with those of others
among the group. Additionally, sensor data from the in-
struments was recorded and analysed to give a secondary
indication of playing style, based on note and silence dura-
tions. In accord with previous studies, the high degree of
constraints led to a diverse range of playing styles, allow-
ing each player to appropriate and explore the instruments
within a short inaugural session. The open, undirected ses-
sions also provided insights which could potentially direct
future work based on each person’s responses to the instru-
ments. The paper closes with a short discussion of these
diverse styles, and the potential role constrained ADMIs
could serve as ‘ice-breakers’ in musical projects that seek
to co-produce or co-design with neurodiverse children and
young people.
Author Keywords
appropriation, constraint, design principles and concepts,
inclusive music, neurodiversity
CCS Concepts
•Human-centered computing → HCI theory, con-
cepts and models; User centered design; •Applied
computing → Sound and music computing;
1. INTRODUCTION
Recent artistic projects such asSound to Music [12], the Ar-
tism Ensemble [3], and Jamboree [6] all reﬂect an increasing
desire among the makers of inclusive art and music to ﬁnd
ways to make work that is either led by, or co-produced with
neurodiverse groups of young people. Such projects create
an exciting space for new music and new musical experi-
ences, and allow mixed groups of people to learn from one
another. However, these are also contexts which are par-
ticularly vulnerable to the enculturated habits and assump-
tions about music and performance held by neurotypical
people participating in, or on the periphery of the music;
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’20, July 21-25, 2020, Royal Birmingham Conservatoire,
Birmingham City University , Birmingham, United Kingdom.
long-standing biases can often slow or impede collabora-
tion [2, 6]. The design of Accessible Digital Musical Instru-
ments (ADMIs) for such contexts, therefore, presents an
interesting requirement: one of needing to remain open to
a diverse range of perspectives and preferences, which can
all be at play simultaneously within an ensemble [5, 16].
Designing ADMIs with high levels of constraints may be
one way to achieve such openness. As well as presenting a
lower technical and cognitive entry point for music-making,
previous studies with neurotypical groups have found that
not only can diverse performance styles occur in spite of
a DMI’s heavy constraints, they may actually be encour-
aged by them [7, 18]. Instruments with extreme constraints,
modelled after instruments in these previous studies, could
be valuable as an open and more immediate alternative
to hyper-conﬁgurable, commercially available accessible in-
struments, as the choice oﬀered by the latter can risk dis-
empowering the player by oﬄoading aesthetic decisions to
a music/arts facilitator [17]. The work outlined below ad-
dresses this very notion, of the potential utility of delib-
erately constrained instruments as a means to support or
develop unique musical practices with young neurodiverse
performers.
2. ONE-BUTTON SOUND CUBES
Figure 1: One of three one-button sound cubes.
A single-button ADMI was designed speciﬁcally for the
small scale study. The instrument’s structure was 3D printed,
with two colours marking out a single analogue push-button
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
564
and speaker grille. These were placed on opposite sides of
an 8cm cubic frame, as shown in Figure 1. Inside, the fully
embedded instrument houses a Teensy 4.0 microcontroller
and I2S ampliﬁer. Sounds were designed using the Teensy
Audio Library and FAUST platforms, and were all based
around the same clarinet physical model. A bluetooth mod-
ule was also added to the instrument to allow sensor data
to be streamed to a laptop.
Three versions of this instrument were used in the study,
with a variety of approaches to sound design taken in order
to support a diverse range of sonic preferences. This was
based around the idea ofinteraction-congruence, in which
sounds are designed based on anticipated relationships be-
tween sound, technique and expectations in the performers’
use of the instrument [16]. The ﬁrst instrument, coloured
blue, was designed to behave in a highly predictable fash-
ion by mapping the analogue range of the button directly
to the volume of a single tone. A second orange instrument
also had a predictable mapping of the button to volume,
but with added potential to play melodies. Quick succes-
sive presses would cycle through a 12-tone row, while a long
pause would reset the play position to the start of a row.
This was inspired by Skoog Music’s 1-button instrument,
theSkwitch [11]. The tone row was randomly generated
each time the instrument is turned on. As a result, the or-
ange instrument was predictable in its behaviour, but with
some ‘hidden’ information that could be discovered and ex-
plored. The third, white instrument was designed to provide
a more ambiguous relationship with gestures and sounds.
The clarinet physical model was placed within a feedback
loop, controlled by the button, resulting in non-linear be-
haviour. Repeated gestures on this instrument would pro-
duce broadly similar results, but which were also diﬃcult
to predict in detail.
3. METHODS
The instruments were played by a small group of seven non-
verbal young people in short solo sessions of up to ﬁfteen
minutes, situated in an uncluttered music room at a col-
laborating special school. These sessions were planned and
structured based on prior experiences in inclusive theatre,
particularly with the Oily Cart theatre company [10]. This
work typically employed social stories to minimise any po-
tential anxiety over changes to routine, made use of clear,
minimal performance structures and used little or no ver-
bal language, helping to focus activities around the materi-
als on oﬀer, and on non-verbal interaction between partic-
ipants. Following a similar model, social stories were sent
out in advance of the sessions, and the sessions were largely
non-verbal and non-instructive, leaving each player to in-
teract with the instruments as they saw ﬁt. The sessions
were clearly structured in ﬁve possible sections: a warm up
with some recorded music, the introduction of the blue, or-
ange and white instruments one by one, and, if needed, a
cool-down section with another recorded track. Adults in
the sessionscould interact in the sessions, but only in ways
prompted by the player (an approach similar to Intensive
Interaction [8]), or if a lack of direction could cause distress
or confusion. Sessions were recorded with a compact HD
video recorder, secured discreetly to a wall in the room.
The subsequent analysis of the session recordings was
informed by prior studies on constrained instruments by
Gurevich et al. [7], and Zappi & McPherson [18]. How-
ever, the range of data for this study was restricted to two
aspects that could be directly seen and recorded – gesture
types and note/silence lengths – as there was little or no
possibility for verbal feedback from the group, and a high
risk of interpretive error beyond these categories. Even with
these limited modes of analysis, it is important to acknowl-
edge that the data presented below is qualitative, and takes
a very simpliﬁed view on playing styles within the group,
as seen by a neurotypical observer.
Gestures were codiﬁed inductively – similar to the ap-
proaches taken in [7] and [18] – by recording the ﬁrst in-
stances of a new gesture in each session, and organising
the subsequent list by category and variation. This process
loosely deﬁned a ‘new gesture’ as anything that would feel
or sound signiﬁcantly diﬀerent for the player in their use of
the instrument. In some cases, the process of deﬁning a new
gesture involved the use of sketching as a form of non-verbal
thinking about the spacial nature of the gestures [9], and/or
physically copying sets of gestures from the video footage
to gain a ﬁrst-hand interpretation of what they might feel
like. These gestures were then plotted against a list of par-
ticipants as a means to observe the commonalities and dif-
ferences in gestures performed by the group.
Sensor data was recorded via bluetooth from the instru-
ments for the active duration of the session. Initially, the
use of heat maps (as in [18]) was explored as a way of suc-
cinctly representing the use of the sensor’s dynamic range
across a whole session. This was eventually abandoned,
however, as it became diﬃcult to separate intentional dy-
namic gestures from cases where some dynamic motion is
simply a byproduct of a playing technique. Instead, the sen-
sor data was used to give an indication of rhythmic style,
taking inspiration from the analysis of note-silence pairs in
one button instruments by Gurevich et al. [7]. The same
deﬁnitions for short, medium and long notes/silences were
used: short durations were deﬁned as under 1s, medium du-
rations between 1 and 3s, and long durations as over 3s. As
some players used all three instruments at once, it wasn’t
possible to analyse the sensor data by note-silence pairs as
in [7]. Instead, the distribution of note/silence lengths is
represented as a percentage of the time from the onset of
the ﬁrst gesture to the end of the last within a session. In
cases where multiple instruments were used simultaneously,
the percentages for short/medium/long notes was taken as
a proportion of the playing percentage for a session. This
use of time as an indicator of engagement with musical fea-
tures is similar to the approach taken on a previous project
that aimed to record responses to ADMIs’ with diﬀering
interaction-congruence [16]. A simple sketch in Processing
3 was used to calculate and render the note/silence lengths
and percentages for each session. Regions of sensor data
for short, medium and long notes were coloured red yellow
and green respectively, and silences with darker versions of
those same colours. This allowed the rhythmic ﬁngerprint
of each session to be seen once the data was visualised.
Finally, all categorised gestures were again sketched from
video stills as part of the documentation process. This was
primarily a means by which the creative contributions of
the young people at the school could be made visible and
acknowledged, without causing ethical and safeguarding is-
sues related to privacy and identity. Identifying features –
such as facial features, hair, etc. – were not drawn.
For reasons of space, only some of the data from this study
can be shown here, but what is included are sketches of all
the sounding gestures, visualised sensor data, percentages
for note/silence lengths, and a gesture comparison chart1.
1Supplementary data, as well as larger-size versions of the charts and
images, can be found at:
http://joewrightmusic.co.uk/NIME20Files.zip
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
565
Figure 2: Gestures performed with the Constrained Instruments.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
566
Figure 3: Chart of recorded gestures from the seven players.
Figure 4: Sensor data collected during each player’s session.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
567
4. FINDINGS
4.1 Analysis
The responses of the seven players to the constrained in-
struments were indeed very diverse across all aspects of
this data. A total of 83 gestures were recorded comprising
75 sounding gestures (where the instrument is producing
sound), and 8 non-sounding gestures (in which a player is
engaged with the instrument in a way that does not directly
produce sound). Sounding gestures were divided into a fur-
ther set of categories: Squeezes (10), thumb-presses (8),
hand/arm-presses (24), strikes/taps (8), grabs/holds (13),
swipes (1), mutes (1), body presses (3), as well as cooper-
ative pressing (5) and cooperative tower stacking gestures
(2). Of all the gestures, only 13 (16%) were not unique to
one person, and only one of these actions was shared by
more than two people. This can be seen in Fig. 3. All
except one of the players’ gesture-sets were at least 60%
unique, and none shared gestures with more than half of
the whole group. All of these perspectives on the recorded
gestures suggest that the constrained instruments elicited
a very diverse range of playing techniques, and that the
playing style of each musician was more unique than it was
shared with the group (although there were commonalities).
Visualisations of sensor data were similarly varied. Al-
though all players engaged positively with the instruments,
the session times varied drastically. This was to be ex-
pected, given that the group were trying something new,
with a relatively unknown person, and with little in the
way of speciﬁc instructions. Players 2-5 have clear rhyth-
mic and dynamic ﬁngerprints which can be seen in Figure
4, and where there are similarities in some aspects of the
sensor data, diﬀerences can be seen elsewhere. For instance,
the ﬁrst four minutes of data for players 6 and 7 are similar,
but diverge with the introduction of the white sound-cube.
One appears disinterested, while the other begins to ex-
plore longer gestures. Sessions from players 1 and 6 have
similar rhythmic proportions, but appear very diﬀerent in
the sensor data plots. Player 2, who appeared to share the
most in common with other players in the gesture chart, is
set apart in this dataset by a strikingly consistent session
timeline, which is overwhelmingly dominated by punctu-
ated, medium length notes. The sensor data, then, also
suggests a degree of individuality in the playing styles of
each player.
As Fig. 3 shows, there are sets of related gestures within
each category which emerge from a single player. As the
sketches in Fig. 2 appear in the same order, it is possible
to see how these sets of gestures ﬂow from one another as
part of exploratory musical play. In some cases, this ex-
ploration led to the discovery ofhidden aﬀordances in the
constrained instruments. This can be seen in gestures 2H,
5L and 5M, where the cubes’ open speaker grille can be
obstructed, producing a wah-wah eﬀect; in gestures 5B-5E,
where the body of the instrument is slammed onto another
surface for an acoustic percussive sound; and in 6A, where
a player swept their ﬁngers over the holes in the speaker
grille, no-doubt leading to a satisfying tactile experience
along with the gentle sweeping sounds.
The data gathered during this small study suggests a sim-
ilar outcome to previous studies on constrained instruments
[7, 18], but in a diﬀerent context, with a slightly diﬀerent
approach. At the very least, the constrained instruments
were capable of supporting the diverse playing styles within
this small group of young people. It is also possible that
– given the exploratory play and discovery of hidden aﬀor-
dances – the constraints of these instruments encouraged
the players to look for satisfying ways to play them.
4.2 Individual Styles
At this point in the paper, I wish to explore the less im-
personal aspects of the data gathered for the study. Not
only does the information arising from the constrained in-
struments suggest a degree of individuality for each player
relative to rest of the group, it also suggests potential av-
enues for further collaboration with each of these people.
This is especially true when coupled with my ﬁrst-hand ex-
periences of the sessions.
As discussed in [17], constrained instruments can create
more clarity for the user in the exploration of diﬀerent ges-
tures, and greater clarity for the observer in discerning how
and why a player might be responding to an instrument. As
a result of this clarity, my ﬁrst impressions for each player
in these sessions with the constrained sound cubes, can be
summarised as follows:
Player 1 was most engaged by cooperative press ges-
tures. Future work might explore a musical equivalent of
Ahlquist’sSocial Sensory Architectures [1], where the most
satisfying sensory results are only accessible through coop-
erative play.
Player 2had a highly consistent style, seemingly focused
on joining/combining sounds into phrases, rather than vary-
ing technique or note length. A more traditional keyboard-
like approach, distributed across many devices, may expand
this yet further.
Player 3’s gestures were exclusively percussive, but were
also mediated by a thirst for new sounds. Future work could
explore how a large number of sounds could be made acces-
sible through a drum-like interface.
Player 4used the instruments in a wide variety of ways,
being the only player to use an instrument as a drone whilst
playing another more percussively. This could lead to explo-
rations of instruments that take contrasting textural roles
in sound, and can either be set up to play continuously, or
on a momentary basis.
Player 5, by contrast, played drones almost exclusively
during their session, and ignored the white sound cube.
Next steps might include the design of drone-devices that
create a sonic environment that supports anindwelling rather
than musicking stance (see [13]) towards instruments in per-
formance.
Player 6was very engaged for most of their short session,
and it appeared that much of the exploration of the instru-
ments sought to maximise vibrotactile intensity. Further
work could explore how the haptic potential of the instru-
ment could be increased and extended to diﬀerent sounds.
Player 7 also seemed highly motivated by the vibrotac-
tile potential of the instruments. But the performance style
changed with the introduction of the more chaotic instru-
ment, becoming more focused on its unpredictability. Fu-
ture work could therefore explore strongly vibrating or res-
onant devices with non-linear sound design.
5. DISCUSSION
This study found that, with a small pool of neurodiverse
players, the three constrained ADMIs facilitated a very di-
verse range of playing techniques and styles, providing a
valuable ﬁrst impression for each person’s musical tastes.
Future research plans stemming from this project will aim
to explore how the collaborative ideas listed above can guide
the development of bespoke prototype ADMIs for each of
the seven players in the study. Like all ﬁrst impressions,
these ideas could be wrong, and where this proves to be the
case, constrained ADMIs may again provide a clear tool
with which to explore such a misunderstanding. More gen-
erally, highly constrained ADMIs may prove useful for in-
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
568
clusive arts, music and design when used in this way. As
detailed above, they can provide fewer technical/cognitive
barriers to participation, and instead emphasise personal
style in sonic/musical interaction. As such, they may be
able to serve as ’ice-breakers’ for contexts that aim for ef-
fective collaboration with neurodiverse children and young
people, and also serve as a mediating tool through which
diverse groups of people (players, makers, designers, mu-
sic providers etc.), can take part in a longer-term dialogue
through musical play, observation and production. In both
the ﬁelds of inclusive ADMI design and performance, this
could be a fruitful area for further research and experimen-
tation.
6. INCIDENT AL OBSERV A TIONS
I have seen yet more evidence in this study for the value
of fully embedded instruments in inclusive musical settings,
building on similar evidence in my prior work [15]. Vi-
bration seeking behaviours in many of the group members
reinforces arguments put forward by Frid [4] that vibro-
tactile feedback is currently under-utilised in ADMIs. The
embedded nature of the sound cubes also allowed users to
project sounds where they wanted to (i.e. Gestures 1H, 2E,
3T, 8B). This enforces the need to consider an ADMI’s sen-
sory coherence (the co/dis-location of sensory feedback an
instrument produces), as stressed by Ward et al. [14].
7. ACKNOWLEDGMENTS
I would like to thank Andrew McPherson and Jacob Harri-
son for a very enjoyable and thought provoking conversation
which helped a great deal during a sticking point in prepara-
tion for this project. Also instrumental in the project were
BS and KHS for their willingness to collaborate and help in
the organisation of this work. Most of all I wish to thank
the seven participants. They, along with the staﬀ working
with them, cannot be named, but the creativity, originality
and ingenuity I observed in their musical play was a plea-
sure to witness, and has inspired me to be more open and
creative in my won instrumental practice.
8. ETHICAL ST ANDARDS
This research was conducted in accordance with ethical
standards and best practices at the Royal Birmingham Con-
servatoire, Birmingham City University and the participat-
ing school. All the data for the study has been gathered
with permission from parents and guardians, and every ef-
fort has been taken to safeguard the young people involved.
9. REFERENCES
[1] S. Ahlquist. Social Sensory Architectures:
Articulating Textile Hybrid Structures for
Multi-sensory Responsiveness and Collaborative Play.
ACADIA, Computatio(39):262–273, 2015.
[2] M. Bakan. “Don’t Go Changing to Try and Please
Me” : Combating Essentialism through Ethnography
in the Ethnomusicology of Autism.Ethnomusicology,
59(1):116, 2015.
[3] M. B. Bakan. Speaking for Ourselves: Conversations
on Life, Music, and Autism - Michael B. Bakan -
Google Books. Oxford University Press, New York,
NY, 1 edition, 2018.
[4] E. Frid. Accessible Digital Musical Instruments—A
Review of Musical Interfaces in Inclusive Music
Practice.Multimodal Technologies and Interaction ,
3(3):57, 2019.
[5] E. Griﬃths. Spinning Bowls and Milk Bottle Shoes.
http://bit.ly/spinning-bowls, May 2017.
[6] E. Griﬃths. Making Jamboree: A Blog from Ellie.
https://oilycart.org.uk/resources/making-jamboree-a-
blog-from-ellie/, Sept.
2019.
[7] M. Gurevich, P. Stapleton, and A. Marquez-Borbon.
Style and constraint in electronic musical instruments.
InNIME ’10 Proceedings of the 2010 Conference on
New Interfaces for Musical Expression , pages
106–111, Sydney, Australia, 2010. Univeristy of
Technology Sydney.
[8] Intensive Interaction Institute. Intensive Interaction -
Fundamentals of Communication.
https://www.intensiveinteraction.org/, 2020.
[9] M. M ¨akel¨a, N. Nimkulrat, and T. Heikkinen. Drawing
as a research tool: Making and understanding in art
and design practice.Studies in Material Thinking ,
10:3–12, 2014.
[10] Oily Cart. Oily Cart – Reimagining theatre for young
audiences to make it more accessible.
https://oilycart.org.uk/, 2020.
[11] Skoog Music. Skwitch | one-button music making
gadget | Skoogmusic.
https://skoogmusic.com/skwitch/, 2020.
[12] Sound to Music. SOUND to MUSIC - Trailer.
https://www.youtube.com/watch?v=iMS2sXgL0hQ,
2013.
[13] K. Tuuri, J. Parviainen, and A. Pirhonen. Who
controls who? Embodied control within
human–technology choreographies.Interacting with
Computers, 29(4):494–511, 2017.
[14] A. Ward, L. Woodbury, and T. Davis. Design
Considerations for Instruments for Users with
Complex Needs in SEN Settings. InNIME ’17
Proceedings of the 2017 Conference on New Interfaces
for Musical Expression, Copenhagen, Denmark, May
2017. Aalborg University.
[15] J. Wright. The Design of Exploratory Sonic-Play
Instruments With Non-Verbal Young People on the
Autistic Spectrum. Ph.D. thesis, Royal Birmingham
Conservatoire, Birmingham City University,
Birmingham, UK, 2019.
[16] J. Wright. Interaction Congruence in the Design of
Exploratory Sonic Play Instruments With Young
People on the Autistic Spectrum. In
R. Hepworth-Sawyer, J. Hodgson, J. Paterson, and
R. Toulson, editors,Innovation in Music:
Performance, Production, Technology, and Business ,
pages pp301–322. Routledge, London, 1st edition
edition, 2019.
[17] J. Wright and J. Dooley. On the Inclusivity of
Constraint: Creative Appropriation in Instruments
for Neurodiverse Children and Young People. In
M. Queiroz and A. X. Sed´ o, editors,Proceedings of
the International Conference on New Interfaces for
Musical Expression, pages 162–167, Porto Alegre,
Brazil, June 2019. UFRGS.
[18] V. Zappi and A. P. McPherson. Dimensionality and
Appropriation in Digital Musical Instrument Design.
InNIME ’14 Proceedings of the 2014 Conference on
New Interfaces for Musical Expression , pages 455–460,
London, 2014. Goldsmiths, University of London.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
569