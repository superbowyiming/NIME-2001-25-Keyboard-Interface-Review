From Atmosphere to Intervention: The circular dynamic of installations in hospital waiting areas  Georg Hajdu, Benedict Carey, Goran Lazarević Center for Microtonal Music and Multimedia (ZM4) Hamburg University of Music and Drama Harvestehuder Weg 12  20148 Hamburg, Germany  {georg.hajdu, benedict.carey, goran.lazarevic}@hfmt-hamburg.de  
 Eckhard Weymann Institute for Music Therapy Hamburg University of Music and Drama Harvestehuder Weg 12  20148 Hamburg, Germany  eckhard.weymann@hfmt-hamburg.de   ABSTRACT This paper is a description of a pilot project conducted at the Hamburg University of Music and Drama ( H f M T ) d u r i n g  t h e  academic year 2015-16. In this project we have addressed how interventions via interactive, generative music systems (i.e. sound installations) may contribute to the improvement of the atmosphere and thus to the well-being of patients in hospital waiting areas. The project was conducted by both the students of the music therapy and multimedia composition programs and has thus offered rare insights into the dynamic of such undertakings covering both the therapeutic underpinnings, as well as the technical means required to achieve a particular result.  DJster, the engine we used for the generative processes is based on Clarence Barlow’s probabilistic algorithms. Equipped with the proper periphery (sensors, sound modules and spatializers), we looked at three different scenarios, each requiring specific musical and technological solutions. The pilot was concluded by a symposium in February 2017 and the development of a prototype system. The symposium yielded a diagram detailing the circular dynamic of the factors involved in this particular project, while the prototype was demoed in June 2016 at the HfMT facilities. The system will be installed permanently at the University Medical Center Hamburg-Eppendorf  (UKE) in June 2017.  1. INTRODUCTION  The concept of “healing environment for healthcare buildings” has been described as: “… a physical setting and organizational culture that supports patients and families through the stresses imposed by illness, hospitalization, medical visits, the process of healing, and sometimes, bereavement. The concept implies that the physical healthcare environment can make a difference in how quickly the patient recovers from or adapts to specific acute and chronic conditions” [1]. It is not only the room’s architecture, materials, colours and light design t h a t affect patients and personnel. Acoustic conditions, the soundscape, are no less influential than these aspects—“soundscape regards the complex sound environment, embracing positive sounds as well as annoyance” [2]. All these varied sensuous influences tune the atmosphere of a room, they modify the a c t u a l p s y c h o l o g i c a l  s tate; and vice versa: the inner “framing” (the circumstances and reasons for sitting here) influences the perception of a situation.  Coming from music therapy and from multimedia composition our questions in the pilot project were: 
 
 • What are the acoustic and atmospheric conditions both for patients and for staff in three different waiting areas of the UKE? • Could we modify and improve these conditions by means of an interactive, generative sound installation? Although music therapists were a m o n g  t h e  i n s t i g a t o r s  o f  t h i s  project, this kind of sound intervention is not to be called music therapy. Music listening and sound interventions can be part of the practice of music therapy, but there is a consensus that a therapeutic relationship is needed to call a musical intervention music therapy. “Music therapy is a reflexive process where the therapist helps the client to optimize the client’s health, using various facets of music experience and the relationships formed through them...” [3]. In our case there was no therapist, no therapeutic relationship and no treatment agreement involved. However our interest in observing the everyday soundscape in hospital waiting rooms from the position of therapeutic sensitivity: the soundscape is an important part of the “healing environment”—for patients as well as employees.   
 Fig. 1. Circular dynamic of installations in healing environments  2. FROM SONIC ENVIRONMENT TO ATMOSPHERE TO WELL-BEING Atmosphere, a key concept in the philosophy of Gernot Böhme and other proponents of the New Aesthetics movement, connects the physical and the psychological conditions in their environment: the emotional state of a person in a waiting room and the physical environment of the room b o t h  i n f l u e n c e  t h e  
364
perceived atmosphere. Böhme p l a c e s  a t m o s p h e r e  w i t h i n  “the relation between environmental qualities and human condition” [4]. So we have an object-pole and a subject-pole as two sides of the evolving atmosphere in a given situation. The atmosphere is not in the room, like a substance; but the specific conditions of the room allows one to perceive atmospheric “tuning” a g a i n s t  t h e  b a c k g r o u n d  o f  one’s e m o t i o n a l  s i t u a t i o n .  Atmospheres are relational in-between phenomena. Sound interventions modify the acoustic conditions of a room, they influence the atmosphere in a room and thus may modify the mood and increase the well-being of listeners, patients and staff (see Fig. 1).  Our a i m  t o  c r e a t e  music o r  a  s o u n d s c a p e  w h i c h  h a s  l i t t l e  performativity and draws little attention, but has an implicit effect in modifying the atmosphere, is rooted in the work of well-known progenitors. When Eric Satie composed his “Musique d’ameublement” in 1920 for a vernissage at an art gallery, he claimed that the music “creates a vibration: it has no other goal; it fills the same role as light, heat— as comfort in all its forms” [5]. Satie compared the compositions to furniture, tapestry and acoustic tiling—and did not even want people to sit and listen attentively to this “background noise”.  Since the middle of the 20th century composers like John Cage and Morton Feldman, and later György Ligeti, have been engaged in abstaining from dynamic and dramatic development in their music. When Cage turned his interest to the sounds of the environment within his compositions he wanted to have “music” without the intentions of a composer. Feldman wrote pieces of “silent music” which sometimes never exceeded the dynamic of piano—he was “seldom raising his musical voice above a whisper” [6].1 Or think of Ligeti’s Atmosphères (1971), where the compositional technique of micropolyphony and the absence of hierarchical structures like melody, harmony, and rhythm convey atmospheric impressions of a process of emergence.  Brian Eno composed ambient music, which emphasizes atmosphere within space. “An ambience is defined as an atmosphere, or a surrounding influence: a tint. My intention is to produce (...) environmental music suited to a wide variety of moods and atmospheres. (...) Ambient music must be able to accommodate many levels of listening attention without enforcing one in particular; it must be as ignorable as it is interesting”[7], a concept that could also be referred to as “neutral music”. In 2013 Brian Eno designed (generative) light and sound installations, called “77 Million Paintings for Montefiore” and “Quiet Room for Montefiore”, at Montefiore Hospital, Hove, England for patients, staff and visitors. A spokesperson for Brian Eno, as reported by The Independent, said that Eno w a s  d i r e c t l y  i n s p i r e d  b y  F l o r e n c e  N ightingale who wrote i n  1 8 5 9  t h a t  “ v a r i e t y  o f  f o r m  a n d  b r i l l i a n cy of colour in the objects presented to patients have a powerful effect and are actual means of recovery.” [8]. Our approach differs from Eno's "Quiet Room" in that our audience is, due to how the room is used, forced to participate, and is more alike to "77 Million Paintings" and his airport music. This, to us, poses an ethical dilemma and prompts us to use additional caution when d e a l i n g  w i t h  t h e  s o u n d  m a t e r i a l  and its presentation. As will be shown below in our case studies we opted to use textures characterized by the following qualities: • Disjunction (harmonic, melodic, timbral and/or spatial) • Aperiodicity  • Sonic richness (”beauty”) of the individual event                                                                     1 Feldman had a collection of oriental rugs and compared his composing to weaving a rug. 
• Slow to medium tempo • Low to medium dynamics   3. FROM INTERVENTION TO SONIC ENVIRONMENT 
Fig. 2. The conceptual stages in the generative processes employed in the hospital waiting room installations   3.1 DJster  For our installations, we chose DJster as an event generator [9]. DJster is based on the probabilistic algorithms Clarence Barlow created in the 1970’s and implemented in his program AUTOBUSK. It features a flexible 17-dimensional parameter space in which some of its parameters are linked in clever ways to create a sense of tonality and metricity, or its opposites, atonality and ametricity. In addition, a virtually unlimited number of scales (in any temperament) and meters (in any number of stress patterns) can be chosen as the material basis on which the probabilistic event generator operates on. In contrast to many other generative systems DJster is agnostic towards style and does not define any rules in terms of harmonic progression or voice leading. As style is an emergent property of the parameter space and not a built-in feature as such, DJster lends itself perfectly for mapping environmental and psychophysical data onto musical parameters. DJster is a Max abstraction which exists in several incarnations, an Ableton Live device and a MaxScore plugin among them.   
 Fig. 3. The DJster GUI in its incarnation for Ableton Live  For our installations, it was embedded into a patcher receiving its data from sensors on its periphery and sending them through a complex mapping process (see 3.2) to adjust them to the appropriate value ranges.   
 Fig. 4. Five instances of DJster driving the sound generation process.  
Gesture / Motions ↓ Mapper ↓ Generative Process ↓ Sound ↓ Space  
365
Several instances of DJster can be employed independently, each representing a player communicating with a sound engine—a multi-timbral and microtonal sampler originally created for the networked multimedia performance environment Quintet.net and now part of the DJster package (see Fig. 4). It also features a multi-channel version capable of sending its audio output to 16 different outputs which can in turn be spatialized independently from one another. In our preliminary experiments, we used both VBAP and Ambisonics for spatialization [10][11].   3.2 Mapping Strategies  In algorithmic composition, the mapping of gestures to sounds may be considered the composition itself [12].  As described in section 5, the three rooms due to their specificities require considerable tweaking of the system. Two of the rooms (NOT and PRIV) require constant capturing of the environment in terms of visual brightness, loudness, amount of motion, etc. while the third one (PACU) may just rely on the time o f  d a y  a n d  a v e r a g e  s o u n d  p r e s s u r e  l e v e l . W e  n e e d e d  a  flexible environment capable of dealing with the many mapping scenarios we might be facing (few-to-many, many-to-few and everything in between) [13]. We are therefore developing a mapper abstraction in Max called PatMap which uses its own patching paradigm on top of Max. Just as Max possesses a large number of objects, which can be connected by patch cords, PatMap basically uses its GUI to script the instantiation of abstractions and establish the dataflow between them. These abstractions are built with standard Max objects as well as third-party objects implementing the whole range from simple scaling to machine learning, such as backpropagation neural networks. Neural network simulations prove to be particularly effective when dealing with the high-dimensional parameter space offered by DJster. Much effort from the side of the music therapy and multimedia students has gone and will still go into creating seamless calibrations between sensory input and sonic output, whose effectiveness in creating a particular atmosphere or emotion will be gauged by patients and volunteers providing information which will be fed back into the calibration process.   
  Fig. 5. The PatMap GUI built on top of Max’s own patching mechanism, built to facilitate an intuitive mapping strategy. 
 Fig. 6. Inspector for PatMap’s nn (neural network simulation) abstraction.  4. FROM EMOTION TO INTERVENTION   Since we decided to focus on creating an algorithmically driven, quasi-therapeutic sound installation we looked for examples of similar endeavors when preparing the next phase of the project. What we found was that our case is unique in that we wished to generate the music algorithmically via modulation o f  d i s c r e t e  h i g h-level parameters, namely those within the DJster parameter space. Linking research methods from the field of music therapy to this compositional approach presents some challenges, since we collected qualitative data about the environments, which cannot be easily translated into compositional instructions without a composer reworking and reviewing material. Dealing with a kind of music that seeks to function within an already established health context, we looked into existing health-focused design concepts to influence the design of our own system. Agency and situatedness are key notions which helped us to understand the implications of such a design. One suggestion from within the group was that we use descriptors that can be translated into sonic results, via an evidence-based design (EBD) influenced approach [14]. EBD focuses on implementing credible evidence in design practice, and usually expresses itself via architecture and interior design. Aspects of this a p p r o a c h  w h i c h  c o u l d  b e  r e l e v a n t  t o  o u r  scenarios are the use of positive distractions (attention modulation) and incorporating nature themes in various ways. Attention fatigue and the dangers of using overly abstract art in a healing context have also been noted [15]. This brought about the understanding that we needed to design a system capable of modulating between the states of musical silence and activity and strengthened our idea that “neutral” music would give the best results. During our review of the existing literature, we realized that the musical terms used in medical journals are not always clearly defined to the extent we would like them to be for our purposes. Key questions that arose in discussions on this issue were: how can we overcome such subjectivity? And should we in fact embrace it? The problem remains that the next incarnation of the installation needs to be of a generally agreeable nature musically (in terms of its disruption to the environment). Despite evidence existing that music that has 
366
been selected by an individual for their own listening having benefits in health settings [16], the aspect of control (i.e. personal light switches, privacy given to patients in their rooms, controls for adjusting their beds) is not possible here to the same degree since these are all shared spaces. In our case, the individuals passing through these areas are fairly diverse as the local population come from an array of cultural backgrounds. Making general predictions about their harmonic, rhythmic or stylistic preferences as a group would not immediately be possible and the music would have to be evolved dynamically based on feedback from the users of the spaces. One proposal was to implement a n  e v a l u a t i o n  t e r m i n a l  f o r  f e e d b a c k  a t  t h e  end of their time in the space. By presenting a range of emoticons to users this system could offer both an aspect of control (affecting the patients’ e x p e r i e n c e  o f  t h e  s y s t e m )  a n d  give us the ability to assess the effectiveness of the system as a controller for musical applications. Pictograms in the form of emoticons represent an ideal feedback/control mechanism, due to the ease and speed of their usage, and the universally understandable character to which they a s p i r e  [17]. We are currently in the process of researching various levels of emoticon complexity and arousal/valence models, but in the next phase of our project will start with the basic triad of satisfied-neutral-unsatisfied emoticons. In order to automate the process we are considering using a backpropagation neural network with said emoticons as an evaluation function for the training of the network. It has however been noted that if the patient is not made fully aware of the ways the music functions therapeutically they might form preference rather than a response [18].   
 Fig. 7. Tuning of the mapping process 5. CASE STUDY: THE THREE SCENARIOS  The three rooms we will be placing our sound installations in are the peri-anesthesia care unit (PACU), private waiting room (PRIV) and emergency waiting room (NOT) all located in the main building of the UKE [19]. Each possesses a specific and distinct ambience and poses a  d i f f e r e n t  s e t  o f  c h a l l e n g e s .  S t u d e n t s  p a r t i c i p a t i n g  in the project were asked to spend 20 minutes in each of the rooms and fill out two questionnaires in order to assess the qualities of the rooms. These questionnaires were dubbed “Description of Soundscape” and, “Atmospheric Assessment of Rooms” and were created by Katharina Nowack and Eckhard Weymann respectively (see Appendix). A brief description of the rooms follows: 
5.1 PACU  Peri-anesthesia care unit (PACU)—this room hosts the patients going under or coming out of anesthesia. It is a large hall (200+ m2) with beds separated by thin, movable walls, filled with subtle noises of medical instruments and voices of medical personnel. The general feel of the room, as described by students, is o n e  o f  a n o n y m i t y ,  sterility and isolation. One of the biggest challenges in working with this space is reducing its “artificiality”, and d o i n g  s o  w i t h o u t  disrupting the sonic feedback which the medical personnel is getting from the medical monitoring equipment. Most of the important sonic information lies above 250 Hz, so we are considering u s i n g  o n l y  frequencies below this threshold for our installation, so as not to interfere with the sonic feedback. Another way to avoid interference is using distinctly different timbres. Alternatively, a pair of speakers could be installed for each bed, thus localizing the sound and preventing interference. Due to the size of the room and the fact that the patients are unable to move, we will be using a simple data feed to control our algorithmic composition (see section 3.2).  5.2 PRIV  Private waiting room (PRIV) - t h e  r o o m  i s  d e d i c a t e d  t o  a  s m a l l e r  number of patients, mostly suffering from vascular c o n d i t i o n s .  T h e  room is small (some 20 m2) and furnished to resemble a living room. The room is acoustically dry and even the slightest sounds are clearly perceivable. The general feel is that of a small space. Sitting on a comfortable sofa was assessed to induce sleepiness and passivity. In order to increase the alertness of  t he occupant s,  we ar e pl anni ng to use Microsoft Kinect cameras to drive the algorithmically generated music a n d  i t s  s p a t i a l i z a t i o n. T h i s  w a y ,  w e  h o p e  t o  p r o v i d e  t h e  patients with active controls over the sound output.2 A n  array of speakers will spatialize the s o u n d .  O f  a l l  t h e  t h r e e  r o o m s ,  t h i s  o n e  allows the composers the greatest freedom of expression.  5.3 NOT  Emergency waiting room (NOT) - this middle sized room (ca. 60 m2) is well lit and noisy. The main acoustic feature is a vending machine—every 5 to 10 minutes it produces a noise with a peak frequency around 709 Hz. As a background to it there is a constant drone of air conditioning, quiet voices, coughing, sneezing and movement outside. Unrest, petulance, nervousness and tension are the words our students used to describe this room. An approach we decided to take in dealing with this situation is “masking” the vending machine noise by incorporating its sound into the soundscape. The 709 Hz is a F5 tone 26 cents sharp and was used as the tonic of a just intonation scale. Apart from time/date/day of the week (measured by in-built computer clock), light intensity (measured by light sensors connected to the Arduino board) and the average room loudness (measured by microphones), we are considering also measuring t h e  a i r f l o w  a n d  C O2 l e v e l s .  D u e  t o  t h e  current limitations on the range of Kinect cameras, at this point we are opting out of using them in this setting.    
                                                                    2 The sound materials we were planning to use are samples of wind noises, rushing water, air noise of the accordion, processed accordion sounds, gongs, wind bells, harps, celestas etc. 
367
6. CONCLUSION  After approaching this project from a dual perspective formed by two  groups differentiated by their backgrounds (music therapy and multimedia composition students and educators), we were succesful in creating a prototype design for our installations. Some of the intial explorations into the philosophy of the atmospheres produced an impetus to seek interdisciplinary solutions to a complex and highly situational range of ethical, philosophical, musical and technical challenges. After explicating the circular nature of healing environments, we identified a number of poles governing its dynamic (see Fig. 1). The descision to pursue an ideal of “neutral” music was realized after the analysis of the first sound designs and their execution with DJster. This project has a wide scope for further development, where we hope to incorporate an evidence-based design approach.   Moving forward, we wish to continue work with complex mapping strategies, including machine learning to assist with the “tuning” of future incarnations of our systems. This would expand the range of possibilities available to us when wishing to assess the effectiveness of our approach.  7. ACKNOWLEDGMENTS Our thanks go to Prof. Dr. S. Debus (UKE), Prof. Dr. Jan Sonntag (Medical School Hamburg) for their support and Johann Niegl for his work on the mapping environment. 8. REFERENCES [1] J. F. Stichler. Creating healing environments in critical care units. Crit Care Nurs Q. 24(3), 2001, 1-20. [2] E. de Ruiter. Healing soundscape: hospital acoustics 2.0. In Proceedings of EuroNoise 2015, Maastricht, Netherlands, 2015, 2439 – 2444. [3] K. E. Bruscia. Defining Music Therapy. Barcelona Publishers, 3rd edition, 2014. [4] G. Böhme. Atmosphäre: Essays zur neuen Ästhetik. Suhrkamp, Berlin, 2013, 21-100. [5] M. Nyman. Collected Writings, Pwyll ap Siôn (ed.) Routledge, Abingdon-on-Thames, 2016, 124. [6] A. Ross. The Rest Is Noise: Listening to the Twentieth Century, Picador, 2007, 527. [7] B. Eno. Music for Airports/Ambient 1, Album liner notes, 1978, http://music.hyperreal.org/artists/brian_eno/MFA-txt.html (retrieved on 29. January 2017) 
[8] A. Sherwin. From Roxy Music to the cure? Brian Eno composes soundscapes to treat hospital patients. 2013.  http://www.independent.co.uk/arts-entertainment/art/news/from-roxy-music-to-the-cure-brian-eno-composes-soundscapes-to-treat-hospital-patients-8577179.html (retrieved on 25. January 2017) [9] G. Hajdu. Resurrecting a Dinosaur—the adaptation of Clarence Barlow's legacy software AUTOBUSK. In Proceedings of the TENOR conference, Cambridge, 2016, 181–186. [10] V. Pulkki. Generic panning tools for MAX/MSP. In Proceedings of the International Computer Music Conference, Berlin, Germany, 2000, 304–307. [11]  J. C. Schacher and P. Kocher. Ambisonics Spatialization Tools for Max/MSP. In Proceedings of the International Computer Music Conference, New Orleans, LA, 2006, 274–277. [12] E. R. Miranda and M. Wanderley. New Digital Musical Instruments: Control and Interaction Beyond the Keyboard (Computer Music and Digital Audio Series, 21). A-R Editions, Inc., 1st edition, Middleton, WI, 2006. [13] C. Goudeseune, Interpolated Mappings for Musical Instruments. Organised Sound 7(2), Cambridge University Press, Cambridge, UK, 2002, 85–96. [14] B. Lawson. Healing architecture. Arts & Health 2(2), Taylor & Francis, London, England, 2010, 95-108. [15] L. Lankston, P. Cusack, C. Fremantle and C. Isles. Visual art in hospitals: case studies and review of the evidence. Journal of the Royal Society of Medicine, 103(12), SAGE Publications, Thousand Oaks, CA, 2010, 490-499. [16] H. Rasila and P. Rothe (2012). A problem is a problem is a benefit? Generation Y perceptions of open-plan offices. In Property Management 30(4), Emerald Group Publishing Limited, Bingley, United Kingdom, 2012, 362-375. [17] S. Kjørup. XV. Ausgewählte Gegenstände der Semiotik. Pictograms. Semiotik / Semiotics. 4. Teilband,  R. Posner (ed), Walter de Gruyter, Berlin, Germany, 2004, 3504. [18] E. Salamon, S. R. Bernstein, S. A. Kim, M. Kim and G. B. Stefano. The effects of auditory perception and musical preference on anxiety in naive human subjects. Med Sci Monit, 9(9), 2003, 396-399. [19] D. Zhou. Interactive Environmental Sound Installation for Music Therapy Purpose. In Proceedings of the International Workshop of Computer Music and Audio Technology  (WOCMAT), Taoyuan City, Taiwan, 2016.   
368
9. Appendix: Questionnaires used for the assessment of the hospital waiting areas   
     
 
369