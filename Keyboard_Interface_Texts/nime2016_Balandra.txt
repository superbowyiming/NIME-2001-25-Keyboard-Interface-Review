Haptic Music Player - Synthetic audio-tactile stimuli
generation based on the notes‚Äô pitch and instruments‚Äô
envelope mapping
Alfonso Balandra
Tokyo Institute of Technology
26-8503 Y okohama,
Kanagawa
Midori-Nagatsuta 4259
R2-624, Japan
poncho@haselab.net
Hironori Mitake
Tokyo Institute of Technology
26-8503, Y okohama,
Kanagawa
Midori-Nagatsuta 4259
R2-624, Japan
mitake@haselab.net
Shoichi Hasegawa
Tokyo Institute of Technology
26-8503, Y okohama,
Kanagawa
Midori-Nagatsuta 4259
R2-624, Japan
hase@haselab.net
ABSTRACT
An en tertainmen t en vironmen t to enric h m usic listening ex-
p erience is presen ted. This en vironmen t is comp osed of 3
mo dules: a MIDI pla y er, a m usic animation and a haptic
mo dule that translates the notes, pla y ed b y one instrumen t,
in to a resem blan t vibration. T o create the haptic vibration,
the notes' relativ e pitc h in the song are calculated, then
these p ositions are mapp ed in to the haptic signals' ampli-
tude and frequency . Also, the en v elop e of the haptic signal
is mo died, b y using an ADSR lter, to ha v e the same en-
v elop e as the audio signal. T o ev aluate the p erceiv ed cross-
mo dal similarit y b et w een users, t w o exp erimen ts w ere p er-
formed. In b oth, the users used the complete en tertainmen t
en vironmen t to rank the similarit y b et w een 3 dieren t hap-
tic signals, with triangular, square and analogue en v elop es
and 4 dieren t instrumen ts in a classical song. The rst ex-
p erimen t w as p erformed with the prop osed amplitude and
frequency tec hnique, while the second exp erimen t w as p er-
formed with constan t frequency and amplitude. Results,
sho w dieren t en v elop e user preferences. The square and
triangular en v elop es w ere preferred in the rst exp erimen t,
while only analogue en v elop es w ere preferred in the sec-
ond. This suggests, that the users' en v elop e p erception w as
mask ed b y the c hanges in amplitude and frequency b et w een
the notes. Ev en so, it is necessary to p erform further studies
to clarify the en v elop e's role on the p erceiv ed cross-mo dal
similarit y .
Author Keywords
virtual realit y , haptic m usic, audio-tactile, cross-mo dal p er-
ception
ACM ClassiÔ¨Åcation
H.5.5 [Information In terfaces and Presen tation] Sound and
Music Computing, H.5.2 [Information In terfaces and Pre-
sen tation] User In terfacesHaptic I/O
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME‚Äô16,July 11-15, 2016, GrifÔ¨Åth University, Brisbane, Australia.
.
1. INTRODUCTION
The sound of ph ysical m usic instrumen ts are usually gener-
ated b y the mec hanical vibrations of dieren t kinds of ob-
jects, lik e: the string in a piano or the stretc hed mem brane
in a drum. When some ph ysical instrumen ts are pla y ed, the
pla y er can listen to the pro duced sound and also feel the
mec hanical vibration though the instrumen t itself. Almost
the same phenomena happ ened to m usic listeners, while lis-
tening to a liv e concert, the listeners ear the m usic and
sim ultaneously feel the m usic mec hanical vibrations from
the sound source that repro duce the m usic. So, w e consider
that in some unkno wn degree m usic can also b e p erceiv ed
trough our touc h sense. Then, b y em ulating this phenom-
ena a no v el metho d to translate the basic elemen ts of m usic
in to a resem blan t syn thetic haptic vibration is prop osed.
So, this pro ject aims to translate the basic m usic struc-
ture elemen ts of a song, as: the instrumen t c haracteristic
en v elop e, the notes' pitc h, timing and duration, in to an
enjo y able and resem blan t haptic vibration. T o ac hiev e an
immersiv e and enjo y able exp erience, w e build an sp ecial en-
tertainmen t en vironmen t, that consists of 3 main mo dules:
a MIDI pla y er mo dule, a m usic animation mo dule and a
haptic mo dule. The MIDI pla y er mo dule is only a MIDI
pla y er build from scratc h. The m usic animation mo dule
pro vides a self-understandable 3D animation of the m usic
structure. And the haptic mo dule pro vides a syn thetic hap-
tic vibration of one particular instrumen t of the song. These
3 mo dules are sync hronized on real time, so while the user
hears the m usic, he can also see the corresp onden t anima-
tions and feel the vibration of an y sp ecic instrumen t in the
m usical piece (see pro ject's video [4]).
Ev en if the prop osed en vironmen t is comp osed b y 3 mo d-
ules, the haptic mo dule is considered the most imp ortan t
one. So, our eorts are concen trated on creating a no v el
metho d to translate the auditiv e stim uli, from only one in-
strumen t of the song, in to a resem blan t haptic vibration.
Consequen tly , w e are not fo cused on recreating the haptic
mec hanical vibration that an instrumen t when it is pla y ed,
instead w e are fo cus on creating a syn thetic haptic stim uli
that resem bles the sound's tim bre of sp ecic instrumen ts.
Also, the haptic mo dule only transforms the sound of only
one instrumen t of the song in to a resem blan t haptic vibra-
tion, b ecause w e seek to fo cus the user's listening atten tion
in to an sp ecic instrumen t.
W e p erformed sev eral informal user observ ations during
previous public demonstrations of the system. On those o c-
casions, w e observ ed that the users could easily understand
90
the role of an sp ecic instrumen t in to the complete song,
ev en without ha ving an y prop er m usical kno wledge. Also,
small c hildren (less than 10 y ears old) w ere able to under-
stand the complete system b y themselv es without an y pre-
vious explanation. A dditionally , most users v erbally ga v e
go o d commen ts ab out the system and activ ely men tion dif-
feren t applications for the system. These informal obser-
v ations sho w us, that most participan ts enjo y ed using the
en vironmen t to listen m usic. Ev en so, on this pap er w e
do not ev aluate the users enjo ymen t or measure their sub-
jectiv e p erception, instead w e fo cus in up date the haptic
signals and ev aluate the p erceiv ed similarit y b et w een the
audio and tactile stim uli.
2. MOTIV ATION
The motiv ation of this researc h is v ery simple, this system
is aimed to exc hange the m usic listening exp erience though
a haptic vibrations and pro vide the user with the opp ortu-
nit y to enjo y the basic elemen ts of m usic with a dieren t
p ersp ectiv e. Consequen tly , our eorts are fo cused on nd-
ing a no v el w a y to use the m usic elemen ts lik e: notes' pitc h,
timing and duration to create a resem blan t and enjo y able
haptic stim uli.
Apart of the complete system itself. W e consider that
the most imp ortan t v alue of this pro ject are the h uman
p erception observ ations and the presen ted tec hniques used
to create the syn thetic haptic vibration. W e consider that
these and future results could b e directly applied to enhance
the p erception correlation in div erse en tertainmen t systems
that use sync hronized audio and haptic signals, lik e: elec-
tronic instrumen ts without haptic feedbac k, video games,
immersiv e cinema theatres and virtual realit y applications.
3. PREVIOUS WORK
A simpler and more rudimen tary v ersion of this system w as
presen ted as a demonstration on the EC 2013 (En tertain-
men t Computer Symp osium) in T ak amatsu, Japan [5]. Also
the same v ersion w as presen ted as a demonstration for Eu-
rohaptics 2014 [10], [3]. Ev en so, w e considered it necessary
to reno v ate the curren t system, b ecause the h uman p ercep-
tion limitations w ere o v erlo ok ed when the haptic mo dule
w as designed. In con trast, the presen t metho d considers
the h uman p erception limitations to generate the resem-
blan t haptic stim uli.
f(t) =A¬∑exp(‚àíd¬∑t) sin (t¬∑f ‚àó2œÄ) (1)
where:
t: time
d: exp onen tial damping rate
f: frequency in Hz
A: initial exp onen tial amplitude at t= 0
Also, an impro v ed algorithm to transform the note's prop-
erties in to a syn thetic haptic vibration is presen ted. The
previous v ersion used only an exp onen tial damp ed sine w a v e
function (see Equation 1), to represen t an y kind of instru-
men t, without considering the en v elop e c haracteristics of
the m usical instrumen t itself. Consequen tly , if the en v e-
lop e shap e w as generated b y an exp onen tial sine w a v e func-
tion, then the haptic en v elop e shap e will not matc h for in-
strumen ts with a steady sustain, lik e: organ or ute. In
con trast, the presen t metho d generates audio-tactile signals
with a correlated en v elop e shap es, in order to represen t the
en v elop e c haracteristics of dieren t m usical instrumen ts.
4. RELATED RESEARCH
The system prop osed b y Nana y akk ara et al.[13] used the
same 3 mo dule conguration as in this prop osal. This sys-
tem also used 3 dieren t mo dules to visualize, ear and touc h
the m usic vibration. Also it w as sp ecically aimed to en-
ric hing the listening exp erience of deaf users. In addition,
a custom made c hair with sev eral con v en tional diaphragm
sp eak ers w as built to b e used as haptic device, in order to
amplify the vibration of m usic. In con trast to our prop osal,
Nana y akk ara et al. used the amplied audio signal itself as
a haptic signal, but w e consider that due the haptic sense
limitations [16] is more eectiv e to build a syn thetic haptic
signal to resem ble the notes' prop erties.
Ha wng et al. in tro duced a no v el dual-band haptic m usic
pla y er [9]. This system used an sp ecial dual-mo de actuator
attac hed to a mobile device and a vibration generation algo-
rithm to build the haptic signals from a m usic le. Ha wng
also ev aluated the sub jectiv e p erformance of the dual-band
metho d v ersus a bass-band vibtotactile pla ybac k, sho wing
that the dual-band had a b etter sub jectiv e p erformance.
Con trary to our prop osal, this metho d rela y ed only a dual-
band strategy , to separate the bass and trem ble frequencies
of m usic in to dieren t vibrations; so displa ying the vibration
of individual instrumen ts w as implausible. Also the metho d
design did not consider the individual notes' prop erties to
build their resp ectiv e haptic signals. In con trast, w e pro-
p ose a simpler and gran ular strategy to generate the haptic
vibration of an sp ecic instrumen t, where the instrumen ts'
en v elop e, note's pitc h and notes' duration are considered to
create an sp ecic vibration for ev ery note.
5. SYSTEM‚ÄôS DESCRIPTION
This en tertainmen t en vironmen t is comp osed of 3 main com-
p onen ts: a MIDI pla y er, a simple 3D m usic animation and
a haptic vibration mo dule, that transforms the audio signal
of one instrumen t in to a resem blan t haptic signal. All these
comp onen ts are sync hronized in real time, so the listening
m usic exp erience is enric hed with a self-explanatory visual
animation that sho ws the m usic score and a haptic stim uli
that resem bles the sound of an sp ecic instrumen t inside
the song.
5.1 MIDI player module
F or this mo dule a MIDI pla y er w as dev elop ed. This sp ecic
format w as selected for 3 sp ecic reasons: First, the MIDI
format is discrete, so the notes' pitc h, notes' duration and
instrumen t information can b e read directly , then an y fur-
ther audio pro cessing analysis tec hnique isn't needed. Sec-
ond, in MIDI it is easy to precisely measure the en v elop e
c haracteristic of an y MIDI instrumen ts, then this lets pre-
cisely measure the audio signal en v elop e, of dieren t MIDI
instrumen ts, to design the haptic signals en v elop es. Third,
the sequence of MIDI messages w as used to sync hronize the
haptic and visual mo dules with a relativ e precision ( ¬±2 ms).
5.2 Music animation module
This mo dule generates a m usic animation, b y using the
songs' notes' pitc h, duration and timing, so implicitly the
animation pro vides the information to the user. Also the
same animation sho ws other information lik e: the n um b er
of trac ks (instrumen ts) that are in v olv ed in the song and
the curren tly pla y ed notes. The main purp ose of this an-
imation is to help the most inexp erienced users to matc h
the notes' sound of an sp ecic instrumen t in the song with
their resp ectiv e haptic stim uli.
91
Figure 1: The animation of a song with 2 trac ks, sho wn in
blue and green. The activ e haptic trac k is sho wn in blue.
Also the curren t haptic pla y ed notes are sho wn in y ello w,
while the curren t pla y ed notes of the other trac ks are sho wn
in white.
The animation w as build using Op enGL, and it is based
on Kevin Kelly's Music Animation Mac hine pro ject [11]. In
the animation ev ery individual note is represen ted using 3D
rectangles. The rectangles' length, p osition and color repre-
sen t dieren t prop erties of ev ery note. The notes' length is
represen ted b y using the rectangle length. The rectangles'
p osition in X-axis represen ts the note p osition in the song's
time-line. The rectangle's p osition in the Y-axis represen ts
the note's pitc h, so notes with a higher pitc h are placed
higher that the notes with a lo w er pitc h. The rectangles'
Z-axis p osition and color are used to order the dieren t in-
strumen ts (trac ks) of the song, therefore when the haptic
activ e trac k c hanges all the rectangles are re-order and the
curren t haptic activ e trac k rectangles are placed o v er the
others (see Figure 1).
A dditionally , the rectangles mo v e around the screen from
righ t to left with the same temp o as the m usic. Then the
notes that are going to b e pla y ed are on the righ t of the
screen, the curren t notes that are b eing pla y ed are in the
middle and the notes that had b een pla y ed are on the left
side of the screen. Also when the rectangles' resp ectiv e
notes are pla y ed their color c hange to iden tify them. Then,
after the notes are b eing pla y ed, the rectangles con tin ue
their w a y though the screen from left to righ t un til they
disapp ear from the screen. Then new rectangles come from
the righ t of the screen and the cycle rep eats un til the com-
plete song is pla y ed. T o sync hronize the animation w e tak e
adv an tage of the the MIDI tic ks and the MIDI messages to
generate and sync hronize the animation on real time. so
the dela y b et w een the audio, visual and haptic signals w as
measured and con trolled around ¬±2ms.
5.3 Haptic Music Module
This mo dule creates the haptic signal b y considering: the
notes' pitc h, notes' duration, the note's timing and the in-
strumen t en v elop e c haracteristics.
This metho d emplo ys t w o lineal mappings to establish
the frequency and amplitude of the haptic signal b et w een
a previously selected range. Therefore, this metho d is not
a straigh t forw ard mapping b et w een the auditiv e p ercep-
tion range and the tactile p erception range. Instead, the
purp osed metho d tak es adv an tage of the MIDI data struc-
ture to narro w the p ossible audio frequencies to b e mapp ed.
First the metho d calculates the relativ e p osition of the notes'
k ey in b et w een the song, and then this relativ e p osition is
used to determine the amplitude and frequency of the hap-
tic signal. In addition, the haptic signal is built with the
same temp oral amplitude c haracteristics as the instrumen t,
in order to resem ble the instrumen t's audio en v elop e c har-
acteristics.
Spidar G6 [1] w as selected as a haptic in terface, b ecause it
is more v ersatile if compared with and sp eak er based haptic
displa y . Also, it can b e also used to haptically in teract
with the m usic animation in order to: switc h the haptic
instrumen t or touc h the notes individually . In addition,
this in terface can transmit frequencies b et w een 60 Hz ‚àº1
kHz; strongly and accurately [1].
5.4 Notes‚Äô pitch haptic mapping
If the h uman and auditory senses are roughly compared
in terms of their p erception limitations. The auditory sense
p erformance to p erceiv e dieren t frequencies is outstanding,
with a frequency JND (Just Noticeable Dierence) of 0.6%
for frequencies around 1000Hz [6]. In con trast the haptic
sense has a v ery p o or p erformance with a frequency JND of:
18% [14]. No w, if b oth mo dalities are then compared based
on their p erception range, the frequency hearing range is
v ery wide, with: 0.0032 kHz ‚àº16 kHz [8], while the so-
matosensory sense has a narro w p erception range b et w een:
20 Hz ‚àº700 Hz[15]. In con trast, there is evidence that h u-
mans are able to tell if a pure tone haptic vibration has the
same frequency as a pure tone audio signal. But this this
has only b een pro v en for lo w frequencies rates b et w een 50
Hz to 250 Hz [2].
Is eviden t that the somatosensory sense is unable to de-
tect frequency with the same sharpness and wideness as the
auditory sense. Then w e consider, that trying to directly
map all the audible frequencies or to use audio itself as a
haptic signal are inadequate metho ds to create a resem blan t
haptic vibration.
Therefore, w e only consider the frequency range and the
n um b er of dieren t k eys pla y ed in the MIDI song to nd the
relativ e pitc h p osition of ev ery note in the song and map it
in to the haptic signal's amplitude and frequency . Also, to
impro v e the p erception b et w een haptic signals, w e decided
to cut o the total n um b er dieren t MIDI k eys (127), to
only the range b et w een the lo w est note's k ey ( kMIN) to the
highest note's k ey ( kMAX) in the song. By these means,
the n um b er of MIDI k eys to b e mapp ed is limited, so there
are less k eys to b e mapp ed and consequen tly there is more
ro om to t dieren t k eys in the haptic range.
‚ñ≥k= kMAX ‚àíkMIN (2)
‚ñ≥f = fMAX ‚àífMIN (3)
‚ñ≥a= aMAX ‚àíaMIN (4)
The prop osed algorithm uses t w o lineal relations to map
the notes' pitc h in to predened frequency and amplitude
ranges ( ‚ñ≥f , ‚ñ≥a) for the haptic signal. The rst lineal
relation uses: the curren t note k ey ( k), the range b et w een
the lo w est and highest k ey of the song ( ‚ñ≥k), the n um b er
of dieren t notes with a dieren t k ey inside the song ( kœµ),
and the lo w est k ey in the song ( kMIN); to nd the note's
relativ e pitc h p osition in the song ( n). (see Equation 5)
n= kœµ ¬∑(k‚àíkMIN)
‚ñ≥k (5)
After this, another lineal relation is used to map the pre-
vious computed relativ e p osition ( n) in to the selected fre-
quency and amplitude ranges, b y using the follo wing for-
92
Instrumen t t1 ms t2 ms t3 ms s =ah% r =ah%
Instrumen ts' ADSR P arameters
Organ 5 0 t4‚àí25 100 1
Flute 75 0 t4‚àí60 100 1
Harpsic hord 55 0 t4‚àí55 100 17.39
Guitar 15 0 t4‚àí15 100 1.36
T rump et 30 110 t4‚àí100 32.09 1
Violin 66 376 t4‚àí225 57.14 1
Cello 40 290 t4‚àí200 47.45 1
Con trabass 55 355 t4‚àí225 52.74 1
Simple En v elop es' ADSR P arameters
Square 0 0 t4 100 0
T riangular 0 t4 0 100 0
T able 1: ADSR en v elop e parameters, used in the Equa-
tion 10, in order to generate the haptic en v elop e of dieren t
m usic instrumen t. Also the parameters of the simpler en-
v elop es, used in the ev aluation, are men tioned in the table.
m ulas:
fh = fMIN +
(‚ñ≥f
kœµ
¬∑n
)
(6)
ah = aMIN +
(‚ñ≥a
kœµ
¬∑n
)
(7)
So, the equations 6 and 7 dene the frequency and ampli-
tudes v alues that are relativ ely to the curren t k ey p osition
in the song. By these means, treble instrumen ts will b e rep-
resen ted with haptic signals with high pitc h and amplitude,
while bass instrumen ts will b e represen ted with haptic sig-
nals with lo w pitc h and amplitude.
5.5 Envelope haptic mapping
In addition, the en v elop e of the haptic signal w as dened
to ha v e the same amplitude temp oral c haracteristics as the
audio signal. By these means, the same en v elop e c haracter-
istics of dieren t m usical instrumen ts can b e represen ted in
the haptic signal. T o generate an audio-tactile stim uli with
a p erfectly correlated en v elop e, rst the en v elop e shap e of
dieren t MIDI instrumen ts w ere measured, b y using an os-
cilloscop e and the Windo ws MIDI syn thesizer without an y
extra audio lters. So, the instrumen ts' timing and ampli-
tude during attac k, deca y , sustain and release phases w as
measured (see Figure 2). Then, these measuremen ts w ere
used in an ADSR lter to precisely dene the haptic signal
en v elop e. So b y these means the can b e designed to ha v e
the same en v elop e and fundamen tal frequency prop erties as
an y MIDI instrumen t.
b(x) = sin (x¬∑fh ¬∑2œÄ) (8)
m= s‚àíah
t2 ‚àít1
(9)
E(x) =
Ô£±
Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥
x¬∑ah
t1
¬∑b(x) x<t 1
[(m¬∑x) ‚àí(m¬∑t1) +ah] ¬∑b(x) t1 ‚â§x<t 2
s‚àób(x) t2 ‚â§x<t 3
[
s¬∑exp
(log(r) ¬∑(x‚àít3)
t4 ‚àít3
)]
¬∑b(x) t3 ‚â§x<t 4
(10)
Figure 2: Equation 10 timing ( t0,t1,t2,t3,t4) and ampli-
tude (p eak amplitude ah, sustain s, nal amplitude r) pa-
rameters.
The nal haptic signal is created b y using: an ADSR lter
(dened in Equation 10), the mapp ed haptic frequency and
amplitude (dened in Equations 6 and 7) and the MIDI en-
v elop e measuremen ts (see T able 5.4). So, the haptic signals
masim um amplitude will b y dened b y ah, it's frequency
will b e dened b y fh. So b y these means the haptic signal
could ha v e the same en v elop e and fundamen tal frequency
as an y MIDI instrumen t. Also the purp osed metho d (see
Equation 10) k eeps the signal frequency constan t ev en if the
en v elop e shap e is mo died.
6. EV ALUATION
T w o psyc hoph ysical exp erimen ts w ere p erformed to ev alu-
ate if the en v elop e correlation of an audio-tactile stim uli can
impro v e the sub jectiv e p erceiv ed similarit y b et w een b oth
signals. In b oth exp erimen ts, the users rank ed the simi-
larit y b et w een an sp ecic instrumen t in a song and sev eral
haptic signals build with dieren t en v elop e shap es. On the
rst exp erimen t, the frequency and amplitude of the hap-
tic signals w as c hanged accordingly to the notes' k ey (as
describ ed in Section 5.4), while in the second exp erimen t
the notes' k ey w as ignored and the haptic signal used only
constan t frequency and amplitude.
6.1 Experiment #1 setup and description
In the rst exp erimen t the user task w as to rank the p er-
ceiv ed similarit y b et w een 3 dieren t haptic stim uli and the
sound of 4 dieren t instrumen ts in a song. The haptic sig-
nals w ere build using dieren t t yp es of en v elop es: a tri-
angular en v elop e, a square en v elop e and the actual sound
en v elop e. The haptic signal with the same en v elop e c har-
acteristics as the audio signal w as dened as the analogue
en v elop e. The haptic signals' frequency and amplitude w as
dened b y the tec hnique men tioned in the Section 5.4. So,
the amplitude haptic range w as set b et w een: aMIN = 7.5dB
and aMAX = 30dB, while the frequency w as set b et w een:
fMIN = 50Hz and fMIN = 250Hz. This particular fre-
quency range w as used in order to a v oid aliasing in the hap-
tic signal, due the haptic device refreshing rate ( 1000Hz).
The previously men tioned virtual en vironmen t let the
users listen to the m usic, see the animation and feel the
instrumen t's vibration. F or this exp erimen t the en viron-
men t w as sligh tly mo died to let the user rank and c hange
b et w een dieren t haptic vibrations. The particular m u-
sic piece used for the exp erimen t w as a MIDI rendition of
Bac h's 1079 Sonata - Largo mo v emen t [12]. This particu-
lar song used 4 dierence instrumen ts: harpsic hord, violin,
con trabass and ute. So, w e presen ted 3 dieren t en v elop es
for ev ery instrumen ts, then in total ev ery user had to rank
12 dieren t audio-tactile stim uli. While listening to the
93
m usic, the user w as able to c hange b et w een the 3 dier-
en t en v elop es at an y time, and rank them using an A,B,C
scale. Also, the user w as instructed to rank the 3 haptic
en v elop es b efore con tin ue to the next instrumen t. In addi-
tion, the 3 haptic en v elop es w ere presen ted in random order
and the next instrumen t to rank w as also randomized. The
exp erimen t nished after the user rank ed the 12 dieren t
audio-tactile stim uli presen ted in the song.
Due Spidar G6 particular design, the con tact stiness b e-
t w een the user's nger and the haptic p oin ter dep ends on
the user's grasping force. Therefore, this issue can create an
amplitude v ariabilit y on the haptic signal b et w een the par-
ticipan ts. Then, to tac kle this problem the user's righ t in-
dex nger w as attac hed to the haptic p oin ter using a V elcro
strap. Also, the user w as not allo w ed to touc h the haptic
p oin ter with an y other nger. And, b efore ev ery exp eri-
men t, the p eak amplitude ( aMAX) for ev ery sub ject w as
measured and con trolled to b e around 1mm.
The participan ts listen the audio signal though a Sennheiser
MX 475 earbuds and to isolate the participan ts auditiv e
sense they also used industrial grade noise cancel earm us.
T o minimize inadv erten t vibration of the haptic device, this
w as placed o v er urethane foam o v er a solid 1.5cm iron plate.
Also the user's righ t arm w as placed on a armrest separated
at the same heigh t as the haptic in terface. Finally , to a v oid
an y visual clue from the Spidar's mec hanisms mo v emen t,
the haptic in terface w as placed b ehind a tall white screen.
In order to clarify the similarit y concept among the users,
without bias the their particular preference, 2 rounds of
practice w ere p erformed b efore the main exp erimen t. F or
the practice rounds the isolated trac ks of violin and con-
trabass from Bac h's BWV 1079 Sonata - Allegro mo v emen t
[12] w ere used. As in the main exp erimen t, w e randomly
presen ted 3 dieren t haptic signals build with dieren t en-
v elop es and then w e ask ed the participan ts to rank the pre-
sen ted vibration accordingly to the similarit y b et w een the
instrumen t's sound and the vibration. After nishing ev ery
practice round the analogue en v elop e p osition w as rep orted
to the user, so the participan t could understand the simi-
larit y b et w een b oth signals b y his o wn p erceptional means.
Also these practice rounds help ed the users to familiarize
with the k eystrok es used to: c hange the vibration (0~1),
rank the vibration (A,B,C) and c hange the instrumen t (t).
6.2 Experiment #2 setup and description
Also a second exp erimen t w as p erformed with the exact
same conditions, metho dology and participan ts. Con trary
to the previous exp erimen t, a constan t haptic frequency and
amplitude w ere selected for this exp erimen t. So, the notes'
pitc h w ere o v erlo ok ed and constan t frequency of 250Hz and
a p eak amplitude ( aMAX) of 1mm w as used for ev ery hap-
tic signal. This exp erimen t w as p erformed to ev aluate the
cross-mo dal similarit y p erception of the signals' en v elop es
under more con trolled circumstances. By these means, w e
ev aluate if the amplitude and frequency v ariabilit y aect
the users' cross-mo dal en v elop e p erception.
7. RESULTS
Both exp erimen ts w ere p erformed b y 11 participan ts, 5 fe-
males and 6 males. All of them health y adults b et w een 23 to
30 y ears old. A computer with an In tel i7-3770S, Windo ws
7 and a Realtek ALC662 sound card w as used to p erform
b oth exp erimen ts.
If the Cop eland's metho d is applied to the results of the
Figure 3: The gure sho ws the n um b er of v otes receiv ed b y
the b est rank ed audio-tactile stim uli. The v otes of the ex-
p erimen t with a constan t amplitude and frequency for hap-
tics are sho wn in ligh tgreen, while the results in dark green
are for the constan t frequency and amplitude exp erimen t.
And the small triangles indicate the Cop eland's winners for
ev ery instrumen t.
rst exp erimen t, then the Cop eland's fa v ourites of eac h in-
strumen t are: the square en v elop e for violin and ute, the
triangle en v elop e for the harpsic hord and the actual sound
en v elop e for the con trabass (see Figure 3). These results
suggest, that the participan ts preferred haptic signals with
simpler en v elop es (square and triangular) o v er the analogue
en v elop e, when the frequency and amplitude of the haptic
signal w as v ariable.
On the other hand, in the second exp erimen t the Cop eland's
metho d results sho w, that the analogue haptic vibration
w as the b est rak ed haptic audio-tactile stim uli for all the
instrumen ts. So these results sho w a clear preference to the
analogue en v elop e for all instrumen ts. In addition the same
preference is clear b y coun ting the n um b er of v otes giv en to
the b est rak ed en v elop e.
As men tioned b efore b oth exp erimen ts w ere p erformed
under the same conditions and with the same participan ts.
So, the con trast in the results suggest that, the frequency
and amplitude v ariabilit y b et w een the notes, created b y the
presen ted mapping tec hnique, mask ed the haptic en v elop e
p erception. Then, w e consider that, the participan ts w ere
not able to p erceiv ed the en v elop e similarities of b oth sig-
nals with the same accuracy as in the second exp erimen t.
The results of the rst exp erimen t sho w that ev en if the
participan ts preferred the simpler haptic en v elop es, ho w ev er
the participan ts c hose simpler en v elop es, who had more am-
plitude similarities to the audio en v elop e. F or example, for
the ute and violin the square en v elop e w as preferred o v er
the triangular, so in this case w e supp ose that the steady
sustain of violin and ute caused a preference of the square
en v elop e. Also w e supp ose that the similar deca y rate b e-
t w een the harpsic hord and triangular en v elop e caused the
preference of the triangular en v elop e o v er the square en v e-
lop e. Ev en so, for the con trabass the users preferred the
analogue en v elop e. So, w e supp ose that the particular am-
plitude uctuations in the con trabass en v elop e shap e help ed
the users to p erceiv e the haptic en v elop e shap e. In an y case
it is necessary to p erform further studies to clarify these ob-
serv ations.
8. CONCLUSION
The prop osed en tertainmen t system in tro duced a no v el w a y
to map the notes' pitc h, duration and the particular instru-
94
men t en v elop e in to a haptic vibration. T o measure the sub-
jectiv e p erceiv ed similarit y b et w een the en v elop e shap es of
the audio and haptic signals; t w o p erception exp erimen ts
w ere p erformed. Both exp erimen ts w ere p erformed under
dieren t amplitude and frequency conditions for the hap-
tic signals. In the rst exp erimen t the amplitude and fre-
quency w ere v ariable and dened b y the prop osed mapping
metho d (Section 5.4) while in the second exp erimen t the
amplitude and frequency w ere constan t, at 1mm p eak am-
plitude ( aMAX) and 250 Hz resp ectiv ely . The obtained re-
sults, clearly sho w that the users preferred the analogue en-
v elop e, when the amplitude and frequency of the haptic sig-
nal w ere constan t. But, at v ariable amplitude and frequency
the users preferred the simpler analogue en v elop es (square
and triangular), o v erlo oking the en v elop e shap e similarit y
of b oth signals.
Therefore, w e supp ose that the dynamic amplitude de-
tection range of the haptic receptors is more narro w if com-
pared to the same range in audio. So, it seems that displa y-
ing the notes' k ey though amplitude and frequency v ari-
ations in addition to the instrumen ts' en v elop e though a
haptic signals saturates the haptic mec hanoreceptors. Con-
sequen tly , it seems necessary to omit the frequency and am-
plitude v ariations, so the user could b e able to p erceiv e the
en v elop e cross-mo dal similarit y .
In conclusion the exp erimen ts suggest that the haptic sig-
nals' amplitude and frequency v ariation pro duced the p er-
ception masking of the haptic en v elop e. Ev en so, it has
b een rep orted that the vibrotactile in tensit y discrimination
is not aected b y the stim ulus frequency condition [7]. So,
w e susp ect that phenomena could b e caused only b y the
amplitude v ariations b et w een the vibrotactile stim uli. On
the other hand, the selected frequency v alue at 250Hz, used
in the second exp erimen t, migh t help ed the users to iden tify
the en v elop es' attac k easily , due that the h uman absolute
detection threshold has a minim um v alue of 0.12¬µat 250Hz
[15]. In an yw a y , w e consider it necessary to p erform further
and a more detailed ev aluation on the rep orted en v elop e
p erception masking and on audio-tactile en v elop e correla-
tion p erception.
9. ACKNOWLEDGEMENTS
W e w an t to thank professor T ak ak o Y oshida for her con tin-
uous advice and supp ort.
10. REFERENCES
[1] K. Ak ahane, S. Hasega w a, Y. K oik e, and M. Sato. A
prop osal of a high denition haptic rendering for
stabilit y and delit y . In Articial Realit y and
T elexistenceW orkshops, 2006. ICA T '06. 16th
In ternational Conference on, pages 162167, No v
2006.
[2] M. Ercan Altinso y and Sebastian Merc hel. Haptic and
Audio In teraction Design: 5th In ternational
W orkshop, HAID 2010, Cop enhagen, Denmark,
Septem b er 16-17, 2010. Pro ceedings, c hapter
Cross-Mo dal F requency Matc hing: Sound and
Whole-Bo dy Vibration, pages 3745. Springer Berlin
Heidelb erg, Berlin, Heidelb erg, 2010.
[3] M. Auvra y and C. Duriez. Haptics: Neuroscience,
Devices, Mo deling, and Applications: 9th
In ternational Conference, EuroHaptics 2014,
V ersailles, F rance, June 24-26, 2014, Pro ceedings.
Num b er 2 in Lecture Notes in Computer Science.
Springer Berlin Heidelb erg, 2014.
[4] Alfonso Balandra. Haptic Music Pla y er.
h ttp://www.y outub e.com/w atc h?v=6wx7V3H3_MY ,
2016. [Online; accessed 15-April-2016].
[5] Alfonso Balandra, Hasega w a Shoic hi, Mitak e
Hironori, and Sato Mak oto. Haptical m usic pla y er.
En tertainmen t Computing Symp osium 2013 P ap ers,
pages 210213, Sep 2013.
[6] Jacob Benest y , M. Mohan Sondhi, and
Yiteng (Arden) Huang. Springer Handb o ok of Sp eec h
Pro cessing. Springer-V erlag New Y ork, Inc., Secaucus,
NJ, USA, 2007.
[7] George A Gesc heider, Stanley J Bolano wski Jr,
Ronald T V errillo, Dean J Arpa jian, and Timoth y F
Ry an. Vibrotactile in tensit y discrimination measured
b y three metho ds. The Journal of the A coustical
So ciet y of America, 87(1):330338, 1990.
[8] Henry E Hener and Ric ky e S Hener. Hearing
ranges of lab oratory animals. Journal of the American
Asso ciation for Lab oratory Animal Science,
46(1):2022, 2007-01-01T00:00:00.
[9] In w o ok Hw ang, Hy eseon Lee, and Seungmo on Choi.
Real-time dual-band haptic m usic pla y er for mobile
devices. IEEE T ransactions on Haptics, 6(3):340351,
2013.
[10] L. Jones. News from the eld [demonstrations
presen ted at the 2014 eurohaptics conference].
Haptics, IEEE T ransactions on, 7(3):271272, July
2014.
[11] Kevin Kelly . The Music Animation Mac hine.
h ttp://www.m usanim.com/, 1985. [Online; accessed
15-Jan uary-2016].
[12] Pro ject P etrucci LLC. In ternational Music Score
Library Pro ject - IMPSLP.
h ttp://imslp.org/wiki/Musik alisc hes_Opfer, _BWV_
1079_(Bac h, _Johann_Sebastian). [Online; accessed
15-Jan uary-2016].
[13] Suranga Nana y akk ara, Elizab eth T a ylor, Lonce W yse,
and S H. Ong. An enhanced m usical exp erience for
the deaf: Design and ev aluation of a m usic displa y
and a haptic c hair. In Pro ceedings of the SIGCHI
Conference on Human F actors in Computing Systems,
CHI '09, pages 337346, New Y ork, NY, USA, 2009.
A CM.
[14] H. P ongrac. Vibrotactile p erception: Dieren tial
eects of frequency , amplitude, and acceleration. In
Haptic Audio Visual En vironmen ts and their
Applications, 2006. HA VE 2006. IEEE In ternational
W orkshop on, pages 5459, 2006.
[15] Ronald T. V errillo. Eect of con tactor area on the
vibrotactile threshold. The Journal of the A coustical
So ciet y of America, 35(12):19621966, 1963.
[16] Ronald T. V errillo. Vibration sensation in h umans.
Music P erception: An In terdisciplinary Journal,
9(3):283, 1992.
95