Physical Interactions with Digital Strings - 
A hybrid approach to a digital keyboard instrument 
Palle Dahlstedt
University of Gothenburg
Dept. of Computer Sc. & Engineering
Division of Interaction Design
SE-4126 Gothenburg, Sweden
palle.dahlstedt@gu.se
Aalborg University
Dept. of Communication & Psychology
Rendsburggade 14
DK-9000 Aalborg
dahlstedt@hum.aau.dk
ABSTRACT
A  new  hybrid  approach  to  digital  keyboard  playing  is
presented,  where  the  actual  acoustic  sounds  from  a  digital
keyboard are captured with contact microphones and applied as
excitation signals to a digital model of a prepared piano, i.e., an
extended wave-guide model of strings with the possibility of
stopping  and  muting  the  strings  at  arbitrary  positions.  The
parameters  of  the  string  model  are  controlled  through
TouchKeys  multitouch  sensors  on  each  key,  combined  with
MIDI  data  and  acoustic  signals  from  the  digital  keyboard
frame, using a novel mapping.  The instrument  is evaluated
from  a  performing  musician's  perspective,  and  emerging
playing  techniques  are  discussed.  Since  the  instrument  is  a
hybrid  acoustic-digital  system  with  several  feedback  paths
between the domains, it provides for expressive and dynamic
playing,  with  qualities  approaching  that  of  an  acoustic
instrument, yet with new kinds of control.  The contributions
are two-fold. First, the use of acoustic sounds from a physical
keyboard  for  excitations  and  resonances  results  in  a  novel
hybrid keyboard instrument in itself. Second, the digital model
of  "inside  piano"  playing,  using  multitouch  keyboard  data,
allows  for  performance  techniques  going  far  beyond
conventional keyboard playing.
Author Keywords
Augmented  keyboard,  Musical  keyboard,  Multi-touch,  Mapping,
Gestural interfaces, Physical modelling
ACM Classification
H.5.5 [Information Interfaces and Presentation] Sound and Music
Computing H.5.2 [Information Interfaces and Presentation] User
Interfaces — Auditory (non-speech) feedback 
 1 INTRODUCTION
Keyboard instruments provide an interface optimized for a large
number  of  notes,  but  little  control  of  each  note.  New  sensing
technologies could, in theory, change that. This paper presents a
novel keyboard instrument, which combines features from acoustic
instruments with digital sensing and control. The instrument, for now
called Living Strings, is meant to be an answer to two questions, one
related to technical curiosity, the other to a long-term artistic search:
1. When multitouch sensors for normal keyboard interfaces are
available, how can these be used to allow for extended control
of electronic instruments?
2. How can we design electronic instruments that allow for the
kind of musicianship denoted by the German and Scandinavian
word "musikant" – a musician embodying the music and the joy
of physical  playing,  and is a hybrid  instrument, integrating
digital and acoustic techniques an answer to this question?
The  instrument  is  developed  by  and  for  a  keyboard  performer
(myself), and the main focus is not on correct physical models, but on
finding an effective interaction model that allows for expressive,
dynamic  and  varied  playing,  with  intimate  control  over  pitch,
dynamics and timbre, while taking advantage of the motor skills
acquired from years of musical practice.
The reasons for  this focus  is simply that this instrument  is
developed to be used, in a wide variety of improvisational contexts,
solo, with other musicians, and together with other kinds of stage
performers (e.g., dancers). In such contexts, you either repeatedly
develop something adequate for the temporary context, or try to
design an instrument diverse and expressive enough to be applied in
all these contexts.
The  instrument  has  specific  qualities  from  the  merging  of
acoustic excitation with a virtual string model, and controlling this
from a rather new multidimensional digital keyboard interface. It is
evaluated based on the aesthetic results and playing techniques that
have  emerged  during  the  prototyping  phase,  the  hybrid
electronic/acoustic  qualities  of  the  instrument,  and  from  how  it
bridges the physical/virtual divide.
This instrument is part of a series of artistic research projects
developing  for  new  electronic  instruments  and  technologies  for
improvising musicians.
 2 BACKGROUND
 2.1 Pre-history
Living  Strings  stems  from  a  previous  hybrid  electric-acoustic
keyboard  instrument,  augmenting  an acoustic piano  with  virtual
strings  [1].  When  this  project  was  implemented  with  digital
keyboards,  a  contact  microphone  was  sometimes  added  to  the
instrument panel to allow for the same kinds of physical interactions
as  could  be  applied  on  an  augmented  acoustic  piano,  such  as
knocking or scratching. At some point, this feature was tested on its
own, and a digital keyboard instrument based on acoustic excitation
was born. This was merged with the newly presented TouchKeys
sensors [2], and with an expanded string model, it is now a mature
instrument.
 2.2 Previous art
There are a number of existing instruments and products based on
touch and physical interactions with object, combined with digital or
analog processing, such as Enrique Tomas' Tangible Scores [3], and
the Mogees add-on for iOS devices based on a contact microphone
and software.1
Physical models of strings have developed far from the early
Karplus-Strong algorithm [4], into complex waveguide  synthesis
[5, 6, 7], and even specific models for prepared piano strings [8]. An
overview of virtual acoustic instruments can be found in [9].
Physical models have inspired physical interfaces, for example in
the  merging  of  multitouch  surface  meshes  with  physical  mesh
models  of  vibrating  membranes  [10].  One  particular  point  of
inspiration has been Carla Scaletti's work Slipstick2, where physical
1 http://www.mogees.co.uk/2 https://youtu.be/eAVLrtOrcyc
115
models of friction and vibration forms the basis both for performance
method and sound synthesis.
One important point of departure for Living Strings has been the
idea of commuted synthesis [11,12], which originally was a way to
simplify physical models using the insight that the complex filtering
done by the final resonating body of an instrument could be pre-
applied to the excitation impulse, since an ideal string model is a
linear system, and those characteristics are retained. However, in
Living Strings, this becomes a core feature. The excitation impulse
comes from vibrations in the actual keyboard, and thus embodies its
acoustic imprint, and brings that into the virtual string model.
 2.3 Method
This  project  is  an  example  of  practice-based  artistic  research,
combined with research-based practice, according to Smith's and
Dean's model [13]. Based on a clearly stated problem and the given
premises, a number of iterated prototypes are developed, trying to
solve the problem. Each iteration is evaluated qualitatively, through
extensive  practice  and  playing,  possibly  tested  in  preliminary
performances. When a sufficiently plausible result is achieved, the
design is frozen, and used in a large number of performances and
recordings, often over several years. This is part of the long-term
evaluation. Then, the instrument is evaluated again, with a focus on
the playing techniques that have emerged over this time. With these
as a departure point, we are able to see the relationship between
design choices and implementation details on one hand, and the
aesthetic results on the other.
The Living Strings project is currently in the early part of the
long term evaluation phase. Early prototypes have been used on
stage, and based on experiences gained from that, a sufficiently good
design has been developed, frozen, and used in a series of concerts.
 3 IMPLEMENTATION
 3.1 Hardware and software platforms
The Nord Stage series of keyboards are well-known digital pianos,
which have been on the market since 2006. They are crafted in heavy
steel with  wooden birch sides. These robust materials make  the
panels  eminently  playable.  Furthermore,  the  Nord  series  of
keyboards feature a pitch stick instead of the more common pitch
wheel. This stick is a piece of wood mounted on a piece of spring
steel with a bend sensor. Thanks to this construction, it can be used as
an interesting excitation source. Finally, these keyboards have a large
number of buttons emitting a bright spectrum when clicked.
For signal processing, the Nord Modular G2 platform has been
used. It is robust, has high internal precision (96kHz/24bit resolution)
and is very quick to program. There are some limitations. E.g., it is
MIDI only, which is a limiting factor due to the high bandwidth of
sensor data required for this kind of instrument. Emulating 8 strings,
it is currently at the limit of its capacity, and future version will most
likely be implemented in Kyma3, which has native OSC support.
 3.2 Sensors
There  are  now  a  number  of  continuous  keyboard  and  surface
controllers  available,  which  could  in  principle  be  used  for  this
project. Some of them, like the Madrona Labs SoundPlane4, can be
used as a 2-dimensional keyboard, but lack distinct keys. The Roli
Seaboard5 is a foam-covered surface of keyboard-like geometry, with
multitouch and pressure sensitivity, but its wedge-shaped key design
prevents any advanced keyboard technique to be used, and seems to
be  mainly  aimed  towards  non-keyboard  players.  As  a  trained
keyboard player (piano, harpsichord and clavichord), I want to take
advantage of the motor skills I have developed over years of practice.
The TouchKeys  sensors are currently the only available sensors
which are applied on a normal keyboard action.
3 http://kyma.symbolicsound.com4 http://madronalabs.com/soundplane5 https://roli.com/products/seaboard-rise
TouchKeys  is  a  set  of  capacitive  sensor  plates,  installed
permanently on top of the keys on an existing keyboard or piano,
with supporting electronics on PCBs mounted inside the keyboard. It
is  connected  to  a  computer  via  USB,  and  its  custom  software
provides  an  interface  for  configuring  customized  mappings,
communicated  further  through  the  OSC  and/or  MIDI  protocols.
There is also a possibility to receive all sensor data in raw form
through OSC, for other kinds of mapping, which is used here.
A  disadvantage  compared  to  some  other  keyboard  sensor
interfaces  is  that  the  TouchKeys  do  not  provide  pressure.  The
TouchKeys output is made to be combined with other keyboard data
from the keyboard controller it is mounted on. It could in principle be
mounted on a keyboard with polyphonic aftertouch, but those are
hard to find, especially if piano-like action is preferred. So, this was
not  possible  for  this  project.  However,  with  contact  area  data
provided  for  each  finger,  together  with  channel  aftertouch
information, TouchKeys provides a rich set of performance data.
The  musical  potential  of  TouchKeys  has  previously  been
discussed [14], concluding that, without being an obstacle to trained
keyboard skills, it adds the ability to go deeper into each single note,
and alter between these two different states. What comes out of this
of course depends on the chosen mapping and sound engine.
 3.3 The String Model
The physical string model is based on wave-guide synthesis [5, 6, 7].
Departing from a well-known waveguide model of a perfect string,
which  divides  the string into four  segments, two  in each travel
direction, representing the stretch of the string on each side of the
"pick" position where the excitation impulse is injected (see Fig. 1).
In each end, the bridge and nut are represented by low-pass filters
and a 180 degree phase shift. To this basic model, I have added a
simple representation of what happens when the string is "stopped",
i.e., when an object (finger, fret, etc.) is pressed against the string.
This is implemented as a crossfade between just passing the
wave through the injection point (while adding the external injected
feed), and bouncing it back. On a real string, a soft object on the
string, such as a finger held with a light touch, would let some sound
pass through, and bounce some. A rigid object pressed hard against
the string would instead reflect everything, just like a new bridge,
inserted at the injection point. In effect, it turns the string into two
sub-strings, with a moveable midpoint (see Fig. 2 for the actual
implementation).
Normally, when a wave is reflected by a rigid object such as a
bridge, it is inverted, which in effect doubles the periodicity of the
wave.  In  this  implementation,  inversion  was  removed  from  the
reflections at the injection point when the string is stopped. In this
way,  the fundamental is brought down one more octave, which
brings the usable range of the stopped notes to a musically more
usable register.
Additionally, at the bridge and nut, an adaptive level mechanism
is inserted, which prevents the signal in the string from going over a
certain level, while at the same time allowing input to come in. If
there is input, it is injected, but if there is none, the signal level is kept
Fig. 1: A simplified schematic of the plucked string model
used, where L is the total string length, y is depth position on
the key, k is the amount of stopping.
116
constant, or slowly growing, depending on the current filter values
(affected by many aspects of the playing). In this way, infinite sustain
is possible, without sacrificing external resonance and without the
risk of feedback explosion.
Since waveguide synthesis is a well-known technique, and the
focus of this paper is not on signal processing, I will not go into
further detail about the implementation, except when needed in the
discussion of the interactions and playing techniques.
Thanks to the high time resolution in the used DSP platform
(96kHz for audio signals, 24Hz for control signals), the delay buffers
can change size while the string is sounding without generating any
artifacts. This means that all parameters of the string model can be
dynamically modulated by the interface. For example, while playing,
you can change the injection or stopping point, and simultaneously
change the degree of stopping.
 3.4 Excitation and injection
String models must be injected with energy to produce sound. In
basic  waveguide  models  (such  as  the  original  Karplus  Strong
algorithm), this is a often a burst of colored noise. In Living Strings,
external  sounds  captured  live  by  contact  microphones  on  the
instrument panel are used to excite the string, both at note onset, and
continuously as long as the string is active.
The excitation impulse is taken from the sum of a set of acoustic
excitation sources, and is not a predetermined sound grain.
The excitation sources are:
1. Two contact mics on the instrument shell, one on the left side
of the top panel, close to the modulation wheel and pitch
stick, and the second is fastened to the bottom steel plate on
the right side of the instrument.
2. Internal feedback from the instrument's own output (this can
be turned off if acoustic feedback is present, since they partly
fill the same function of coupling the strings to each other)
3. A bowing mechanism, which generates a pulse train when a
finger is moved rapidly along the key
The input from the contact microphones can contain a lot of low
frequencies,  and  since  the  vibrations  sometimes  have  traveled
through various parts of the instrument (the keys and the bottom of
the keybed, for example), some sounds are low in high frequency
content. Hence, it is pre-processed through a wave-shaping function,
based on a simple folding function, to give it more suitable spectral
profile. In this way, an adjustable amount of new harmonics are
generated  without  compromising  the  basic  gestural  profile  and
general character of the excitation source. The signal is also high-
pass filtered to remove DC components and rumble which can kill
the string resonance, if it contains frequencies lower than the tuned
delay loop. This is especially important when exciting strings in the
upper register.
When a key is pressed, an excitation burst from the incoming
signal is injected into the string. It is enveloped with 5ms attack and
65ms decay (although different values have been tested). After the
initial  excitation,  an  envelope  follower  on  the  incoming  signals
controls the amount of injected sound into the string. To simplify,
when there is none, the string is left alone. When sounds are coming
in, the signal in the string is dampened a little, and new signal is
injected proportionally.
 3.5 Internal inter-string feedback paths
The string model contains several feedback paths coupling the strings
to each other. There is feedback within the digital model, where the
complete output is fed back into the injection mechanism of all active
strings. There is also feedback from the amplified sound in the room,
through vibrations in the steel panels of the keyboard, propagated
into the virtual strings through the contact microphones.
 3.6 Mapping
The TouchKeys sensors output raw data of up to three touches per
key, together with their Y positions, contact areas, and a shared X
position. To process this, a custom software was implemented in the
free high-level programming tool OSCII-bot6, specially made for
processing OSC and MIDI information. The code implements a
voice allocation algorithm, and sends relevant finger data through
MIDI CC messages to the voices. Data is filtered to avoid repetitions
and minimize MIDI bandwidth. The details of the mapping are
explained in a following section.
 3.7 Performance mapping
In Living Strings, nothing happens unless a key is pressed. First, we
will look at one-finger playing, followed by a description of what
happens when several simultaneous fingers are applied to a key. 
A key down event opens a string and triggers an excitation burst
into the string, scaled by key velocity. For slow key presses, velocity
is zero, so it is possible to open a string for resonances and other
playing techniques without any excitation.
A key up event starts as an exponential release phase of the
string, which is normally about half a second.
The  sounding  character  of  a  waveguide  string  is  primarily
affected by the spectral content of the excitation, and the nature of the
filters at the bridge and nut, where the sound wave bounces. These
one-pole low-pass filters are controlled globally with the modulation
wheel, to fine-tune the character of the instrument. Furthermore, they
are affected by other performance parameters.
Increased touch area of the finger raises the filter, making the
sound brighter and slowing down the decay of higher partials, and
possibly also the whole note. Correspondingly, touching the key with
just the tip of the finger, results in a more muted character. Thanks to
the adaptive level control mechanism, this can be used to mute and
swell a note without re-triggering an excitation.
Increased aftertouch (channel pressure) lowers the bridge and nut
low-pass filters, so that the string is muted. Because of the phase
response of the filter, this also has the effect of bending the pitch
slightly downwards in a characteristic way, much like when muting a
guitar string close to the bridge.
The Y position of the finger on the key (in the front to back
direction) affects where on the string excitation and injection signals
are fed into the waveguide model. The range is from close to the
bridge to the midpoint of the string. On a guitar, this would be called
the pick position - where the string is plucked. If excited near the
bridge,  the sound  is very  bright,  the  well-known  sul  ponticello
character, and near the midpoint of the string, the sound is hollow.
These timbral differences are very noticeable when playing, and are
caused by wave cancellations when the sound travels through the
string in both directions, with different time displacement, resulting
in a comb-filtering effect.
The X position of the finger, sideways, controls intonation. E.g.,
to bend a note slightly upwards, move the finger to the right. This is
an absolute mapping, and is not relative to the position of the first
6 http://www.cockos.com/oscii-bot/Fig. 2: The string model as implemented in the Nord G2.
117
touch on the key, which could be slightly safer. Keyboard players are
usually not trained to care about where on the key the finger is
placed, so to avoid too much unintentional bending, the bend is
scaled to give very little response near the middle of the key, with
more audible bending towards the left and right edges.
A key can be played with one, two or three fingers at the same
time, with different behavior. In the following, I will use the term
"top finger" to refer to the finger furthest away from the player.
Moving the top finger back and forth triggers a pulse train, to
emulate the effect of bowing on a string. This pulse train is amplified
proportionally to the speed of the finger movement and pressure, and
the number of pulses is proportional to the distance travelled by the
finger. The bowing signal is mixed with the other input signals and
injected into the current string. It does not affect other strings. The
coarseness and spectral characteristics of the pulse train can be
adjusted in the patch. Currently, bowing resulting from movement on
higher pitched strings contains less low frequency content.
Bowing  can  be  applied  to  a  silent  open  string,  to  initate
vibrations, or to inject more energy into already sounding strings.
When two or more fingers touch the key, this has the effect of
"stopping" or "preparing" the string with an object, such as a finger or
a piece of metal  (see Sec.  3.3 for  a description of how this is
emulated). The top finger decides the position of the stopping, which
in this implementation is always the same as the injection position.
The current implementation of the prepared string allows for a
continuous transition between a normal open string, over a string
lightly stopped with a soft object, to a string stopped completely with
a rigid object, acting like a new bridge for two substrings, each
consisting of a subsection of the original string. The Y position of the
top finger determines the ratio between these substrings. In principle,
the key surface serves as a physical map of the virtual string, from the
nut to the midpoint of the string. Since a string is symmetric, there is
no need to map the whole string, but only one half.
This transition from light to heavy stopping of the string is
controlled with the contact surface area of the finger.
The metaphor here is the following: Holding a small, sharp
object onto the string results in two substrings. This is similar to
holding just the tip of the finger (and possibly the nail) against the
key. Pushing the soft, flat part of the fingertip against the key will
instead  emulate  a  soft  touch,  damping  the  fundamental  while
retaining frequencies having a node at the touching point. This allows
for  the  playing  of  harmonics  (flageolets)  and  the  creation  of
resonances based on overtones of key pitches.
It can be argued that a performance metaphor of muting the
string would feel more adequate for such playing, since quite some
force  is  required  to  push  a  sufficient  skin  are  agains  the  key.
However, inverting the mapping of these two behaviors was found to
be equally awkward.
Just like with a real string, the audible results in the middle of the
transition (stopping the string half-hard with  a half-rigid  object)
simply results in a muted string, so the mapping from contact area to
the stopping parameters is scaled as an S-curve, keeping most of the
range within the musically useful far ends of the range, with a sharp
transition in the middle.
To provide for further flexibility in playing, the value used for
this parameter is the sum of the contact area of the second and third
fingers. So, by alternating touch with the thid finger, jumps in this
value can be controlled.
In a similar fashion, a third contact finger can be used to cause
jumps in the position value (which is decided from the position of the
top finger). With the current bowing algorithm, such a jump causes a
rapid burst of pulses to be injected into the string, which allows for
repeated tremolo-like tap playing.
Playing with two or more fingers on one key is difficult, both
motorically, and because the space is small. In some cases, one may
want to access stopped strings in faster or polyphonic playing. For
this purpose, the left pedal serves as a switch, triggering stopped
behavior without the need of a second finger. As before, the top
finger position controls stopping/injection point, and the sum of the
contact areas on the key is mapped to stopping character, from
flageolet to rigid stopping, as before.
All  these  mappings  are  active  simultaneously,  and  can  be
combined. For example, a note can be pitchbent while bowing, and
bowing can be applied with one or more fingers on the key.
For all the above behaviors, the general decay characteristics of
the strings can be adjusted with the setting of the modulation wheel.
In this way, very muted or very bright and resonant strings can
quickly be configured. Finger-mapped filter modulations are added
on top of this global value.
 4 PLAYING TECHNIQUES
The instrument has been used regularly over four months, and some
recurring  playing  techniques  have  emerged.  Further  playing
techniques may emerge from the continued use of the instrument.
One can attempt an exhaustive inventory of possibilities, but because
of the inclusion of physical interactions with the keyboard  as a
physical sounding object, this is also very hard to do.
String excitations can in the simplest case be the actual thump
from  the  key  hitting  the  keybed.  One  of  the  contact  mics  is
intentionally placed close to one of the screws connecting the keybed
to the panel bottom, so these vibrations are captured well. The
instrument shell is a steel panel with a grainy surface suitable for
friction sounds such as scratching with nails or finger. Different kinds
of knocking and drumming on the panel or the wooden sides also
work well. A nail glissando on the keyboard, without depressing the
keys, provides an effect very similar to strumming, when injected
into open strings.
Button clicks and the springy pitch stick are also good sources
for sonic interaction with the virtual strings. The slotted openings for
power supply cooling provides a guiro-like excitation when stroked
with the nail or a stick. As is evident, it is hard or impossible to do a
complete inventory of such playing techniques.
Another technique is to hold certain strings, and excite them with
the sounds from other strings. In this way, certain harmonics can be
emphasized through resonance.
Thanks to the rich data from the interface, vibrato-like gestures
can be applied to almost any parameter of the string model, such as
bridge filter, injection point (causing timbral change or pitch change
depending on if the string is stopped). Initially silent clusters of
strings can be held and used as bank of resonators, approaching a
reverb, or be played with subtle scrapings or bowing.
There are to many ways to exploit this interface to be able to
mention  them  all.  For  examples  of  a  wide  range  of  playing
techniques, I refer to the attached video example of an improvised
performance on the instrument.
 5 DISCUSSION
The main contribution of this instrument is the tight integration of the
acoustic and virtual/digital domains, in both directions. This brings
back the possibilities of acoustic interactions with the object for the
musician, and the vibrations in the instrument body regains their
meaning. A lot of hybrid instruments have been developed, but this
one is hybrid in the opposite way to what is common – it adds
acoustic properties to a digital instrument, instead of vice versa. It
adds physical interaction of a different kind to a digital keyboard.
To bring in the complexity and diversity of acoustic sounds as
part  of  the  digital  instrument  greatly  enhances  the  sonic  range,
gestural expressivity and available playing techniques. Since you can
play physically on the panel in infinitely many different ways, it also
provides an open-endedness, and source of variation in the hands of
the performer. By introducing an open-ended dimension, it imports
the complexity of the real world, so hard to emulate in synthesis. It
also imparts the material properties of the actual digital instrument on
the sound, and manifests the digital instrument as a physical object.
118
Thanks to the principle of commuted synthesis [11,  12], the
characteristic  acoustic  properties  of  the  casing,  as  heard  while
knocking on the panel, is imparted on the string resonances. So, the
acoustic properties of the physical keyboard interface really becomes
an integrated part of the musical output. Different keyboards will
sound different; material and fabrication methods make a difference.
 5.1 Expressivity and playability
Over all acoustic instruments, there is a balance between the amount
of control over each voice, and the number of voices [15]. This is
also present here, and the virtuoso player will use short-cuts and
grouped control of several notes at the same time, to reduce cognitive
load. Humans are simply not cognitively able to control a high
number of parameters for a large number of notes at the same time.
Still, the availability of fingertip control when desired is a great
feature, which is lacking in most acoustic keyboard instruments,
unless you introduce inside playing.
 5.2 Repeatability
Sounding  strings  have  complex  internal  states,  so  absolute
repeatability is in principle not possible. It is also difficult to repeat
exactly  the  same  gestural  input  due  to  amount  of  performance
dimensions and the small size of the keys. Still, if possible, any
gesture and effect can in theory be repeated. There is no randomness,
only real-world complexity, which we have spent a lifetime learning
to manage. The instrument can be controlled in a quasi-deterministic
manner, and it can be most likely be learnt to a degree of virtuosity.
Some  features  are  difficult  to  control,  because  of  interface
shortcomings. For example, finding the exact location of harmonics
is difficult because there are no points of reference on the key, and
they are distributed over a very short distance on the key surface.
Here, a quantization of position information  to the approximate
positions of the harmonics could help. Still, this should be a soft
quantization, allowing some freedom of movement around them, to
avoid  too perfect and sterile results and limiting the performers
control over the sound.
 5.3 The sound
The string model can most likely be improved. The focus in the
development  has  so  far  been  on  the  interaction  aspects  of  the
instrument,  allowing  for  an  intimate  connection  between  the
performer's gesture and the sound. The string synthesis needs to be
effective, flexible and good enough. There are a number of physical
models  of strings, more sophisticated than the one used in this
project, e.g., finite difference methods [8] or waveguide meshes [11],
and other more fine-grained physical models of an actual string. Such
models  would  allow  for  interaction  with  the  string  in  multiple
positions at once, which is feasible with the current interface.
Prioritizing  between  accuracy  and  fidelity  to  the  modelled
natural systems, and the quality of the interaction model, is not easy.
From a reseach point of view, both are interesting and important, and
worth pursuing. From a musician's perspective, however, without a
good interaction model, the instrument will not be fun or rewarding
to play. The opposite does not hold, though. With adequate control
over the sound, a simple sound source can be the vehicle for good
musicianship.
At one point in the development, there was a possibility to play
the strings with touch only, without pressing the keys. However, this
turned out to be very difficult to control in some situations. It worked
well when only touch was used, or when one hand played the keys
and the other only used touch. However, it turned out to be hard to
mix touch playing with normal keyboard playing, at least within the
same hand. It is part of normal keyboard technique to use the sense of
touch and the morphology of the keyboard to navigate to the right
position.  When  doing  this  without  touch,  you  have  to  rely  on
eyesight to avoid unintended key activations, which might not be
possible when playing difficult passages involving both hands.
 6 FUTURE EXTENSIONS AND 
IMPROVEMENTS
This project is quite new, and there are a number of planned
improvements and extensions of the performance mapping that
simply  have  not  been  implemented  yet  because  of  time
constraints. Here, I will mention a few of those, as well as some
of the more speculative potential extensions.
Traditional  keyboard  instrument  playing  relies  on
multiplicity of notes, and the relations between them regarding
timing, dynamics and timbre. The purpose of Living Strings is
to extend this to gain more control also over each note. The
performer  may  still  want  to  perform  in  a  more  traditional
keyboard  fashion,  triggering  a  multitude  of  notes.  For  this
purpose, the left pedal shortcut was introduced, triggering the
effect of an extra finger all played keys.
In the same way, a master-key could be assigned, reserved
for touch interactions applied to all currently active strings. In
this way more complex chords can be controlled as one entity.
The plan is to use the lowest key on the current Living Strings
keyboard, contra-E, for this purpose. It is an all-white key, with
no cutout for a black key, which makes it especially suitable for
precise touch interactions.
There are a couple of improvements planned for the bowing
mechanism.  The  dynamics  of  the  bowing  should  also  be
modulated  by  finger  contact  area,  instead  of  just  speed  of
movement. This would enable repeated playing on flageolets,
through  short-throw  "rubbing"  movement  around  the  touch-
point, similar to hard bow pressure. If bowing with either first
or second finger, instead of as now, only with the top finger.
This  would  allow  for  a  decoupling  of  stopping  point  and
bowing movement.
Currently, the mapping of finger X position to pitch bend
leads to some out-of-tune playing, especially in fast passages. A
keyboard player is not trained to care about the position on the
key. This can be regarded as a feature, and motivate for further
practice,  or,  one  could  implement  pitch  bend  based  on
divergence from first point of contact, so that the note always
starts according to equal 12 tone temperament (which may or
may not be desired).
A special sustain pedal mechanism is planned, which opens
all last active  strings  (8 voices  currently).  They will  get  no
direct excitation, but will be open for signal injection from the
signal sources. In this way both hands can be used to play, e.g.,
complex percussive rhythms on the panel.
 6.1 Prepared piano
The word "prepared" in prepared piano signifies modifications
of  the  instrument  that  have  been  carried  out  beforehand,
allowing for detailed control of pre-prepared strings at design
time, but less flexibility during performance, with a focus on
traditional keyboard interaction.
On  the  other  hand,  "inside  piano  playing"  refers  to  the
practice of using alternative playing techniques directly on the
strings and elsewhere in the piano.
Living Strings is more closely related to the latter, thanks to
its focus on access to the parameters of string alteration during
performance.  Still,  it  would  be  a  quite  simple  extension  to
implement a mechanism for preparation of strings, with one or
more parameters of the string model decided beforehand, while
leaving  others  for  real-time  performance.  This  can,  e.g.,  be
done using normal playing  combined  with  a set of switches
triggering the storage of certain parameters (injection/stopping
position, stopping amount, etc.) and a reset switch that releases
all parameters to performance control again. This functionality
could easily be expanded upon into presets, alternate tunings,
etc.,  but  there  are  already more  sophisticated  approaches  to
such well-controlled synthesis of prepared piano sounds.
119
In  an  improvisational  context,  an  easily  accessible
"preparation"  interface  could  be  used  to  keep  and  further
exploit  interesting sounds found  while  playing,  in a manner
very  similar  to  the  other  timbre-focused  improvisation
instruments I have previously designed, e.g., [1, 15].
 6.2 Experimental sound engines
Now, when there is an interaction that works well, it could be
fruitful to further develop the Living Strings instrument in a
direction  away  from  acoustic  metaphors,  towards  nonlinear
behavior,  while  keeping  the  rich  interaction  model.  For
example, the current model can be modified with experimental
bridge-filter  types,  causing  interesting  nonlinearities  and
feedback behaviors. Some initial testing has been done with
interesting results. It works quite well, thanks to the adaptive
level control mechanism. The string stays at the same level, in
spite  of  feedback.  Some  initial  testing  has  been  done,  with
interesting results.
In addition to the string engine, a prototype sound engine
based on physical models of blown pipes, with gestural control
over  a  number  of  parameters.  Also,  an  engine  based  on
frequency modulation synthesis has been developed and used in
a stage production. These will be published in the near future.
It would also be possible to develop a sound engine based
on banks  of resonant filters, excited  by the current acoustic
sources, essentially a version of modal synthesis.
One could consider using alternate interfaces, instead of, or
in addition to the TouchKeys enhanced keyboard. For example
the idea of a master key for control of all played strings at the
same time could be further improved by using a longer ribbon
controller,  which  gives  better  precision  for  intonation  and
harmonics playing.
Two-dimensional  multi-touch  control  surfaces  such  as
Madrona Labs SoundPlane or Haken Continuum [16] could be
used with only a slightly altered version of the current mapping,
if the surface is divided in a series of strips from left to right,
with further playing techniques possible thanks to the larger
freedom  of  sideways  movement  without  physical  key
boundaries.
Finally, in a related project, instruments have been designed
using vocal signals for string excitation and injection. If this is
applied  to  Living  Strings  performance  mapping,  complex
timbres  can  be  injected  while  keeping  both  hands  free  for
keyboard playing.
 7 CONCLUSIONS
I have presented a novel hybrid acoustic-digital keyboard instrument
based on multi-touch sensors on the keys. The instrument provides
extensive control over, and intimate fingertip interaction with, a large
number  of  virtual  strings.  The  acoustic  input  from  the  contact
microphones, used as the main source of string excitation, provides a
richness that is hard to produce with purely synthetic means. The
instrument  provides  a  large  variety of playing  techniques, from
traditional keyboard playing down to detailed control over a single
string and its resonating properties, through a simple but effective
model of prepared strings.
The instrument merges physical modeling synthesis with the
acoustic properties of the actual physical keyboard as material object,
providing  rich  mechanical  interactions,  as  well  as  a  complex
mapping from multitouch sensors to string synthesis.
The synthesis model is quite simple and can be improved. Still, it
is already a satisfying instrument for the able keyboard player, and
the addition of multitouch control allows for very dynamic playing,
but also requires the musician to practice new kinds of playing
techniques, since features such as touch position and finger contact
area suddenly have a great impact on the sound.
This  is  not  a  substitution  for  real  string  instruments,  but  it
provides for new kinds of musical interaction with physical models,
through a successful synthesis of the physical and the virtual.
 8 ACKNOWLEDGMENTS
Thanks to Chet Singer for some details of the Nord Modular G2
string implementation. The research is supported by the Swedish
Research Council.
 9 REFERENCES
[1] P. Dahlstedt. Mapping Strategies and Sound Engine 
Design for an Augmented Hybrid Piano. Proceedings of 
NIME. AMC, 2015.
[2] A. McPherson. TouchKeys: Capacitive Multi-Touch 
Sensing on a Physical Keyboard. Proceedings of NIME. 
ACM, 2012.
[3] E. Tomás and M. Kaltenbrunner. Tangible Scores: 
Shaping the Inherent Instrument Score. Proceedings of 
NIME. ACM, 2014.
[4] K. Karplus and A. Strong. Digital synthesis of plucked-
string and drum timbres. Computer Music Journal, 7.2 
(1983), 43-55.
[5] J. O. Smith. Physical modeling using digital waveguides. 
Computer Music Journal, 16.4 (1992), 74-91.
[6] M. Karjalainen, V. Välimäki and T. Tolonen. Plucked-string 
models: From the Karplus-Strong algorithm to digital 
waveguides and beyond. Computer Music Journal, 22.3 
(1998), 17-32.
[7] J. O. Smith. Physical modeling synthesis update. Computer 
Music Journal; 20.2 (1996): 44-56.
[8] S. Bilbao and J. Fitch: Prepared Piano Sound Synthesis. 
Proceedings of the 9 th International Digital Audio Effects
Conference (Montreal, Canada), 2006, 77-82.
[9] J. O. Smith. Virtual acoustic musical instruments: Review 
and update. Journal of New Music Research, 33.3 (2004), 
283-304.
[10] R. Jones and A. Schloss. Controlling a physical model 
with a 2D force matrix. Proceedings of NIME. ACM, 
2007.
[11] M. Karjalainen, V. Välimäki and Z. Jánosy. Towards 
high-quality sound synthesis of the guitar and string 
instruments. Proceedings of the International Computer 
Music Conference. ICMA, 1993.
[12] J. O. Smith III. Efficient synthesis of stringed musical 
instruments. Proceedings of the International Computer 
Music Conference. ICMA, 1993.
[13] Smith, Hazel, and Roger Dean, eds. Practice-led research, 
research-led practice in the creative arts. Edinburgh 
University Press, 2009.
[14] P. Dahlstedt. Expert Commentary: Turning the Piano 
Keyboard Inside Out. A.R. Jensenius, M.J. Lyons (Eds.): 
A NIME Reader: Fifteen Years of New Interfaces for 
Musical Expression. Springer, 2017, 430–432.
[15] P. Dahlstedt. Dynamic Mapping Strategies for Expressive 
Synthesis Performance and Improvisation. Lecture Notes 
in Computer Science, 5493, Springer, 2009, 227–242.
[16] L. Haken, R. Abdullah, and M. Smart. The continuum: a 
continuous music keyboard. Proceedings of the 
International Computer Music Conference. ICMA, 1992.
120