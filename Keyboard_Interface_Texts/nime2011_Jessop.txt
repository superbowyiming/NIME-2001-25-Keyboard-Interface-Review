Music and Technology in Death and the Powers
Elena Jessop
MIT Media Lab
E14-333A, 75 Amherst Street
Cambridge, MA 02139
ejessop@media.mit.edu
Peter A. Torpey
MIT Media Lab
E14-333A, 75 Amherst Street
Cambridge, MA 02139
patorpey@media.mit.edu
Benjamin Bloomberg
MIT Media Lab
E14-333A, 75 Amherst Street
Cambridge, MA 02139
benb@media.mit.edu
ABSTRACT
In composer Tod Machover’s new operaDeath and the Pow-
ers, the main character uploads his consciousness into an
elaborate computer system to preserve his essence and agency
after his corporeal death. Consequently, for much of the
opera, the stage and the environment itself come alive as
the main character. This creative need brings with it a host
of technical challenges and opportunities. In order to satisfy
the needs of this storyline, Machover’s Opera of the Future
group at the MIT Media Lab has developed a suite of new
performance technologies, including robot characters, inter-
active performance capture systems, mapping systems for
authoring interactive multimedia performances, new mu-
sical instruments, unique spatialized sound controls, and
a uniﬁed control system for all these technological com-
ponents. While developed for a particular theatrical pro-
duction, many of the concepts and design procedures re-
main relevant to broader contexts including performance,
robotics, and interaction design.
Keywords
opera, Death and the Powers, Tod Machover, gestural in-
terfaces, Disembodied Performance, ambisonics
1. INTRODUCTION:
DEATH AND THE POWERS
The new opera, Death and the Powers [2], by composer
Tod Machover, brings numerous artistic and technological
innovations to the stage. In this show, the main character is
the rich, powerful inventor and businessman, Simon Powers.
Simon ﬁnds that he is dying and thus seeks to extend his life,
legacy, and ability to interact with the world by uploading
his consciousness, memories, and essence into a computer
system built into his house. Powers’ transformation from
human being into the pervasive “System” occurs at the end
of the ﬁrst scene in the opera. The other characters in the
opera—Powers’ third wife Evvy, his daughter Miranda, his
research assistant Nicholas, and representatives from the
world at large—must learn how to relate to Simon in his
new form. They question whether he is still alive and still
the same person, and ﬁnally decide whether they wish to
come join him in “The System.”
While this story and the theatrical production involve a
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’11,30 May–1 June 2011, Oslo, Norway.
Copyright remains with the author(s).
signiﬁcant amount of technology, we wanted the story to
be the primary focus. The technology needed to be in ser-
vice of the story, not the story in service of the technology.
Additionally, the technology had to be considerate of the
needs of live theater: it had to be ﬂexible, be expressive,
and facilitate creativity.
This opera was developed by Machover’s Opera of the
Future group at the MIT Media Lab in collaboration with
experts from the worlds of theater and ﬁlm, including the-
ater and opera director Diane Paulus and production de-
signer Alex McDowell. Machover and the Opera of the Fu-
ture group (formerly Hyperinstruments) have extensive ex-
perience with creating large-scale musical performances that
incorporate signiﬁcant technological innovations, including
Valis[10], Brain Opera[15], and Toy Symphony[9]. The au-
thors are students working with Machover at the Media Lab
and were responsible for signiﬁcant technical contributions
toDeath and the Powers.
The premiere performances of Death and the Powerswere
in Monte Carlo, Monaco in September 2010, with additional
performances in Boston in March 2011 and Chicago in April
2011.
2. CONTEXT:
TECHNOLOGY IN THE OPERA
As computer-based technology is such a a signiﬁcant part of
daily experience, it is now not unusual to introduce cutting-
edge technology into performance. In fact, theater and per-
formance artists have often been early adaptors of technolo-
gies from electric lighting to the Internet to digital video [5].
Technology has also found a place in the relatively new per-
formance form of opera. While music, dance, and theater
have been practiced for millennia, opera has its roots in
16th Century Italy. In fact, opera can be seen as a fairly
new model of performance, still developing and still free for
experimentation and exploration. Opera is also conducive
to the integration of new technologies due to its history
of incorporating elements from a variety of other perfor-
mance traditions, combining musical performances, narra-
tive storylines, theatrical design elements such as costume
and scenic design, and occasional dances. Thus, a vari-
ety of opera productions and new operas have also incorpo-
rated technological performance elements into the medium.
For example, Tod Machover’s Valis [10] used two early hy-
perinstruments to create the musical score, with computer-
generated music extending the live performance of a digi-
tal piano and a percussion instrument. Lost Highway, an
opera based on the ﬁlm of the same name by David Lynch,
uses intricate live and prerecorded video streams and a rich
synthesized soundscape to translate a complex movie into
a compelling live musical performance. This production
was directed by Diane Paulus with video design by Philip
Bussman [6]. StarChild (1996) is an example of a “multime-
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
349
Figure 1: A rendering of the stage environment forDeath and the Powers.
dia opera,” incorporating surround-sound technology, plan-
etary data soniﬁcation, and precise synchronization between
a number of audio and video streams [12]. The Canadian
director Robert Lepage has also brought interactive per-
formance technologies into the world of opera, with works
including his 2008 staging of Hector Berlioz’sLa Damna-
tion de Faustfor the Metropolitan Opera. This production
used microphones to capture the pitch and amplitude of
the performers’ voices and the orchestra’s music, as well as
infrared lights and cameras to capture motion. The data
from these sensors was used to shape projected images in
real time, such as projected curtains waving behind dancers
or giant projected ﬂames that varied based on the singer’s
voice [14]. In contrast to many productions where single
inputs are tied directly to independent outputs, we take
a more abstracted approach to deriving expressive perfor-
mance output from multiple live input streams. In exam-
ining the technology designed for Death and the Powers, it
is also important to remember that most “high tech” the-
atrical performances simply use projection on screens and
perhaps live camera feeds. If onstage performers’ actions
are measured, as in [4] and [14], that data typically is used
to shape sound or visuals that share the stage with the
measured performer. Additionally, theatrical technologies
usually consist of discrete, disconnected systems.Death and
the Powersfeatures a distributed control system, an oﬀstage
performance translated into an expressive onstage presence,
and a chorus of robotic characters. Through these elements
and others,Powers extends the range of existing theatrical
and operatic performance.
3. DISEMBODIED PERFORMANCE
One of the most unique theatrical challenges presented by
the storyline of Death and the Powersis that, for the ma-
jority of the 90-minute opera, the main character is not rep-
resented by a physical actor onstage, but by the theatrical
set. Powers’ primary manifestation within the set takes the
form of three ﬁfteen-foot tall wall structures, or periaktoi.
The structures can rotate and move freely about the stage.
The walls represent book shelves and each book spine forms
an LED display surface. The character of Simon Powers is
expressed through a visual language created for this display
surface, a language which develops and grows as Powers
becomes more at home in The System.
A core performance issue is how to transform the char-
acter of Simon Powers from the physical form of our lead
performer (James Maddalena in the premiere performances)
into the theatrical environment. The stage must breathe,
react, be emotionally expressive, and be as compelling as a
human performer. One could have pre-recorded the singer’s
voice and have the behavior of the set and visuals on the
stage be pre-scripted and triggered for separate scenes; how-
ever, we felt that it this would be constraining to the other
performers and the orchestra and not expressive or con-
ducive to the story or the performance. We determined it
was a theatrical necessity to keep the power and presence
of the singer’s live performance, even though he would not
be physically on the stage. Therefore, in our approach, the
behavior of the scenic elements, including lighting, visuals,
and robotics, are inﬂuenced in real time by the singer’s per-
formance.
Through a technique that we call Disembodied Perfor-
mance, the singer’s gestures, breath, and voice are observed
and used to shape the output media on the stage in ex-
pressive and active ways. The Disembodied Performance
System (DPS) consists of four separate layers: performance
capture sensors (including both on-the-body sensors and
audio sensors); data analysis software that transforms the
raw data from performance capture system into meaningful
abstractions; a mapping layer that relates the abstracted
input parameters to parameters for output control; and
an output layer, including visual, audio, and robotic ele-
ments, that shapes its behavior based on the control param-
eters. This system addresses a variety of questions about
how to map a performance from one expressive modality,
the human body, to a variety of other modalities, includ-
ing non-anthropomorphic visual representations, lighting,
movement, and sound [13].
3.1 Performance Capture and Analysis
3.1.1 Wearable Sensors
In order to measure the vitality and expressivity of a singer’s
physical performance, it was necessary to thoughtfully choose
a set of performance capture sensors that would allow us
to collect important features of the performance while not
restricting the performer. We found that one of the key as-
pects of this physical presence is the performer’s breath.
The breath delivers information about musical phrasing,
emotion, and a sense of life that would be evident to au-
diences watching the performer live on stage. Therefore,
part of the sensor system includes a ﬂexible band around
the performer’s chest that detects his inhalations and exha-
lations. The fabric band contains a stretch sensor located
in a region of elastic fabric at the performer’s back. As the
performer inhales, his chest expands and therefore stretches
the elastic region and the sensor. This simple sensor was
found to detect information about the breath of the per-
former and his vocal phrasing that was more detailed than
the information obtainable from audio or the score.
Accelerometers on the arms and the backs of the hands
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
350
are used to obtain information about the performer’s ges-
tures as he sings. Importantly, drawing on our group’s back-
ground in Hyperinstrument design, we wanted to allow the
singer to perform as he normally would onstage, with his
training in how to use his body to convey a character’s
emotions. We thus chose not to capture speciﬁc gestures;
more important was the overall character and expressive
quality of his natural motion while singing expressively. We
thus process the movement data into a set of higher-level
parameters drawing on features of accelerometer data re-
lated to the quality of the movement (sharply changing,
smooth, sudden, etc.). Such parameters are related to some
of Rudolf Laban’s qualities of movement, as discussed in
the next subsection. All wearable sensors collect data with
Funnel I/O microcontrollers and send that data wirelessly
using the XBee protocol to external computers for analysis.
Figure 2: James Maddalena (Simon Powers) wear-
ing prototype Disembodied Performance sensors.
3.1.2 Laban Effort Notation
In our analysis of movement data, we decided that the per-
former should not be required to use any particular move-
ment vocabulary (essentially, his performance should not
be choreographed); instead, the system should adapt to
the performer’s personal style of expression and augment
his normal performance. We therefore chose to transform
live movement data into information about the performer’s
emotionally-driven quality of movement.
We analyzed the qualities of movement using concepts
borrowed Laban Eﬀort Notion. Rudolf Laban held that the
quality of any movement could be viewed as a point in a
four-dimensional space, described by the four axes of Time,
Weight, Space, and Flow [8]. The Time axis describes the
speed at which a particular movement is being performed,
from very fast and sudden to very slow and sustained. The
Weight axis describes movement on a scale from ﬁrm to gen-
tle. Firm movements are forceful, strong, resisting, heavy;
gentle movements are relaxed, unresisting, light, weightless.
Importantly for detecting this quality from sensor input,
Weight is also a measurement of how much energy is be-
ing put into the movement. The third quality that Laban
discusses is that of Space, which explores the way in which
a movement travels through the space around the body,
whether it moves directly or indirectly from one point to
the next. Movement ranges on this axis from direct (mov-
ing in a straight line) to ﬂexible (moving in curved, vary-
ing lines). The ﬁnal quality of motion, Flow, is primarily
descriptive of the amount of freedom of energy in a partic-
ular movement, reﬂecting how smoothly and continuously
the movement is changing. This quality is on an axis from
“ﬂuid” movement to “bound” movement. In the Disembod-
ied Performance System, immediate movement data and
data trends are analyzed to locate the performer’s move-
ment in a three-dimensional quality space based on Laban’s
theories and deﬁned by the axes of Time, Weight, and Flow,
using techniques laid out in [7].
3.1.3 Vocal Processing
Additionally, vocal data from the performer was collected
using microphones and used as input for audio processing.
This vocal data, including both sung and spoken sounds,
was analyzed for such audio parameters as amplitude, pitch,
timbre, and purity of sound (consonance). These parame-
ters, along with the parameters calculated from the breath
data and movement quality analysis, are used as the inputs
to the mapping system. In this way, the emotional content
and quality of the actor’s performance can be retained, but
abstracted into a parameter space that is not tied to his
physical body.
3.2 The DPS Mapping System
Interactive performances, where the live actions of a per-
former are captured by technology and used to shape vi-
sual, audio, or other aspects of a performance piece in real
time, have a rich tradition in performance. In most inter-
active pieces, a pervasive and vitally important question is
how the inputs from the live performance—sound, move-
ment, location on stage, etc.—are mapped to parameters of
the interactive output media. However, the systems that
exist for creating these mappings are frequently limited by
the small number of diﬀerent mappings that can be created
during the course of a particular piece, as well as by their
focus on low-level sensor input rather than more meaningful
abstractions of the input data. During our work on Death
and the Powers, we developed a general-purpose mapping
system to address these issues while additionally remain-
ing sensitive to the needs of this particular piece and of the
theater more broadly.
It was necessary for this mapping system to be very ﬂex-
ible and react appropriately to the fast-paced theatrical re-
hearsal process. The opera’s systems are capable of creating
an enormous variety of representations of Simon Powers;
as those representations change from scene to scene and
are developed during the course of rehearsals, the way that
they are controlled by the live performance has to change as
well. Additionally, the system needed to allow us to adjust
the mappings between the live performance and the visuals
immediately when given directions from the stage director
Diane Paulus or visual notes from the production designer
Alex McDowell, without having to stop the program or in-
teractive output to make changes.
We developed a node-based ﬂow interface that allows a
user to create mappings by connecting streams of input
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
351
Figure 3: Mapping System screenshot.
data to outputs. Data analysis and arithmetic nodes allow
for the creation of sophisticated transformations of perfor-
mance data. All mappings can be manipulated and edited
in real time. Each mapping between input and output data
can be saved in a cue, allowing for mapping modes to be
changed as needed during the performance. This mapping
software, together with the performance capture sensors and
a specially-designed visual display system, constitutes the
Disembodied Performance System.
Figure 4: The Disembodied Performance System
translates James Maddalena’s performance into vi-
suals on the walls.
3.3 The DPS Visualization System
As the primary representation of Simon Powers is through
the visual displays on the three bookcase periaktoi, it was
necessary to develop a system for creating visual content
that could be not only shaped and developed with the pro-
duction designer during the rehearsal process, but also mod-
iﬁed in real time by live performance parameters. We ac-
complished this through the creation of a novel visual ren-
dering system. This rendering software incorporates ele-
ments of a video compositing and animation environment,
with the major organizing principle being the cue. Each cue
can include compositions of procedural animation primi-
tives, images, and pre-rendered video content. Additionally,
triggering each cue puts the system into a particular mode
where the live data from the performer procedurally shapes
the generation of speciﬁc graphics and image. An operator
can then mix the visual inﬂuence of the live performance on
the preshaped cues using an Apple iPad during the perfor-
mance. The result is a non-anthropomorphic manifestation
of the actor’s performance throughout the set.
4. OPERABOTS
Death and the Powersfeatures two principal types of robots.
The robots have multifaceted roles as set pieces, lighting
elements, individual characters, and part of the manifesta-
tion of Simon Powers. The main periaktoi set pieces pre-
viously mentioned are three large robots. In addition to
these robotic walls, the opera features nine smaller wire-
less Operabots, designed and fabricated at the MIT Me-
dia Lab. These robots, with triangular heads and bodies
made of thin rods, can extend from four feet tall up to
seven feet in height, have articulated heads, and use a holo-
nomic omnidrive system that allows them to translate and
rotate independently across the stage. Each Operabot has
11 expressive channels of LED lighting, including the bases,
heads, and acrylic rods. The computational core of each
of these robots is the small, eﬃcient, and inexpensive One
Laptop per Child XO computer.
In the context of the story, the Operabots serve as a Greek
chorus, both characters in the action and commenting on
it. In a prologue and epilogue, performed entirely by the
robots, it is revealed that the robots habitually retell the
story of Simon Powers, though they are still attempting to
understand the idea of death. The Operabots also appear
as ﬁgures throughout the main storyline.
As these robots play such major roles in the story, it
was necessary to create a system for choreographing their
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
352
Figure 5: The nine members of the Chorus of Op-
erabots.
behavior and movement that could allow the robots’ perfor-
mance to be shaped and developed along with the human
performers during the rehearsal process. As Diane Paulus
and choreographer Karole Armitage created choreography
on robots, it was necessary for the robot system to quickly
adapt to the demands of the moment and not limit the
rehearsal process. The robots needed to be as ﬂexible as
the human performers. In order to accomplish this, we
developed a new type of automation and control system
speciﬁcally for theatrical robotics. The system combines
timeline playback and parameter curves, familiar from typ-
ical animation software programs, with cuing, autonomous
operation, procedural behaviors, and live control from a
multitude of sources. This system has proven eﬀective in
choreographing the fast and complex Operabot movements
and lighting, as well as the graceful repositioning of the
three wall structures. Additionally, operators can assume
control over any robot at any time, overriding any of its
programmed behaviors. A 3D graphical simulation module
in the choreographic software is included for assistance not
only with monitoring the system during live control scenar-
ios, but also to allow for oﬄine programming and chore-
ographing without needing to use the physical robots [11].
An ultra-wideband RFID absolute positioning system en-
compassing the stage tracks the location of operabots, walls,
and singers, and communicates position information to each
of the robots. This allows the robots to autonomously navi-
gate along a predetermined trajectory and avoid each other
and actors onstage, ensuring safe and robust operation. The
nine Operabots may also be puppeteered as needed by oper-
ators situated above the stage, using commercially available
video game controllers.
5. AUDIO SYSTEM
Death and the Powers is performed by a small ensemble
with lightly ampliﬁed voices and accompanied by a 15-piece
orchestra and electronic sound. To locate Simon Powers in
The System, this production relies on sonic transformations
in addition to visual transformations. To help express Pow-
ers’ new omnipresence, his voice must be able to appear
from anywhere, shifting location from moment to moment.
The audio infrastructure to support this movement is quite
extensive, utilizing two formats of surround sound, real-time
performance control and several custom eﬀects engines; all
with the goal of achieving a smooth continuum ranging from
acoustic to ampliﬁed textures. The large dynamic range in
the audio system allows the most basic characteristics of the
sound to follow Simon’s emotions very closely.
5.1 Architecture
The heart of theDeath and the Powersaudio system is a dig-
ital signal processing (DSP) engine based on CoreAudio Au-
dioUnits plugins running inside Digital Performer 7. This
engine performs processing on the production’s 350 audio
inputs and 250 audio outputs. Custom plug-ins implement
3rd order ambisonic encoding and decoding and wave ﬁeld
synthesis (WFS) encoding and decoding. All DSP systems
connect via three 64 channel bi-directional MADI ﬁbre op-
tic trunks to a Studer Vista 5SR mixing console, where the
production is mixed on 12 VCAs. Each of the Duran Audio
Axys loudspeakers in the front Left-Center-Right audio sys-
tem runs additional DSP internally to manage crossovers,
system-wide equalization and time alignment.
5.2 Localization Techniques
Death and the Powers uses two methods for localizing sound:
ambisonics and WFS. The ambisonic system reproduces a
consistent 3-dimensional sound-ﬁeld over a large range of
venues and speaker conﬁgurations. It is used to move voices
and orchestral textures around the perimeter of the audi-
ence. The WFS system generates a wave-front where the
origin of the wave is a location on stage. The WFS system
is used with the tracking system to provide realistic rein-
forcement of the voices and robots. Natural ampliﬁcation
radiates from the location of the performers, instead of the
WFS speaker array located along the front of the stage.
5.3 Seating Zones
Surround sound is an essential part of Death and the Pow-
ers, so it is critical for the entire audience to experience
it. This presents a challenge in theaters where seating ar-
eas may be acoustically isolated (i.e. upper balcony or box
seats). In this case, it is necessary to have a speaker sys-
tem for each acoustic zone. InDeath and the Powers, each
zone contains a small surround sound system as well as sup-
plementary front speakers. The system’s DSP is tailored
for the size and shape of the zone through the weighting of
harmonic orders for the ambisonic decoders on each output.
This maintains apparent resolution of each zone’s surround
system. For the premiere performance, 143 unique speaker
outputs were used.
5.4 Control
All routing of sources to speakers is managed intelligently
by the DSP engine and controlled live by streaming Open
Sound Control (OSC) protocol [3] messages from Apple
iPads and from the same RFID tracking system that tracks
the robots. The DSP system utilizes a central shared mem-
ory where coordinates and audio are made available to all
encoders and decoders. A network daemon listens for OSC
and writes DSP parameters to the shared memory. An ex-
ternal system accepts tracking, cuing and remote control
data, smooths it and deﬁnes which data is forwarded to the
DSP network daemon.
6. THE CHANDELIER
Another of Simon Powers’ manifestations in his environ-
ment is through the form of the Chandelier, a large stringed
set piece that serves as a lighting element and, in a romantic
scene in the middle of the opera, a musical instrument. For
the ﬁrst several scenes of the opera, the chandelier remains
aloft and unmoving over the stage. As Simon’s wife Evvy
attempts to communicate with her husband in his new form,
Simon inhabits the Chandelier and descends to wrap around
Evvy. As she touches the Chandelier, it reveals itself to be
a musical instrument. The Chandelier’s primary sound is a
complex electronic mix created from Simon’s voice. When
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
353
Evvy strokes and strums the Teﬂon strings of the Chande-
lier, she controls this rich sound - bringing it out, dampen-
ing it, as if she’s physically touching and manipulating his
voice. Additionally, when she plucks the strings, she adds
more processed string-like sounds to the mix. Stretch sen-
sors wrapped around the tops of the Chandelier’s strings
detect the vibrations of the strings as they are played, al-
lowing the performer in the role of Evvy to interact in a
highly physical and sensual manner with the instrument.
Figure 6: Patricia Risley as Evvy with the Chande-
lier.
7. UNIFIED CONTROL ARCHITECTURE
All of the elements of the theatrical set—from the move-
ment or robotic elements, spatialized sound, lighting, and
visuals—must act in synchrony if they are to provide a con-
sistent impression of a single expressive character. To ac-
complish this, the distributed show control systems are net-
worked and interact by sharing data and interfacing with
traditional theatrical controls. Data is exchanged over a
common IP-based network infrastructure using OSC so that
any system can respond to input from any other. Our pro-
tocol borrows from MIDI Show Control for cue-based and
timeline navigation, as well as the Architecture for Con-
trol Networks (ACN) protocol [1]. Although robust ACN
implementation was not readily available at the time we be-
gan creating the control systems for Powers, we did imple-
ment an ACN-inspired form of device description language
and autodiscovery. Using OSC also meant that our novel
systems could immediately exchange data with oﬀ-the-shelf
audio software suites used in the production as well as user
interfaces such as TouchOSC for the iPad. Additionally, the
ranges of all data and control instructions are normalized
into a range from -1.0 to 1.0 so the systems can logically
communicate. With this system, gestures can be created
across media: the sound of Powers’ voice can match the
movement of a visualization on the walls, or a robot’s light-
ing can be driven by a performer’s voice. The individual
systems can be treated as parts of an artistic whole.
8. FUTURE DIRECTIONS
The technologies developed for and used in Death and the
Powers have been designed so that they can be general-
ized for other performance contexts as well. The mapping
system designed as part of the Disembodied Performance
System can easily be adapted to allow the rapid develop-
ment of mappings between any performance inputs and any
control parameters for interactive systems. In fact, the Dis-
embodied Performance mapping system has already been
used in a piece for solo cello written by Tod Machover. In
this work, “Spheres and Splinters”, the sound of the cello
and various properties of the cellist’s bowing are used as in-
puts to the mapping system, which transforms those inputs
into control of sonic transformations applied to the cello,
and movement of sound in an ambisonic setup.
Additionally, many of the concepts and software systems
developed for the opera are applicable for ﬁelds such as re-
mote presence, storytelling, personal expression, and robotic
control. For example, remote presence tools could be greatly
enhanced the ability to capture emotional information about
a person’s movement and transform that to a set of expres-
sive parameters for visual control. With tools such as those
developed forDeath and the Powers, subtleties and evoca-
tive details of physical movement can be used to create even
richer interactions, performances, stories, and experiences:
experiences that use and beneﬁt from digital technology,
but which are still inexorably linked to very human stories.
9. ACKNOWLEDGMENTS
Thanks to Tod Machover and the Opera of the Future Group,
the MIT Media Lab, and the cast, crew, and creative team
of Death and the Powers.
10. REFERENCES
[1] Architecture for control networks.
http://www.engarts.com/acn/.
[2] Death and the powers website.
http://powers.media.mit.edu.
[3] CNMAT. opensoundcontrol.
http://opensoundcontrol.org.
[4] M. Coniglio. New Visions in Performance, chapter
The Importance of Being Interactive, pages 5–12.
Taylor and Franci, 2004.
[5] S. Dixon, editor. Digital Performance: A History of
New Media in Theater, Dance, Performance Art, and
Installation. MIT Press, Cambridge, MA, 2007.
[6] I. Hewitt. Lost highway: Into the dark heart of david
lynch.
http://www.telegraph.co.uk/culture/music/opera/3672082/lost-
highway-into-the-dark-heart-of-david-lynch.html.
[7] E. Jessop. A gestural media framework: Tools for
expressive gesture recognition and mapping in
rehearsal and performance. Master’s thesis,
Massachusetts Institute of Technology, 2010.
[8] R. Laban. Mastery of Movement. Northcote House,
4th edition, 1980.
[9] T. Machover. Shaping minds musically. BT
Technology Journal, 22(4):171–179.
[10] T. Machover. Hyperinstruments: A progress report,
1987-1991. Technical report, MIT Media Laboratory,
1992.
[11] M. Miller. Show design and control system for live
theater. Master’s thesis, Massachusetts Institute of
Technology, 2010.
[12] J. Olivero and J. Pair. Design and implementation of
a multimedia opera. Proceedings of the 1996
International Computer Music Conference, 1996.
[13] P. Torpey. Disembodied performance: Abstraction of
representation in live theater. Master’s thesis,
Massachusetts Institute of Technology, 2009.
[14] D. Wakin. Techno-alchemy at the opera: Robert
lepage brings his ”faust” to the met. New York Times,
November 2008.
[15] S. Wilkinson. Phantom of the brain opera. Electronic
Musician, January 1997.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
354