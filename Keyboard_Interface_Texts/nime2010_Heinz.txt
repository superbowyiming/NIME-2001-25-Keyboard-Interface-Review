Designing a shareable musical TUI
Sebastian Heinz
Sonic Arts Research Centre (SARC), Queen's
University Belfast
University Road
Belfast BT7 1NN
0044 (0) 2890 974641
sheinz01@qub.ac.uk
Sile O'Modhrain
Sonic Arts Research Centre (SARC), Queen's
University Belfast
University Road
Belfast BT7 1NN
0044 (0) 2890 974641
sile@qub.ac.uk
ABSTRACT
This paper proposes a design concept for a tangible interface for
collaborative performances that incorporates two social factors
present during performance, the individual creation and
adaptation of technology and the sharing of it within a
community. These factors are identified using the example of a
laptop ensemble and then applied to three existing collaborative
performance paradigms. Finally relevant technology, challenges
and the current state of our implementation are discussed.
Keywords
Tangible User Interfaces, collaborative performances, social
factors
1. INTRODUCTION
Collaboration in music creation does not necessarily only refer
to musicians playing together, it also includes their mutual
influence, the sharing of their ideas in various forms inspiring
them and causing a continuous progression in the development
of their art. The flexibility of electronic and digital technology
today not only shapes new formats to encode and distribute
these ideas, but it also allows for the reconfiguration and
customization of the instruments in ways that were not
previously possible. Computer musicians utilize this flexibility
to express their ideas in the creation and adaptation of their
music technology as well as through their actual musical
expression.
Programming environments such as MAX/MSP [3] and
SuperCollider [15] are good examples of systems that provide
this flexibility. They also simplify the distribution and sharing
of the artists' patches, so that the fruits of their creativity can be
found in forums, mailing lists and internet blogs. It is not just
highly customizable software that reflects and promotes this
thriving exchange of creativity. Even much less sophisticated
music software such as Propellerhead Reason [12] has this
practice integrated within its design. An individually created
rack setup of instruments and effect devices can be shared,
included in a tiny song file, ready for distribution and
inspiration within a web community. Hardware devices such as
synthesizers also allow for the creation or modification of
individual patches and presets. This creation, customizing,
sharing and reworking of musical technologies and material
appears to be a driving force in the development of electronic
music, as it can be found in the design of many modern music
systems. In addition to GUI software systems and 'knob &
fader' hardware devices the past decade has seen the
development of a new musical interaction paradigm namely the
Tangible User Interface (TUI). This paradigm promises many
interaction-related benefits, and has the potential to allow the
integration of creative customization, sharing and reworking of
musical material in an entirely new context. But this design
opportunity has yet not been fully explored or implemented by
musical TUI designers. Therefore, we began this exploration by
studying the practice of individual members of the BLISS
laptop ensemble in order to develop an understanding of how
these individual music systems are formed and how they could
be shared in a live performance context. The results of this
exploration were then applied to musical TUIs to identify the
requirements for a collaborative tangible system that
encompasses this creative practice.
2. BACKGROUND
The disembodied and indirect interaction with virtual
performance systems through business oriented user interfaces
like the mouse and the keyboard causes a disconnection
between the performer and the instrument as well as between
the performer and the audience [14, 1]. The physical nature of
tangible user interfaces (TUIs) appears to be a promising
solution to overcome these problems. Not only do these
interfaces provide a higher transparency to the audience, as the
musician is no longer hidden behind the glare of a laptop
screen, they also allow interfacing with data and logic
embodied in physical form. Furthermore, the hidden coupling
of virtual worlds through a network is not required to enable
collaboration on a tangible system; the physicality grants access
to everyone nearby. These could be the reasons why TUIs for
musical applications have become increasingly popular. This
trend started with projects such as Musicbottles [6] and
Audiopad [11] and evolved to include sophisticated products
like the Reactable [7] and AudioCubes [13] which are now
commercially available. Most of these projects are prototypes
aimed at a very specific application domain, yet some like the
Reactable show potential to compete with the versatility of the
laptop in a musical context. However, in order to fully address
this musical context the design should also be concerned with
social factors relevant to electronic music creation. This is why
we take the creative process of the community into account.
Inhis discussion of embodied interaction Dourish points to the
importance of social factors in designing interactive systems so
that the users way of working becomes an integral part of the
design [4]. According to Benson music develops in a
community where the way of working involves artists
borrowing ideas from other artists and bringing them into a new
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee.
NIME2010, 15-18th June 2010, Sydney, Australia
Copyright remains with the author(s).
Proceedings of the 2010 Conference on New Interfaces for Musical Expression (NIME 2010), Sydney, Australia
339
context [2]. DJ Spooky [5] describes this process more
specifically as follows:
"Electronic music is, in a way, the folk music of the 21st
century. Instead of, say, the '20s, where you had everyone who
knew a blues riff playing a guitar, you now have everyone who
knows certain beats and things like that putting them together
and then circulating them - this scene is about mixing and mix
tapes. Technology is making the creative process democratic."
As we will later discuss in more detail, the design and
implementation of a TUI that allows this sharing and mixing of
personal material presents several challenges. Personal TUI
elements have to be customizable yet compatible with each
other in order to allow mixing. Furthermore, they have to be
data containers, not just references, in order to promote sharing.
Therefore, we suggest the utilization of embedded computing
technology. Projects like AudioCubes, the Tangible Sequencer
[16], BlockJam [10] and the Siftables [8] are good examples of
TUIs based on integrated micro-controllers. However, we have
yet not seen an embedded computing TUI that strongly
emphasizes customization and sharing within a community.
We started this development by working with the BLISS laptop
ensemble to gain insight into such a community.
3. DEVELOPING THE CONCEPT
3.1 The BLISS Ensemble
BLISS stands for “Belfast Legion for Improvised Sights and
Sounds” and is a laptop ensemble at SARC. Its members use a
variety of software including MAX/MSP, SuperCollider and
Ableton Live. In addition to using different software, the way in
which members also approach their performances varies
greatly. Some start with a blank patch and improvise with what
is available on their hard-drive, others continuously develop and
improve the same performance system, while still others create
a specific setup prior to every performance. But BLISS is not a
strict laptop ensemble that only allows the use of the computer
as it is, the performers also use different hardware controllers of
their choice. This selection of hardware and software, as well as
their personal style in adapting and using it, gives both form
and expression to their ideas. When asked how they build their
patches and were they get their ideas from, they typically
pointed to a range of sources including a mailing list,
documentation files and patches of friends and colleagues. This
indicates that a lot of the ideas and technology implemented in
their systems is shared and developed within their community.
In short this community is not about mixing mix tapes, it is
about mixing technology.
Summarily as an outcome of discussions with the ensemble two
relevant social factors were observed on which we will base our
design:
• The individual artists have very different approaches to their
performances including the preparation, creation, selection
or adaptation of their own performance systems.
• Personalized technology, techniques and ideas are shared
and reworked within their community
3.2 Abstracting the differences
In order to create our concept of a TUI based collaborative
performance system we compare three different collaborative
performance paradigms, now including aspects of these social
factors in collaborative music making. We then introduce our
tangible ensemble concept. Figure 1 shows the relationship
between the different performers and their performance systems
as well as the relationships between the systems themselves.
These are canonical paradigms and actual systems may reflect
different or hybridized topologies.
3.2.1 Laptop ensemble
Every performer uses their own system, consisting of an
interface connected to the logic of their setup. The interface in
this case usually consists of a Laptop with a MIDI controller.
The logic is defined by the inner workings of the individual
performance system. The selection and adaptation of the
software, sound material and control devices embodies the
performers' ideas and personal sound. There is no interaction
between the individual systems during performance nor can the
performers access the interface of the other performers' systems.
This paradigm integrates the first social factor; the performers
can integrate their own personalized technology. However, the
second factor, the sharing and mixing of their technology, is not
present during the ensemble's performance.
3.2.2 Network performance
Network performance environments like netpd for PureData [9]
allow the performers to prepare, create and bring their own
performance elements, each having their own interface and
logic. The interface is not represented as one specific instance
(one laptop setup) and is therefore purely virtual. This grants all
performers access to it over a network, hence creations can be
accessed, modified and combined with other elements, by
everyone. This paradigm actually embeds both of the social
factors identified, the integration of personalized technology, as
well as the sharing and reworking of it. However, this freedom
comes at a cost. As the representation of their systems resides
completely in the virtual domain, problems like the indirect
interaction and lack of transparency for the audience arise.
Figure 1. The different performance paradigms
logic
interface
logic
interface
logic
interface
logic
interface
logic
interface
logic
interface
logic
interface
physical physical
physical physical
virtual
virtual
virtual virtual
Laptop ensemble
Musical TUI Tangible ensemble
Network performance
Proceedings of the 2010 Conference on New Interfaces for Musical Expression (NIME 2010), Sydney, Australia
340
3.2.3 Musical TUI
In the musical TUI paradigm all performers use the same
physical interface with the same logic. In the case of the
Reactable the interface consists of acrylic pucks which because
of their physical nature and confined space (the table) can be
accessed by every performer. This also increases the
transparency of the performance for the audience. However, the
customizability is limited and performers can not easily prepare
and integrate their own technology, such as their customized
patches. Therefore, ideas and techniques based on the systems
model might be shared and reworked on the table, but the
ability to provide and mix personalized technology is missing.
3.3 The tangible ensemble
Our design concept, the tangible ensemble, would allow the
performer to create and bring their own personal performance
elements as tangible pieces of a system. However, unlike the
laptop ensemble it enables them to access, share and mix all
their personal technology; and unlike a network performance
the sharing and mixing happens in the physical world. This
physicality and the embedding of individual technology into
their tangible representations provides many opportunities for
performers to exchange material before and during
performance. Problems such as multiple users clicking on the
same GUI widget [18] or the lack of performance transparency
can be reduced. Also, these tangible elements can become the
format for sharing and distribution of the performers ideas and
technology, even outside the performance context. No virtual
system is required to share a file because the 'file' exists in the
world that we all live in as it is embodied and embedded in the
tangible object itself. Moreover, if the physical objects contain
their functionality no additional system is required (except for
an amplifier and speakers). This is unlike the computer,
projection table and the camera setup of the Reactable and other
musical camera-based TUIs. The individual objects actually
form the performance system in the same way as the individual
performance setups of the BLISS members form their
ensemble. Furthermore, this performance system will constantly
change depending on who the performers are and what they
contribute.
4. CHALLENGES
In order to realize a system such as the tangible ensemble
several obstacles have to be overcome. Firstly, there is the
problem of data and logic containment. Most tangible systems
are based on physical objects that are referenced to data or parts
of the logic. The Reactable uses optical recognition of fiducial
markers while systems like Mediablocks [17] are based on ID
tags. These systems might be very effective interaction-wise but
the problems of their underlying technology become clear if
taken out of the pure performance context. Portability instantly
crystallizes as an issue. More precisely, a physical object that
has meaning in one instance of such a system has no meaning in
another one if the referenced data associated with the object
was not also transferred from one system to the other. A
performer attaching data to an object during preparation at
home will not necessarily have the data available at the
performance location even though they brought the object with
them. Solutions to this problem could be centralized data
storage on a web-server requiring an internet connection to
access the data of the system; accompanying data storage and
handling, for example on a USB stick; or storing the data
directly in the actual object. The last solution proposed,
containment, is the most preferable as it does not involve
unnecessary additional technology – the transfer format is the
actual object. But data containment alone does not already
allow a performance system to be formed by simply combining
independent modules, as the tangible ensemble suggests. The
objects have to be equipped with processing units in order to
also include the logic and provide digital functionality. This
suggests using embedded computing devices.
Secondly, there is the problem of standardization. All the
individual modules have to speak the same language in order to
allow the interconnection between their interfaces. Even though
expression of the performer's creativity in the module's content
is desired it has to be restricted in order to conform to a
standard communication and exchange protocol. As an initial
solution we propose the exchange of a variable signal level per
connection, much like traditional analogue synthesizer modules.
This level could for example be a slowly changing control
signal, or a very fast value change representing an audio signal.
A more sophisticated solution would be based on two different
signal types, the variable signal level and additionally a note
information protocol like MIDI. To distinguish between these
two the advantages of physical representation can be applied,
either by having different types of sockets and cables, or even
by having different types of modules with different input and
output socket configurations. However, the performers have to
communicate what their modules actually take, process, and
transmit. Nevertheless, eventual errors might lead to unexpected
and possibly inspiring results. This issue will be studied as soon
as our first prototype is ready to be used in a performance.
Thirdly, the performers have to be equipped with a tool to
express and embed their ideas into the objects, most likely a
patching editor or programming language that allows them to
program their content.
5. IMPLEMENTATION
We are currently developing an initial design prototype based
on an ARM based micro-controller. One of the key design
criteria was to keep the cost per token-module as low as
possible. This would allow us to produce a large number of
modules and might also further promote sharing, as the tokens
themselves are less valuable. We have chosen the LPC1343
from NXP for several reasons:
• It is very low-cost.
• It provides an on-chip USB Mass Storage Device driver to
update the user-customized logic via USB.
• A clock frequency up to 72MHz ensures enough cycles for
DSP.
• Low-cost development with the LPCXpresso board
The PWM outputs can be used to encode and send a variable
signal level between the modules (as the pulse width).
Furthermore, when the PWM cycle is oversampling the digital
audio signal and routed through a low-pass RC filter within the
module it even produces an analog audio signal of, for our
purposes, acceptable quality. This technique allows us to further
reduce the cost per module as no additional DAC chip is
required, while still providing the option of analog audio output
per module. In a network of these it is a requirement that at
least one module can send an audio signal to an amplifier. As
interface cables between the modules we have chosen ordinary
3.5mm TRS cables. Currently we use a sampling rate of 25KHz
and 4 times PWM oversampling. 
A visual programming editor to customize the logic inside these
mini sound-modules is also under development. We believe that
visually connecting DSP blocks can be easier to understand for
Proceedings of the 2010 Conference on New Interfaces for Musical Expression (NIME 2010), Sydney, Australia
341
beginners because of its less abstract presentation compared to
textual programing. The editor also allows performers to map
the limited number of knobs and buttons on the module to
elements of the DSP logic. Currently the prototype supports
only customization of the module's internal logic, but because
this information is flashed as firmware, the module can not be
used to transfer the open patch-file. In order to fully integrate
our tangible ensemble concept this has to be altered because the
modules should also function as shareable information
containers. We need to investigate further to discover how this
can be achieved without increasing production costs
significantly.
Figure 2 demonstrates a simple workflow scenario with only
two modules and performers.
6. CONCLUSION
In this paper we have shown how social factors in collaborative
music performance, such as the creation and adaptation of
personal performance setups, the sharing of the involved
technology and ideas within a community, are relevant for
laptop artists. Therefore, we compared existing performance
paradigms and proposed a new concept of musical TUIs, the
tangible ensemble, which would support both the integration of
individual artistry as well as the sharing of ideas within a
collaborative music performance. We suggested and discussed
that this could be achieved by creating embedded computing
based objects that can be interconnected and programmed by
the performers. Even though the implementation of this concept
presents a number of technical challenges, as our work
progresses we might soon be able to explore a new generation
of shareable musical TUIs.
7. REFERENCES
[1] Armstrong, N. An Enactive Approach to Digital Musical
Instrument Design. Ph.D. Thesis, Princeton University,
Princeton, NJ, 2006.
[2] Benson, B. The improvisation of musical dialogue: a
phenomenology of music. Cambridge University Press,
Cambridge, UK, 2003.
[3] Cycling74 [Online] http://cycling74.com
[4] Dourish, P. Where the Action Is. The Foundations of
Embodied Interaction. MIT Press, Cambridge, MA, USA,
2001.
[5] Holmes, T. Electronic and experimental music: pioneers in
technology and composition. Routledge, London, UK,
2002.
[6] Ishii, H., Mazalek, A., and Lee, J. 2001. Bottles as a
minimal interface to access digital information. In CHI '01
Extended Abstracts on Human Factors in Computing
Systems (Seattle, Washington, March 31 - April 05, 2001).
CHI '01. ACM, New York, NY , 187-188.
[7] Jordà, S., Geiger, G., Alonso, M., and Kaltenbrunner, M.
2007. The reacTable: exploring the synergy between live
music performance and tabletop tangible interfaces. In
Proceedings of the 1st international Conference on
Tangible and Embedded interaction (Baton Rouge,
Louisiana, February 15 - 17, 2007). TEI '07. ACM, New
York, NY , 139-146.
[8] Merrill, D., Kalanithi, J., and Maes, P. 2007. Siftables:
towards sensor network user interfaces. In Proceedings of
the 1st international Conference on Tangible and
Embedded interaction (Baton Rouge, Louisiana, February
15 - 17, 2007). TEI '07. ACM, New York, NY , 75-78.
[9] Netpd [Online] http://www.netpd.org
[10] Newton-Dunn, H., Nakano, H., and Gibson, J. 2002. Block
jam. In ACM SIGGRAPH 2002 Conference Abstracts and
Applications (San Antonio, Texas, July 21 - 26, 2002).
SIGGRAPH '02. ACM, New York, NY , 67-67.
[11] Patten, J., Recht, B., and Ishii, H. 2002. Audiopad: a tag-
based interface for musical performance. In Proceedings
of the 2002 Conference on New interfaces For Musical
Expression (Dublin, Ireland, May 24 - 26, 2002). E. Brazil,
Ed. New Interfaces For Musical Expression. National
University of Singapore, Singapore, 1-6.
[12] Propellerhead [Online] http://www.propellerheads.se
[13] Schiettecatte, B. and Vanderdonckt, J. 2008. AudioCubes:
a distributed cube tangible interface based on interaction
range for sound design. In Proceedings of the 2nd
international Conference on Tangible and Embedded
interaction (Bonn, Germany, February 18 - 20, 2008). TEI
'08. ACM, New York, NY , 3-10.
[14] Schloss, W. A. Using Contemporary Technology in Live
Performance: The Dilemma of the Performer. In Journal
of New Music Research (Routledge: London, V olume 32.3,
September 2003), 239-242.
[15] SuperCollider [Online] http://supercollider.sourceforge.net
[16] Tangible Sequencer [Online]
http://www.tangiblesequencer.com
[17] Ullmer, B., Ishii, H., and Glas, D. 1998. mediaBlocks:
physical containers, transports, and controls for online
media. In Proceedings of the 25th Annual Conference on
Computer Graphics and interactive Techniques
SIGGRAPH '98. ACM, New York, NY , 379-386
[18] Zmölnig, J., Patching music together - collaborative Live
Coding in Pd. In Proceedings of the PureData Convention
(PDCON'07). Montreal, Canada. 2007.
Figure 2. A workflow example
Performer 1
Performance set-up
Performer 2
creates 
synthesizer 
logic
uploads via 
USB
creates eﬀect
logic
uploads via 
USB
synthesizer eﬀ ect sound system
Proceedings of the 2010 Conference on New Interfaces for Musical Expression (NIME 2010), Sydney, Australia
342