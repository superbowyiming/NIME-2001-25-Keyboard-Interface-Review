Homo Restis - Constructive Control Through Modular
String Topologies
Jens Vetter
MA Interface Culture
Kunstuniversität Linz
Ederstr. 5, 4020 Linz, Austria
jensvetter@ymail.com
Sarah Leimcke
Hochschule für Bildende Künste Dresden
Robert-Matzke-Str. 56
01197 Dresden, Germany
sarahleimcke@web.de
ABSTRACT
In this paper we discuss a modular instrument system for
musical expression consisting of multiple devices using string
detection, sound synthesis and wireless communication. The
design of the system allows for diﬀerent physical arrange-
ments, which we deﬁne as topologies.
In particular we will explain our concept and require-
ments, the system architecture including custom magnetic
string sensors and our network communication and discuss
its use in the performance HOMO RESTIS.
Author Keywords
NIME, performance, composition, generated audio, wireless
instruments, strings, latency
ACM Classiﬁcation
C.0 [General] Hardware/software interface, C.2.1 [Network
Architecture and Design] Wireless communication C.3 [ARTS
AND HUMANITIES] Performing arts (e.g., dance, music)
C.5.3 [Microcomputers] Portable devices, H.5.2 [User In-
terfaces] Input devices and strategies, H.5.5 [Information
Interfaces and Presentation] Sound and Music Computing.
1. INTRODUCTION
The attempt to push boundaries of traditional models of
interfacing with instruments and the extensive interest in
new topologies for sound creation not only applies to inter-
active, modular or digital instruments in general, but also
to body-related instruments in particular. Requirements li-
ke mobility, real-time interaction, tactile qualities or stable
network synchronization still demonstrates the need for ex-
perimentation and research.
In order to create custom modular and wireless instru-
ments for our performance project HOMO RESTISwe star-
ted to explore new possibilities for mobile sound-generation,
mobile multichannel audio and stable network communica-
tion.
2. RELATED DESIGN ASPECTS
In the past decade new body-related instruments evolved as
a form of sound and data interaction interfaces, were made
possible through aﬀordable electronics, programming and
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’17,May 15-19, 2017, Aalborg University Copenhagen, Denmark.
often also wireless communication. Known projects in this
ﬁeld amongst others are The Gloves Project [5], BioMuse
by Atau Tanaka or upcoming projects like e.g. Glissando
by Ulla Rauter1. Some of them are working with mechani-
cal or bioelectrical input, others are working with physical
conditions like gravitation, speed, humidity, etc.
The above examples have encouraged us to develop our
own tools, based on our requirements.
2.1 General Interface Design
Accompanying new forms of interactive instruments one has
to take particular needs into consideration in order to embed
the instruments into live performances or concerts. They
could be summarized as followed:
(1) Precision. Instruments should be as precise as pos-
sible to stimulate virtuosity in musical performances.
(2) Understandability. As sometimes Developer and
Performer are not the same persons and the Performer does
not necessarily know all functions or issues of the new in-
strument, those instruments need to be intuitive in functio-
nality and handling.
(3) Robustness. Performances and concerts are often
fast and impulsive. The instrument needs to be robust and
stage-proof, despite the fact of using micro-computer and
fragile sensors.
Figure 1: Homo Restis Costumes
2.2 Strings as Instruments
In our development process, we ﬁrst began to test weight
sensors and mechanical springs until, for practical reasons,
we encountered the possibility of using ropes or strings.
There are examples of the use of strings as musical inter-
faces, such as the group JUNG IN JUNGwith their piece
1see http://ullarauter.com/content_Glissando.html
83
Thermospheric Station[1]. They used the Gametrak 2, a 3-
dimensional game control system based on position tracking.
The Gametrak is an example for decoupling strings from
their traditional acoustic use (e.g. in instruments like Harp,
Piano, etc.) in order to allow more interaction models than
just plucking or brushing.
But unlike Gametrak, we needed stronger and, above all,
longer strings for our intention to use the interfaces in the
public space.
2.3 Modular Topologies
While classical instruments mostly are prefabricated, new
instruments can be developed according to the needs of the
performer or artists. Today the creation of the instruments
is connected to performance aspects, musical improvisati-
on is embedded in the physical or functional form of the
instrument. A new ﬂexible modularity is entering the pro-
cess of sound creation and performance [2], especially by
combining the use of electronic devices and digital proces-
sing. While traditional instruments had ﬁxed architectures
(e.g. parallel strings in Pianos), new modular interfaces can
augment them [4] or even build up diﬀerent topologies (e.g.
mesh, star). Combining those new topologies with real-time
interaction, the performer can enhance his musical impro-
visation by ﬂexible routing and modular reconﬁguration of
the instrument.
Figure 2: Homo Restis at Kunstzug
3. HOMO RESTIS
HOMO RESTIS(see Figure 1 and 2 ) is our recent perfor-
mance project and includes handcrafted costumes designed
by Sarah Leimcke and the mobile modular instrument sys-
tem developed for the use in public spaces by Jens Vetter.
Sound devices and costumes were developed side by side,
as we had to embed all technical requirements inside the
costumes and vice versa.
2see http://en.wikipedia.org/wiki/Gametrak
3.1 Concept and Vision
The starting point of our performance was the idea of Ma-
rionettes, that we understand as a metaphor for human-
beings trapped in the complexity and opacity of modern
live and society. We wanted to create a public representati-
on through the aesthetic and sonic presence of the HOMO
RESTIS (lat. ”Men on Strings”).
While our ﬁrst concept was a body-bondage arrangement,
that would seek to constrain body movement with rubber
strings attached (similiar e.g. ”Muscular Interactions” by
Marco Donnarumma [3]), in the end the weight of the costu-
mes made our decisions. We changed the concept from at-
taching strings only between our bodies to attaching strings
from our bodies to the environment.
Our main requirements were (1)mobility - being inde-
pendent from power supplies, but also from technical sup-
port such as PA Systems, Surround Sound Systems etc.
(2)loudness - mobile devices at minimal weight should pro-
duce enough loudness to ﬁll public spaces,(3)modularity -
multiple devices in order to arrange performance-situations
in a ﬂexible and modular manner and to achieve multichan-
nel audio across bigger spaces, (4)long strings- enlarging
the radius of our performance in order to ﬁll larger envi-
ronments, especially public spaces like squares, streets or
tunnels.
a b
c d
Figure 3: Devices - a) Soundmodule interior - b) So-
undmodules - c) Subwoofer - d) Costume Controller
Our goal was to enter public places in our costumes, to
then place the soundmodules performatively in favorable
places in the environment and to attach our bodies with
long strings to them. Through gesture and movement we
would produce and control sounds. With the help of the
remotes in our costumes, we could change sound presets or
84
mute the sound.
Some particular needs became clear immediately: we nee-
ded battery-powered devices and lightweight constructions
for mobility. Regarding loudness we needed a subwoofer to
generate low-end frequencies that would increase the level
of loudness. We needed wireless communication between all
devices to achieve modularity and ﬂexibility and to be able
to control and modulate the sound-generation process re-
motely.
3.2 System Architecture
The development of the entire system resulted in several
dedicated devices and a complex programming for the use
as wireless sound system. We embedded string-controller,
sound synthesis for generative audio, diﬀerent Output-Modules
including a subwoofer, audio and network protocols for real-
time sound-creation and enabled parallel communication
between groups of devices.
Regarding audio synthesis we embedded diﬀerent sound
presets, that we could access remotely during the perfor-
mance, as well as general volume dimming.
During the development process we had to accomplish
extensive research on how to create robust string sensors,
how to organize battery-driven electronics including speaker
and ampliﬁer in single lightweight devices and how to embed
all the wireless functionality without data-losses.
Figure 4: Soundmodule parts
3.2.1 Devices
The system consists of 10 independent battery-driven so-
undmodules, that provide each a string of 8 meter, a spea-
ker plus ampliﬁer, a Teensy 3 Board3 as micro-controller for
sound creation and a wireless access-point using XBee4. Ad-
ditionally we build a mobile subwoofer-box, including a 400
Watt speaker and ampliﬁer and a wireless access-point with
10 complementary micro-controllers for sound generation of
the low-end frequencies.
Finally we built two controller modules, sewn into the
costumes, that would allow us to access the system in terms
3see http://www.pjrc.com.
4see https://www.digi.com/lp/xbee
of choosing sound presets, dimming the overall volume or
manipulating active sounds (see Figure 3 and Figure 4).
3.2.2 Electronics and Magnetic String Encoder
A challenging task was the development of an appropriate
string sensor. While in the beginning we experimented with
conductive rubber tube sensors 5 we experienced, that none
of the simple stretch sensors would achieve our desired re-
sults. After equally unsatisfying mechanical approaches (e.g.
transmitting the movement of strings onto potentiometers)
we started to focus on magnetic encoder mechanisms, which
was the key to create robust string sensors.
Our custom magnetic string encoder is based on Hall Ef-
fect Sensors6 and a tension roller. Magnets are attached to
the tension roller and as the roller spins, magnetic sensors
on the outside of the tension roller detect changes in the ma-
gnetic ﬁeld. With a minimum of two magnetic sensors per
tension roller we were able to calculate und use 1) speed
and 2) direction of the spinning. In order to guarantee
stable circuits we chose to produce custom circuits using
Fritzing7.
Figure 5: Screenshot SuperCollider
3.2.3 Wireless Network and Sound
The programming and networking in all devices is realized
using Teensy Boards and XBee modules. They communicate
over their serial connection. In order to create a modular
system of sound devices that would permit both ﬂexibility
during performance and loudness, we decided to connect a
subwoofer wirelessly to the single sound devices. This allows
distribution of sound output across multiple devices, which
means that we are able to keep the single sound devices at
small sizes, whereas the subwoofer is the only really big and
heavy device.
Our way to realize this sound architecture was to em-
bed a dedicated arrangement of separate micro-controllers
inside a separate subwoofer-module next to the subwoofer.
The subwoofer-module mirrors processes of each single so-
undmodule, so that whenever a soundmodule is played, all
calculations are wirelessly triggered both in the single de-
vice and in the subwoofer-modules complementary micro-
controller.
5http://www.adafruit.com/product/519
6http://en.wikipedia.org/wiki/Hall_effect_sensor
7http://fritzing.org/
85
In order to embed the network communication with as
little latency as possible we reduced the bandwidth to 8
bits or 256 patterns that we used to encode activity.
Incoming string-sensor-messages generated following re-
duced output-informations: a message for (1) string moved
one step forwards, (2) string moved one step backwards, (3)
choose 1 from 3 sound presets, (4) dim the volume, (5) reset
internal calculations.
According to our observation, limiting wireless interacti-
on to 256 pattern produced higher reliability during trans-
mission. The reliability of the connection, however, depends
on the XBee modules used - stronger models bridge longer
distances.
A big beneﬁt was the possibility to access all devices di-
rectly from the computer and to remotely control them.
Also the development of other aspects of the programming
could now be done very comfortable without having to phy-
sically move the strings and modules 8. A custom software
written in SuperCollider helped to access, monitor and con-
trol all devices remotely (see Figure 5).
3.2.4 Generated Sound
All sounds are created using the MOZZI sound synthesis
library for Arduino9 and the Teensy’s Analog Output. Using
MOZZI allowed to generate synthesized sounds, to use pre-
recorded samples and to embed interactivity (e.g. remotely
changing presets etc.). The Teensy’s 72 MHz Cortex-M4
processor is a limiting factor.
3.3 Instrument Design
The cases for the soundmodules are made of waterproof
plywood. All parts were manufactured by CNC. This was
necessary to achieve precisely the same dimensions for every
box, as there is not much space to mount all electronic parts
inside the case (Figure 6). The subwoofer case serves as a
transport space for the individual modules.
Figure 6: Soundmodules
3.4 Performance and Experiences
After completing the development process we attended se-
veral festivals in 2016 10, so that now we can conﬁrm by
overall performance experience, that the entire system is
8A great help in programming multiple Teensy’s was TyQt.
https://github.com/Koromix/teensytools
9see http://sensorium.github.io/Mozzi/
10e.g. Ars Electronica, Spekulum Artium, Kunstzug, Sonic
Lab of Anton Bruckner University
suﬃciently stable and reliable. As previously mentioned in
section 2.1 our instruments are close to self-explanatory and
robust and also precise in analyzing and transmitting sensor
data coming from the strings. The sounds were loud enough
to compete with street sounds or other noisy situations. In-
teracting with the strings was also stable and satisfying.
We were apprehensive, that the battery power would be
a limitation, but that didn’t happen.
To summarize we were able to perform, move and also
maintain the soundmodules in the desired way and as they
are a very fundamental part of our performance HOMO
RESTIS they really completed our appearance and perfor-
mance in the best possible way.
4. FUTURE DEVELOPMENTS
The production of this modular interactive instrument sys-
tem as well as the application in a performance context has
brought us many insights. The next step inHOMO RESTIS
will be the improvement of the dramatic embedding of the
interaction with the strings and programming new sounds
based on the MOZZI library.
Furthermore it is also conceivable to use this system as the
basis for interactive exhibitions, in which the active strings
may be connected to passive strings or objects.
It could also be interesting to use it as a group interface
with dancers, musicians or the public on stage or in public
places.
5. ACKNOWLEDGMENTS
We would like to thank the University of Arts and Industrial
Design Linz for technical support and facilities, in particular
Prof. Laurent Mignonneau, Fabricio Lamoncha and Prof.
Martin Kaltenbrunner.
Also we want to thank all those, who share knowledge
and contribute in all those forums in the net - without all of
you it would have been signiﬁcantly harder to develop our
project!
6. REFERENCES
[1] Jung in jung, thermospheric station dance 2014.
http://www.junginjung.com/thermospheric-station-
dance-2014. accessed:
2017-01-23.
[2] D. W. C. Chafe, S. Wilson. Physical model synthesis
with application to internet acoustics. Orlando, 2002.
ICASSP.
[3] M. Donnarumma, B. Caramiaux, and A. Tanaka.
Muscular interactions. combining EMG and mmg
sensing for musical practice. In Proceedings of the
International Conference on New Interfaces for
Musical Expression, pages 128–131, Daejeon, Republic
of Korea, May 2013. Graduate School of Culture
Technology, KAIST.
[4] A. Hinrichsen, S.-I. Hardjowirogo, D. H. M. Lopes, and
T. Bovermann. Pushpull: Reﬂections on building a
musical instrument prototype. pages 196–207. ICLI
2014, November 2014.
[5] S. Seraﬁn, S. Trento, F. Grani, H. Perner-Wilson,
S. Madgwick, and T. Mitchell. Controlling physically
based virtual musical instruments using the gloves. In
Proceedings of the International Conference on New
Interfaces for Musical Expression, pages 521–524,
London, United Kingdom, June 2014. Goldsmiths,
University of London.
86