Non-Rigid Musical Interfaces:
Exploring Practices, T akes, and Future Perspective
Alberto Boem*, Giovanni Maria T roiano† ,
Giacomo Lepri‡ , Victor Zappi†
Northeastern University† |
(g.troiano,v .zappi)@northeastern.edu
Queen Mary University of London‡ |
g.lepri@qmul.ac.uk
Independent Researcher* | boem.alberto@gmail.com
ABSTRACT
Non-rigid interfacesallow for exploring new interactive paradigms
that rely on deformable input and shape change, and whose possi-
ble applications span several branches of human-computer interac-
tion (HCI). While extensively explored as deformable game con-
trollers, bendable smartphones, and shape-changing displays, non-
rigid interfaces are rarely framed in a musical context, and their
use for composition and performance is rather sparse and unsys-
tematic. With this work, we start a systematic exploration of this
relatively uncharted research area, by means of (1) brieﬂy review-
ing existing musical interfaces that capitalize on deformable input,
and (2) surveying 11 among experts and pioneers in the ﬁeld about
their experience with and vision on non-rigid musical interfaces.
Based on experts’ input, we suggest possible next steps of musical
appropriation with deformable and shape-changing technologies.
W e conclude by discussing how cross-overs between NIME and
HCI research will beneﬁt non-rigid interfaces.
Author Keywords
Non-rigid interfaces; musical interfaces, expert study
CCS Concepts
•Human-centered computing → Sound-based input / output;
• Applied computing → Sound and music computing;
1. INTRODUCTION
Research in human-computer interaction (HCI) is engaging with
non-rigidmaterials and interfaces [34], to explore new interactive
paradigms [3] and control possibilities [40]. In that respect, previ-
ous work has investigated non-rigid musical interfaces [38, 26, 6,
23, 24, 18, 17, 12, 45], showing how they allow for new ways of
performing music [40, 29, 2, 42]. However, whilenon-rigid inter-
faces are now a research area in HCI [3, 1], their research within
NIME is sparse and we lack both (1) systematic overviews of exist-
ing work and (2) clear guidelines for future research. For instance,
while HCI has discussed the role of shape, material, sensing, and
mapping in supporting user interaction with non-rigid interfaces
[3], also within music [40], such discussion has yet to be formal-
ized at NIME. W e address the above shortcomings with a twofold
contribution. First, we overview existing non-rigid musical inter-
faces and deﬁne them as a research area of NIME. Second, we
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’20, July 21-25, 2020, Royal Birmingham Conservatoire,
Birmingham City University , Birmingham, United Kingdom.
survey 11 among experts and pioneers on the past, present, and fu-
ture of non-rigid musical interfaces, to help form a research agenda
and inspire future design and research efforts at NIME.
2. BACKGROUND
In HCI, non-rigid interfaces are generally described as“interfaces
that use dynamic changes in a device’s physical shape for input
and output”[1]. Depending on the research angle, previous HCI
work emphasized either (1) the output characteristics of non-rigid
interfaces, such as self-actuation [34], or (2) the input [3], for in-
stance where deformable materials allow for novel interactions that
are impossible with rigid materials, and/or disentangled from ear-
lier HCI paradigms (e.g., shape-displays that can be “sculpted” for
input [32]). As such, Boem and Troiano [3] distinguished between
deformableand shape-changing interfaces, where the former are
passive and can only shape change by means of user input (e.g.,
[38]), while the latter can autonomously shape change by means
of self-actuation [34]; both interfaces fall under the umbrella term
non-rigid interfaces[3]. Following [3], we deﬁne non-rigid mu-
sical interfaces in music as “musical interfaces that can be physi-
cally deformed [3] to generate and/or manipulate sounds, and that
use shape change [34] to physically represent sounds (e.g., [16])
or dynamically respond to musicians performance”.
While non-rigid interfaces are consolidating as a research area
in HCI [1, 3], in the NIME ﬁelds they remain occasional, and with
no comprehensive overview of existing examples. A comprehen-
sive overview of non-rigid musical interfaces is needed to advance
research in this area and unify the efforts of researchers and mu-
sicians that pioneered their exploration. As said earlier, previous
HCI work [3, 34] has systematically reviewed non-rigid interfaces
to help deﬁne the research area and identify grand challenges [1].
Following the same rationale, we summarize existing examples of
non-rigid musical interfaces, to provide the reader with both (1)
a structured overview of how NIME has appropriated non-rigid
interfaces in previous work and (2) the necessary information to
contextualize the survey presented in Section 3.
Before discussing previous NIME work with non-rigid inter-
faces, it is notable that no examples exist of non-rigid musical in-
terfaces that use shape change for output. As such, self-actuation
as investigated in HCI is foreign to NIME, and actuated shape-
change has yet to be experimented with in musical interactions.
2.1 Non-Rigid Musical Interfaces
Non-rigid musical interfaces are made of malleable and de-
formable materials (e.g., rubber, fabric [3]), which musicians can
squeeze [43, 4, 37, 41, 30], stretch [6, 45, 29], bend [23], and twist
[13, 47], to control sounds and generate music performances. Pre-
vious work used only one type of non-rigid input to manipulate
sounds, for instance like theSonicBanana [38], where a plastic
tube loaded with ﬂex sensors could be twisted to generate music, or
combined different types of non-rigid inputs (e.g., twist + squeeze
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
17
+ bend, [2, 18]) for achieving multidimensional input [3].
Existing non-rigid musical interfaces display a variety of shapes,
including traditional keyboard-like shapes [20, 45], as well as
squeezable spheres likeThe Music Ball [17], squeezable cubes
[19], and malleable tetrahedrons like Sculpton [2], which is
made of springs covered in latex, and embedded with both light-
reﬂective sensors and light-emitting diodes for deformation sens-
ing. TheBallagumi [21] instead, is a musical pillow that displays
a less “conventional” shape, which Boem and Troiano [3] deﬁne
asxenomorphic. SillyT one [26] is shaped like a “rabbit” and its
ears can be squeezed to generate sounds. Clay T one [42] and
DIRTI [36] are non-rigid musical interfaces through which mu-
sicians can directly model sounds by “sculpting” the surface of the
interface; similarly ,MARSUI [46] and Soundﬂex [39] allow musi-
cians to sculpt sounds, but use silicone with metal wire embedded,
instead of clay or sand, for creating shape-retaining musical inter-
faces. Other non-rigid musical interfaces used elastic fabric tensed
on a rectangular [6, 45] or circular hard frame [29], to create ﬂat
surfaces that act like stretchable musical interfaces.
Besides experimenting with materials and shapes, previous
work employed various approaches for sensing deformable inputs
with non-rigid musical interfaces, which approaches Boem and
Troiano [3] categorized as (1)embedded and (2) external sens-
ing. Embedded sensing is most common. The Sponge [23, 24],
for instance, is equipped with accelerometers and force sensing re-
sistors, and deformable input is sensed directly on the surface via
the embedded sensors.F abricKeyboard [45] is a ﬂat MIDI key-
board made with embroidered conductive thread, which allows to
control sounds with both touch and stretch input. Others, used
a combination of inertial measurement units [13] or ﬂex sensors
[38] embedded in their non-rigid musical interfaces to sense twist,
bend, squeeze, and stretch. External sensing is less common, as
it uses more expensive sensors and may present portability issues
(i.e., an entire camera and lighting setup). A common approach to
external sensing is the use of image sensors, like charge-coupled
devices (CCDs) or Kinect® cameras. For instance, Silent Drum
[29] and DIRTI [36] use CCD sensors and computer vision to ana-
lyze the global deformation of their surface and monitor changes to
model the user input.ClayT one [42] uses a CCD sensor to extract
visual information (e.g., color, geometry) of clay being deformed
by musicians, and processes that information in C++ to inform the
mapping of input and output (I/O).
Regarding I/O mapping, Boem and Troiano [3] identiﬁed two
main mappings strategies with non-rigid interfaces (see [3], p.
892), namelyexplicit mapping, where input and output are phys-
ically consistent with each other (i.e., deforming a cube interface
to deform a virtual cube [28]), andimplicit mapping, where cross-
modal correspondences between input and output are mostly estab-
lished through metaphors; since non-rigid musical interfaces allow
to manipulate sounds, which may not always be physically consis-
tent with input, implicit mapping is popular among these non-rigid
interfaces. For instance, Troiano et al. [40] found that musicians
implicitly associate the action of squeezing with increasing loud-
ness, or stretching for controlling the dry/wet signal of reverb and
delay effects. However, no systematic investigation has been done
to advance the understanding of cross-modal correspondences with
non-rigid musical interfaces.
The majority of the non-rigid musical interfaces reviewed above
were used in the context of live music performances (e.g., [24,
13, 43, 2, 38], but previous work showed also promise for their
use in the context of music therapy [7, 12], as well as medical
applications [21]. However, identifying ﬁtting application areas
for non-rigid musical interfaces remains an open challenge. For
instance, the idea of “sculpting” sounds directly through a non-
rigid interface that allows for multidimensional input may beneﬁt
sound design tasks (e.g., modeling the timbre of a sound); yet, to
the extent of our knowledge, no previous work has attempted to
use such interfaces for sound design and discuss the outcome. W e
T able 1: The survey participants and their interfaces
Participant Interface Reference
P1 I1 The Spine [13]
P2 I2 PushPull [14]
P3 I3 IllumiW ear [8]
P4 I4 Marsui[46]
P5 I5 SoundFlex [39]
P6 I6 Sonic Banana [38]
P7 I7 GGT [15] Ballagumi [21]
P8 I8a EchoFoam [18]
I8b NoiseBear [12]
P9 I9 Silly T one Squish Factory [26]
P10 I10 Music Ball Project [17]
P11 I11 Squeezy [41]
attempt to answer the above and other emerging research questions
by consulting experts and pioneers of non-rigid musical interfaces
in a survey study , which we present next.
3. EXPERT SURVEY
Inspired by earlier NIME work [25], we surveyed experts who
previously researched about and designed non-rigid musical inter-
faces, and asked them about the past, present, and future of such
interfaces. W e contacted at least one author/designer for each in-
terface reviewed in Section 2.1, and shared with them an online
questionnaire using a protected Qualtrics1 account. The question-
naire consisted of nine open-ended questions. Five questions asked
the respondents to share details about the experience linked to the
design and use of their non-rigid musical interfaces. These in-
cluded design motivations and intended use, technical insight on
materials and mapping, and the impact that the interfaces had on
research and artistic expression. The initial ﬁve questions were
intended as an opportunity for the respondents to share informa-
tion about their work with non-rigid musical interfaces that may
not be included in their scientiﬁc publications, for instance like
technical issues/patches, anecdotes, and retrospects. Then, two
questions asked the respondents to extend their insights on non-
rigid musical interfaces beyond their own experience, and reﬂect
more broadly on the impact of such emergent interfaces on NIME
and its research. Then, other two questions invited respondents to
share their insights on future research perspective and design of
non-rigid musical interface. As said earlier, we found no existing
examples of non-rigid musical interfaces using shape change for
output. Hence, the last question inquired the respondents about
the use of shape change within non-rigid musical interface design.
W e collected answers from 11 participants (tagged as P1-11).
Their average age was 38.5 ( SD = 7.8). All respondents had an in-
terdisciplinary background in music, engineering, digital art, and
physics. Most respondents (i.e., 8) are musically trained and reg-
ularly perform live on instruments such as cello, piano, drums,
saxophone, or on custom interfaces that they design. Except for
P6, all respondents are conducting research on musical instruments
and are active members of NIME community . T able 1 shows the
list of non-rigid musical interfaces designed by the respondents.
W e reference their work as I1-11 and match the interface tag with
the respondent tag (i.e., I1 was designed by P1, I2 by P2, and so
forth). Athttps://deformableui.com/nime2020/, the reader
can ﬁnd a brief technical description and a picture of each interface
listed in the table. Next, we present the results of our survey .
3.1 Results
All survey responses can be accessed atdeformableui.com/
nime2020/. Upon survey completion, we performed thematic
analysis on the responses based on grounded theory [11]. Af-
1 https://www.qualtrics.com/
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
18
ter two rounds of analysis we reached consensus on the emergent
themes that best summarize experiences and visions discussed by
the participants. W e organized the emergent themes in six cate-
gories that generalize the survey results beyond speciﬁc cases and
provide structure to our discussion in Section 4.
3.1.1 Motivations
At the beginning of the survey we asked the participants to explain
their motivations for designing and using non-rigid interfaces for
music. Six participants (P1, P2, P4, P5, P8, P11) explained that
their desire toexperiment new forms of control in music was their
main drive to design and build non-rigid musical interfaces. They
explained that gestures like twist, stretch, bend, or squeeze could
not be enabled by rigid materials, and hence started experimenting
with non-rigid materials and different sensors’ arrangements that
would allow to identify such gestures. More speciﬁcally , P1 and P8
expressed their wish toexplore continuous and multidimensional
input (see [3], p. 887) in music through non-rigid materials - these
have shown to be favorable for designing and implementing those
types of input [40]. Differently P4 and P5 explained that their goal
when building I4 and I5 was“to study how sound cues (including
musical cues such as harmonics dissonance) can be used to guide
the user to forming certain shape”(P5).
Six participants were motivated by their interest in exploring
new design solutions that challenge the aesthetics of existing con-
trollers (e.g., touch-screens, force-feedback devices), by augment-
ing every-day objects like plastic tubes (I6), toys (I9), or by ex-
perimenting with “unusual” shapes (I7), which Boem and Troiano
describe asorganic ([3], p. 888). P9 and P10, instead, said their
motivation to design non-rigid musical interfaces was mainly to
leverage the intuitiveness of interacting with non-rigid materials to
create“enjoyable and easy to use” musical interfaces. Others (P4,
P3, P1) were interested in designing musical instruments that can
adapt to the shape of the human body and augment its movements
by means of soniﬁcation (I1); for P1, the idea of using non-rigid
materials emerged from the desire of turning a rigid interface (i.e.,
[22]) into a wearable interface for dancers and performers.
3.1.2 Applications
Most participants built non-rigid musical interfaces for application
inexpressive and performative music activities . Particularly , they
were interested in creating control experiences that allow for new
and intuitive ways of performing live music (P1, P2, P5, P10). In
most cases, the designers of non-rigid musical interfaces were also
the only users, except for P1, who built I1 and had dancers and
performers use it in live performances. Others (P4, P5) used non-
rigid musical interfaces applications in areas other than live music
performances. For instance, I4 and I5 were designed for explor-
ing how the soniﬁcation of physical objects that deform can be
used as a cue to help users navigate through different functionali-
ties in ﬂexible smartphones (i.e., folding a smartphone engages the
“smartwatch” mode). P7 mentioned that I7 was designed as a con-
troller that can be used as a “musical pillow”, which can also be
interfaced with medical equipment (e.g., used from within func-
tional magnetic resonance imaging machines), while P8 wanted
to create interfaces that can be used by people with physical and
cognitive disabilities in music therapy (I8b).
Besides their own work, we asked our participants to reﬂect on
which musical applications may beneﬁt from non-rigid interfaces
in the broader context of NIME. Our participants highlighted that
non-rigid materials can be leveraged to create deformable music
controllers and instruments that increase musicians“physical en-
gagement” through full-body input (I1, I3), and serendipitous dis-
coveries (I8a). Our participants also mentioned applications for
playful, visceral, and exploratory music experiences. According
to participants P5, P9, and P10, non-rigid materials are poten-
tially useful for creating interactive installations that appeal large
audiences, and not only musicians, since non-rigid interfaces can
“excel to be manipulated with large actions” (P9). Moreover, P5
suggested that non-rigid musical interfaces that can dynamically
change affordances [35] and retain their shapes can give“more
possibilities for sound encouraged actions to emerge and could
make the affordances of the interface to be more exploratory”.
Notably , P6 and P7 drew an interesting parallel between the
components of acoustic instruments and the characteristics of non-
rigid interfaces. For instance, reeds, strings, whammy bars, and
bendable saws are used to both modulate and produce sounds
through material deformation. According to P6, such components
“often provide signiﬁcant rolls in timbre and pitch expression of
acoustic instruments and can be used to such expressive effects in
electronic ones as well”. Therefore, non-rigid interfaces may also
be used to augment rigid parts (see [3], p. 892) of acoustic in-
struments with non-rigid parts providing additional input. In that
sense, P8 suggested considering a semi-malleable bow grip for the
continuous modulation of the sound output of acoustic instruments
(e.g., violin). Finally , P7 suggested that non-rigid controllers may
be used to help people with disabilities and children to learn and
experience music intuitively and easily (e.g., [7]).
3.1.3 Uptakes
W e asked our participants to talk about the current state of their
non-rigid musical interfaces. Almost all participants answered
that, although their interfaces still exists and may be functional (I1,
I5, I7, I10), they are currently unused and did not undergo further
development or design iterations. Only P2 reported that a few stu-
dents are using copies of his non-rigid musical interface for artistic
experimentation. W e also asked participants to self-assess the im-
pact of their work with non-rigid musical interfaces. Most partic-
ipants saw their work as having most impact within academic and
artistic research, through citations (P1, P3, P4, P5, P6), or through
presentations, lectures and workshops (P1, P5, P6, P8). Others ex-
plained that their interfaces had sparked inspirations and interest
in other musicians (P1, P7), as well as the industry (P5). However,
none of the non-rigid musical interfaces designed and built by our
participants were eventually commercialized, and no distribution
or production plan has been made for that purpose.
3.1.4 Issues And Open Challenges
W e asked our participants to describe the issues that they encoun-
tered while designing and building non-rigid musical interfaces.
They described the crafting of their interfaces as highly challeng-
ing. P10 said that ﬁnding the right materials to build non-rigid
musical interfaces poses many challenges, among which ﬁnding
durable materials that are also pleasing to touch, and strategically
place sensors not to obtrude musicians interaction; these chal-
lenges are also found in previous HCI work with non-rigid in-
terfaces [3]. P9 described embedding sensors inside deformable
materials as the most challenging task, while P8 needed to ﬁnd
appropriate “techniques for embedding micro-controllers in non-
rigid interfaces ”. Three participants described the design of non-
rigid musical interfaces as fragile and difﬁcult to replicate (P7, P9,
P10), thus emphasizing the need for ﬁnding robust and durable
materials to build such interfaces (“This project [I9] taught me
a lot of hard lessons about robustness ” —P9). Participants also
struggled with programming sensors. P8 mentioned “ massive non-
linearities” and “ slow hysteresis ” caused by the foam construction
of I8a, while the “ resistive memory ” of the silicone that composed
I9 forced P9 to cope with sensor values that kept changing over
time. Along these lines, the use of “advanced materials ” were
deemed necessary by P2, P3, P4, P7, P8 and P9, including nano-
technologies, miniaturized components, and long-lasting batteries.
P11 describes overcoming such design challenges as an “ en-
deavour”, and suggests “ a well thought out mapping design strat-
egy is needed to make [it] worthwhile ”. However, another chal-
lenge described by participants was “ understanding” the inter-
faces, as in how to properly design I/O mappings. P1 said that
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
19
“ understanding the behaviour of the instrument for making map-
ping decisions can be particularly difﬁcult with continuously-
deformable interfaces”, while P2 said that they “ ﬁrst had the work-
ing hardware artifact at hand ” before starting to reﬂect on I/O
mappings. P8 reckoned that it was necessary to capitalize on
“techniques for using machine learning to interpret control sig-
nals from non-rigid interfaces ”. The complex “ behavior” of non-
rigid interfaces was described as a hindrance to mastering control.
P8 described I8a as “a fun challenge to play, but also quite difﬁ-
cult”. P1 said that controlling continuous deformations makes it
hard to develop “ idiosyncratic performance practices ”. P11 de-
scribed unwanted coupling effects between deformable and rigid
input, which made music performances “intricate”. P5 noted that
“ as deformable interfaces can take innumerable distinct shapes,
creating speciﬁc target conﬁgurations [to play with] can be a chal-
lenge”.
3.1.5 Future V ision
“W e need to go beyond traditional square/hard/
technology-focused interfaces. ”—P10
As remarkably summed up by P10’s quote, nearly all participants
described non-rigid interaction as one of the future directions of
novel musical expression (P3, P4, P5, P6), speciﬁcally thanks to
its unusual and distinctive features (P7, P8, P9). Popularization
was considered by many participants the crucial next step in the
ﬁeld; this includes the development of novel deformable non-rigid
interfaces (P4, P5), as well as the improvement of existing ones
(P3, P6). In two cases, popularization was referred to as the in-
crease of the number of musicians having access to and playing
non-rigid musical interfaces, leading to interesting takes on mas-
tering and learning: P7 stated that “getting [non-rigid] devices into
the hands of end-users and out of the research labs would allow
for the most interesting insights”, while P6 underlined the need
to “ observe how others use these instruments, without instructing
them, to see how they play them ”. P4 was even more explicit about
the importance of pedagogy , saying that exploring “ the learning
process of deformable NIMEs ” is one of the essential steps for re-
search on non-rigid musical interfaces to advance.
The participants’ future vision of non-rigid musical interfaces
was in some cases clearly inﬂuenced by the challenges they had to
face while designing and using their interfaces (see Section 3.1.4).
In particular, four participants expect an intensiﬁcation of inter-
disciplinary efforts, spanning chemistry and material science (P8),
sensing and nanotechnologies (P4), and more generally electron-
ics (P10, P9); P9 further elaborated this comment, by hinting at fu-
ture “user friendly ” materials that may help artists appropriate non-
rigid interaction, as much as Arduino did for micro-controllers.
The analysis of the proposed future perspectives of non-rigid
musical interfaces highlighted a neat division between participants,
mainly revolving around the concept of expression. Around half of
the participants framed forthcoming non-rigid interfaces as proper
musical instruments, at least as expressive and precise as the in-
struments we currently use on stage and in studio. P5 discussed
their use in performance and composition, P6 and P7 remarked
the analogies with acoustics instruments, while P11 deemed de-
formable input ideal for instrumental control. Along these lines,
when illustrating their interfaces, P3 and P2 discussed how non-
rigid input can be used to sense from macro- to micro-gestures, and
provide multi-modal feedback for expressive and dynamic playing.
In contrast with this vision, a second group of participants em-
phasized the trade-off between precision and expression that non-
rigid input imposes on interaction. P8 described non-rigid interac-
tion as “sacriﬁcing some precision for more expressive control ”, P4
talked about “ expressive potential ” but need for “ more advanced
sensing technologies ”, while P10 used adjectives like “ different”
and “ joyful” that are seldom used to describe musical instruments
that allow for nuanced control and virtuosity . The same incom-
patibility with “nuanced actions ” pushed P9 to consider non-rigid
interfaces suitable for interactive installations rather than music
performances and, likewise, P1 did not directly consider the use
of non-rigid input in the design of musical instruments. Except
for P1, the participants that connected non-rigid interaction to un-
predictability and large scale actions are the same that experienced
troubles with crafting their interfaces (Section 3.1.4), and that fos-
ter a stronger cross-contamination with research in new materials.
3.1.6 Shape Change
Five participants described the potential that shape change [34]
may have in the context of novel musical interfaces. P8 and P4
hypothesized future scenarios in which shape and material proper-
ties of an interface can be adapted to speciﬁc musical tasks, while
P5 emphasized how the “contingent and dynamic nature of NIMEs
could ﬁnd more practice grounds ” with shape-changing interfaces.
In contrast with the idea of shape adaptation, P9 and P1 talked of
shape actuation as new means to provide haptic feedback; in par-
ticular, P1 saw this as a tremendous opportunity to increase “the
subtlety and nuance of interactions with the interface ”.
The same idea was shared by P7, who framed shape change as
a novel feedback modality (“ beyond vibro-tactile and force feed-
back”), and envisioned non-rigid musical interfaces that “ vibrate
along with its auditory output [that] get us toward programmable
acoustic interfaces”. However, P7 also highlighted the extra chal-
lenges that shape-change adds to the design of non-rigid musical
interfaces. How to design for shape change? What good mapping
strategies exist or should be developed for shape-changing I/O?
And how to master it? All these questions were shared among P7,
P3, and P11. Further insight regarding the open problem of master-
ing a shape-changing musical interface was given by P6, who ﬁrst
praised shape change and the “inﬁnite space for exploring playing
and sonic possibilities ” it generates; yet, he explained how dif-
ﬁcult it would be to continuously develop playing techniques on
a instrument that keeps changing its shape and functions, hence
compromising “the opportunity for virtuosity through practice ”.
4. DISCUSSION
W e reviewed existing non-rigid musical interfaces to deﬁne them
as a research area of NIME. As such, we provided an overview
of existing design practices for non-rigid musical interfaces which
were not systematically approached before. Furthermore, we sur-
veyed 11 experts to gather information about their practices, takes,
and future perspectives on non-rigid musical interfaces, to help
guide and inspire future research and design efforts. Next, we fur-
ther discuss the results of our survey and consider possible direc-
tions for future work also referring to existing relevant literature.
4.1 Practices, T akes, and Future Perspective
Our participants had different motivations to design and build non-
rigid musical interfaces, all of which expressed a desire to explore
alternative and “unusual” ways of performing music, even com-
pared to NIME standards. Such a desire for experimentation has
also driven HCI to research about non-rigid interfaces, and both
question and challenge earlier interaction paradigms [3, 1]. HCI
has then moved past exploration through several user studies, prac-
tical applications (e.g., mobile interaction), and by formalizing
grand challenges for non-rigid interfaces research [1]. This con-
trasts with the limited adoption that non-rigid interfaces show in
music research. Except for [9, 14, 24], all the non-rigid musical
interfaces discussed in this paper remain prototypical and were not
further developed.
Our participants attributed such a difﬁculty in adoption and
popularization of their interfaces to challenges in fabrication pro-
cesses, maintenance, and the hardship of ﬁnding robust materials.
Therefore, it was quite arduous for them to reproduce a design,
improve it, as well as adapt it to the needs of other users. In
other words, designers mainly built non-rigid musical interfaces
with only one performer in mind, namely themselves (e.g., [38,
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
20
26, 41, 2, 45]). This emphasizes a general problem with adoption
and popularization of new musical interfaces, which was previ-
ously discussed in NIME literature [25]. However, we have seen
in recent years the emergence of consumer musical interfaces that
feature (semi)non-rigid materials. Interfaces likeSkoog Music 2 ,
ROLI Seaboard 3 , and The Cell 4 , suggest that the latest advance-
ments in material science may relax constraints linked to materials
and crafting, and help foster the adoption and popularization of
non-rigid musical interfaces.
Musical performance is most common among the use and ap-
plications for non-rigid musical interfaces, as evidenced by our
results. Surprisingly , however, none of the participants has men-
tioned developing speciﬁc musical compositions (in contrast with
[24, 43]) or choosing particular sounds to play with their inter-
faces. In that respect, Troiano et al. [40] found that non-rigid
musical interfaces were deemed by musicians as both generic and
speciﬁc; during their performance study , the authors observed that
musicians would try different sounds when experimenting with the
mapping of non-rigid gestures to musical parameters (see [40],
pp. 381–382), but once they found the desired combinations they
would consolidate I/O relations and focus on musical practice; this
suggests that non-rigid musical interfaces can develop into strong
speciﬁcness [44] if used over prolonged time. The lack of musical
“standards” and speciﬁcity found among our participants may be
explained by their primary focus in designing the non-rigid mu-
sical interfaces, rather than focusing on music composition and
practice. By contrast, the musicians involved in the performance
study of Troiano et al. were provided with ready-made non-rigid
musical interfaces, and were then free to concentrate on explor-
ing musical solutions and composition; however, their experience
with performing music using non-rigid interfaces was rather brief
(i.e., 10 minutes). T o further validate the insights from [40], we
need longitudinal studies, studies out-of-the lab [40], and studies
in-the-wild [5] that observe how users learn to play with and mas-
ter non-rigid musical interfaces over time, and relieved from the
burden of design.
Besides musical performance, our participants designed non-
rigid musical interfaces for diverse applications, including music
therapy [7] and soniﬁcation [39, 46]. As such, differently from
other musical interfaces, non-rigid interfaces and non-rigid input
can be leveraged for designing interactions that do not only en-
compass music performances, but can also ﬁt musical interactions
more broadly . For instance, previous work [40] reported that mu-
sicians using non-rigid musical interfaces had the impression of
“having the sound in the hand” and felt like “sculpting sounds”
during their interactions. These insights suggest that such inter-
faces can beneﬁt applications in sound design that disentangle
from WIMP (i.e., window , icon, menu, and pointer) paradigms.
This enhances “true” physical modelling of sounds, a concept that
has been previously explored in virtual reality applications [27],
but not yet with non-rigid musical interfaces.
4.2 What’s Next for Non-Rigid NIMEs?
As evidenced in Section 3.1.4, one of the most pressing issues for
designers of non-rigid musical interfaces is the need to ﬁnd robust
sensors, materials, and design standards that help move beyond
prototypes and enhance reproducibility . According to our partici-
pants, the solution lies in establishing collaborations with material
scientists and chemists, and leverage HCI work that investigates
smart materials and nanotechnologies [33].
Our participants (P1, P8) indicated multidimensional input as
an area of interest within the design of non-rigid musical inter-
face. However, at present, our knowledge of how musicians lever-
age multidimensional non-rigid input for music is limited, and we
2 https://skoogmusic.com/
3 https://roli.com/products/seaboard
4 http://cmg.tokyo/
need studies that systematically explore such novel input method.
For instance, research questions like “What is the maximum num-
ber of deformations that musicians can comfortably and effectively
control simultaneously?”, “How do musicians perceive individual
non-rigid input dimensions when they blur into one another?”, and
“Which musical tasks are a good ﬁt for multidimensional non-rigid
input, and why?” remain unanswered. W e suggest that future
NIME efforts investigating multidimensional non-rigid input align
with what previously suggested in HCI work [3], namely to lever-
age psychophysics method [10] for systematically investigating
users’ perceptions of and the capacity to handle multidimensional
non-rigid input. Similar to earlier work investigating expressive
touch on interactive tabletops [31], a psychophysics approach to
investigate multidimensional non-rigid input may also contribute a
systematic understanding of the precision-vs-expression trade-off
in non-rigid musical interfaces (see Section 3.1.5).
Boem and Troiano [3] pointed out how mapping remains sub-
stantially under-explored in non-rigid HCI and highlighted the
need for further investigating I/O cross-modal correspondences
with non-rigid interfaces. They suggested that HCI may do well
looking at existing work on mapping in digital music instruments
(DMIs) to advance this area. It is not coincidental, in fact, that ex-
isting work with non-rigid interfaces that has more carefully con-
sidered I/O relations, and proposed technical solutions for map-
ping, were mainly research in the musical domain [18, 12, 39,
23, 24, 2]. Given the above, and the long tradition that NIME
and DMIs have on systematically investigating mapping and cross-
modal correspondences, we argue that not only research on non-
rigid musical interfaces, but also research on non-rigid HCI will
beneﬁt from NIME investigations in this particular area.
In Section 3.1.6 participants anticipated that self-actuation and
shape change may be used for creating dynamic, adaptive, and
responsive musical interfaces. This concept has been explored
by MIT in their work TRANSFORM [16], where a hybrid
musical/shape-changing display would change its physical shape
to represent different sound waves (e.g., saw-tooth, sine wave).
W e encourage NIME to further experiment with a physical “em-
bodiment” of sounds through shape change, for enhancing multi-
sensory interactions beyond visual displays, and create reactive
musical interfaces that establish dynamic “dialogues” with musi-
cians via non-rigid I/O.
5. CONCLUSION
Non-rigid interfaces introduce new forms of controlling input and
receiving output that may fundamentally reshape existing interac-
tive paradigms. In this paper, we have explored challenges and
open questions brought by non-rigid interfaces to musical interac-
tions and proposed that future work engage in cross-disciplinary
research efforts between HCI and NIME to advance the area. Our
work will beneﬁt designers and researchers that wish to contribute
to NIME, as well as non-rigid interfaces at-large, by further explor-
ing non-rigid musical interfaces and their prospective potential in
enhancing new forms of musical expressions.
6. ACKNOWLEDGEMENTS
W e thank all the participants for their precious contributions.
7. REFERENCES
[1] J. Alexander, A. Roudaut, J. Steimle, K. Hornbæk,
M. Bruns Alonso, S. Follmer, and T . Merritt. Grand
challenges in shape-changing interface research. InProc.
CHI, 2018.
[2] A. Boem. Sculpton: A malleable tangible interface for
sound sculpting. In Proc. ICMC+SMC , 2014.
[3] A. Boem and G. M. Troiano. Non-rigid HCI: A review of
deformable interfaces and input. In Proc. ACM DIS , 2019.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
21
[4] B. Bongers and Y . Harris. A structured instrument design
approach: The video-organ. In Proc. NIME , 2002.
[5] M. Callon and V . Rabeharisoa. Research “in the wild” and
the shaping of new social identities. T echnology in society ,
25(2):193–204, 2003.
[6] A. Chang and H. Ishii. 2007. Zstretch: A Stretchy Fabric
Music Controller. In In Proc. NIME , 2007.
[7] F . L. Cibrian, O. Peña, D. Ortega, and M. T entori.
Bendablesound: An elastic multisensory surface using
touch-based interactions to assist children with severe
autism during music therapy .Int. Journal of
Human-Computer Studies , 107:22 – 37, 2017.
[8] J. U. Davis. Illumiwear: A ﬁber-optic etextile for
multimedia interactions. In M. Queiroz and A. X. Sedó,
editors,Proc. NIME , 2019.
[9] J. U. Davis and N. Hanover. Illumiwear: A ﬁber-optic
etextile for multimedia interactions. 2019.
[10] G. A. Gescheider. Psychophysics : The Fundamentals .
Psychology Press, USA, June 2013.
[11] B. Glaser and A. Strauss. The Discovery of Grounded
Theory: Strategies for Qualitative Research . Routledge,
USA, 2000.
[12] M. Grierson and C. Kiefer. Noisebear: A malleable wireless
controller designed in participation with disabled children.
InProc. NIME , 2013.
[13] I. Hattwick, J. Malloch, and M. W anderley . Forming shapes
to bodies: Design for manufacturing in the prosthetic
instruments. InProc. NIME , 2014.
[14] A. Hinrichsen, S.-I. Hardjowirogo, D. H. M. Lopes, and
T . Bovermann. Pushpull. reﬂections on building a musical
instrument prototype. InProc. ICLI , 2014.
[15] T . J. Hollinger, A vrum and M. M. W anderley . An embedded
hardware platform for fungible interfaces. In Proc. of the
ICMC, pages 56–59, 2010.
[16] H. Ishii, D. Leithinger, S. Follmer, A. Zoran, P . Schoessler,
and J. Counts. Transform: Embodiment of “radical atoms”
at milano design week. InProceedings of the 33rd Annual
ACM Conference Extended Abstracts on Human F actors in
Computing Systems, CHI EA ’15, page 687–694, New Y ork,
NY , USA, 2015. Association for Computing Machinery .
[17] A. R. Jensenius and A. V oldsund. The music ball project:
Concept, design, development, performance. In Proc. NIME ,
2012.
[18] C. Kiefer. A malleable interface for sonic exploration. In
Proc. NIME , 2010.
[19] Y . Kinoshita, M. Nishio, S. Shiraga, and K. Go.
Investigation of pleasantness in the manipulation of
deformable interfaces for musical expression. InProc. Int.
Conf. on Kansei Engineering Emotion Research , 2018.
[20] R. Lamb and A. Robertson. Seaboard: A new piano
keyboard-related interface combining discrete and
continuous control. InNIME, pages 503–506, 2011.
[21] J. Malloch, S. Sinclair, A. Hollinger, and M. M. W anderley .
Input Devices and Music Interaction . Springer Berlin
Heidelberg, 2011.
[22] J. Malloch and M. M. W anderley . The t-stick : From musical
interface to musical instrument. In Proc. of NIME , 2007.
[23] M. Marier. The sponge a ﬂexible interface. In Proc. NIME ,
2010.
[24] M. Marier. Designing mappings for the sponge: T owards
spongistic music. In Proc. NIME , 2014.
[25] F . Morreale, A. McPherson, M. W anderley , et al. Nime
identity from the performer’s perspective. 2018.
[26] G. C. Morris, S. Leitman, and M. Kassianidou. Sillytone
squish factory . In Proceedings of the International
Conference on New Interfaces for Musical Expression ,
pages 201–202, Hamamatsu, Japan, 2004.
[27] A. Mulder and S. Fels. Sound sculpting: Manipulating sound
through virtual sculpting. In Proc. of the 1998 W estern
Computer Graphics Symposium , pages 15–23, 1998.
[28] T . Murakami and N. Nakajima. Do-it: deformable object as
input tool for 3-d geometric operation. Computer-Aided
Design, 32(1):5 – 16, 2000.
[29] J. Oliver and M. Jenkins. The silent drum controller: A new
percussive gestural interface. In Proc. ICMC , 2008.
[30] D. Overholt. The matrix : A novel controller for musical
expression. In Proc. NIME , 2001.
[31] E. W . Pedersen and K. Hornbæk. Expressive touch: studying
tapping force on tabletops. In Proceedings of the SIGCHI
Conference on Human F actors in Computing Systems , pages
421–430, 2014.
[32] B. Piper, C. Ratti, and H. Ishii. Illuminating clay: A 3-d
tangible interface for landscape analysis. In Proc. CHI ,
2002.
[33] I. P . S. Qamar, R. Groh, D. Holman, and A. Roudaut. Hci
meets material science: A literature review of morphing
materials for the design of shape-changing interfaces. In
Proc. CHI, 2018.
[34] M. K. Rasmussen, E. W . Pedersen, M. G. Petersen, and
K. Hornbæk. Shape-changing interfaces: A review of the
design space and open research questions. InProc. CHI ,
2012.
[35] M. K. Rasmussen, G. M. Troiano, M. G. Petersen, J. G.
Simonsen, and K. Hornbæk. Sketching Shape-changing
Interfaces: Exploring V ocabulary, Metaphors Use, and
Affordances. InProc. CHI , 2016.
[36] M. Savary , D. Schwarz, and D. Pellerin. Dirti —dirty
tangible interfaces. In In Proc NIME , 2012.
[37] H. Sawada, N. Onoe, and S. Hashimoto. Sounds in hands: A
sound modiﬁer using datagloves and twiddle interface. In
Proc. ICMC, 1997.
[38] E. Singer. Sonic banana: A novel bend-sensor-based midi
controller. In Proc. NIME , 2003.
[39] K. T ahiro ˘glu, T . Svedström, V . Wikström, S. Overstall,
J. Kildal, and T . Ahmaniemi. SoundFLEX: Designing Audio
to Guide Interactions with Shape-Retaining Deformable
Interfaces. InProc. of ICMI , 2014.
[40] G. M. Troiano, E. W . Pedersen, and K. Hornbæk.
Deformable Interfaces for Performing Music. In Proc. CHI ,
2015.
[41] J. W ang, N. d’Alessandro, S. S. Fels, and B. Pritchard.
Squeezy : Extending a multi-touch screen with force sensing
objects for controlling articulatory synthesis. InProc. NIME ,
pages 531–532, Oslo, Norway , 2011.
[42] E. W atanabe, Y . Hanzawa, and M. Inakage. Clay T one: A
Music System Using Clay for User Interaction. In
SIGGRAPH, 2007.
[43] G. W einberg. Playpens, ﬁreﬂies and squeezables: New
musical instruments for bridging the thoughtful and the
joyful.Leonardo Music Journal , 12:43–51, 2002.
[44] S. A. W ensveen, J. P . Djajadiningrat, and C. Overbeeke.
Interaction frogger: a design framework to couple action and
function through feedback and feedforward. InProc. ACM
DIS, 2004.
[45] I. Wicaksono and J. Paradiso. Fabrickeyboard: Multimodal
textile sensate media as an expressive and deformable
musical interface. InProc. NIME , 2017.
[46] V . Wikström, S. Overstall, K. T ahiro ˘glu, J. Kildal, and
T . Ahmaniemi. Marsui: Malleable audio-reactive
shape-retaining user interface. InProc. CHI , 2013.
[47] M. Zadel, P . Kosek, and M. M. W anderley . A pliable, inertial
interface. T echnical Report, 2003.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
22