VRMin: Using Mixed Reality to Augment the Theremin for
Musical Tutoring
David Johnson
University of Victoria
3800 Finnerty Rd
Victoria, British Columbia V8P 5C2
davidjo@uvic.ca
George Tzanetakis
University of Victoria
3800 Finnerty Rd
Victoria, British Columbia V8P 5C2
gtzan@uvic.ca
ABSTRACT
The recent resurgence of Virtual Reality (VR) technologies
provide new platforms for augmenting traditional music in-
struments. Instrument augmentation is a common approach
for designing new interfaces for musical expression, as shown
through hyperinstrument research. New visual aﬀordances
present in VR give designers new methods for augmenting
instruments to extend not only their expressivity, but also
their capabilities for computer assisted tutoring. In this
work, we present VRMin, a mobile Mixed Reality (MR)
application for augmenting a physical theremin, with an im-
mersive virtual environment (VE), for real time computer
assisted tutoring. We augment a physical theremin with
3D visual cues to indicate correct hand positioning for per-
forming given notes and volumes. The physical theremin
acts as a domain speciﬁc controller for the resulting MR
environment. The initial eﬀectiveness of this approach is
measured by analyzing a performer’s hand position while
training with and without the VRMin. We also evaluate the
usability of the interface using heuristic evaluation based on
a newly proposed set of guidelines designed for VR musical
environments.
Author Keywords
Virtual Reality, Mixed Reality, Music Pedagogy, Theremin
ACM Classiﬁcation
H.5.1 [Information Interfaces and Presentation] Multime-
dia Information Systems—Artiﬁcial, augmented, and vir-
tual realities, H.1.2 [Information Systems] User/Machine
Systems—Human factors, H.5.5 [Information Interfaces and
Presentation] Sound and Music Computing
1. INTRODUCTION
Developed in the 1920s by Leon Theremin while experi-
menting with radios, the Theremin is one of the earliest
electronic music instruments and one of the few instruments
that is performed without physical contact (and without the
use of a computer). The continuous nature of the Theremin
makes it one of the most expressive electronic music instru-
ments for performers. However, this continuous nature also
makes it one of the most diﬃcult instruments to learn and
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’17,May 15-19, 2017, Aalborg University Copenhagen, Denmark.
Figure 1: Milgram’s Reality-Virtuality Continuum
play. While many musicians have used it as a novel addi-
tion to their compositions it was never fully adopted as a
new musical voice, and only a few players have mastered it.
Instead the theremin is mostly known for the eerie sounds
of Sci-Fi movies of the 1950s. The theremin has, however,
had a substantial inﬂuence on NIME.
One such area is the work on hyperinstruments, a term
introduced by Tod Machover at MIT Media Lab [12]. Hy-
perinstruments are traditional instruments that have been
augmented with sensors for real-time processing of perfor-
mance data. They enable the type of computer control and
music generation provided by digital instrument that is typ-
ically not available to performers of acoustic instruments.
One of Machover and colleagues’ most prominent hyperin-
struments, the Hypercello, used similar electric ﬁeld sensing
techniques to the Theremin for the sensing of an augmented
bow for the cello. The instrument, implemented by Ma-
chover’s colleagues, Paradiso and Gershenfeld, was designed
for Yo Yo Ma to perform Machover’s composition Begin
Again Again.... [20]. The Hypercello, like many hyperin-
struments since then, was speciﬁcally designed for a com-
position and required invasive augmentation with sensors of
a specially designed cello. Such invasive modiﬁcations are
expensive, hard to implement, and diﬃcult to adopt by mu-
sicians. More recently researchers have used advanced and
innovative sensors for non-invasive instrument augmenta-
tion [23]. New technologies for Virtual Reality (VR) and
Mixed Reality (MR) aﬀord more possibilities for augment-
ing instruments. While sensors allow for more gestural con-
trol, VR and MR add a new layer of visual aﬀordances to
the interaction. Instead of interacting with an intangible
location within the performance space, VR can be used to
add virtual objects to the environment providing visual cues
to guide a musician’s interaction with the instrument.
VR and MR are similar concepts that vary in relation to
the degree the user is immersed in a virtual environment.
As Milgram proposed with his Reality-Virtual Continuum,
shown in ﬁgure 1, MR is any environment that mixes real
world components with a virtual environment, with aug-
mented reality and virtual reality at the extremes of the
continuum [14].
In 1992 Jaron Lanier (often thought to have coined the
151
term Virtual Reality) performed The Sound of One Hand ,
a live improvisation of VR music instruments. One of the
more notable aspects of his performance was that Lanier
performed multiple instruments using only one hand, cre-
ating a performance that could not be accomplished with
physical instruments [9]. Since then, however, there has
been little research exploring the possibilities of performing
music in immersive environments.
The visual aﬀordances of VR and MR can extend tra-
ditional instruments, and hyperinstruments, in a number
of ways. With the emergence of depth sensors, such as the
Kinect, that allow performers to interact with virtual space,
VR and AR can be used to add visual signiﬁers to the space
that provide visibility to the additional functionality of in-
strument. Additionally the visual signiﬁers could be used
as training mechanisms for new musicians to learn the par-
ticular instrument. With this work we propose, VRMin, a
system for the later case, in which we augment a physical
theremin with visual objects to help new thereminists learn
correct hand positioning and placement.
1.1 Hyperinstruments
Since Tod Machover’s work on hyperinstruments there has
been signiﬁcant research on augmenting instruments with
sensors and microcontrollers to extend the capabilities of
traditional instruments. Young’s Hyperbow uses sensors and
custom hardware track the position, acceleration, force and
angle of a violin bow. The sensor data aﬀords musicians
new expressivity in their performance by allowing the vio-
linist to alter the acoustic sound of the violin in real-time
using gestures from the bow [25]. Overholt takes augment-
ing the violin one step further by designing the augmented
violin from the ground up building the hardware and sen-
sors directly into the instrument [19]. The Electrumpet is
a standard trumpet augmented with additional sensors and
buttons for additional control of the acoustic output. While
Electrumpet augmentation was not completely invasive to
the original instrument it does require the technical exper-
tise to work with microcontrollers for a musician to imple-
ment in their own instruments [10].
The release of RGB-D sensors such as the Kinect has led
developments in non-invasive augmentation seen in Trail
and collegues’ work on augmenting pitched percussion in-
struments using a Kinect[23]. Using sensors like the Kinect
aﬀords more accessible and aﬀordable instrument augmen-
tation since all that is needed is a Kinect and computer
running the special middleware. As sensors improve and
Virtual and Augmented Reality become more prevalent we
expect to see the emergence of hyperinstruments solely us-
ing these technologies to augment the capabilities of tradi-
tional instruments with virtual objects.
1.2 Virtual Reality Music Instruments
Advances in VR and MR technologies have expand the pos-
sibilities for creating New Interfaces for Musical Expression
(NIME) and Learning. With the advent of VR, a new cat-
egory of NIME is emerging, Virtual Reality Music Instru-
ments (VRMI). VR adds a visual layer to the design of
NIME and thus far there is little research on how the new
visual aﬀordances of VR can to be used for music interfaces.
One of the ﬁrst published research experiments of VR-
MIs may be the work of Maki-Patola and colleagues. In
this work the authors analyzed four VRMIs using Jorda’s
concepts of eﬃciency and learning curve [8]. In their ﬁnd-
ings, they reported that because VR is a diﬀerent medium
compared to a the real world, mimicking traditional instru-
ments in VR may not result in better instruments unless VR
is used to augment real instruments with additional control.
Furthermore, they noted the potential of visualization for
providing visual cues, teaching users and visualizing sound
[13].
The majority of research of VRMI has led to interfaces
in which a perform generates musical sounds through in-
teractions with 3D musical objects using standard VR in-
put controllers, for example Berthaut, Desainte-Catherine,
and Hachet propose the use of 3D reactive widgets [1] and
Moore and colleagues work on The Wedge in which users
build their own musical performance space by adding note
objects to space from a palette [15]. Instead of using stan-
dard input controllers for sound generation, Gelineck and
colleagues proposed a VRMI for interacting with tangible
controllers that can change dimensions of physical models
in real-time through VR capabilities [2]. This work shows
the potential for using VR technologies to create hyperin-
struments. Although the controllers were not acoustic in-
struments (as is the case with hyperinstruments) their work
shows how VR can be used to extend the physical world.
For a more extensive overview of VRMIs see this year’s sur-
vey from Seraﬁn and colleagues. In this work the authors
also proposed nine design principles for VRMIs used to de-
velop an evaluation framework [22].
The bulk of research of VR for musical interfaces has
been in the design of new digital music instruments. VR
also opens the door for two other types of musical inter-
faces, augmented instruments (or hyperinstruments) and
computer assisted music instrument tutoring (CAMIT) in-
terfaces. Furthermore, MR has the potential to augment
physical music controllers with new features and visual feed-
back in real time. In essence VRMIs have the potential for
creating musical experiences not available in the real world.
1.3 Computer Assisted Music Tutoring
Learning to play a musical instrument is a challenging task
that requires years of disciplined practice to master. Ad-
vances in technology have opened the door for computa-
tional methods for musical pedagogy that can make the pro-
cess easier. Research in the ﬁeld of Computer Assisted Mu-
sic Instrument Tutoring (CAMIT) has created tools to im-
prove this process by analyzing students’ performance and
providing personalized feedback [21]. These tools generally
use audio signal processing to analyze the aural performance
of the student. The success of companies like Yousician 1
shows that there is demand for tools to enhance the musi-
cal learning experience. There is not, however, a substantial
amount of research in the area of CAMIT.
There have been a few proposed systems for CAMIT in
non immersive AR. Piano AR is an application for teaching
piano by augmenting a physical piano with virtual ﬁngers
that a student would then follow [6]. Mora and colleagues
use AR to correct poor body posture in piano players [16]
and Liarokapis used non immersive AR for for guitar learn-
ing[11]. Johnson and colleagues proposed a system to ana-
lyze pianists’ hand posture using computer vision with the
goal of implementing an AR based piano tutor application
[7]. While these works provide proof of concept for VR
based musical tutoring more research is required to under-
stand the eﬀectiveness of this approach to learning an in-
strument.
In addition to using VR to teach traditional instruments,
researchers of VRMI have seen the potential for using VR
to teach users how to play VRMIs. As Maki-patola notes,
”in addition to providing visual cues, visualization could be
used to teach the user how to play an instrument. For ex-
ample, the FM Synthesizer could include a scrolling musical
1https://yousician.com/
152
Figure 2: A student practicing the theremin using VRMin with capture of the view on the right
score that marks the correct position of the hand in the air”
[13].
1.4 Heuristic Evaluation
Self evaluation of an interface is a critical step in the interac-
tion design process to quickly evaluate the design before the
intrusive process of a usability study. One commonly used
method is Heuristic Evaluation (HE) in which an evaluator
determines the good and bad aspects of an interface based
on a set of guidelines, known as heuristics [18]. Many of
these heuristics common for traditional user interfaces (see
[17, 24]) are not be well suited to the design challenges pre-
sented for virtual interfaces and environments. As Gabbard,
Hix, and Swan claim, ”[these guidelines are] too general,
ambiguous, and high level for eﬀective and practical heuris-
tic evaluation of VEs” [4]. Instead the authors proposed
a framework of design guidelines developed speciﬁcally for
VEs [3]. VR music environments (including both expres-
sion and learning environments) have diﬀerent character-
istics of than that traditional VE. Seraﬁn and colleagues
presented nine design principals speciﬁcally for for VRMI,
a number of which are also relevant to our work on VRMin
[22]. From a pedagogical standpoint, an optimal use of per-
formance feedback is an important factor in the design of
VEs. Research has been done in simulation based medical
education (SBME) that shows how learning is aﬀected by
diﬀerent types of performance feedback [5]. The ideas from
each of these ﬁelds have informed our development of design
guidelines for heuristic evaluation of MR musical pedagogy
presented in section 3.
2. VRMIN
In this work we present, VRmin, a mixed reality CAMIT
application intended to improve the process of learning the
theremin. The main challenge that aﬀects a user’s ability to
learn the theremin is a lack of aﬀordances and constraints
that provide guidance within the pitch and volume spaces.
Furthermore, the theremin has continuous control rather
than being composed of discrete notes. This makes it dif-
ﬁcult for new thereminists to ﬁnd the correct location of a
given note. VRmin provides visual cues to guide the per-
former within the pitch space by augmenting the theremin
with visual signiﬁers through the use of mobile VR. Figure
2 shows a student practicing the theremin with the VRMin
environment.
2.1 System Description
VRmin is a Mixed Reality (MR) system that integrates
a Moog Theremini 2 for sound generation with mobile VR
technology for visual augmentation. Implementing the sys-
2https://goo.gl/zJNP5E
tem using mobile VR increases accessibility as devices be-
come more readily available. For this implementation we
use the Google Daydream platform 3 and a Google Pixel
XL. We found that the use of the Daydream controller was
intrusive to the interaction with the theremin, as a therem-
inist’s hands should be free to better control of musical out-
put. With that in mind, we’ve designed VRMin so that all
control is performed through interaction with the theremin
instead of the native Daydream controller. This also af-
fords for a system that is extensible to other VR and MR
platforms including mobile VR, such Google Cardboard and
Samsung Gear VR, and more powerful platforms, such as
the Oculus Rift and Microsoft HoloLens.
The Theremini outputs MIDI CC messages for both the
pitch and volume antennae which we use as input for con-
trolling the MR interface. The pitch control values are eas-
ily scaled to frequency based on the frequency range of the
theremin. The frequency range of the Theremini is conﬁg-
urable and for the sake of this work, we have conﬁgured the
Theremini with a frequency range of 65.40 Hz (C2) to 493.8
(B4) Hz.
The Theremini is connected to a computer running a
Pure Data patch acting as middleware for converting MIDI
CC messages to OSC for simpliﬁed network communica-
tion. Additionally the middleware handles simple gesture
detection to add functionality to the theremin. Messages
containing the pitch and volume control data, as well as
detected gestures, are sent from the middleware to the VR
device which is running an OSC server implemented with
Unity. The received messages are then used to control in-
terface elements, as described in the next section.
2.2 User Interface
The VRMin environment, shown on the left in Figure 2,
contains visual representations of the physical elements that
comprise the performance space, in this case the Theremini
and the user’s hands. These are augmented with visual el-
ements not present in the real world, a visual note signiﬁer
and a virtual piano roll. The visual elements are controlled
through input from the middleware allowing the Theremini
to act as the controller. The pitch and volume values con-
trol the locations of the hands relative to the antenna and
gesture messages are used to control interactions with the
tutoring interface.
Within the VE we try to map the physical elements as
closely to the real world as possible in both their dimen-
sions and their positions. The theremin is represented with
a simple 3D model with dimensions that replicate the phys-
ical theremin within the performance space. 3D hand mod-
els are used to represent the location of the user’s hands
relative to each antenna. Each hand is modeled in a pos-
3https://vr.google.com/daydream/
153
0
50
100
150
200
250
300
350
400Pitch Frequency
Session 1 w/ VR (C3 to G3)
C3
G3
Training Results Session 1
C3
G3
Session 2 w/o VR (G3 to D4)
G3
D4
Training Results Session 2
G3
D4
Figure 3: Performance analysis plots of practice sessions with and without VRMin
ture similar to one a thereminist would typically use; the
pose of right hand is similar to the ”OK” sign and left hand
uses a horizontally oriented ﬂat hand. Using the ”OK” sign
also mitigates an issue the authors found in which a verti-
cally oriented ﬂat hand occludes the tip of the middle ﬁnger
from the ﬁeld of view. This posed a problem because of the
precision required to correctly play a note with a theremin.
The location of notes within the pitch space can be rep-
resented with circles since all points are equidistant from
the antenna. For a 3D representation of notes we use hol-
low cylinders to indicate the location of a note relative to
the antenna within the pitch space. Each note is also ac-
companied by text indicating the name of the note for ad-
ditional feedback. Notes are transparent so that the user
has constant feedback as to the location of the tip of virtual
hand even as their hand passes through the cylinder. To
play a displayed note, a user moves their hand such that
the position of the tip of the virtual hand is located at the
center of the two concentric circles that comprise the hol-
low cylinder. To further enhance performance feedback the
cylinder’s color changes to green when the tip of the middle
ﬁnger is in the correct location 4.
The interface also contains a piano roll to display a score
during the performance session. The piano is positioned
just above the pitch antenna and is rotated along the Y
axis by 30 degrees. This positioning provides the best view
of the piano roll that is not obstructed by any portion of
the theremin or note indicators. The user is able to easily
view the piano roll by slightly tilting their head up. This
placement also keeps a view of the right hand and virtual
note in the user’s periphery as they view the score. The pi-
ano roll includes a pitch indicator line to provide additional
performance feedback as the score is being viewed.
Since VRMin has the design constraint of avoiding a sep-
arate controller, we have implemented simple gestures for
interacting with the system using each antenna as a trig-
ger. To activate a trigger a user simply places a hand in
the near position of the antenna for a period of time that
is longer than the hand would typically be in that position
during performance. For example, the volume antennae is
used as a trigger to start and stop each practice session
by holding a hand in the near position of the antennae for
two seconds. Additionally, the user is able to change the
score used for the practice session similarly using the pitch
antenna trigger. A third trigger is available (but not cur-
rently implemented) by placing hands at the near position
of both antenna at the same time.
2.3 Performance Analysis
To improve the analysis of practice sessions, we have imple-
mented performance logging in VRMin. The logging system
records the OSC messages and values sent to VRMin. This
data could then be used to replay a practice session for a vi-
sual analysis of the performance (similar to reviewing video
4see a video demo at https://goo.gl/DxvSqK
recordings). More importantly, teachers can gain insight
into a student’s progress through a quantitative analysis of
the data by using plots similar to ﬁgure 3.
The plots in ﬁgure 3 show the results of two pitch match-
ing practice sessions, one using VRMin and one without.
In each session, the student attempts to match computer
generated tones and hold the tones for ﬁve seconds each.
In this case the student is practicing moving between in-
tervals of a perfect ﬁfth. After each session, the performer
attempted to perform the same tones without VRMin or
the corresponding pitch playing in the background.
In ﬁgure 3 the red and green lines represent the pitches
the thereminst was instructed to play as part of a pitch
matching practice session. The ﬁrst two charts show the
results of the student during the pitch matching training
sessions and the last two show data from the student at-
tempting to play the notes on their own. While these are
by no means conclusive, we do see that when using VRMin
the user is much more precise during the practice session
as there is much less vibrato and it was easier to ﬁnd the
correct location. Post pitch matching, however, it appears
the user trained without VRMin was better able to recall
the locations of the notes after a bit of adjustment.
3. HEURISTIC EV ALUATION
The goal of this work is to design a tool that supports mu-
sical pedagogy in VEs; thus the guidelines chosen for the
evaluation of VRMin have a focus on interface aspects that
lead to positive user experiences for learning in a VE. For
the sake of brevity we will not go into full detail about
each guideline, we save that for future work as we reﬁne the
guidelines (we also direct you to the references for more de-
tail about a speciﬁc guideline). Instead we discuss the high
level guidelines we’ve found most important for the task
of learning musical concepts and mention the supporting
guidelines.
First we must make the distinction between two types of
feedback for learning systems, performance feedback and in-
terface feedback. Performance Feedback relates to the feed-
back given to a user to based on an analysis or their musical
performance. This type of feedback is analogous to the feed-
back a music teacher would give while watching a student
perform a scale. While interface feedback is feedback pre-
sented to a user based on the results of a given interaction
with interface elements. An example of interface feedback is
a visual signiﬁer indicating that an action, such as loading
a new score, was successful.
Based on the research discussed in 1.4 and our experience
designing VRMin, we have established the following cate-
gories of design guidelines for VR based musical pedagogy
systems.
1. Guidelines for performance feedback- these guide-
lines help design performance feedback that optimizes
learning and minimizes the over reliance on feedback
[5].
154
(a) Visual feedback shouldn’t prevent a user from fo-
cusing on aural feedback
(b) Reduce cognitive load by limiting the amount of
concurrent feedback [5]
(c) Provide terminal performance feedback upon com-
pletion of the practice task [5]
2. Guidelines for VE design - these guidelines are
used to guide design decisions about the VE for the
practice space promoting an enriching and comfort-
able experience. A properly environment also increases
the usablity of the virtual interface.
(a) Visibility of system status [17]
(b) Choose metaphor(s) that naturally match the ap-
plication task space [3]
(c) Match between system and the real world [17]
(d) Create a Sense of Presence [22]
(e) Consider Display Ergonomics [22]
(f) Consider Controller Ergonomics
(g) Represent the Player’s Body [22]
(h) Ensure that users’ avatars provide a familiar, ac-
curate, and relevant frame of reference [3]
(i) Allow users to alter point of view, or viewpoint
[3]
3. Guidelines for interaction in VR pedagogy -
while some interaction with the interface may be re-
quired during practice it should be limited to reduce
user’s cognitive load aﬀording more mental capacity
for learning new skills.
(a) Limit nonessential interaction during practice
(b) Recognition rather than recall [17]
(c) Make use of existing skill [22]
3.1 Findings
Performing an heuristic evaluation requires a user task to
guide the evaluation of the interface. For this case study we
use an ear training practice task for beginning thereminists.
During the practice session VRMin plays an aural tone of
a speciﬁc pitch according to the practice score. The user’s
goal is to match the the pitch by moving their hand to
the correct location relative to the pitch antenna. While
wearing the VRMin display the user is presented with visual
signiﬁers to help guide them to the correct location. Some
initial ﬁndings from applying an HE while performing the
practice session are listed in table 1.
3.2 Discussion
By performing evaluation on VRMin using the above heuris-
tics we have identiﬁed several potential design issues. Fur-
thermore, we have established new questions about the VE
to be answered through a formal usability study. Below we
discuss the design issues listed in table 1 that we feel are
most important to address either through interface changes
or through usability studies.
First, design guideline 1.c suggests to provide terminal
feedback upon completion of the practice task. Currently
VRMin does not provide terminal feedback to the user after
the practice session. This can be addressed by designing a
new view to include data from the performance loggling
simliar to the charts ﬁgure 3. One question that arises is
how best to present this data to the student. Should the
visualization be presented directly in the VE or would it be
Table 1: Findings from a Heuristic Evaluation (ital-
ics indicate a potential design issue)
ID Comments
1.a By trying to match the position of the hand to a
visual element a user’s attention is directed to the
visual feedback rather than the auditory feedback
from the theremin.
1.b Performance feedback during practice is limited
to one element at at time.
1.c Performance analysis graphs are available but are
not integrated into the VRMin interface
2.b All current interaction is performed using the only
the theremin. Also the piano roll is a common
2.d Presence is promoted by matching the real world
to the VE and by integrating real objects with
virtual objects.
2.e The Google Daydream is a comfortable display
but has a small ﬁeld of view making it diﬃcult to
view the aspects of the theremin that happen to be
in the periphery
2.h The hands are in postures used by a number of
renowned thereminists but not all thereminists
use the same hand posture.
3.a After starting a practice session there are no ad-
ditional interactions required that are not directly
tied to practice.
best to allow the student to view and analyze the data on
a standard display? Additionally it would be interesting to
ﬁnd new visualization methods that take advantage of the
visual aﬀordances of VR.
Contrary to guideline 2.h, the hand postures of the virtual
hands in VRMin are static and do not necessarily represent
how a student may pose their hand during their perfor-
mance. While we choose a hand posture that is commonly
used, there are multiple techniques with varying hand pos-
tures. To ensure that the virtual hands provide an accurate
representation of the user we plan to modify the interface
so the user is able to change hand posture to reﬂect their
playing style. An alternative would be to implement robust
hand tracking which would require an additional sensor be
added to the system, such as the Leap Motion. We prefer
not to increase complexity unless it shown that exact real
to virtual mapping improves the learning process.
Finally the most signiﬁcant design challenge (as is the
case with any pedagogical system) will be ﬁnding the proper
balance of performance feedback to minimize the chance of
users becoming over reliant on feedback. While performing
pitch matching, one of the authors felt that his attention
was focused more on adapting hand position based on the
visual cues rather than focusing on the auditory feedback
of the theremin. This required the user to expend cognition
that could have been used to focus on listening to diﬀerence
in pitch. The visual feedback does, however, provide valu-
able information for those that have trouble hearing pitch.
By placing cues where hands should be located for given
pitches, the user can be conﬁdent that they are playing the
correct pitch, increasing the eﬃciency of their practice. It
has yet to be seen how the extra strain on cognitive load
from visual feedback aﬀects students’ growth over time. As
a user gains experience with the interface the increased prac-
tice eﬃciency may compensate for the high cognitive load
in the beginning. Finding the proper balance will take a
comprehensive user study that evaluates students’ growth
over time with and without VRMin.
155
4. CONCLUSION
This paper describes the design and formative evaluation
of VRMin, a mixed reality environment for learning the
theremin. Speciﬁcally our work focuses on designing a sys-
tem using the visual aﬀordances of MR for enhanced theremin
practice while minimizing the reliance of feedback. With
this goal in mind, we have established a set of design guide-
lines for heuristic evaluation of MR environments for mu-
sical pedagogy. Using these guidelines we performed an
evaluation of VRMin to uncover potential design issues in
the environment. The issues will either be addressed di-
rectly through design modiﬁcations or will require a more
formal usability study to better understand their eﬀects on
the learning process. While we have presented VRMin as a
tool for pedagogy, the system also lays the foundations for
an MR environment for musical expression.
Our initial evaluation of VRMin taught us that the at-
tention spent focusing on the visual feedback increases the
cognitive load during practice making it more diﬃcult to fo-
cus on aural feedback leading to the potential of a student
becoming over reliant on VRMin. The data from ﬁgure
3, however, indicates that the time spent practicing with
VRMin may be more eﬃcient for the student. To better
understand the eﬀects of real-time visual feedback in this
sense we plan to perform a user study in which users will
attempt to learn the theremin with diﬀerent conﬁguration
of the VRMin environment including one without the use
of visual augmentation through VR.
5. REFERENCES
[1] D. F. Berthaut, M. Desainte-Catherine, and
M. Hachet. Interacting with 3d reactive widgets for
musical performance. Journal of New Music Research ,
40(3):253–263, 2011.
[2] N. B ¨ottcher, S. Gelineck, L. Martinussen, and
S. Seraﬁn. Virtual reality instruments capable of
changing physical dimensions in real-time. Proc.
Enactive, 2005.
[3] J. L. Gabbard. A taxonomy of usability characteristics
in virtual environments . PhD thesis, Virginia
Polytechnic Institute and State University, 1997.
[4] J. L. Gabbard, D. Hix, and J. E. Swan. User-centered
design and evaluation of virtual environments. IEEE
Computer Graphics and Applications , 19(6):51–59,
Nov 1999.
[5] R. Hatala, D. A. Cook, B. Zendejas, S. J. Hamstra,
and R. Brydges. Feedback for simulation-based
procedural skills training: a meta-analysis and critical
narrative synthesis. Advances in Health Sciences
Education, 19(2):251–272, 2014.
[6] F. Huang, Y. Zhou, Y. Yu, Z. Wang, and S. Du.
Piano ar: A markerless augmented reality based piano
teaching system. In Intelligent Human-Machine
Systems and Cybernetics (IHMSC), 2011 Int.
Conference on, volume 2, pages 47–52, Aug 2011.
[7] D. Johnson, I. Dufour, G. Tzanetakis, and
D. Damien. Detecting pianist hand posture mistakes
for virtual piano tutoring. In Proc. of the Int.
Computer Music Conference, 2016.
[8] S. Jord` a. Digital instruments and players: part
i—eﬃciency and apprenticeship. In Proc. of the 2004
conference on NIME, 2004.
[9] J. Lanier. The sound of one hand.
http://www.jaronlanier.com/vr.html. Online;
Accessed: 2016-12-05.
[10] H. Leeuw. The electrumpet , a hybrid electro-acoustic
instrument. In Proc. of the 2009 Conference on
NIME, 2009.
[11] F. Liarokapis. Augmented Reality Scenarios for
Guitar Learning. In L. M. Lever and M. McDerby,
editors, EG UK Theory and Practice of Computer
Graphics. The Eurographics Association, 2005.
[12] T. Machover and J. T. Chung. Hyperinstruments:
Musically intelligent and interactive performance and
creativity systems. In Proc. of the Int. Computer
Music Conference, 1989.
[13] T. M ¨aki-Patola, J. Laitinen, A. Kanerva, and
T. Takala. Experiments with virtual reality
instruments. In Proc. of the 2005 Conference on
NIME, 2005.
[14] P. Milgram, H. Takemura, A. Utsumi, and F. Kishino.
Augmented reality: A class of displays on the
reality-virtuality continuum. In Photonics for
industrial applications, pages 282–292. International
Society for Optics and Photonics, 1995.
[15] A. G. Moore, M. J. Howell, A. W. Stiles, N. S.
Herrera, and R. P. McMahan. Wedge: A musical
interface for building and playing
composition-appropriate immersive environments. In
2015 IEEE Symposium on 3D User Interfaces .
[16] J. Mora, W. s. Lee, G. Comeau, S. Shirmohammadi,
and A. E. Saddik. Assisted piano pedagogy through
3d visualization of piano playing. In 2006 IEEE
International Workshop on Haptic Audio Visual
Environments and their Applications , pages 157–160,
2006.
[17] J. Nielsen. 10 usability heuristics for user interface
design. https://www.nngroup.com/articles/
ten-usability-heuristics/. Accessed: 2017-01-28.
[18] J. Nielsen and R. Molich. Heuristic evaluation of user
interfaces. In Proc. of the SIGCHI Conference on
Human Factors in Computing Systems , CHI ’90,
pages 249–256, New York, NY, USA, 1990. ACM.
[19] D. Overholt. The overtone violin. In Proc. of the 2005
Conference on NIME, 2005.
[20] J. A. Paradiso and N. Gershenfeld. Musical
applications of electric ﬁeld sensing. Computer music
journal, 21(2):69–89, 1997.
[21] G. Percival, Y. Wang, and G. Tzanetakis. Eﬀective
use of multimedia for computer-assisted musical
instrument tutoring. In Proc. of the Int. Workshop on
Educational Multimedia and Multimedia Education ,
pages 67–76, NY, USA, 2007. ACM.
[22] S. Seraﬁn, C. Erkut, J. Kojs, N. C. Nilsson, and
R. Nordahl. Virtual reality musical instruments: State
of the art, design principles, and future directions.
Computer Music Journal , 41(2), 2016.
[23] S. Trail, M. Dean, G. Odowichuck, T. F. Tavares,
P. F. Driessen, W. A. Schloss, and G. Tzanetakis.
Non-invasive sensing and gesture control for pitched
percussion hyper-instruments using the kinect. In
Proc. of the 2012 Conference on NIME , 2012.
[24] S. Weinschenk and D. T. Barker. Designing Eﬀective
Speech Interfaces. John Wiley & Sons, Inc., New
York, NY, USA, 2000.
[25] D. Young. The hyperbow controller: Real-time
dynamics measurement of violin performance. In
Proc. of the 2002 Conference on NIME , 2002.
156