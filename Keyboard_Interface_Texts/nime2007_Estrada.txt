Loop-R: real-time video interface
Rui
Pereira
Estrada do Turismo s/nº
5300-271 Bragança
+351 919 508 215
rux.pgp@gmail.com
ABSTRACT
Loop-R  is  a  real-time  video  performance  tool,  based  in  the 
exploration  of  low-tech,  used  technology  and  human 
engineering research.  With this tool its author is giving a shout 
to  industry,  using  existing  and  mistreated  technology  in 
innovative  ways,  combining concepts  and interfaces:  blending 
segregated  interfaces  (GUI  and  Physical)  into  one.  After 
graspable  interfaces  and  the  “end” of  WIMP  interfaces, 
hardware  and  software  blend  themselves  in  a  new  genre 
providing  free control  of video-loops  in an expressive  hybrid 
tool. 
Keywords
Real-time; video; interface; live-visuals; loop; 
1. INTRODUCTION
The main goal of this project was to study the activity of vj’ing 
in the way of controlling previously created media, small pieces 
of  video  (video-loops),  in  real-time  and  to  use  this  research 
results  in the conceptualization  and construction  of an hybrid 
software and hardware controller. This would  reflect the users 
needs  and  should  try  to  provide  as  less  psychological  and 
physical distress in this system’s operation and to be as much 
intuitive as possible. This interface can be seen as a toy, trying 
to  escape  complex  interfaces  and  systems  though  easily 
providing full control of the media.
2. WHY?
Direct  manipulation  and  The  Wimp  interfaces  are  past, their 
objective  was  lost  in  the  increasing  amount  of  graphical 
interface widgets, continuously  popping and moving windows, 
ancient and generalized input interfaces and, so: the lost of the 
main object of interest in the interaction.  
For a long time,  VJ softwares have been provided filled with 
features but many times forgetting the user that would control 
them and expecting those users to acquire a whole new set of 
hardware  tools  such  as  standard  midi-controllers;  the  users 
would have to adapt themselves to generalized hardware, mostly 
designed  for  audio  applications,  boxes  filled  with  knobs  and 
keyboards,  forcing  themselves  to memorize  the  locations  and 
attributes of each of these knobs or keys with no relation to the 
next or previous widget. 
Based on different approaches to interface design, this project 
tends  to  blend  valuable  principles  from  graspable  interfaces 
theories[1]  but also to post-wimp interfaces [2]  and bi-manual 
input  interaction.  Also  performance  modes  of  interaction  and 
Exploratory  operation  techniques  are  taken  advantage  of, 
allowing  the  user  to  explore  the  interface  and  different 
controllers positions and combinations with no risks or dangers 
and having immediate feedbacks from the system. 
The  combination  and  blending  of  the  GUI  with  the  physical 
interface is done in ways of allowing the user to instinctively 
know  which  feature  is  controlled  by  which  interface  device; 
besides the natural mapping also the physical constraints of the 
interface devices are taken into account when attributing them to 
the application features.
Assumed as a DIY project  the limits  were only the available 
technology on the market and the builder's budget.
It is also an attitude towards the non-development of specific 
and dedicated solutions by the industry and its feeble response 
to the vj’s needs.
Both seen as a creative process and the continued study of the 
activity  and  its  needs,  demands  and  efforts  from  a  user's 
perspective, this project has grown from a theory/practical essay 
and conceptualization into a functional prototype, currently used 
as a tool  for  vj'ing  and real-time  video  control  performances 
such as theater plays and presentations. 
3. LOOP-R DESCRIPTION
3.1 Vj’ing activity premises
As a performance activity, vj'ing demands ease on the control of 
multiple parameters simultaneously and on the fly, intuitive and 
natural gestures reflected as commands,  natural mappings and 
appropriate constraints to the actions.  As an instrumental real-
time control interface, loop-R provides:
-No fixed ordering in the human-computer dialogue;
-Human controls <–> Computer reacts;
-Continuous  and  immediate  controls  rather  than  menus,  sub-
menus and intermediate and confirmation widgets and dialogue 
boxes;
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made  or distributed  for profit or commercial advantage  and  that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, or republish,  to post on  servers or to redistribute  to  lists, 
requires prior specific permission and/or a fee.
NIM E07 , June 7-9, 2007, New York, NY
Copyright remains with the author(s).
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
411
-Overall control by the user with possible automation features;
-Hybrid device (coordinated Physical and graphical interfaces) 
providing simultaneous multi-parametric control;
-Easily  learnable,  by  practicing  the  user  develops  further 
intimacy with the system;
-Cognitive  freedom  for  the  user,  providing  low  cognitive 
distress while operating the system;
-Matching device structure with perceptual structure of the tasks 
involved;
3.2 System description
Combining  both  hardware  and  software  forces  and  taking 
advantage of their own features, each Loop-R’s module has been 
designed bearing in mind the activity and expression needs and 
the input and output characteristics  of the used hardware and 
software.  Each feature is directly activated and controlled by a 
correspondent interface control, with no intermediate menus or 
need for confirmation of the choices/actions.
Figure 1 - Loop-R  - topview
3.2.1 Library Module
Extended and user-expandable Library featuring customizable 
sub-category organization, page navigation plus thumbnail 
preview and name labeling for each video loop. This way, the 
user can organize and preview each and any piece of media 
directly from the interface, the choice and activation of each. 
media piece is direct, just by touching the previewed thumbnail. 
Directly positioned above the the editing module and its preview 
screen creates a direct relationship of the controls involve.
Figure 2 - Library Module
3.2.2 Edit Module
Regarding the media’s timeline as an horizontal representation, 
a  line  in  time,  its  attributes  are  naturally  controlled  by  two 
physical horizontal sliders, which  provide start and end points 
for  selections.  Therefore,  and  despite  having  visual  feedback 
from the graphical representation of the timeline placed directly 
above the physical sliders, the user has also an accurate tactile 
feedback of the selection. The speed and direction attributes of 
the  media  are  controllable  by  a  jog  dial  which  incorporates 
pause,  speed  and  direction   features  into  its  actions:  when 
positioned  at 0º the media  is paused,  rotating  it to each side 
provides positive or negative speed of the loop. 
Figure 3 - Edit Module
3.2.3 Effects Module
Choose effects seeing their previews on the video you’re using 
through  Effects  thumbnails  buttons.  Providing   independent 
physical  controllers / knobs for each effect channels parameter, 
loop-R  lets  the  user  freely  control  and  express  each  effect 
through  3  parameters.  Effects  can  also  be  automated  using 
Oscillators  – wave  generators  and,  so,  allowing  the  user  to 
“beat-match” effects and them dedicate himself to other parts of 
his composition.
Figure 4 - Effects Module
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
412
3.2.4 Mixing Module
The mixing between the two video decks can be made through a 
smaller  horizontal  slider,  in  which  its  position  is  directly 
connected to the intensity of each video deck, so, positioned to 
the further  left the left  deck will  have 100% opacity and the 
right  side  deck  its  full  transparency.  Besides  the  ability  to 
choose from  different  mix modes,  the keying modes  (chroma 
and luma) can be easily controlled through color maps: allowing 
the  user  to  directly  select  the  “keyable” saturation  and 
luminosity by choosing the color itself and not dwelling with 
inﬁnite and abstract parameters.
Figure 5 - Mixing Module
3.2.5 Automation Module
Some features can be automated using two independent  wave 
generators  with  four  different  wave  modes  (sine,  square, 
sawtooth, random) directly selected from GUI buttons,  an extra 
wave draw-mode is available allowing the user to draw a wave 
in a GUI surface and thus creating  a personalized automation 
feature.  Each  wave  generator  has  its  knob  to  control  its 
frequency,  allowing the user  to freely  and directly  control  its 
features. The frequency can also be controlled by means of the 
users body motion; a Tap Tempo surface, placed in the ground, 
allows the user to match the beat of the music with his beating 
foot, freeing the user’s hands to control other features and taking 
advantage  of  the  feet  – a  rhythmically  very  important  and 
trustful part of our body.
Figure 6 - Automation Module
3.2.6 Correction Module
Color  correction  control   is  provided  through  4  exclusive 
vertical graphic sliders for Brightness, Contrast, Saturation and 
Hue. Perspective and Detail browsing are also provided through 
panning and 3D rotation controls; a 2d surface (X,Y axis) and an 
extra slider (Z axis) provide natural control and positioning of 
the image in space.
Figure 7 - Correction Module
4. CONCLUSIONS
As an integrated visual media instrument, Loop-r denies the use 
of  generalized  physical  interfaces  (mouse,  keyboard, 
standardized  midi  controllers)  providing  dedicated  interface 
devices  to  control  each  of  the  media  characteristics:  each 
physical  controller  has  a  close  spatial  placement  to  the 
correspondent  GUI  controls  and  feedbacks,  and  a  natural 
behavior regarding the features it controls.  The nature of the 
actions and the constraints of the interface widgets was taken 
into account in the placement and attribution to the controlled 
features.
Thus  this is an hybrid tool, mixing and blending two distinct, 
and many times segregated, aspects of the interface design such 
as the GUI and the physical controllers for a more rich and 
natural control and expression of the media in the context of 
real-time performance.
5. PROJECT STATUS
The  Loop-R  video  interface  was  built  using  2nd hand/used 
electronic parts: 10.4”  TFT + touchscreen and a disassembled 
Doepfer  Midi  controller.  Loop-R  software  is  currently  built 
using Isadora (www.TroikaTronix.com).
As  this  is  an  evolving  project  some  graphic  and  functional 
features  might  not  be  available  as  shown  in  the  3d  preview 
model. This might also be due  to limitations of some parts used 
and/or software GUI elements.
Loop-R is currently on its way to be replaced by Looop-R, a  2nd 
version featuring a whole  new hardware and software platform. 
Among  its  new  features:  bigger  touch  surface,  3  video 
decks/players/libraries,  GUI  re-design;  longer  sliders;  4 
dedicated  parameter controllers  per effect,  3 automation wave 
generators, wave generator draw mode, media sequencer, color 
correction  and  3d  and  2d  space  positioning  of  each  clip.
Features still currently missing:
- color picker for luma and chroma mixing modes only 
available as a 2 dimensional slider (no color map)
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
413
6.ACKNOWLEDGMENTS
My thanks to W. Buxton,  D. Norman,  G. Fitzmaurice  for the 
inspiration  and  shared  knowledge.  Also  thanks  to  the  VJ 
community,  Vj  Forums,  Mark  Coniglio  and  the  Isadora 
community. My mother Luisa, my sisters Ana and Carmo, my 
love  Petra  and  all  my  friends  who  shared  my  excitement, 
exhaustion and happiness during this process.
7.REFERENCES
[1] Fitzmaurice,G. , Ishii, H. , Buxton,W. Laying the 
Foundations for Graspable User Interfaces. In 
Proceedings ACM Human Factors in Computing Systems 
(CHI’95) . ACM Press.
[2] Beaudouin-Lafon, M. Instrumental Interaction: An 
Interaction Model for Designing Post-Wimp Interfaces. 
In Proceedings of the SIGCHI conference on Human 
factors in computing systems (CHI ’00) . ACM Press. 
[3] Norman,D.A. and Draper, S. W. There’s More to Interaction 
than Meets the Eye: Some Issues in Manual Input.  
Lawrence Erlbaum Associates, Hillsdale, New Jersey, 319-
337, 1986
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
414