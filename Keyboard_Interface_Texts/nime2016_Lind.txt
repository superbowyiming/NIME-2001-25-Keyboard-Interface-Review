Mapping Everyday Objects to Digital Materiality in The Wheel Quintet: Polytempic Music and Participatory Art     Anders Lind              Daniel Nylén  Department of Creative Studies         Swedish Center for Digital Innovation   Teacher Education            Department of Informatics Umeå University              Umeå University S-901 87 Umeå, Sweden           S-901 87 Umeå, Sweden anders.lind@umu.se            daniel.nylen@umu.se   ABSTRACT Digitalization has enabled material decoupling of sound from the physical devices traditionally used to conceive it. This paper reports an artistic exploration of novel mappings between everyday objects and digital sound. The Wheel Quintet – a novel musical instrument comprising four bicycle wheels and a skateboard – was created using off-the-shelf components and visual programming in Max/MSP. The use of everyday objects sought to enable people to quickly master the instrument, regardless of their musical backgrounds, and collectively create polytempic musical textures in a participatory art context. Applying an action research approach, the paper examines in detail two key cycles of planning, action, and analysis related to the instrument, involving an interactive museum exhibition open to the public and a concert hall performance conducted by an animated music notation system. Drawing on insights from the study, the paper contributes new knowledge concerning the creation and use of novel interfaces for music composition and performance enabled by digitalization.   Author Keywords Digital materiality, physical materiality, music composition and performance, participatory art, polytempic music.  ACM Classification Human-centered computing~Haptic devices Applied computing~Sound and music computing Hardware~Sensors and actuators  
 Figure 1. The wheel quintet demonstrated by the first author. 
 1. INTRODUCTION The term polytempo is used to describe music in which two or more different tempi occur simultaneously [6]. Well-known examples of composers who have used polytempic textures include Karlheinz Stockhausen, Pierre Boulez, Henry Brant, György Ligeti, Conlon Nancarrow, and John MacCallum. Traditional musical instruments typically require performers to have acquired significant skills to be able to compose and collectively perform any type of musical piece, but the composition and performance of musical pieces with polytempic textures requires particularly highly trained and skilled musicians. However, due to large-scale pervasive digitalization, sound as a form of content is being increasingly decoupled from the physical materiality of traditional musical instruments [18; 24], opening new possibilities for utilizing less complex physical artifacts as input and output devices. Indeed, while traditional musical instruments offer rich possibilities for music composition and performance, established performance traditions may also constrain the development of new musical expressions. To counter some of these limitations, novel mappings of physical artifacts and digital sound could potentially be used. While devices such as smartphones and tablets enable new ways of interacting with sound, the input and output modalities (e.g. touch-screens) associated with these devices typically fail to fully capture the experience of interacting with traditional musical instruments. That loss of embodied aspects is unfortunate since the tangible physical components of traditional musical instruments comprise a vital part of the interaction patterns and overall experience of music composition and performance [8].   Research into new interfaces of musical expressions has investigated ways of overcoming this loss through leveraging the decoupling of content and form for novel recouplings of digital and physical materialities in various ways [see, for example, 3; 5; 19]. However, a general shortcoming of this research is a tendency to focus on the novelty of a technical design and its potentials while overlooking collaborative artistic processes and outcomes that occur as instruments are used in situ. This raises a question that has been insufficiently considered: How can digital sound be recoupled with traditional physical artifacts in order to facilitate intuitive and embodied experiences of composing and performing polytempic musical textures?  To address this question, we draw on an applied artistic research investigation (conducted by the first author) of new ways of mapping everyday objects to digital sound. We follow the construction and use of a musical instrument called The Wheel Quintet (see Figure 1), comprising five stations, including four bicycle wheels and a skateboard. In creating the instrument, the first author used off-the-shelf hardware components and visual programming in Max/MSP. Everyday objects were used in seeking to enable people with highly 
84
varying musical backgrounds to swiftly master the instrument. The quintet concept, with multiple stations, was chosen to facilitate collective creation of polytempic musical textures through participatory art. The artistic research study applied an action research approach based on work by Lewin [12]. This paper reports the evolution of two cycles of planning, action, and analysis involving an interactive museum exhibition open to the public (where museum visitors were encouraged to take part in exploring the instrument) and a concert hall performance that involved around 200 non-professional singers and was conducted by an animated music notation system.  Our findings reveal how spontaneous use of the Wheel Quintet instrument emerged during the museum exhibition (producing advanced and unique polytempic musical textures) and how it was implemented in the concert hall performance of a large-scale contemporary art music composition. We also highlight some of the key challenges that arose during the process and how they were addressed. Based on these findings, the paper generates new knowledge concerning how novel interfaces for musical composition and performance can be created and used. In particular, we illuminate the important roles of generativity during such processes. 2. DIGITAL MATERIALITY, PARTICIPATORY ART, AND POLYTEMPIC MUSIC Large-scale pervasive digitalization has enabled the decoupling of any form of content (text, sound, images, video) from the physical materiality of the services and devices used to produce and consume it [18; 24]. In this context, the term digital materiality refers to the purely digital aspects of an artifact, such as a file or software that are intangible (cannot be touched). While digital materiality is argued to render artifacts more fluid and boundless [9; 24], these aspects are not purely conceptual. Rather, they fundamentally afford or constrain human action and shape the character of user interactions [11]. A key property of digital materiality that can partly explain the fluid and boundless character of digital artifacts is reprogrammability – “the ability of a digitalized artifact to accept new sets of logic (instructions) to modify its behaviors and functions” [23, p. 231]. In this way, the embedding of software in traditional physical artifacts is frequently used as a way of controlling their behaviors [17].  An emerging body of research has generated valuable insights regarding new interfaces for musical expression through exploring novel mappings between digital sound and movement [5], tangible interaction [19] or traditional physical objects [3], and how interaction rules can facilitate intuitive music composition and performance [15]. In the past, engineers and technical experts mainly constructed such devices. However, reductions in costs and increases in availability of components such as touch screens, motion sensors, and haptic feedback devices on the consumer market have enabled technical non-experts with (for example) artistic backgrounds to construct various technical artifacts that enable increasingly embodied interactions. In this way, scholars have argued that digital artifacts exhibit increased levels of generativity [24], defined as “a technology’s overall capacity to produce unprompted change, driven by large, varied, and uncoordinated audiences” [25, p. 1977].  Participatory art seeks to tap into such generative mechanisms. It refers to artistic work that includes “interactive, relational, cooperative, activist, dialogical, and community-based” elements [4]. Scholars have argued that it is an art form that requires the audience to participate in the artwork itself or a performance of it; not merely for it to function properly, but because the work does not become meaningful until participants interact with it [16]. Participatory art does not require participants to have any domain-specific knowledge. Rather, the artist creates a platform that serves as a basic structure, which participants utilize in creating outcomes that the artist cannot completely control or predict. 
 Participatory art seeks to encourage citizens and non-artists to interact with professional artists to create artistic works [4]. In this way, an artifact such as The Wheel Quintet becomes a participatory art object when people interact with it. Specifically, The Wheel Quintet was developed to enable people with any musical background to perform, and encourage multiple actors to perform collectively. A key objective in creating the instrument was to simplify the interactions with the instrument while maintaining high artistic ambition.  The term polytempo refers to musical compositions in which two or more different tempi occur simultaneously [6], hence “Creating polytempic music means to apply the compositional techniques and concepts of polyphony (i.e. the independence of parts) also to the parameter of tempo” [10, p. 532]. A classic example is Gruppen (1955-1957) by Karlheinz Stockhausen (1928-2007), where the orchestra is divided into three sections, which are conducted simultaneously by three different human conductors. The setting with multiple conductors enabled Stockhausen to explore different aspects of polytempic textures. Meanwhile, composers such as Henry Brant (1913-2008) and Conlon Nancarrow (1912-1997) incorporated polytempic textures in several of their compositions. Highlights of their respective work include Brant’s Desert Forests: Spatial Panoramas for Separated Orchestral Groups (1983), where different tempi occur simultaneously throughout the composition, and Nancarrow’s Study no. 37 for Player Piano (1960), which is a twelve voice canon including twelve different tempi. More recently, polytempic textures have been explored in John MacCallum’s compositions and writings [see, for example, 1; 14].  The first author had previously composed pieces inspired by the concept of using multiple conductors1. For example, he created a visual electronic multi-conductor in Max/MSP that conducted his piece “Music for Chamber Ensemble and Five Electronic Conductors”. During the performance the visual multi-conductor was displayed on several computer screens to enable polytempic textures to be performed. However, with the Wheel Quintet he sought to create a dedicated instrument for this musical concept to deepen the exploration. A further aim was to invite the general public not only to discover polytempic music, but also participate in the process of conceiving and performing it. 3. RESEARCH METHODOLOGY The research reported in this paper draws on insights generated through a broader artistic research project entitled Voices of Umeå (See Appendix) informed by a participatory art perspective. The project was geared towards creating novel musical instruments, tools, and techniques that could be used by performers with various musical backgrounds to explore new possibilities for contemporary art music composition and performance. The artistic outputs and publications created within the Voices of Umeå project included concerts, the development of an animated music notation system (findings are reported in [13]), two interactive voice recording instruments (findings are reported in [21]) and three interactive instruments. The Wheel Quintet was one of these three instruments.  The research approach applied can be broadly characterized as artistic [e.g. 7], since it utilized experience, knowledge and skills of the individual artist/researcher, while at the same time sought to contribute new knowledge to the domain of artistic research and practice. More specifically, action research                                                                     1 Lind, Anders. 2009. Music for Chamber Ensemble and Five Electronic Conductors. https://www.youtube.com/watch?v=e_l97ND1kvE   Lind, Anders. 2012. Fire Alarms and Orchestra.  https://www.youtube.com/watch?v=9oS2opLMEbo  
85
methodology based on work by Lewin [12], was applied. The action research process evolves in cycles, each of which includes three key steps: planning, action, and analysis. Consequently, in a project with multiple cycles, the conclusions drawn from one cycle inform the next. The action research approach was chosen since it corresponded well with the first author’s exploratory approach, while also providing support for the artistic process.   To date, the Wheel Quintet has been subjected to four cycles, each associated with a specific implementation involving active participation of various forms of audiences: (1) Interactive museum exhibition: Singing Instruments!! at Västerbottens Museum in Umeå, Sweden;  (2) Concert hall performance: Everybody Scream!!! At Norrlandsoperan in Umeå, Sweden; (3) Interactive museum exhibition: Singing Instruments!! at Felleshus in Berlin, Germany; (4) Concert hall performance: Spin n´ Play at the Center for New Music, San Francisco, CA, USA.   In this paper, we focus on the first two cycles and the main process whereby the Wheel Quintet instrument was created.  4. FINDINGS 4.1 Interactive Museum Exhibition (First Cycle) The planning step of the first cycle was guided by the following question that informed development of the Wheel Quintet instrument: How can an intuitive music instrument be developed that: first-time users can quickly master, encourages new musical expressions, and facilitates participatory art? The initial idea was to use everyday objects and map their associated interaction modalities, behaviors, and symbolic meanings with musical parameters. Inspired by the work of composers, musicians, and researchers such as Perry Cook [e.g. 2] and Gary Scavone [e.g. 20], the first author argued that using everyday objects as physical controllers for musical sounds could provide a useful starting point for two reasons. Firstly, their use as musical instruments could provide a means for enabling people, regardless of their musical backgrounds, to master the instruments when they first encountered them, and hence participate. Secondly, from an artistic perspective, the absence of performance tradition rooted in everyday objects (as opposed to, for example, a guitar or a piano) was deemed likely to inspire and contribute to the development of new musical expressions.  Having considered an array of everyday objects to utilize, the first author finally settled on bicycle wheels and skateboards. Wheels were perceived as particularly interesting due to their association with the concepts of motion and speed, which could be connected with relative ease to the musical parameters of rhythm and tempo. In particular, the idea of mapping the circular motion to tempo control was perceived as a new and unique approach to a musical controller. Hence, the first author decided to focus on these two fundamental musical parameters when setting out to create for the Wheel Quintet. From an artistic perspective, introducing constraints by delimiting control to two musical parameters was deemed likely to inspire and facilitate innovative use and result in new artistic expressions.  Given the objective of generating participatory art, the first author decided to structure and name the instrument after a well-established kind of musical ensemble. Settling on the concept of a quintet, the decision was made to construct an instrument with five stations, comprising four bicycle wheels and a skateboard, and call it the Wheel Quintet (see Figure 1). In addition to the focus on rhythm and tempo, what had 
emerged as the Wheel Quintet on a conceptual level at this point provided an excellent opportunity to explore the concept of polytempic music. The next step was to examine how the concept could be materialized and technically implemented.  
 Figure 2. Schematic diagram of the Wheel Quintet  Firstly, the objects’ movements needed to be encoded into digital information. For this, digital reed sensors and magnets were deemed most appropriate (see Figure 2). As users initiate movement of the wheels (1) they trigger sounds and thus serve as the instrument’s main controller interfaces. Two to three magnets are attached to each of the four bicycle wheels and the four wheels of the skateboard. When wheels start spinning the reed sensors send signals as magnets pass beside them. A control panel (2) attached to each station enables the user to select different sounds and apply additional sound processing. The control panels include three buttons, five LED lights, and two potentiometers. The buttons allow the performer to switch between three different sounds, switch from rhythm to tempo mode, and enable/disable a random pitch effect. The LEDs show which buttons are activated and the two potentiometers allow the performer to adjust volume and pitch.  Signals from both the reed sensors and control panels are routed via an Arduino board (3) to a USB port of a Mac mini (4), then into a stand-alone application coded using the visual programming language Max/MSP and transformed into musical actions. When the application detects signals it plays the selected sounds from the control panel (see Figure 3).   
Figure 3. Example of a subpatch from the Max/MSP stand-alone application. 
86
The Max/MSP application puts out the sounds through a M-AUDIO ProFire 2626 multichannel soundcard (5), enabling five separate audio outputs (one for each of the four wheels and the skateboard), and a dedicated M-AUDIO BX5 D2 monitor speaker (6) for each of the five stations. The first two cycles of the Wheel Quintet utilized vocal sounds recorded by citizens (of Umeå, Sweden) through the Voice Harvester  – an interactive voice recording installation (see [21]) that was developed within the Voices of Umeå project. By interacting with the installation, citizens used their own voices to create and record non-linguistic, abstract, organic, and expressive sounds. Out of these, the first author processed a selective amount of short and percussive sounds.   In this first cycle, the action step occurred when the instrument was first displayed to the public in an interactive music exhibition called Voices of Umeå Part II: Singing Instruments!! The exhibition ran from 29th September to 24th November, 2013, at Västerbottens Museum in Umeå, Sweden. During the exhibition period, people with highly varying musical backgrounds interacted with the Wheel Quintet. By effectively performing as they used the instrument, The Wheel Quintet was enacted as a piece of participatory art. By spinning the wheels and mixing the electronic sounds using the control panels, museum visitors performed with the instrument. Different rhythmic patterns were created by spinning the wheels at various speeds. As multiple visitors used the multiple stations simultaneously, spinning several wheels simultaneously at different speeds, polytempic music was created. In addition, unique rhythms could be created manually by pulling the wheels back and forth in a rhythm (similar to “scratching” a vinyl record).  In addition to interactions and performances by museum visitors, the first author further explored the artistic potential of the instrument to create polytempic textures from his composer perspective. Moreover, school classes (with pupils ranging from 9 to 16 years old) participated in a series of four 50-minute workshops, supervised by music teacher students and the first author, to explore the possibility of non-professional musicians performing polytempic music collectively using the Wheel Quintet. To support this venture, a specific graphical score was provided for each station (see Figure 4).  
 Figure 4. Graphical scores used in workshops (in Swedish). Drawing on his first-hand experience, the first author analyzed the planning and actions undertaken in the first cycle that had involved the development and use of the Wheel Quintet in specific settings. During the opening of the exhibition it became clear that some parts of the instruments were weakly constructed and needed to be stabilized. For instance, the magnets were replaced with dedicated bike wheel magnets. The experiences so far had shown that regardless of musical background people were able to both create and perform polytempic music with the Wheel Quintet. From an artistic perspective, the first author argued that the ability to test 
and explore different theoretical composition ideas by physically interacting with the Wheel Quintet and hearing the audible results was a highly rewarding experience. The workshops showed that with only 50 minutes of interaction with the Wheel Quintet non-professional musicians were able to collectively perform complex musical formations including polytempic textures that would be difficult to perform using traditional ensemble or orchestral instruments. The Wheel Quintet seemed to enable performers to rapidly engage in musical interaction and collaboration. Informed by these insights, the next cycle was geared towards further exploration of the possibilities of the Wheel Quintet by using it in the composition process and performance of a large-scale musical piece in front of an audience in a concert hall setting. 4.2 Concert Hall Performance (Second Cycle) In the second cycle, the Wheel Quintet was made a fundamental instrument for one of the movements in the premiere stage performance of the large-scale composition Voices of Umeå: Everybody Scream!!!, involving (in addition to the Wheel Quintet) around 200 non-professional singers and an electronic music part. The main challenge in conducting the piece lay in synchronizing these three components. Accordingly, the planning step of the second cycle was guided by two new questions: (1) How can people with varying musical backgrounds collectively perform polytempic textures with the Wheel Quintet synchronized with additional electronic music content and 200 non-professional singers? (2) How can the process be organized and coordinated in order to achieve this with limited time for rehearsal?  To meet the challenge encapsulated in these questions a novel methodological approach was clearly required. Using a traditional human conductor did not seem a viable option, since none of the performers had any experience of taking instructions from one. Furthermore, a single conductor would not be able to set several different tempi simultaneously, a key requirement to realize the polytempic textures. Having already faced this challenge within the larger scope of the Voices of Umeå project, the first author had created The Max Maestro – an animated music notation system that had helped to overcome this issue, see [13] for an extensive in-depth account and analysis of this system.  
 Figure 5. Animated Music Notation for The Wheel Quintet   
87
 Figure 6. The Wheel Quintet and the animated music notation (The Max Maestro) in the performance of Voices of Umeå: Everybody Scream!!!  While the Max Maestro was primarily developed to enable a large crowd of non-professional singers to perform complex musical textures using their voices, the piece performed in this cycle (Everybody Scream!!!) demanded additional visual output providing instructions to the Wheel Quintet performers (see Figure 5). Thus, in the concert hall the animated notated instructions were projected onto the balcony of the stage (see Figure 6). The instructions (showing which sound to play at a certain volume, and when and how fast to spin the wheel for each of the five performers) were exported from the Max Maestro to a video file, which was synchronized with a second video that contained the animated notated instructions for the singing crowd and the electronic music part.  The action step of the second cycle occurred in May 2014 at Norrlandsoperan (Umeå, Sweden) with the premiere stage performance of Everybody Scream!!! – a piece specifically composed by the first author using the Wheel Quintet. The composition had a total duration of 45 minutes, including eight movements. In addition to the Wheel Quintet, the composition included parts for two other interactive instruments, thousands of recorded and preprocessed voices from the citizens of Umeå, and around 200 non-professional singers using their voices live on stage. The Wheel Quintet was the fundamental input for movement 4, and the instrument’s artistic characteristics were intended to influence the movement’s musical material. Five people with various musical backgrounds, including the head of the music department at Norrlandsoperan, the first author (composer), two music teachers (a singer and a percussionist) and a music teacher student (Umeå University) were set to perform with the Wheel Quintet. All of the five performers could be described as people with various musical skills and knowledge of different musical concepts, but none of them could be described as professional performers dedicated to performing complex contemporary classical music.  Drawing again on his first-hand experience, the first author analyzed the planning and actions undertaken in the second cycle that had involved use of the Wheel Quintet in the composition process and performance of a large-scale composition in a concert hall with non-professional musicians and around 200 singers. From participation in the action step during the second cycle he could answer the two questions formulated in the planning step. First, the performers who used the Wheel Quintet could synchronize their actions with both the electronic music part and the hundreds of non-professional singers, by following instructions from the animated music notation system. Furthermore, the Max Maestro managed to provide instructions for performing polytempic textures throughout the fourth movement. Second, just one hour of rehearsal time was required to prepare for performance of the fourth movement with the Wheel Quintet, using the animated music notation system.  
5. DISCUSSION AND CONCLUSIONS The reported action research regarding ways to couple digital sound with everyday objects in order to facilitate intuitive and embodied experiences of composing and performing polytempic musical textures provided several insights. Perhaps most importantly, while highly trained and skilled musicians are typically required for the performance of musical pieces with such textures, our observations show that by mapping digital sound to everyday objects these knowledge barriers can be overcome. Furthermore, performers not only quickly understood how to use the instrument, the novel mappings enabled participants with highly varied musical backgrounds to collectively conceive musical outputs with high artistic value: spontaneous use of the Wheel Quintet at the museum exhibition produced advanced and unique polytempic musical textures.  The findings also illuminate important roles of generativity in two key parts of the process of creating and using the Wheel Quintet. The first was during the planning step of the first action research cycle, as the first author set out to create the instrument. The generative aspects of digital technology were revealed as Max/MSP and Arduino were chosen as platforms that are both affordable and easy to use. Collectively, these two platforms provided a generative structure that the first author (a composer with novice skills in computer engineering and coding) could utilize to create novel artifacts beyond the design intent of their creators. In particular, the first author leveraged the reprogrammability of digital materiality as he embedded everyday physical objects with software. Specifically, visual coding in Max/MSP permitted assignation of novel functions to the wheels. Secondly, generativity also played a key role as the instruments were used to create new musical expressions. Here, the novel mappings of digital and physical components enabled museum visitors to co-create the Wheel Quintet as an artistic piece. The instrument itself provided the generative structure, but the specific actions and artistic output were neither specified nor fully controlled by the first author. Indeed, the specific constraints introduced by using wheels and their circular motion as controllers facilitated artistic musical output; if (for example) guitars had been used instead, participants would almost certainly have created sound, but probably of dubious artistic value.  In conclusion, the study has contributed rich insights through research carried out in specific contexts [cf. 22]. It has clearly illustrated the potential of mapping digital sound to everyday objects to stimulate participatory art and both the composition and performance of music. This, and the limited scope of our study, clearly indicate that further research in this domain is warranted. In terms of animated music notation, our findings show how the Max Maestro managed to provide performance instructions for a novel instrument to non-professional performers with very limited rehearsal time. However, we encourage further investigations of the viability of using animated music notation in situations when professional and non-professional performers together use novel musical instruments to perform fixed compositions in various genres as well as the new artistic possibilities it can facilitate.  Further, the rapid increases in processing and storage capacity of digital artifacts (following Moore’s law), and reductions in their prices should greatly facilitate such explorations, while open standards such as those of the Max/MSP platform allow increasingly wide ranges of artifacts and services to be seamlessly integrated. These developments allow artists and scholars to conduct increasingly advanced explorations in terms of both scale and scope. Numerous aspects warrant detailed investigation, but we specifically encourage future researchers to examine the role of generativity in creating and utilizing new interfaces for musical expressions. 
88
6. ACKNOWLEDGMENTS We thank Västerbottens Museum and Norrlandsoperan, as well as the museum visitors, performers, and musicians whose participation enabled this project. 7. REFERENCES [1] J. Bresson and J. MacCallum. Tempo Curving as a Framework for Interactive Computer- Aided Composition. Sound and Music Computing Conference (SMC), 2015. [2] P. Cook. Principles for Designing Computer Music Controllers. In Proceedings of the International Conference on New Interfaces for Musical Expression (NIME), 2001. [3] T. Feldt, S. Freilich, S. Mendosa, D. Molin, and A. Rau. The Peripipe: A Sip-And-Puff Remote Control for Music Playback. In Proceedings of the International Conference on New Interfaces for Musical Expression (NIME), 2015. [4] T. Finkelpearl. Participatory Art. In Encyclopedia of Aesthetics (2 ed.). M. Kelley (Ed.), 2014, N. pag.  [5] J. Françoise, N. Schnell, R Borghesi, and F. Bevilacqua. Probabilistic models for designing motion and sound relationships. In Proceedings of the International Conference on New Interfaces for Musical Expression (NIME), 2014 [6] J. Greschak. Polytempo Music An Annotated Bibliography, Retrieved from http://www.greschak.com/polytempo/ptbib.htm. 2003.  [7] M. Hannula, J. Suoranta, and T. Vadén, Artistic Research: Theories, Methods and Practices. Helsinki: Academy of Fine Arts; Gothenburg: University of Gothenburg. 2005. [8] R. Hornecker, and J. Buur. Getting a Grip on Tangible Interaction: a Framework on Physical Space and Social Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 437-446. 2006. [9] J. Kallinikos, A. Aaltonen, and A. Marton. The Ambivalent Ontology of Digital Artifacts. MIS Quarterly, 37(2), 357-370. 2013.  [10] P. Kocher. Polytempo Network: A System for Technology-Assisted Conducting. In Proceedings of the International Computer Music Conference (ICMC), 2014.  [11] P.M. Leonardi. Materiality, Sociomateriality, and Socio-technical Systems: What Do These Terms Mean? How Are They Different? Do We Need Them? In Materiality and Organizing: Social Interaction in a Technological World, P.M. Leonardi, B.A. Nardi and J. Kallinikos (Eds). Oxford University Press, Oxford, 25-48. 2012. [12] K. Lewin. Group Decision and Social Change. In Readings in Social Psychology, T. N. Newcomb & E. L. Hartley (Eds.), Holt, Rinehart & Winston, Troy, MO, 197-211. 1947. [13] A. Lind. New Artistic Possibilities with The Max Maestro – An Animated Music Notation System for Non-Professional Performers, Retrieved from <https://www.researchcatalogue.net/view/224363/224364>, 2015.  [14] J. MacCallum and A. Schmeder. Timewarp: A Graphical Tool for the Control of Polyphonic Smoothly Varying Tempos. In Proceedings of the International Computer Music Conference (ICMC), 2010. [15] W. Marley, and N. Ward. Gestroviser: Toward Collaborative Agency in Digital Musical Instruments. In Proceedings of the 
International Conference on New Interfaces for Musical Expression (NIME), 2015 [16] D. Novitz. Participatory Art and Appreciative Practice. The Journal of Aesthetics and Art Criticism, 59(2), 153-165. 2001. [17] D. Nylén and J. Holmström. Digital innovation strategy: A framework for diagnosing and improving digital product and service innovation. Business Horizons, 58(1), 57–67. 2015. [18] D. Nylén, J. Holmström, and K. Lyytinen. Oscillating Between Four Orders of Design: The Case of Digital Magazines. Design Issues, 30(3), 53-68. 2014. [19] S. Papetti, S. Schiesser, and M. Fröhlich. Multi-Point Vibrotactile Feedback for an Expressive Musical Interface. In Proceedings of the International Conference on New Interfaces for Musical Expression (NIME), 2015. [20] G. P. Scavone. THE PIPE: Explorations in Breath Control. In Proceedings of the International Conference on New Interfaces for Musical Expression (NIME), 2003. [21] N. True, N. Papworth, R. Zarin, J. Peeters, F. Nilbrink, K. Lindbergh, D. Fällman, and A. Lind. The Voice Harvester: An Interactive Installation. In Proceedings of the CHI '13 Extended Abstracts on Human Factors in Computing Systems. 2013. [22] G. Walsham. Interpretive Case Studies in IS Research: Nature and Method. European Journal of Information Systems, 4(2), 74- 81. 1995. [23] Y. Yoo. Computing in Everyday Life: A Call for Research on Experiential Computing. MIS Quarterly, 34(2), 213-231. 2010.  [24] Y. Yoo, O. Henfridsson, and K. Lyytinen. Research Commentary—The New Organizing Logic of Digital Innovation: An Agenda for Information Systems Research. Information Systems Research, 21(4), 724-735. 2010. [25] J. L. Zittrain. The Generative Internet. Harvard Law Review, 119(7), 1974-2040. 2006. 8. Appendix Relevant/selective video documentation taken from findings of the artistic research project Voices of Umeå (2012-2015): The Max Maestro - animated music notation system https://www.youtube.com/watch?v=4iePLi5uQzU The Voice Harvester - interactive voice recording instrument https://www.youtube.com/watch?v=iaLBcY6mHgk Singing Instruments!! - interactive museum exhibition with three interactive music instruments. From Västerbottens Museum, Umeå, Sweden (2013). https://www.youtube.com/watch?v=wLQ5Hs4GTeU Everybody Scream!!! - concert hall performance of a large scale composition in eight movements for three interactive instruments, 200 non-professional singers and an electronic music part including thousands of recorded and pre-processed voices from the citizens of Umeå. (Starting with the 4th movement). Performed at Norrlandsoperan, Umeå, Sweden (2014). https://www.youtube.com/watch?v=cxEkvz0wgBk Spin n´ Play - stage performance of a composition for the Wheel Quintet and chamber ensemble (flute, clarinet, percussion, viola, double bass). Performed by the Now Hear Ensemble and the composer at Old Little Theatre, Santa Barbara, California (2015).  https://www.youtube.com/watch?v=kW9I17HRoI4 
 
89