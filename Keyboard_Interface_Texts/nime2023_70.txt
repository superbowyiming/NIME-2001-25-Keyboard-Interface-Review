 
The Implementation of Envelope-Based Complex Mapping Strategies to Extend and Augment Human Control     Nicholas Kirk-Canny Music Computing Laboratory, The Open University, Milton Keynes UK nicholaskirkcanny@gmail.com 
    ABSTRACT This paper presents complex mapping strategies that offer flexibility for improvising with elaborate digital environments by allowing for more human control with less physical input. The intention is not to reduce human physicality, but instead actions are further extended and altered through complex envelopes. This software was originally designed for the augmented guitar, to address the issue of a lack of spare bandwidth (Cook, 2001) that is inherent to guitar playing. This makes it challenging to simultaneously control digital interfaces without compromising guitar technique. The Slider MultiMap software discussed in this paper enables a guitarist to control multiple audio effects with a single gesture while individually customising how each parameter is controlled prior to the performance. At the same time, it explores the delegation of tasks to the computer in situations where indirect control is more desirable. Author Keywords Mapping strategies, envelopes, augmented guitar, embodied interaction,  agency. CCS Concepts • Applied computing→ Arts and humanities; Sound and music computing  • Applied computing→ Arts and humanities; Performing arts 1.    INTRODUCTION The mapping strategies one implements have a direct effect on the experience of the performer and audience, influencing whether a performer can utilise the intelligence of physicality and embodied interactions while displaying liveness to audiences. Mapping strategies are pivotal for determining the effectiveness of an interface and, therefore, it is important to consider the many ways mappings can be configured. When setting up mapping strategies, digital performers often need to decide what they feel is important to control and what type of interface is most suitable to achieve this. At the same time, performers have the option to carry out direct, continuous control or engage in indirect control by setting computer processes in motion that will automatically adjust parameters. Both approaches have their merits depending on the circumstance, therefore, it is useful for a performer to 
evaluate which approach is most suitable throughout their digital environment. This paper discusses this topic through the use of Ableton Live. This software's mapping strategies has its limitations, which were overcome by developing complex mapping strategies in Max for Live. Although this bespoke software was  designed for Live and Livid's Guitar Wing, the affordances it provides could be beneficial to other forms of software and hardware, including more affordable approaches, such as Pure Data and Bela. The software can also be used to simplify interaction with an interface, as it enables a performer to utilise a single sensor to control eight parameters in diverse ways. This is especially beneficial for augmented instrumentalists, where a performer may not be able to interact with numerous sensors while simultaneously playing their traditional instrument. This paper demonstrates this using the Guitar Wing, which is a compact, non-invasive controller that can be attached to the guitar, resulting in a lightweight and mobile instrument. 2.   DESIGNING CONTROL STRATEGIES FOR THE PERFORMER AND AUDIENCE The ability to customise mappings to such a high degree makes digital musical instruments (DMIs) unique. Unlike acoustic instruments where the “playing interface is inherently bound up with the sound source”, a digital interface is “usually a completely separate piece of equipment from the sound source” (Hunt, Wanderley and Paradis, 2003, p. 429). With DMIs this relationship must be defined by the user to achieve their musical goals, making mappings as important to the performance of digital music as the compositional process. 
Figure 1 Based on Wanderley (2000). Common musical interface paradigm, with a disconnect between the controller and sound engine, with flexibility in the mapping engine which is open to change. • One-to-one, where one synthesis parameter is driven by one gestural parameter 

2 
• One-to-many, where one gestural parameter may influence various synthesis parameters at the same time • Many-to-one, where one synthesis parameter is driven by two or more gestural parameters (Hunt and Wanderley, 2002, p. 97). Miranda and Wanderley (2006) suggest these three intuitive mapping strategies for DMIs, whereas the term many-to-many can be applied to various combinations of these strategies. This variety allows digital performers to configure the mappings between their interfaces and software environments to varying degrees of complexity, from a basic one-to-one mapping of a slider to an oscillator, to complex interconnected mappings that can become challenging for a performer and audience to comprehend. Although one-to-one mappings are easy to learn, they can be less enjoyable and not as capable of producing complex outcomes (Hunt and Kirk, 2000). Complex mappings tend to be more interesting and rewarding to the user as they can produce expressive, diverse and sometimes unpredictable results. This results from the fact that they replicate the experience of acoustic instruments which have evolved over centuries to improve their interactivity (Hunt, Kirk and Wanderley, 2000). For example, like acoustic instruments, complex mappings allow for interesting interactions between different limbs. As a result, complex mappings will likely take longer to learn, yet have the benefit of allowing for more possibilities and, therefore, a deeper exploration and relationship with the instrument. 2.2   Navigation and Wayfinding Another important consideration when deciding upon mapping strategies is whether they facilitate navigation or wayfinding. According to Owen Green, “the use of an equaliser” to try “to locate some specific aspect of a sound” (Green, 2011, p. 139) is a form of wayfinding. Navigation is “characterised by knowing in advance one’s destination, as opposed to simply knowing one's destination when one gets there” (ibid.). Implementing “overly simple and direct mapping strategies” tends to provide an “unsatisfactory experience in terms of the degree to which such schemes afford only navigation rather than wayfinding” (ibid.). This form of mapping militates “against skilled development” and can “give rise to breakdown more frequently” (ibid.). Wayfinding requires users to practice a DMI to acquire the skill needed to quickly find the desired sound and Green suggests “skilled practitioners will home in more quickly as they have learned to interpret the response in the sound as a guide of where to go next” (ibid.). 2.3   Human Versus Computer Control When setting up control strategies, it is also useful to consider whether to implement direct or indirect control. According to Lexer, direct control encompasses performer actions that “enable intensional changes of parameters for either operational or performative control gestures” (Lexer, 2012, p. 60). A performative activity immediately affects the sonic outcome, whereas an operational activity is preliminary, and does not have an immediate effect on the sound (ibid.). Indirect control relates to events that are not controlled through a performer's actions, such as envelope following, side-chain compression (ibid.) or generative computer processes. Although direct control offers more potential for displaying real-time human control, indirect control is useful for creating interesting interactions within a digital environment, allowing instruments to influence one another, much like in a human ensemble. Control strategies influence the degree to which a performer is in control of their environment. While some performers desire complete control, others prefer an environment or interface that 
provides unexpected contributions. An example of someone who desires the latter is John Ferguson, which he achieves by designing features into his environment that encourage real-time interaction and create a scenario where it is uncertain whether he is controlling the technology, or it is controlling him (Ferguson, 2016). To achieve this, he gives the computer agency, which can take away human autonomy and liveness; however, Ferguson suggests this only heightens his attention and involvement during performances (ibid.). Similarly, Maja Ratkje aims to create a situation where she is not in total control as this keeps her performances original and unpredictable (Kjus and Danielsen, 2016). She accomplishes this by not pre-planning performances and making the technology difficult to control as she suggests “you can use technology that is super easy to handle or extremely advanced, sometimes having full control and sometimes not at all” (ibid., p. 331). Ferguson's and Ratkje's approaches can be replicated using Slider MultiMap, which was a primary goal when designing the software. 3.   SOFTWARE Live's inbuilt mapping strategies are useful for expeditiously mapping an interface to parameters; however, when it comes to multi-mapping strategies, Live has its limitations. For example, it is possible to map a slider to multiple parameters and use the min/max functionality to separately constrain the range of each parameter or invert a mapping. However, parameters will still be controlled in a similar linear manner. 
Figure 2: Ableton Live's inbuilt mapping strategies. Slider MultiMap is a one-to-many mapping software that utilises intermediary envelopes that alter the gesture-sound relationship of each parameter. The software uses up to eight envelopes, each of which can be mapped to any parameter within Live to extend and alter human control. During a performance, all these envelopes can be controlled using a single slider, pad, knob or other type of continuous controller. With this approach, depending on how these intermediary envelopes are configured, a slider may affect each parameter in a linear or non-linear manner. Alternatively, the software can be controlled indirectly using an inbuilt sequencer or envelope generator, which can be set in motion by the performer to continuously change the envelope positioning. These features can be useful when a performer desires movement in  parameters yet is too occupied with other aspects of the performance to control the software themselves. Depending on how the device is configured and controlled, it can produce intentional or indeterminate outcomes, as well as subtle or drastic changes. To achieve this range of possibilities, the device includes the following functionality:  • Eight envelopes customised to individual parameters • Zoom function to create more detailed envelopes • Min/max setting to constrain parameter range • Possibility to generate random envelopes: manually or     automatically 

 
• Set probability for the number of envelope breakpoints randomly generated • Sequencer to jump to different points in the envelopes • Envelope generator to interpolate through envelopes and modulate two other parameters within Live • Gesture recording • Presets  
Figure 3: SliderMultiMap horizontal extension. The figures below illustrate how these intermediary envelopes work in greater detail. Figure 4 represents a standard Live linear mapping, in this instance as a performer moves a slider from its minimum to maximum value the parameter it is mapped to acts in the same manner. Figure 5 shows how an intermediary envelope can be used to alter this relationship, in this case, as a slider moves from minimum to maximum, at the slider's halfway point the parameter will reach its maximum value, then as the slider continues to move up to its maximum, the parameter will instead move back to its minimum value. Figure 6 shows another envelope that contains numerous breakpoints, in this instance, the slider's movements will affect the parameter in ever-changing ways. This can be challenging for a performer to comprehend; however, it is possible to customise complex envelopes to make them easier to learn. For example, in figure 6, the start and end of the slider position will be the parameter's minimum value, whereas the middle of the slider will be its maximum. 
Figure 4: Linear envelope. 
Figure 5: Semi-linear envelope. 
Figure 6: Complex envelope. Nevertheless, complex envelopes still take time to get accustomed to, especially when all eight envelopes control parameters in this manner. However, they have the benefit of producing complex outcomes that facilitate wayfinding and embodied interactions, as it can be difficult to predict the outcome of actions when slight changes in a slider's position can produce drastic results. Thus, a performer must experiment with their actions and continually be guided by their perceptions. When indirect control is desirable, a user can set a sequencer in motion that automatically changes the position of all eight envelopes as it moves through the sequence. To customise this feature a user should specify an envelope position for each step, if a step is set to the MIDI note 0, the device will move back to 
the start of the envelopes position, whereas if a step were set to 127, it will move to the end of the envelopes position, and so forth. Thus, as the sequencer progresses it will constantly jump to a different position in the envelopes, altering all the mapped parameters on every step. The time-based envelope generator follows the same principle; however, rather than moving in a stepwise motion, the envelope generator interpolates between the specified breakpoints. The envelope generator also ceases activity after one pass of its envelope; therefore, it needs to be constantly triggered by the performer. If desirable, these indirect control processes can be used to create indeterminate outcomes, as the sequencer can be configured to randomly jump between steps, whereas the envelope generator can randomly change its breakpoints when triggered. These features can be useful for heightening a performer's attention and involvement. Slider MultiMap also incorporates a gesture recorder functionality, which develops ideas presented by Rodrigo Constanzo (2015). This lets a performer record a gesture and have the computer repeat it indefinitely, thereby  translating direct human expressive control into continuous indirect control. When used in combination with a traditional instrument, Slider MultiMap produces interesting results when controlling the parameters of audio effects processing the instrument's sonic output. In doing so, the performer can readily achieve movement in all of these effects, which continuously changes the sonic outcome of their traditional instrument and produces human-computer interactions. 4.   HARDWARE Slider MultiMap was specifically designed for the guitar, which was augmented using the Livid Guitar Wing and Keith McMillen SoftStep. When augmenting an instrument, perfor-mers need to adapt to new sensors and functionality, yet this transition can be seamless if the sensors are designed around a musician's pre-existing performance technique. It is, therefore, important to design the technology around the affordances and constraints of a particular instrument as some have more spare bandwidth than others (Cook, 2001), which involves the extra cognitive and physical capacity an instrumentalist has to expend. 
Figure 7: The Guitar Wing and SoftStep. The Guitar Wing and SoftStep were ideal for making use of the guitar's spare bandwidth. The Guitar Wing is designed to be placed near the guitar’s strings, making it ideal for controlling with the picking hand. Whereas the SoftStep requires similar technique as guitar effect pedals, which allows for its application in combination with the guitar and Guitar Wing. In this research, the Guitar Wing's largest slider was used to control Slider MultiMap's envelopes position, as this allowed for more nuanced, detailed and expressive control. The envelopes were mapped to the parameters of multiple audio effects. These 

4 
effects were placed on a dedicated processing track, which was used to process the guitar and pre-recorded material. To make live control more flexible, the SoftStep's pads were mapped to the on/off of these effects, thereby providing the ability to change how many effects Slider MultiMap is controlling. This configuration meant that the effects could be implemented in different combinations, thereby providing extensive sonic possibilities. Furthermore, this allowed for flexibility in mapping strategies, as if only one effect is on the mapping is one-to-one, whereas when multiple effects are on the mapping becomes one-to-many. This strategy makes the instrument accessible while providing challenge upon deeper exploration. These controllers enabled the intelligence of physicality and a full-body experience, which improved the performance experience by replicating the interaction between limbs found with acoustic instruments. The complex, continuous control of effect parameters had a direct impact on the sonic material, which facilitated wayfinding and embodied interactions, as it became necessary to search for the desired outcome while being continually guided by perceptions. Furthermore, it was imperative to rehearse with the instrument to acquire the skill necessary to find the desired outcome quickly. As a consequence of these control strategies, the instrument displays liveness as it allows audiences to see more of the instrument, gestures and skill. These actions are visually apparent since the guitar is directed towards the audience at most times while inbuilt lighting shows the current state of the software. The ability to control numerous parameters with the Guitar Wing's slider, freed up the other sliders, pads, and buttons to change instrumentation and set indirect computer processes in motion. This proved beneficial as it allowed for more processes to be used in combination. 5.   LIMITATIONS When I first put this software into practice, engaging in embodied interactions was difficult as the complex envelopes I was using at the time made it hard to predict the outcome of actions and be guided by perceptions. I concluded that it would be advantageous to limit the number of processes I was controlling at any given moment. I also utilised a mixture of simple and complex envelopes. Simple envelopes were easier to learn since there is less movement and variation in how they behaved. However, I retained a few complex envelopes as these were useful for creating unpredictable results with subtle actions producing drastic outcomes. In situations where I wanted to feel not in total control, much like Maja Ratkje strives to accomplish, it was possible to randomly generate new envelopes for some of the parameters before a performance so that I was unfamiliar with the gesture-sound relationship. 
Figure 8: Simple and predictable envelopes. 
Figure 9: Complex and chaotic envelopes. 
Figure 10: The final outcome. 
6.   CONCLUSION This paper presented Slider MultiMap, a one-to-many mapping device that extends and augments human control. This software is discussed within the context of Ableton Live, which has its limitations regarding mapping strategies. Slider MultiMap strives to overcome these limitations using intermediary envelopes that allow a performer to control up to eight parameters in customisable ways using a single gesture. The software was designed for the guitar, which was augmented using the Guitar Wing and SoftStep. The affordances Slider MultiMap provides were particularly useful for the augmented guitar, as a guitarist has a limited amount of spare bandwidth, which makes it challenging to simultaneously control the digital layer of the instrument. Slider MultiMap simplifies interaction with the digital layer of the instrument by allowing a performer to focus their concentration on a single slider while still being able to control a substantial amount of a digital environment's features in diverse ways. The instrument was designed to facilitate the intelligence of physicality; embodied interactions; and a full-body experience, which helps make the instrument more adaptable and immersive for the performer while displaying liveness to audiences. The software also explored indirect computer control processes, as these can be beneficial for adding variation to the mapped parameters when a performer is too busy to operate their interface or in situations when computer contributions are desirable. This paper focused on the use of commercial software and hardware; however, these methods are relevant to other types of technology. This is especially true for performers who want to  to control their digital environments in diverse ways and expand the capabilities of their interfaces. Slider MultiMap could also be useful for generating ideas during the compositional and sound design processes, for example, by mapping the software to the parameters of a synthesizer to alter its pitch and timbre automatically. Thus, the software has many practical applications that can be applied as each user sees fit. 7.   ACKNOWLEDGMENTS This research was carried out with guidance from my PhD supervisors, Dr. Jules Rawlinson and Dr. Tom Mudd. 8.    ETHICS STATEMENT I do not see any ethical issues with regards to this work. 9.   REFERENCES [1] Butler, Mark. (2014). Playing with Something That Runs.       TECHNOLOGY, IMPROVISATION, AND COMPOSITION IN DJ AND LAPTOP PERFORMANCE. Oxford University Press: New York. pp. 71-151. [1] Constanzo, Rodrigo. (2015). Cut Glove – a new gamepad-  based software. [software] Available at: https://rodrigoconstanzo.com/2015/06/cut-glove/ [2] Cook, Perry. (2001). Principles for Designing Computer Music Controllers: proceedings of New Interfaces for Musical Expression, 2001, Seattle, USA. p. 1. [3] Emerson, Gina and Egermann, Hauke. (2017). Mapping, Causality and the Perception of Instrumentality: Theoretical and Empirical Approaches to the Audience’ s Experience of Digital Musical Instruments. Musical Instruments in the 21st Century. Springer: Singapore. p. 365. [4] Emerson, Gina and Egermann, Hauke. (2020). Exploring the motivations for building new digital musical instruments. Musicae Scientiae, 24 (3). SAGE Journals: London. p. 2. 

 
[5] Eno, Brian. (1999). The Revenge of the Intuitive. Available at: https://www.wired.com/1999/01/eno/. [6] Ferguson, John. (2016). Fostering a Post Digital Avantgarde. Organised Sound 21 (2), Available at: https://www.cambridge.org/core/journals/organised-sound/article/fostering-a- postdigital-avantgarde-researchled-teaching-of-music- technology/6AF04A9E33246646A1277F696F6E0727. pp. 129-135. [7] Green, Owen. (2011). Agility and Playfulness: Technology and Skill in the Performance Ecosystem. Organised Sound, 16 (2). Cambridge University Press, Cambridge. Available at: https://www.cambridge.org/core/journals/organised-sound/article/agility-and-playfulness- technology-and-skill-in-the-performance- ecosystem/29ABE40ADA253D028407473AA8365EF4. p. 140. [8] Hunt, Andy and Kirk, Ross. (2000). Mapping Strategies for Musical Performance. Reprint from: Trends in Gestural Control of Music, M.M. Wanderley and M. Battier, eds. © 2000, Ircam Centre Pompidou. [9] Hunt, Andy and Wanderley, Marcelo. (2002). Mapping Performer Parameters to Synthesis Engines. Organised Sound, 7 (2). Cambridge University Press, Cambridge. Available at: https://dl.acm.org/doi/10.1017/S1355771802002030. p. 97. [10] Hunt, Andy, Kirk, Ross and Wanderley, Marcelo. (2000). Towards a Model for Instrumental Mapping in Expert Musical Interaction, proceedings in international Computer Music Conference September 2000 [11] Hunt, Andy, Wanderley, Marcelo and Paradis, Matthew. (2003). The Importance of Parameter Mapping in Electronic Instrument Design. Journal of New Music Research, 32 (4). New York: Taylor & Francis Online. Available at: https://www.tandfonline.com/doi/abs/10.1076/jnmr.32.4.429.18853. p. 429.                           
[12] Kjus, Yngvar and Danielsen, Anne. (2016). Live mediation: performing concerts using studio technology. Popular Music, 35 (3). Available at: https://www.cambridge.org/core/journals/popular-music/article/live-mediation-performing- concerts-using-studio-technology/557E6F2A6118A5B7506FE18AD8DB2908. pp. 330-332. [13] Lexer, Sebastien. (2012). Live Electronics in Live Performance: A Performance Practice Emerging from the piano+ used in Free Improvisation. Thesis (PhD). Goldsmiths College, London. pp. 40-61. [14] Miranda, Eduardo Reck and Marcelo, M. Wanderley. (2006). New Digital Musical Instruments: Control and Interactions Beyond the Keyboard, Middleton, Wisconsin: A-R Editions. pp. 15-16. [15] Polymath, A. (2011). Brian Eno: The Philosophy of Surrender, Available at: http://polymathperspective.com/?p=9. [16] Wanderley, M. Marcelo. (2000). “Gestural Control of Music.” Ircam-Centre Pompidou, Available at: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.9460&rep=rep1&type=pdf.  10.    APPENDICES Video documentation: https://www.youtube.com/watch?v=gVh6jxr5kH4 https://www.youtube.com/watch?v=vmf5Ydxx-nY                        