Establishing a Musical Channel of Communication
between Dancers and Musicians in Computer-Mediated
Collaborations in Dance Performance
Carlos Guedes
Escola Superior de Música e das Artes do Espectáculo – Instituto Politécnico do Porto (ESMAE-IPP)
Porto, Portugal
+351 225 193 760
Escola Superior de Artes Aplicadas — Instituto Politécnico de Castelo Branco (ESART- IPCB)
Castelo Branco, Portugal
+351 272 340 800
carlosguedes@mac.com
ABSTRACT
In this demonstration, I exemplify how a musical channel of
communication can be established in computer-mediated
interaction between musicians and dancers in real time. This
channel of communication uses a software library
implemented as a library of external objects for Max/MSP[1],
that processes data from an object or library that performs
frame-differencing analysis of a video stream in real time in
this programming environment.
Keywords
Interactive dance, interactive performance, interactive
performance systems, interaction between music and dance,
musical rhythm and rhythm in dance.
1. INTRODUCTION
1.1 The m-objects
The m-objects are small library of Max/MSP externals
designed for interactive dance performance. These objects
allow the creation of a musical channel of communication
between dancers and musicians in computer-mediated
collaborations in real time. The m-objects perform certain
types of analysis and processing of dance movement as
captured by a video camera, and extract what I call musical
cues from dance movement in real time. Musical cues are
rhythms produced by movement in dance that bear qualities
akin to musical rhythms in their durational and articulatory
nature.
The library contains six objects: m.bandit,  m.clock , m.weights,
m.peak, m.sample, and m.lp (Max/MSP objects appear in bold
typeface in the text.). These objects can be
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee.
Nime’07, June 6-10, 2007, New York, NY, USA.
Copyright remains with the author(s).
combined in several ways to perform the temporal domain
analysis of dance movement, and can be grouped into objects
that do analysis (m.bandit , m.peak, m.weights ), processing
(m.clock  and m.lp ), and extras (m.sample ). m.bandit and
m.clock  are the core of the library since they are responsible
for doing the frequency domain representation of the frame-
differencing signal and musical tempo control respectively.
Except for m.lp that is a subpatch, all objects were coded in C
by following the published guidelines for writing external
objects for Max/MSP. In [3] I do a presentation of the whole
library. In [1] I explain the how the extraction of the musical
rhythmic elements form dance movement is done in real time.
For more detailed information about the overall study,
including a tutorial introduction to the library, see [2].
1.2 A Possible Framework for Computer-
Mediated Interaction in Dance Performance
This software library intends to promote certain ways of
computer-mediated interaction in real time between a
dancer/choreographer and a composer/musician. It is designed
to be operated by specialists from the fields of dance and
computer music. The main goal is to allow the composer of
electronic music certain types of control over the temporal
articulation of the electronic music score during performance,
otherwise impossible to achieve with pre-recorded music. This
control ranges from tempo adaptation of the score to the
dancer’s movement — thereby enabling the dancer to slightly
accelerate or slow down the music being played — to the
generation of musical rhythmic structures extracted from
certain types of rhythms in the dancer’s movement.
A camera connected to the computer observes the dancer and
the computer produces movement analysis data that is
interpreted musically at the temporal level. The
musician/composer who operates the computer receives a
musical temporal-level interpretation of the movement
analysis data in real-time. It is up to the musician to decide
what type of controls/parameters for interaction are given to
the dancer over the musical content.
The computer thus acts as a mediator in the process and is
responsible for providing the musical elements extracted from
movement that can be used for interaction. It acts as a sort of a
filter that can extrapolate musical elements from a dance,
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
417
thereby opening a channel for musical
communication/interaction between dancers and
electronically-generated music in real time. This type of
interaction framework thus calls for a more intense
participation of the composer/musician in the performance of
dance with electronic music. It also opens interesting
possibilities for improvisation or for the performance of open-
form music/dance structures. The musician operating the
computer can always change the parameters for interaction
during performance and feed back different musical content to
the dancer, or map the musical elements extracted from the
dance to different parameters in the electronic score.
2.  SOFTWARE APPLICATIONS AND
DEMONSTRATION
2.1 Software Applications
The m-objects are to be used within the framework for
computer-mediated performance proposed here. This opens a
possible musical channel of communication between
(electronic) musicians and dancers in interactive dance
performance. Like any other software that maps movement
qualities to musical parameters, the performances utilizing the
m-objects show a strong relationship between movement and
musical output. However, since the relation between movement
and music is established at the temporal level, the
performances utilizing this software show in general a “human
feel” in the music being generated as the dancer’s movement is
articulating the musical rhythm. This opens interesting
possibilities for shared musical improvisation between
musicians and dancers.
In the performances utilizing the m-objects, I use generative
algorithms in which the pitches are articulated by the
computer’s rhythmic interpretation of the dancer’s movement.
During a performance, one can give or take away the rhythmic
control of the music to the dancer as well as modify the output
of the algorithms according to the musical result being
produced.  
I used this library in four artistic collaborations so far: Etude
for Unstable Time (2003-2005), Olivia (2004), Will.0.w1sp
(2005), and With Drooping Wings (2007).
Etude for Unstable Time was the first piece for interactive
dance created using the m-objects in 2003 in collaboration
with choreographer/dancer Maxime Iannarelli and was
premiered publicly in Pisa at the PLAY! concert of the
Computer Music Modeling and Retrieval 2005 conference on
September 26. This short piece consists of a structured
improvisation in two parts. In the first part, the rhythm of
music is generated solely by the computer’s rhythmic
interpretation of dancer’s movement. In the second part there
is a game played between the dancer and me over the control of
the tempo of sequence of samples being played.
The m-objects had their first public presentation in Olivia,  a
dance solo for children based on the cartoon character created
by Ian Falconer. This solo was choreographed and danced by
Isabel Barros, with music composed by me, and was premiered
at Teatro Rivoli, in Porto, Portugal, on May 6, 2004. In this
piece, I used the m-objects to create two magical moments in
the show. The first was when Olivia went to the museum and
pictured herself in a ballet class. When the dancer started
dancing, a piano solo was generated utilizing the rhythms
produced by her movement, thereby giving the impression
that the character Olivia was controlling the piano music. The
second magical moment  happened when Olivia was having
insomnia at night and started rolling in bed until eventually
began to dance, generating all of the rhythm being played by
her movement.
Will.0.w1sp  is an interactive installation conceived by Kirk
Woolford in which a visual particle system is generated from
captured sequences of dance movement, premiered at The Waag
Society in Amsterdam on March 16, 2005. In this installation,
the m-objects interpret the movement of the visual particles in
order to generate the rhythms that control the sonic grains of
the soundscape. This is the only piece in which all the
behavior of the system is pre-programmed and no algorithms
are manipulated during runtime.
In With Drooping Wings, a choreography by Né Barros for the
Balleteatro of Porto (Portugal) utilizing Henry Purcell’s music
from Dido and Aeneas, I used the m-objects with more than
one dancer moving at the same time. In this piece, I created this
schizophrenic harpsichord  that plays on top of Purcell’s
music activated by the dancers’ movement on stage. Although
the result is (purposefully) chaotic, there is this strange
connection established by the overall movement of the
dancers and the rhythms being played by the harpsichord.
2.2 Demonstration
In the conference, a dancer and I will do a live demonstration
of how this software library potentiates the musical
communication between dancers and musicians in computer-
mediated collaborations, as well as showing how the m-objects
can be used to make a dancer generate musical rhythmic
structures in real time and/or control the tempo of an
electronically-generated score.
The patches that are utilized in this demo are available at
http://homepage.mac.com/carlosguedes
3. REFERENCES
[1] Guedes, C. Extracting Musically-Relevant Rhythmic
Information from Dance Movement by Applying Pitch-
Tracking Techniques to a Video Signal. In Sound and
Music Computing Conference 2006 Proceedings  (SMC
’06) (Marseille, France, May 18-20, 200), 25-33
[2] Guedes, C. Mapping Movement to Musical Rhythm: A
Study in Interactive Dance. Ph.D. Thesis, New York
University, New York, NY, 2005.
[3] Guedes, C. The m-objects: A Small Library for Musical
Rhythm Generation and Musical Tempo Control from
Dance Movement in Real Time. In Proceedings of the
International Computer Music Conference  (ICMC ’05)
(Barcelona, Spain, September 5-9, 2005), 794-797
[4] http://www.cycling74.com/downloads/maxmsp
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
418
INSTALLATIONS
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
419