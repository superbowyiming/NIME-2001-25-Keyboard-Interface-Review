Evaluating the Performance of a New Gestural Instrument 
Within an Ensemble  
 
 
Alon Ilsar 
University of Technology, Sydney  
alon.ilsar@student.uts.edu.au 
 
Mark Havryliv 
The Australian Institute of Music, 
Sydney 
mhavryliv@ieee.org 
 
 
Andrew Johnston 
University of Technology, Sydney  
andrew.johnston@uts.edu.au 
 
 
 
ABSTRACT 
This paper discusses one particular mapping for a new gestural 
instrument called the AirSticks. This mapping was designed to be 
used for improvised or rehearsed duos and restricts the AirSticks 
performer to only utilising the sound source of the other musician 
playing an acoustic instrument. Several pieces with different 
musicians were performed and documented, musicians were 
observed and interviews with these musicians were transcribed. In 
this paper we will examine the thoughts of these musicians to gather 
a better understanding of how to design effective ensemble 
instruments of this type. 
 
Keywords 
mapping, new instrument, electronic percussion 
1. INTRODUCTION 
This paper examines mapping des ign for a new gestural 
interface for electronic percussion called the AirSticks.  The 
design of the mapping is described and findings from a series of 
interviews conducted with musicians who perf ormed in 
ensembles with the AirSticks are presente d. All of t he 
musicians interviewed c ollaborated on Vacuums or on pieces  
where the Vacuum mapping was used. Vacuums are a  set of 
pieces that feature Ilsar playing the AirSticks. Ilsar had limited 
his palette of sounds to only those sam pled from the other 
featured instrument s; for example, in Drum Vacuum One , an  
acoustic drum kit was sampled. The process of working on one 
of these pieces either started from a score or from an 
improvisation, and either ended with an improvisat ion or a 
written composition. All improvisations and compositions were 
recorded, and most were  also filmed (see Table 1) . With the 
exception of some samples p re-recorded during rehearsals for 
the use in the compositions , all the sounds in these pieces , other 
than those created by the acoustic instrument,  were sampled, 
triggered and manipulated in real-time by Ilsar on the AirSticks. 
The AirSticks allows the electronic percussionist to map various 
percussive gestures in different spaces to different sounds. It 
also allows the manipulation of these samples through changes 
in position and orientation of the hands, fingers and feet.  
 In this paper, we will give a brief outline of the workings of 
the AirSticks, specifically for the Vacuum mapping. We will 
summarise the initial motivations for the mapping, and discuss 
how these motivations have changed as other musicians have 
become involved in the creative process. The data gained from 
journal entries and the observation of and interviews with the   
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are not 
made or distributed for profit or commercial advantage and that copies bear 
this notice and the full citation on the first page. To copy otherwise, to 
republish, to post on servers or to redistribute to lists, requires prior specific 
permission and/or a fee. 
NIME’14, June 30- July 3, 2014, Goldsmiths, London, UK.  
Copyright remains with the author(s). 
 
musicians will be summarised, with the themes of composition, 
improvisation, collaboration and choreography explored.  
2. THE AIRSTICKS 
The AirSticks are designed to take full advantage of the 
performance possibilities that open up when a percussionist is 
not required to strike a surface, while still maintaining a clea r 
relationship between performer gestur e and computer generated 
sounds. The AirSticks give the percussionist control over 
complex sound textures at the same time as allowing them to 
time and execute precise rhythmic gestures. The interface takes 
advantage of the motor skills of an expert percussionist and 
combines it with all the real -time control over sound permitted 
by modern software  [6]. The AirSticks are currently made up of 
the Razer Hydra Gaming  Controllers. Position and orientation 
data for the two controllers is captured and analysed by a 
custom piece of software running on OSX which outputs MIDI 
data. The Graphic User Interface, or GUI (see Figure 1),  is 
made of a grid and two floating points that represent  the middle 
of each controller. A differently coloured box and a differently 
shaped floating point ins tructs the performer as to the y  position 
of their hands, while the x and z  positions are shown on the 
screen like a curser controlled by a mouse. The per former can 
see in which box each hand is in, and note that when they tilt 
past the trigger angle, the box lights up, signaling a note-on 
message. The faster the performer  crosses a tilt point, the 
greater the velocity. This data is accompanied by MIDI data  
containing information about hand, finger and foot change s in 
position and orientation . Combined, this  data provide s the 
performer and composer with a plethora of mapping 
possibilities within such music programs as MAX/MSP and 
Ableton Live. A MIDI Trainer  capability, of particular use with 
Ableton Live, allows for easy MIDI mapping.  For a more 
comprehensive technical overview of the AirSticks and a 
comparison to other open -air controllers see previous work [6].  
 
 
Figure 1. The current Graphic User Interfa ce for the 
AirSticks. 
Proceedings of the International Conference on New Interfaces for Musical Expression
339
3. THE VACUUM MAPPING 
There has been a long tradition of percussionists being 
‘attracted to the use of electronics ’ [2]. The Vacuum mapping 
was initially designed with the motivation of creating an 
electro-acoustic instrument that would allow the percussionist 
to sample and manipulate their sonic environment.  In 
designing this mapping for the AirSticks, ‘ the instrument’s  
responsiveness to its acoustic environment, how it reacts to 
other instruments and how it reacts to the physical aspects of 
performing,’ was considered  [3]. The concept of the  accidental 
was ‘exploited through the amount of control exercised over the 
instrument, from complete - producing exactly what the player 
dictates - to none at all - letting the instrument have it s say’ [3]. 
In a mapping designed for performing a predetermined fixed  
composition, an instrument must be extremely predictable, 
whereas a mapping for improvisation may involve a more 
unpredictable output from the instrument.  
3.1 Collaboration 
Electro-acoustic im provised music pioneer Evan Parker, in an 
interview with Derek Bailey, states that for him the ‘ ideal 
music is played by groups of m usicians who choose one 
another’s company and who improvise freely in relation to the 
precise emotional, acoustic, psycholog ical and other less 
tangible atmospheric conditions in effect a t the time the music 
is played’ [3]. However, during the beginnings of designing a 
mapping of a new instrument, work needs to be done alone to 
get the mapping to a state where these conditions can be dealt 
with as a musician on an unfamiliar instrument; an instrument 
that isn’t ‘conceptually complete,’ one which undergoes  ‘a 
constant series of revisions, redesigns and upgrades’ [12].  
 For this reason, like most new instruments we see today 
including Imogen Heap ’s Gloves [8, 9] and Onyx Ashanti’s 
beatjazz [11], the earliest Vacuum mapping was designed for 
solo playing. Named the Air Vacuum , it culminated in several 
solo performances by Ilsar where he could sample and 
manipulate the sounds of a mi crophone feeding back in the 
room. Other pre -chosen samples were also used in these semi -
improvised pieces. One of these performances with the Air 
Vacuum mapping involved short overlapping duos with other 
acoustic instruments on either end of his solo. Thi s led to the 
idea of collaborating with a violinist to make an electro -
acoustic improvisation called Violin Vacuum . With the success 
of Violin Vacuum , Vacuum pieces for AirSticks duos with 
drums, bass, guitar and vocals have all been performed. This 
process of collaborating with other musicians in the field of 
electronic music can be a lot more fulfilling than the common 
approach of cutting up samples in a studio for such musicians 
as Earle Brown, as he explains in an interview with Derek 
Bailey. 
 
‘…I found it very boring just to sit down in the studio and cut and 
splice tape and combine these things. I mean I really like the society 
of making music with people…’ [3] 
 
 Since this early mapping, the Vacuum mapping has been 
developing in two ways to accommodat e different types of 
collaboration. One use of the mapping is for improvisation or 
exploration of compositional ideas, while another is for the 
performing of a composition itself.  We argue that using new 
instruments in more collaborative contexts across both the 
improvising and composing streams of music will not only help 
promote the culture of new instruments more rapidly, but 
through the process of observing and interviewing 
collaborators, we can design better instruments for high-level 
social interplay. 
3.2 Vacuum Pieces 
The process of gathering information from musicians was 
always a result of a creative process for either im provising or 
composing a piece. A journal was kept noting down certain 
ideas that were discussed during rehearsals and interviews wer e 
organised after the final performance  (see Table 1). A grounded 
theory approach was taken to avoid hindering the creative 
process, keeping an open mind to the ideas of the other 
musicians. Interviews were recorded and transcribed, and the 
transcriptions were analysed for common themes and concepts. 
The musicians were invited to recall some of their most 
memorable performances involving an electronic interface and 
compare it to the experience of playing alongside the AirSticks. 
Then some of the ideas broug ht up during rehearsals were 
discussed finishing with a discussion of future possibilities for 
the AirSticks and new interfaces in general.  An action research 
approach was then taken where i nformation from these 
interviews was then put back updating the Vacuum mapping for 
the next collaboration. 
3.3 Mapping for Improvisation 
The Vacuum mapping for improvising has evolved throughout 
the creative process and the interviews with the collaborators. 
The original mapping utilised the upstroke to record a sample, 
and the downstroke to play it. This was sparked by the desire to 
communicate to the acoustic musician as to when they were 
being recorded. Unfortunately, the effect of  the gesture of  
lifting the hands up into the air was ‘confusing’ (GJ), resulting 
in the conventional response of the other musician awaiting an 
instruction to play . Some performers did not ‘ feel comfortable 
feeding sound into the machine ’ (GJ), and though they 
commented on liking the ‘energy’ (GJ) given off by the 
gestures - falling in line with Pierre Hérbert’s philosophy that 
‘…the measure of a work of art is whether one can sense in it 
the presence of the artist's bo dy’ [12] - they felt that the flow of 
musical ideas was interrupted by the grand gesture of hitting 
the record button. 
 A more discreet mapping of using a button on the controller 
to record was employed, and the idea of instructing the acoustic 
musician as to when they were being recorded was relegated to 
a ‘ figurative gesture  - wholly sym bolic gesture[s] of the 
performer’ [8], - one that is neither used to produc e sound nor a 
biproduct of producing sound. It is important to note here that 
mapping discreet movements to sound must be chosen 
carefully. The more a mapping relies on discreet movements , 
the more the interface merges with o nes like the mouse and 
keypad, the exact interfaces that the AirSticks is attempting to 
improve on. Discreet movements may give the performer more 
control over subtle parameters, perhaps leading to a more 
expressive instrument in one way, but these discreet 
movements start to hide the correlation between the 
performer’s movement and sound from the other musicians and 
the audience . Having said that, the button accordion  for 
example relies on small buttons for its playing, but the audience 
often knows enough about the workings of such an  acoustic 
instrument to feel a sense of virtuosity  and expression  in th e 
way the musician plays and moves with the instrument. 
 With the Vacuum mapping, different buttons correlate to 
different boxes in which samples can be tri ggered. Pitch and 
speed of the sample could do controlled wit h a rotation on the 
y-axis, volume on the x -axis and reverse  playing with the 
thumb. The shortcoming of this part of the original mapping 
was the inability to avoid silence at the start of a sample within 
an improvised context, hence the need for a visual cue to start 
recording. Within the context of performing a rehearsed 
composition this was absolutely fine, as in  Dark as a Dungeon,  
Proceedings of the International Conference on New Interfaces for Musical Expression
340
Table 1. A list of collaborations with the Vacuum mapping 
Music-
ian 
Alias 
Instru-
ment 
Piece Per-
form-
ance 
Type 
Docu-
menta-
tion 
Per-
form-
ance 
Date 
 BC Violin Violin 
Vacu-
um 
One 
(Aal-
borg) 
Impro-
visa-
tion to 
Camera  
Video/
Audio 
24/09/ 
2013 
 GJ Drums Drum 
Vacu-
um 
One 
(Am-
ster-
dam) 
Com-
posi-
tion for 
Film 
 
Video/ 
Audio 
11/10/ 
2013 
 NM Double 
bass 
Bass 
Vacu-
um 
One 
(Tel 
Aviv) 
Live 
Impro-
visa-
tion 
Audio 05/11/ 
2013 
 KS Guitar/ 
Electro
-nics 
Dark 
as a 
Dun-
geon 
Com-
posi-
tion 
 
Video/ 
Audio 
23/11/ 
2013 
 TM Guitar/ 
Effects 
Tales 
of the 
Black- 
Winged
Bird 
(Part 
II) 
Live 
Impro-
visa-
tion 
Video/ 
Audio 
08/12/ 
2013 
 JM Voice Voice 
Vacu-
um 
One 
(Syd-
ney) 
Com-
posi-
tion for 
Film 
 
Video/ 
Audio 
22/01/ 
2014 
 JC Guitar Guitar 
Vacu-
um 
One 
(Syd-
ney) 
Com-
posi-
tion for 
Film 
 
Video/ 
Audio 
23/01/ 
2014 
 
 
a performance to silent film for acoustic guitar, electronics and 
AirSticks that utilised some of the features of the Vacuum 
mapping. W ithin improvisation , however, the use of a gate has 
been developed to delay the recording of a sample so that the a 
sample with a clean attack could be played back. Having said 
that, ‘e xperimental improvised music is music that turns 
unexpectedly, leaping abruptly and uncon trollably away from 
conventions’ [1], so having an unpredictability to the mapping, 
as discussed before, can have its ben efits. 
 Another way of attaining a clean attack was to use granular 
synthesis, loosely based on the mapping of Michel Waisvisz for his 
instrument The Hands [9]. A strike through the air in certain areas 
would play the last two seconds of sound recorded. The velocity of 
the strike would control the velocity of the sample. Pitch could be 
controlled by moving along the x-axis, grain size and spray could be 
controlled with the thumb and the sample would remain being played 
forwards or in reverse by rotating dow n or up on the x -axis 
respectively, until a lift above the trigger point would turn the sound 
off.  This use of a percussion instrument metaphor is used to improve 
transparency [5] and utili se the motor skills of the exper t 
percussionist [10]. The AirSticks, as all open -air controllers [13], 
demands the performer and audience to use their imagination in 
ways that acoustic instruments, or even electronic pads have 
not done in the past.  Consequently, a virtual space is created 
around the performer. One obvio us way of exploring this space 
in a meaningful way is to map a layering of a drum kit. The 
AirSticks allows the easy manipulation of this space, moving 
drums around to places they would not usually be, or changing 
between different sounds with different ap proaches to a virtual 
trigger box . For example, striking a box with the palm facing 
up could trigger a sound resembling a kick drum, but striking 
that same box with the palm facing down could trigger a snare 
sound, with the sounds morphing between each oth er across the 
z-axis rotation . Forming continuity between these sounds is a 
great advantage of such an open -air controllers, morphing 
between different sounds in the space, as opposed to jumping 
from one to another.  This can help the audience better 
understand the way the original sampled acoustic sounds are 
manipulated through movement.  
 The use of the drum metaphor can also be explored to 
communicate ideas and cues to the other musicians, as one of the 
collaborators explains. 
 
‘BC: I think I’d need to pl ay with you more to really 
understand what the mapping is doing. Because when I 
understand what the mapping is doing and I understand what 
you are actually playing, it would be like watching a violinist 
play, or a drummer play. You know when the drummer is  
playing the toms, you can see what they are doing, or  when 
they are hitting a cymbal . W hereas with the AirSticks I can’t  
see how the space relates to the sound yet. All I can see is that 
if you wave your arms around there tends to be more intensity. 
Or if  you hit at a certain rate, it’ s more like a rhythm. So... 
Um... being able to read where on your spatial map those 
different sounds are and having that quite clear so if you move 
over there I can hear... I can hear that you are moving onto the 
toms or an equivalent drum kit or I  can see that you are about 
to hit a cymbal or something . 
AI:  You’d like it to be more like a drum kit even though it 
doesn’t sound like a drum kit? 
BC: No, I'm just using that metaphor for you.’ 
 
 On top of these options for sampl ing and triggering, the 
Vacuum mapping also features  a set of gestures that enable  the 
manipulation of the recorded samples and the acoustic 
instrument in real time. These include  reverbs, delays, 
vocoders, distortions, bit reducers, equalisers and panning , all 
mapped to gestures that can be learned by the other musician, 
except for mode changes between these effects which were 
mapped to discreet buttons. 
 
‘BC: The gestural elements of the instrument are really quite 
powerful. And the reason why they are po werful is because they 
cue me... the inten sity of your movements reflect the sound, so 
sometimes you are waving your arms around quite fast, and 
you’re doing beat, or... you know I  can see what y ou are doing, 
so in that way it’ s like an acoustic instrument  and it ’s much 
more um... informative for me. I feel like I am playing with 
someone, whereas if you are playing from behind a laptop it is 
much more one sided, it’ s not nearly as inspiring for the 
improvisation I think.’ 
Proceedings of the International Conference on New Interfaces for Musical Expression
341
3.4 Compositional Approach 
The Vacuum mapping for the performance of a composition did 
not feature the ability to sample in real -time, only to 
manipulate. Samples were prerecorded and edited earlier in the 
creative process so that the composer could have more control 
over them. Some of these co mpositional ideas came from an 
improvisation, others from previously composed pieces. 
Samples for the compositions were placed in the virtual boxes 
and manipulated in a similar fashion to the mapping for 
improvisation. 
 Perry Cook informs instrument designers to ‘make a piece, 
not an instrument or controller ’ [4]. Similarly, Schell and 
Battier coin ed the term ‘composed instruments’ design to help 
instrument designers think of mapping in a new way. They split 
electronic instruments into three categories – ‘musical 
instrument, machine and representation ’ – to help us understand 
their complexities  [14]. They define a musical instrument as 
something that enables ‘the performer enough degrees of 
liberty to explore personal and original ways of playing with it.’ 
[14]. For them, a machine ‘is under the control of complex 
computational and algorithmic layers,’ while a representation 
combines the two first categories. ‘Composers use the 
representational nature of the system to define events, write 
scores and specify t he computational and algorithmic layers 
while performers can apply gestural  controls and adjust 
parameters’ [14]. This combination of the composer and 
performer in new instrument design is analogous with the 
approach taken with the Vacuum mapping in combin ing the 
roles of the electronic producer and the expert percussionist. A 
compositional approach here starts with the electronic produ cer 
making a sketch of a piece of music on a computer, deciding on 
the main structures of the piece  and the samples to be u sed. The 
electronic producer then turns their attention to deciding how to 
perform the piece, in other words how to map this sound to 
movement. Taking on the role of a percussionist, the electronic 
producer then learns how to play the piece on the AirSticks, 
improvising around the main structures of the  piece, adding 
more layers of manipulation  of parameters  to the mapping. 
Finally, the percussionist collaborates  with the acoustic 
musician in th e rehearsal room to complete the semi -
improvised composition, w hich includes the live manipulation 
of the acoustic instrument.  The ‘score’ is then left open for 
different interpretations during each live performance .  
 Another way of looking at this trajectory of the creative 
process is defining these sections as composition, performance 
and choreography, and identifying the order at which they are 
placed. In the example  above, composition moves to gesture 
mapping or choreography, then  to rehearsing improvisation s or 
playing with the written material, and finally  to performing the 
semi-improvised work.   
 In the field of instrument design, t his trajectory more 
commonly begins with the gesture mapping. T hough changing 
this trajectory does not necessarily solve the problem of how 
sounds should be mapped to movements,  starting with a more 
complete composition can inspire different ways of mapping 
sound to movement, or in this  more choreographic approach, 
movement to sound . An example of this within the piece Dark 
as a Dungeon was the mapping of sounds to a confined small 
space during a section in the composition that represented men 
going down a shaft into a mine, juxtaposed against the mapping 
of sounds to a n open large space in a section representing the 
vastness of a mountainous landscape.  The collaborator in this 
case m entioned that ‘it was great to have that visually  [the 
choreography of the AirSticks] as part of the performance … ’ 
(KS). 
4. FUTURE WORK 
In this paper we have taken the approach of analysing the 
thoughts of expert musicians to help  create a better mapping for 
a gestural instrument . Through performing several new works 
with these musicians, we do not only increase the output of 
creative works on new instruments to help promote the culture 
of new instrument design, we can also investigate ways of 
improving th e way we map movement to sound , and sound to 
movement. B y collaborating in several different ways, either 
through improvisation or composition, we can improve the 
experiences of musicians in utilising new instrument s in their 
ensembles. More data about what mu sicians need and want 
from new instruments as composers or as collaborators can be 
used to improve new interfaces. We will continue to use the 
AirSticks in as many different contexts as possible and observe 
and interview musicians who come in contact with the 
instrument to get a better understanding of new instrument 
design for ensemble playing.  See www.alonilsar.com for the 
latest performances on the AirSticks. 
5. REFERENCES 
[1] Arias, R. I know it’ s only noise but I like it: scattered 
notes on the pleasures of experimental improvised 
music. Leonardo Music Journal  (Dec. 2002), 31-32. 
[2]  Bahn, C., Hahn, T. , and Trueman, D. Physicality and 
feedback: a focus on the body in the performance of 
electronic music. In (ICMC’11). (Huddersfield, UK, 
July 31 - 5, 2011). Michigan Publishing, MI, 2011, 44-
51. 
[3]  Bailey, D . Improvisation: i ts nature and practice in 
music. Da Capo Press, Cambridge, MA, 1993. 
[4]  Cook, P. R. Music, cognition, and computerized sound: 
an introduction to p sychoacoustsics. MIT P ress, 
Cambridge, MA, 2001. 
[5] Fels, S. , Gadd, A., and Mulder , A . Mapping 
transparency through metaphor: towards more 
expressive musical instruments. Organised Sound ,7, 
(Nov. 2002), 109-126. 
[6]  Ilsar, A., Havryliv, M., and Johnston, A. The airsticks: a 
new interface fo r electronic percussionists.  In SMC’11. 
Stockholm, Sweden , 2013. KTH Publishing, 
Stockholm, Sweden, 2013.  220-226 
[7]  Krefeld, V., and Waisvisz, M. The hand in the web: a n 
interview with Michel Waisvisz. Computer Music 
Journal, 14, 2, (Nov.1990) 28-33.  
[8] Mitchell,  T., and Heap,  I. SoundGrasp: a  gestural 
interface for the performance of live music.  In 
NIME’11. (Oslo, Norway, 2011). Oslo, Norway: 2011. 
[9] Mitchell,  T. J.,  Madgwick, S., and Heap,  I. Musical 
interaction with han d posture and orientation:  a toolbox 
of gestural control mechanisms.  In NIME12. (Daejeon, 
  Korea, 2013) 
[10] Mulder, A. Towards a choice of gestural constrain ts for 
instrumental performers,  Trends in gestural control of 
music. 315-335. 2000. 
[11] Ngwerume, P. M. The Digital Theremin, 2012. 
[12]  Ostertag, B. Human bodies, computer music. Leonardo 
Music Journal, 12, (Nov. 2002). 11-14. 
[13] Rovan, J., and Hayward,  V. Typology of tactile sounds 
and their synthesis in gesture -driven computer music 
performance, Trends in Gestural Cont rol of Music  
(Nov. 2000). 297-320. 
[14]  Schnell, N.,  and Battier , M . Introducing composed 
instruments, technical and musicological implications. 
In NIME’02. (Dublin, Ireland, 2002) 
 
Proceedings of the International Conference on New Interfaces for Musical Expression
342