MicroJam: An App for Sharing Tiny Touch-Screen
Performances
Charles P . Martin
Department of Informatics
University of Oslo
Norway
charlepm@iﬁ.uio.no
Jim Torresen
Department of Informatics
University of Oslo
Norway
jimtoer@iﬁ.uio.no
ABSTRACT
MicroJam is a mobile app for sharing tiny touch-screen per-
formances. Mobile applications that streamline creativity
and social interaction have enabled a very broad audience
to develop their own creative practices. While these apps
have been very successful in visual arts (particularly photog-
raphy), the idea of social music-making has not had such
a broad impact. MicroJam includes several novel perfor-
mance concepts intended to engage the casual music maker
and inspired by current trends in social creativity support
tools. Touch-screen performances are limited to ﬁve sec-
onds, instrument settings are posed as sonic “ﬁlters”, and
past performances are arranged as a timeline with replies
and layers. These features of MicroJam encourage users not
only to perform music more frequently, but to engage with
others in impromptu ensemble music making.
Author Keywords
mobile music, touchscreen, social computing, ensemble
ACM Classiﬁcation
H.5.5. [Information Interfaces and Presentation] Sound and
Music Computing — Systems, H.5.3. [Information Inter-
faces and Presentation] Group and Organization Interfaces
— Asynchronous Interaction
1. INTRODUCTION
MicroJam is a touch-screen app designed to encourage en-
semble interactions among users who are separated in space
and time. Much as forum posts and tweets can have replies,
so might musical performances. In MicroJam, users per-
form short performances on the touchscreen, up to a max-
imum time of ﬁve seconds, which are uploaded automati-
cally. Other users’ apps automatically download their friends
performances, to which they can listen and reply. The in-
terface for MicroJam emphasises frequent creation of short
performances and direct connection between touch-screen
interaction and sound. The layering of replies and perfor-
mances allows ensemble performances to be accrued over
time, enabling distributed and asynchronous collaborative
creativity. In this demo, MicroJam is presented a working
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’17,May 15-19, 2017, Aalborg University Copenhagen, Denmark.
prototype1. We aim to explore possibilities for ensemble in-
teraction in a mobile music DMI and the creative space of
tiny touch-screen musical performances.
Figure 1: MicroJam is an app for recording and
sharing very short touch-screen performances.
1.1 Jamming through space and time
Ensemble performances generally take place in the place,
and at the same time, for all performers in the group. This
is most often the case for ensemble NIME performances
that occur in the concert hall, studio, or pub stage. HCI
frameworks for cooperative work systems do address the
collaboration across space and time [4]. What could such
systems look like for musical performances? Can performers
derive some of positive aspects of ensemble performances by
collaborating asynchronously?
Mobile devices are a prime candidate for asynchronous
and distributed ensemble performances as users tend to
carry these wherever they go. Mobile device ensembles have
been extensively explored [6, 3, 5] although these have usu-
ally focussed on co-located and synchronous performances.
Smule’s apps such as Ocarina [7], Magic Piano, and Sing
Karaoke notably connected remote users. Ocarina intro-
duced the concept of a “world stage” where users could lis-
ten and rate performances by other users and Sing Karaoke
allows users to record diﬀerent layers of pop songs creating
asynchronous band demos.
While Sing Karaoke is limited to pre-arranged pop songs,
many musical possibilities are ruled out by this restriction;
in particular, new interface designs not modelled on existing
instruments could be distributed and tested by ensembles of
remote users. Such users may ﬁnd hidden aﬀordances of this
online medium and expand the possibilities of mobile music
1The source code for MicroJam is available at: http://
doi.org/10.5281/zenodo.322364
495
Figure 2: MicroJam’s list screen showing previously
recorded jams. Each can be selected for playback
or recording a reply.
performance. MicroJam is posed as an app platform for
exploring mobile, distributed, and asynchronous co-creative
systems.
2. DESIGN
The present version of MicroJam is an iOS app written in
Swift with web backend provided by Apple CloudKit. The
main screen consists of a list of performances (see Figure 2)
downloaded from other app users. These can be selected,
played back, and used as the basis for reply performances.
New performances can be created by selecting the “+”
symbol. The jamming screen (Figure 3) then appears, al-
lowing the user to record a new performance. A number of
sound schemes can be selected for the performance. As of
writing, these consist of a simple theremin-like sound, a key-
board sound, a Karplus-Strong modelled string sound, and
a drum set. Reﬁnements in the mapping from touch-screen
to synthesised sounds is ongoing to provide a variety of ex-
pressive options for users. During performance, touchscreen
interactions are visualised similarly to a simple “paint” app.
This visual trace of the performance is used to represent
the jam on the list screen. As seen in Figure 3, initial tests
suggest that users enjoy creative cross-over between visual
doodling and musical performance.
While the current prototype only supports one reply, fur-
ther enhancements aim to support multiple replies leading
to threads of continually evolving ensemble performances.
2.1 Tiny Musical Performance
In MicroJam, a musical performance is deﬁned to be ﬁve
seconds of interaction in the square touch screen area seen
in Figure 3. In this ﬁve seconds, users may tap, swipe, swirl,
and otherwise interact in any way in the touch-screen area.
Touchscreen data is simultaneously recorded, mapped to
synthesised sounds, and visualised. After the performance,
a list of the touch-screen interactions is stored on the web
service (CloudKit). This recording can also be exported
as a CSV ﬁle for later analysis. MicroJam performances
recorded so far result in CSV ﬁles of about 5kB in size so
uploading is possible even on very slow connections.
3. RESEARCH GOALS
MicroJam is intended to be used as a research tool to ex-
amine the potential for ensemble performance in everyday
Figure 3: The MicroJam recording screen; 5-second
long performances encourage a fast cycle of record-
ing, listening, and replies.
smartphone music interaction. Research goals include de-
veloping a large corpus of tiny musical performances and de-
veloping methods for generating these automatically based
on the styles of individual users. Future investigations in
this app will focus on the potential to predict [1] reactions
from a user’s friends and implement improvising and ac-
companying algorithms [2] that emulate an ensemble per-
formance experience in real-time.
Acknowledgments
Supported by The Research Council of Norway as a part
of the Engineering Predictability with Embodied Cognition
(EPEC) project, under grant agreement 240862.
4. REFERENCES
[1] A. R. Brown and T. Giﬀord. Prediction and
proactivity in real-time interactive music systems. In
Musical Metacreation: Papers from the 2013 AIIDE
Workshop (WS-13-22), 2013.
[2] A. Eigenfeldt, O. Bown, P. Pasquier, and A. Martin.
Towards a taxonomy of musical metacreation:
Reﬂections on the ﬁrst musical metacreation weekend.
In Musical Metacreation: Papers from the 2013 AIIDE
Workshop (WS-13-22), 2013.
[3] G. Essl. The mobile phone ensemble as classroom. In
Proc. ICMC 2010, pages 506–509, 2010. URL: http:
//hdl.handle.net/2027/spo.bbp2372.2010.119.
[4] S. Greenberg and M. Roseman. Using a room
metaphor to ease transitions in groupware. Technical
Report 98/611/02, Dept. of Computer Science,
University of Calgary, 1998.
[5] C. Martin, H. Gardner, and B. Swift. Tracking
ensemble performance on touch-screens with gesture
classiﬁcation and transition matrices. In Proc. NIME
2015, pages 359–364, 2015. URL: http://www.nime.
org/proceedings/2015/nime2015_242.pdf.
[6] J. Oh, J. Herrera, N. J. Bryan, L. Dahl, and G. Wang.
Evolving the mobile phone orchestra. In Proc. NIME
2010, pages 82–87, 2010. URL: http://www.nime.org/
proceedings/2010/nime2010_082.pdf.
[7] G. Wang. Ocarina: Designing the iPhone’s magic ﬂute.
Computer Music Journal, 38(2):8–21, 2014.
doi:10.1162/COMJ_a_00236.
496