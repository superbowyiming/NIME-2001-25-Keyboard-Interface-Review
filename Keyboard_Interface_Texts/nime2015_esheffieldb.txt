Distributed Mechanical Actuation of Percussion Instruments  Eric Sheffield University of Michigan Department of Performing Arts Technology School of Music, Theatre & Dance Ann Arbor, Michigan ersheff@umich.edu 
Michael Gurevich University of Michigan Department of Performing Arts Technology School of Music, Theatre & Dance Ann Arbor, Michigan mdgurev@umich.edu    ABSTRACT This paper describes a system for interactive mechanically actuated percussion. Design principles regarding seamless control and retention of natural acoustic properties are established. Performance patterns on a preliminary version are examined, including the potential for cooperative and distributed performance.  Author Keywords NIME, percussion, actuated instrument, augmented instrument  ACM Classification H.5.2 [Information Interfaces and Presentation] User Interfaces J.5 [Arts and Humanities] Performing Arts  1. INTRODUCTION The recent proliferation of actuated acoustic instruments presents intriguing potential for expanding the available gestures and timbres on instruments that already have an established performance practice and repertoire. Since most implementations of actuation operate by amplifying and reinforcing natural resonances in the instruments, the world of non-pitched percussion has seen little development in this area; what does exist tends to focus on robotic musicianship. In this paper, we present a non-robotic performance system of mechanical actuation that does not rely on acoustic resonance, thus opening the door to any percussion instrument, including those found, assembled, or designed by the performer. We describe the principles that influenced our interaction and mechanical design. Finally, we document performance gestures that we saw emerge in demonstrations on an initial implementation of the system, which suggest directions for future development of similar systems. 2. ACTUATED INSTRUMENTS Actuated instruments have recently received significant attention in NIME and related communities. Examples from multiple instrument families utilize excitation techniques that generally fall into three categories: electromagnetic, transducer-driven, and mechanical. There is insufficient scope to comprehensively enumerate examples in each category here; rather, we discuss a few of the projects that were influential in our work.  Electromagnetic actuation has perhaps seen the richest development to date. Electromagnets placed near a ferromagnetic material, such as a steel string, are driven with amplified signals to induce acoustic vibration. A variety of signals may be used, from sine tones to white noise to recorded samples, with differing results. The strongest responses are achieved when the source sound contains energy at a resonant frequency of the actuated object. There are currently at least two versions of pianos augmented with addressable electromagnetic actuators [2,12]. McPherson details strategies to improve this system using low-cost components that can cover the entire range of the keyboard and a signal processing method to ensure that signals remain phase-locked with the motion of the 
strings [12]. Similar electromagnetic systems have been applied to a Fender Rhodes [17], the electric guitar [15], and the vibraphone [3].  In the transducer-driven category are instruments like the Overtone Fiddle [14] and the EMDrum [16]. It could be argued that these examples are in fact still electromagnetic in that they use voice coils as the excitation method, but a major distinction from purely electromagnetic systems is that the transducer is mechanically coupled to the instrument. In the Overtone Fiddle, this is done with a transducer attached to the body of a violin, while the EMDrum’s transducer is coupled to the drum membranes using a rod that extends through the center of the moving coil.  Perhaps a subset or extension of the electromagnetic and transducer-driven categories are feedback systems that can be used in conjunction with an input device, such as a contact mic, to create feedback loops at resonant frequencies. Processing, commonly in the form of bandpass filters, can be used within the loop to accentuate specific harmonics. A popular guitar accessory, the Ebow, employs this technique, though it has also been applied to some of the aforementioned actuated instruments, among others [e.g. 15, 16]. Bowers and Haas’s “Hybrid Resonant Assemblages,” which share some aesthetic characteristics with the world of multi-percussion in the use of found objects and performer-designed instruments, create feedback loops with a fixed base and a malleable superstructure [4]. The properties of the feedback change as the performer manipulates the tins, jars, boxes, Petri dishes, and other objects used as superstructure elements.  Much of the development of mechanically actuated instruments has centered on robotic music systems. Kapur provides a survey of robotic instruments from multiple instrument families, including pianos, turntables, percussion, string, and wind instruments in [10]. In the same paper, he defines the robotic instrument as “a sound-making device that automatically creates music with the use of mechanical parts, such as motors, solenoids and gears.” This level of autonomy, though a key component of robotic musical instruments, can exist with varying degrees of human input. The robotic Indian drummer MahaDeviBot pulls rhythmic patterns from a database derived from pre-recorded examples and live input from human drummers [11]. It also reacts to sensor and tempo tracking data from a human performing on the ESitar. Shimon, the four-armed marimba playing robot with a pseudo-anthropomorphic head, automatically improvises chords, rhythms, and melodies in sync with a human player [9].  Non-robotic mechanically actuated instruments, that is, devices that depend on human input to function and do not generate material of their own, have probably received the least attention to date. RobotHands uses human performance input on a NovInt Falcon force-feedback device to transmit real-time and recorded gestures through a virtual connection [15]. An interesting aspect of RobotHands is that performance information can be sent simultaneously to multiple devices from a remote location. A similar project, Stapleton and Davis’ Ambiguous Devices, approaches mechanical actuation as a means to transmit the gestures or “presence” of the performers across locations on a single distributed 
11
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
musical instrument in which the input and output does not necessarily have a one-to-one relationship [18]. For example, a strike on a percussive instrument on one end may cause a turntable motor to spin on the other. Gurevich’s Stringtrees distributes performance between a mechanical actuator—a central rotating plectrum-arm—and human performers who can both adjust the speed of the rotation and manipulate the strings as they are struck by the plectrum-arm [8]. 3. MOTIVATION For the current project, we were primarily interested in exploring non-robotic mechanical actuation. This was born in part out of frustration with the limitations of our first foray into actuated instruments, a device called Metal Mirror. This instrument is built from a large 2’X3’ sheet of scrap steel actuated by a surface-mounted transducer and amplified with a contact microphone. The sheet of steel is suspended from a low wooden frame, putting the performer in a meditative kneeling position face-to-face with the metal (see Figure 1). The transducer is driven with sine tones generated in a Max patch that also uses a webcam to track the positions of blocks that can be magnetically attached and moved around the surface of the sheet. By moving these blocks, the performer has control over subtle adjustments to the tuning and amplitude of the sine tones. Since the scrap material was not tuned or modified outside of a few holes drilled for mounting purposes, we discovered many interesting and unexpected resonances when excited by the transducer, which led to a drone-like performance style that suits the meditative pose of the performer.  
 Figure 1. Metal Mirror in performance at PASIC 2014  In an attempt to extend the capabilities of the Metal Mirror, 
experiments were conducted with various audio source signals to excite the steel, including prerecorded audio samples and live input from a voice and guitar. As expected, and as is mentioned in [12], results are very weak unless the excitation source signal contains significant energy at a resonant frequency of the instrument. With our sample of untreated scrap metal, these resonances did not necessarily conform to concert tuning or the harmonic series, nor were they particularly narrowband, so while explorations with voice produced some interesting results when searching in microtonal steps and sweeps, similar to those achieved with sine tones in the original design, results from other sources were lackluster.   Appropriation of found objects and materials is a common phenomenon in the world of percussion. In these instances, the unique timbres resulting from indistinct or weak resonances, a departure from the expertly tuned bars of marimbas and vibraphones, are usually the aim of the instrument search. Indeed, a great deal of standard percussion repertoire requires the performer to essentially build an instrument out of found parts. For example, John Cage’s 27’10. 554” for a Percussionist asks the percussionist to build a setup from metal, wood, and skin. In the more recent Anvil Chorus by David Lang, the composer specifies only: “three resonant metals, four non-resonant metals, four foot pedal-operated non-resonant metals, one foot pedal-operated bass drum, and two woodblocks” [6]. Augmenting instruments through mechanical actuation is an especially suitable method in these situations as it does not rely on resonances for excitation. Rather, it can preserve the idiosyncratic timbres of the materials as the actuation can be modeled on the type of gestures a percussionist would naturally explore, including extended techniques (e.g. striking with mallets or sticks, scraping, rubbing, dragging a chain across the surface, etc.).  To further accentuate the distinctions between performable mechanically actuated percussion and robotic percussion, we were interested in exploring the emergent behaviors afforded through shared human-mechatronic interaction similar to that observed by Gurevich with Stringtrees [8]. In that system, the most interesting modes of performance occurred when the human and mechatronic components acted simultaneously on different aspects if the same acoustic system. 4. DESIGN Our primary design concept was to create an assemblage of mechatronically-actuated percussion instruments from found objects. The instruments should be playable simultaneously by human performers and mechatronic actuators, with the control signals to the actuators seamlessly integrated into the instruments themselves. In other words, we did not want a separate controller or interface to control the actuation that might draw away or divide the performer’s attention.   To fit with the spirit of multi-percussion, we went scavenging in a recycle center with stick bag in hand, trying out various materials by striking with mallets and sticks. For the initial system, we decided on a large ceramic tile and scrap piece of aluminum in bar form. Unlike a traditional percussion keyboard instrument in which the bars are carved and trimmed for tuning and emphasis of a fundamental pitch, ours was flat and unmodified. 4.1 Control In devising a performable method of actuation, we aimed to preserve the pre-existing instrument interface as much as possible. Most of the aforementioned actuated instruments achieve this to a degree, though the Magnetic Resonator Piano is particularly successful with its method of key sensing that does not require the performer to physically alter their primary mode of interaction—that of pressing a piano key—nor appreciably change the physical characteristics of the piano [12]. Rather, an additional level of control is layered on top of the existing performance practice via a modified Moog Piano Bar, allowing the performer to enhance their playing as bandwidth allows. 
 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. NIME’15, May 31-June 3, 2015, Louisiana State University, Baton Rouge, LA. Copyright remains with the author(s).  
12
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
 In the percussion world, the instrument interface can take many forms, including sticks, mallets, hands, or other striking implements. Indeed, a percussionist is expected to be especially adaptable to different situations, reflecting on sonic outcomes and adjusting behaviors in real-time. This being the case, we have taken the approach that such a non-standardized method of interaction implies that the focus should remain on the material itself rather than extraneous sensors or buttons. This proved to be a successful method for Metal Mirror, in which the designed interaction was moving magnetic blocks around the surface of the steel. We found that because the performer’s attention remained on the plate, they quickly developed performance techniques beyond the design of the system and introduced extended techniques e.g. hanging chains from the plate to vibrate sympathetically or pressing tuning forks against the plate to induce their own acoustic vibrations that were then amplified by the contact mic.  We addressed this priority in two ways. First was the decision to use the acoustic energy from the objects to drive the system: that is, the input to the system is simply the sound from the tile and bar, activated directly by the human performer. This helps to remove some of the cognitive load normally required of the performer when navigating an external control scheme on top of their habitual gestures. Second, we gave control to the performer to turn the actuation on and off, which we call opening and closing the gate. Both of these decisions consider the potential “seams” of the interaction, in this case transitions between playing the device acoustically and activating the actuation. Benford et al. discuss approaches designers can adopt to cope with seams: they may be removed, hidden, exploited, etc. [1]. We did not wish to completely hide or remove our seams by either obfuscating or eliminating the performer’s control over the actuation, but we sought to minimize their disruption of acoustic performance. A capacitive touch-sensing strip was adhered to the edge of the ceramic tile (see Figure 2) to control opening and closing of the gate. Since it is conductive, the entire surface of the aluminum bar became a capacitive sensor for the same purpose. Although this method deviates from the way the performer would otherwise play the unmodified acoustic instrument, similar gestures are within the realm of standard percussion techniques for muting, tuning and other modifications. Furthermore, as with any new instrument composed of found objects, performers will need to develop or adapt existing techniques in developing a new performance practice; we anticipate the touch control of the gate can be integrally incorporated into this novel practice.  
 Figure 2. Capacitive touch strip on ceramic tile 4.2 Maintaining Natural Acoustics Our goals for acoustic sensing and mechanical actuation started with the principled approach of “first, do no harm.” In other words, our augmentations should not have an appreciably detrimental effect on the desired sounds. To that end, a method for contactless acoustic sensing was explored. We looked to an existing actuated instrument, 
the EMVibe, for a solution [3]. Since the bars on a vibraphone are traditionally made from an aluminum alloy, they would not normally be sensitive to electromagnetic excitation, unlike the steel that comprises an electric guitar or piano string. To solve this problem, Britt et al. affixed tiny neodymium magnets to the end of each bar. We theorized that if this worked as an excitation method then it should also work as a sensing method. Inexpensive bass guitar pickups were used for testing. Indeed, though careful placement and alignment of the affixed magnets over the pickup poles were required, we were able to achieve output voltages in the range of 100mV when the aluminum bar or ceramic tile was struck, similar to the output expected from a pickup installed in an electric guitar. A simple smoothing circuit consisting of an RC filter and diodes was added in line with the pickup’s output to reject negative voltages and provide subtle low pass filtering. One unexpected benefit of this method was that the pickups could also be used for amplification, and so a second output without this filter circuit was added. Amplification has not been significantly exploited in the current instantiation, but we are nevertheless excited about the sonic potential this affords.  Another aspect of the “first, do no harm” philosophy was to ensure satisfactory acoustic response of the bar and tile. To accomplish this, custom laser cut mounts were designed to hold both the materials and the actuation drivers (see Figure 3). References on plate acoustics and keyboard percussion bar tuning were consulted to easily identify the nodal points of the bar and tile and design the mounts to hold them along those points [7,19]. The mounts also provided convenient places to attach the mechanical excitation devices, pickups, and output jacks.  
 Figure 3. Mounts for aluminum bar and ceramic tile 4.3 Actuation For actuation, a trio of small solenoids is used on the aluminum bar while a motorized fader with an attached metal brush actuates the tile (see Figure 4). Output from each of the pickups is fed into an Arduino Uno, which in turn controls the actuators through a motor shield. The control signals are fed from one device into the other so that the actuated material is an external extension of the original material. In other words, the audio output from the aluminum bar directly drives the fader brush mechanism on the ceramic tile and vice versa; essentially, an envelope follower. No significant treatment to the signals is implemented in software. Since we had already implemented a hardware low-pass filter circuit, the code on the Arduino does three simple tasks: 1) sets a threshold for actuation, 2) ensures that the three solenoids alternate in series, creating a rapid tapping gesture on the bar, and 3) rapidly alternates the direction of travel of the motorized in order to create a continuous scraping gesture on the tile. The speed of the motorized fader is controlled with a pulse width modulation signal with a duty cycle derived from the amplitude of the input signal.  Employing the instrument’s continuous acoustic energy output as the control signal driving the mechatronic actuation abides by principle of ergoticity, which Cadoz identifies as an essential property of instrumental interactions [5]. The system’s components interact exclusively through energetic exchange, physically and digitally: kinetic energy is transformed into sound in response to the human input; a digital representation of this acoustic output in turn drives the mechatronic actuator, which produces additional sound as 
13
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
a result. Adjusting the sensitivity and dynamic ranges of input and outputs affords the ability to “tune” the system in order to achieve a subjective impression of proportionality in these energetic exchanges.  
 Figure 4. Mechanical actuators 5. OBSERVATIONS We collected feedback and observations through our own exploratory improvisational practice with the system, as well as a series of open, public workshops with music and music technology students, and smaller sessions with professional-level concert percussionists.   We observed at least four distinct performance gestures: • Acoustic Only: Playing the material normally with no mechanical actuations. As with any item explored as a percussion instrument, participants varied strike position, damping, and different striking implements as desired. • One-To-One: The performer simply held the gate open while playing. Despite the simple one-to-one interaction, they still explored the materials just as much as they would acoustically with short, long, or rapid sounds with identical results on the externally actuated piece. • Accents: Similar to the One-To-One method except that the performer would dynamically open and close the gate, using the actuated percussion as a timbral extension to certain notes, essentially like a rhythmic accent. • Pulsed Actuation: The performer would open and close the gate rhythmically when a single long tone was played on the acoustic instrument, creating an additional overlaying pattern on the actuated device.  When two players were involved a few more unique behaviors emerged. We saw a version of human-mechatronic interactions [8] in which a player on one device would ignore their acoustic material and alter the mechanical actuator itself by dropping coins in the path of the metal brush or sticking paper between the solenoids and the metal bar. There was also potential for feedback loops if both players kept their gates open. The system was sensitive enough that an actuated gesture on one device was strong enough to then in turn send enough acoustic energy back to the original device to trigger additional actuation. Finally, we saw players alter the sound of their acoustic device through damping or additional gestures while it was being actuated by the other player.  Making the aluminum bar its own control surface through capacitive touch sensing had mixed outcomes. Touching the bar to open the gate obviously had some effect on the acoustic sound of the bar itself, though his was mitigated substantially by touching the bar over one of its nodes. An interesting result of this method was that the performer was more apt to rhythmically explore different levels of acoustic sustain by touching or grasping the bar in different places. The only gesture not afforded by this setup was that of damping the bar with a hand while keeping the control gate closed. 6. FUTURE WORK The system described in this paper is being developed further in anticipation of public performance. The system is being expanded with additional instrumental components, but the primary focus is on the development of performance practice and repertoire through 
rehearsal, workshops, and iteration. Multiple percussionists are integrally involved in the instrument design process, developing playing techniques and interaction strategies, as well as providing input into material selection and actuation methods. We agree with Newton and Marshall’s opinion that musicians “know the most about their instruments and about the sounds and music they wish to create and so it is the musician who should make the decisions on how the instrument should work” [13].   Aside from an expansion of the quantity and quality of salvaged materials installed in this system, we are also exploring dynamic actuation response beyond the simple envelope follower. While we intend to avoid turning this into an autonomous robotic performance system and keep the focus on human input, gestures can be further mediated by software through delays, recorded loops, rhythmic processing, etc. There is also still a great deal of room to explore a similar concept acoustically though more complex actuation methods that introduce their own additional dynamic acoustic or mechanical energy such as springs or mechanical linkages.  Finally, despite the simplicity of our current gate control, we intend to explore alternative methods that will improve the freedom of movement afforded to the percussionist; specifically to facilitate two-handed gestures with simultaneous gate control. One possible approach to accomplish this, though it moves the location of the control mechanism away from the acoustic material, would be the implementation of foot controls. Unlike most other instruments, the use of foot pedals already fits the drumset or multi-percussion paradigm. If such a design is sufficiently robust, an electronic switch activated rhythmically with a foot is akin to pressing a hi-hat or kick drum pedal. 7. REFERENCES [1] S. Benford, G. Giannachi, B. Koleva, and T. Rodden. From interaction to trajectories: designing coherent journeys through user experiences. In Proceedings of CHI, pages 709-718, 2009. [2] P. Bloland. The electromagnetically-prepared piano and its compositional implications. In Proceedings of ICMC, 2007.  [3] N. C. Britt, J. Snyder, and A. McPherson. The EMvibe: An Electromagnetically Actuated Vibraphone. In Proceedings of NIME, 2012. [4] J. Bowers and A. Haas. Hybrid Resonant Assemblages: Rethinking Instruments, Touch and Performance in New Interfaces for Musical Expression. In Proceedings of NIME, pages 7-12, 2014. [5] C. Cadoz. Supra-Instrumental Interactions and Gestures. Journal of New Music Research, 38, 3 (Sep. 2009), 215-230. [6] M. Coleman. Instrument Design in Selected Works for Solo Multiple Percussion. DMA. Thesis, Arizona State University, Tempe, AZ, 2012. [7] W. E. Flynt. The Construction and Tuning of Vibrating Bars. http://www.mmdigest.com/Gallery/Tech/XyloBars.html [8] M. Gurevich. Distributed Control in a Mechatronic Musical Instrument. In Proceedings of NIME, pages 487-490, 2014. [9] G. Hoffman and G. Weinberg. Shimon: an interactive improvisational robotic marimba player. In Proceedings of CHI, pages 3097-3102, 2010. [10] A. Kapur. A history of robotic musical instruments. In Proceedings of ICMC, pages 21-28, 2005. [11] A. Kapur, E. Singer, M. S. Benning, G. Tzanetakis, and others. Integrating hyperinstruments, musical robots & machine musicianship for North Indian classical music. In Proceedings of NIME, pages 238-241, 2007. [12] A. McPherson and Y. Kim. Augmenting the acoustic piano with electromagnetic string actuation and continuous key position sensing. In Proceedings of NIME, pages 217-222, 2010. 
14
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 
[13] D. Newton and M. T. Marshall. Examining How Musicians Create Augmented Musical Instruments. In Proceedings of NIME, pages 155-160, 2011. [14] D. Overholt. The Overtone Fiddle: an actuated acoustic instrument. In Proceedings of NIME, pages 4-7, 2011. [15] D. Overholt, E. Berdahl, and R. Hamilton. Advancements in Actuated Musical Instruments. Organised Sound, 16, 02 (Aug. 2011), 154–165. 
[16] D. Rector and S. Topel. EMdrum: An Electromagnetically Actuated Drum. In Proceedings of NIME, pages 395-398, 2014. [17] G. Shear and M. Wright. The electromagnetically sustained Rhodes piano. In Proceedings of NIME, pages 14-17, 2011. [18] P. Stapleton and T. Davis. Ambiguous Devices. http://www.paulstapleton.net/portfolio/tomdavis [19] http://www.physics.ucla.edu/demoweb/demomanual/acoustics/effects_of_sound/chladni_plate.html  
15
Proceedings of the International Conference on New Interfaces for Musical Expression, Baton Rouge, LA, USA, May 31-June 3, 2015 