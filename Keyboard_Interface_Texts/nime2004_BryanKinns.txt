Daisyphone: Support for Remote Music Collaboration
1st
N. Bryan-Kinns
IMC Group,
 Dept. of Computer Science,
Queen Mary, University of London,
Mile End, London, E1 4NS. UK.
nickbk@dcs.qmul.ac.uk
P. G. T. Healey
IMC Group,
 Dept. of Computer Science,
Queen Mary, University of London,
Mile End, London, E1 4NS. UK.
ABSTRACT
We have seen many new and exciting developments in new
interfaces for musical expression. In this paper we present the
design of an interface for remote group music improvisation
and composition – Daisyphone. The approach relies on players
creating and editing short shared loops of music which are
semi-synchronously updated. The interface emphasizes the
looping nature of the music and is designed to be engaging
and deployable on a wide range of interaction devices.
Observations of the use of the tool with different levels of
persistence of contribution are reported and discussed. Future
developments centre around ways to string loops together into
larger pieces (composition) and investigating suitable rates of
decay to encourage more group improvisation.
Keywords
Music, collaboration, improvisation, composition.
1. INTRODUCTION
In this paper we are interested in support for a basic form of
human creativity – group music improvisation [12]. Typically
people still improvise music together by playing individual
instruments in the same space. Examining the literature on new
music devices (see, for example, [7]) it is clear that there is a
growing body of work in new instruments such as the
HyperBow [15] – a development of the conventional violin
bow – and more unconventional instruments such as the
control of music using Ultrasound imaging [13], or ‘painting’
as a musical metaphor [9]. However, developments which are
explicitly concerned with how to support the creation and
performance of music as a group (e.g. COOL [6], as opposed to
individual composition support such as Audiopad [11]) are
less common, especially when the group is not physically co-
present (e.g.  see Blaine and Fels survey of the area [1]). Such
support is exemplified by systems which support group
composition through sharing of music files e.g.  FMOL [7]
where a novel individual music controller is complemented by
file sharing and on-line repositories. Supporting group music
improvisation whilst players are remotely located is a difficult
design challenge not least because the inherent network delays
would make synchronous interaction very costly and
technically complex. Typically these challenges are overcome
by relying on improvisation with short loops of music which
are semi-synchronously co-ordinated through some
networking infrastructure – e.g. WebDrum [4] and MetaTone
[8]. It is this less explored area that this paper focuses on –
how to support people playing music together when they are
not in the same space, and have limited network resources.
2. DESIGN
The instrument reported in this paper is part of ongoing
research into mutual engagement in collaboration [2, 3, 10]
and is referred to as Daisyphone reflecting its aesthetic and
musical features. The primary design aim for Daisyphone is to
provide a remote group music experience on a range of
interaction devices and as such Daisyphone is built using Java
1.4.1 and uses default MIDI instruments.
2.1 Supporting Interaction
Daisyphone’s interface is made up of four main elements
illustrated in figure 1. First is the representation of the
musical loop  itself which takes up most of the screen real
estate. Players click on the circles to set and unset notes which
are played as the rotating grey arm passes over them as
discussed later. Second is the modal control  of the player’s
instrument and volume in the centre of the Daisyphone. Third
is the session selector  in the top left hand corner of the
Daisyphone. Fourth is the continual annotation  which takes
place over the whole interface – when the player clicks using
whatever interaction device they have, a graphical annotation
is produced.
Figure 1: The Daisyphone user interface
2.1.1  Musical loop and modal control
The musical loop consists of 45 beats represented by spokes
radiating from the centre of the Daisyphone. 45 notes were
chosen in order to produce a symmetrical pattern of spokes
around the Daisyphone whilst ensuring that notes were not too
small to interact with. The notes on each spoke cover an octave
of MIDI notes in different instruments represented by different
shapes. Notes range from MIDI 80 in the centre to MIDI note
68 at the outer edge. We decided to rely on default MIDI
instruments so that Daisyphone could be used on a range of
devices including tablet PCs, PDAs, mobile phones, home
computers, etc. Whilst technology is developing to support
richer sound production (e.g.  Vector sound production for
mobile devices) it is still proprietary and requires players to
install plug-ins.
The player selects their current instrument and volume for
composition from the central 4 spokes (modal control).
Currently the default MIDI instruments of piano (circle), bell
(square), glockenspiel (diamond), and percussion (triangle) are
selectable. The volume of notes is indicated by the saturation
of color – the more saturated, the louder the note is.
The visual design emphasizes the looping nature of the music
created. When observing novice players using other interfaces
for creating short loops based on a linear, horizontal timeline,
we noted that the loops tended not to ‘join up’. That is, they
created a sequence of notes in which there was a noticeable
break when the loop restarted. We hope that the circular
representation will reduce this phenomenon.
We decided not to provide notes on a scale such as pentatonic
which would have made it easier for novices to construct
tuneful compositions. This was because we wanted to provide
some challenge for people who had, or developed, musical
skills.
2.1.2  Session selector
Currently 20 sessions are supported – these are selected using
the session selector illustrated in figure 1. Each circle in the
session selector contains a tiny representation of the content
of that session. Furthermore, the content of the circle flashes
when activity occurs in that session with the hue of the
contributing player.
2.1.3  Annotation
Annotation in Daisyphone is continual and shared. Whenever
a player presses with their interaction device (e.g. mouse, or
pen) a mark is made and shared with others. Unlike notes,
annotations are persistent which provides some history of
action – when notes are set and then unset the small
annotations created from setting and unsetting the notes
remain. Figure 3 illustrates the use of persistence to illustrate
the location of notes which have been deleted in the
composition process. Note that in a typical 10 minute
composition so many notes are added and deleted that the
sequences become lost in a mess of annotations – some more
effective design needs to be developed in this area.
Figure 3: Persistence of annotation
2.2 Supporting Collaboration
Daisyphone uses a client-server configuration similar to that
used by WebDrum [4]. Messages are sent from clients to the
server and then, if appropriate, messages are broadcast to other
clients. This provides semi-synchronous collaboration with
low-bandwidth requirements.
In a previous study of the use of WebDrum we identified
several features of human interaction which we believe are
important to make the logistics of collaboration efficient and
free-flowing [2]. The Daisyphone user interface is designed to
visually support these features which are:
•  Identity  – knowing who is contributing what. In
Daisyphone each player is assigned a unique hue which
provides a form of identity.
•  Mutual awareness  of actions – knowing who is doing
what. Each contribution by each player is shared with all
other players through the server, the color of the
contribution gives an indication of authorship, and the
session selector provides some indication of what is going
on in other sessions.
•  Mutual modifiability  – being able to modify each other’s
contributions. There is no edit control in Daisyphone so
each player can edit any one else’s notes simply by clicking
on them.
•  Localization  – being able to easily reference parts of the
joint product. The graphical annotation provides an
intuitive localization mechanism e.g.  circling interesting
sequences of notes and writing comments next to them.
2.2.1  Client-server protocol
A proprietary text based protocol is used to support
communication between clients and the server via TCP/IP
sockets (illustrated in figure 4) – we are investigating
migrating the protocol to more open protocols such as
OpenSound Control [14] to make Daisyphone more generally
usable and possibly co-ordinate it with other musical devices.
Three categories of message are supported in the proprietary
protocol: Notes (set, unset); Annotations; Session control.
Figure 4: The Daisyphone client-server infrastructure
The server keeps a copy of all messages for future analysis and
to support the persistence of sessions.
3. STUDY OF USE
Previous studies [2, 3] have identified several design issues
with Daisyphone and its support for group creativity. In this
paper we explore the nature of persistence in contributions. In
pervious versions of Daisyphone all contributions were
persistent. In order to investigate the effect of persistence of
musical contribution, a new version of Daisyphone in which
notes slowly disappear was developed (referred to as the decay
version). Only the notes are transient, therefore the graphical
annotation created when the notes are contributed remain
providing some visual cues to the contributions. The rate of
decay of the notes is critical to the design – too quick and
coherent sharing of music will not occur given the semi-
synchronous nature of the infrastructure; too slow and the
musical space will continue to became overcrowded. For the
studies here, decay is created by halving the volume of notes
every time the arm passes over them. This typically gives 3
plays of a loud note before it disappears which appears to be
sufficient for co-ordination
3.1 Format
Ten post graduate students were set a piece of coursework in
which they were asked to use both the persistent and decay
versions of Daisyphone to remotely create music together over
three weeks, perform their piece of music for the rest of the
group, and analyze and report on the interaction that took
place in Daisyphone in both versions. The students grouped
themselves into 3 groups and had a wide range of musical
ability. None had ever used a tool like Daisyphone before.
Logs of all actions in Daisyphone were stored for later re-play
and analysis.
4. PATTERNS OF USE
This section outlines the patterns of use and behavior that
took place in the study with the persistent and decay versions
of Daisyphone. Initial analysis of logs are presented here –
detailed analysis is currently being undertaken. An average of
8 sessions with the persistent version and 3 sessions with the
decay version were recorded for each group. Each session
lasted on average 16 minutes for the persistent version and 12
minutes for the decay version.
4.1 Patterns of Use with Persistent Version
As with ongoing analysis of the use of Daisyphone, in both
versions the participants tended to spend the first parts of
their sessions exploring Daisyphone on their own. Typically
in the shared environment this meant working in a particular
quadrant of the loop of music. Once participants were able to
understand Daisyphone’s interface they then moved on to
working in other areas to develop longer tunes or contribute to
other participants’ work.
Interestingly, an informal role assignment developed when
using the persistent version with participants tending to stick
to one instrument. Moreover, a ‘leader’ tended to emerge
during the sessions. This person typically constructed the
main melody which was then supplemented by others in the
group. Daisyphone has no explicit mechanisms or guidance
for how to divide the collaborative effort, so we believe that we
are starting to see here some emerging behavior which could
give us insight into how to develop more engaging
collaborations in the future. We suggest that role assignment
emerges naturally and does not need to be explicitly built in
to the interface i.e. in this case there was no need for ownership
control of instruments as participants negotiated it
themselves.
In pervious studies we noted that participants tend to write
their name on Daisyphone. Given the ongoing nature of
Daisyphone public trials, and the informal nature of other
trials, we suggested that this name writing was a form of
stating ownership - saying ‘This is mine’. From post study
discussion it became clear that participants were using their
names as presence and authorship indicators – saying ‘This is
me’. We suggest that the emergent and conventionalized
behavior of writing one’s name on entry to a session indicates
that the messy nature of the interface additionally supports the
informal evolution of expressions of identity. To this end we
do not believe that the introduction of explicit identity into
the interface is necessary or worthwhile. Interface features such
as pictures, textual names, etc.  add an unnecessary layer of
interaction (setup, login, and so on) which we seek to avoid in
the development of informal, ad-hoc , serendipitous interfaces.
Participants reported being fairly relaxed about deleting other
participants notes and making modifications to their
contributions. This is in contrast to previous studies and
ongoing public use where reluctance to edit others’
contributions is evident. We suggest that this is due to the
nature of the exercise set (‘you must create a piece of music
together for performance later’) and the social situation (they
all knew each other quite well and had possibly worked
together before).
4.2 Patterns of Use with Decay Version
The use of Daisyphone with decaying contributions was not as
engaging as anticipated. Participants complained that they
could not keep up with the required contributions and that
sessions tended to become unstructured and uncoordinated.
Experience with Daisyphone as a musical instrument was a key
factor in engagement with the decay version – the more
experience participants had, the easier they found the decay
version to handle.
When looking back over the logs of the interactions it is clear
that in the version with decay participants tended to make
musical ‘gestures’ rather than placing individual notes as they
had on the persistent version. This is illustrated by the amount
of annotation in figure 6 which reflects the creation of music
through gesture rather than placing of notes as in figure 5.
These gestures tended to be quickly drawn lines which could
easily be replicated to keep the tune going. Perhaps providing
an even more fluid form of interaction where gestures are
interpreted around the Daisyphone would provide easier ways
to create musical motifs in real time. It was also clear that the
decay version required more focus on the music, and much less
discussion of pieces, with participants having to keep musical
motifs in their head in order to keep a tune going. In some
ways this makes the decay version more akin to conventional
group musical improvisation where typically the music and
gestures provide for communication between participants as
opposed to speech (text in Daisyphone).
Figure 5: Persistence Figure 6: Decay
Persistence of annotation which provides some history of
contributions did not prove as useful as anticipated as the
proliferation of contributions meant that there were a lot of
indications of old notes as illustrated by the mess of graphical
lines in figure 6. Perhaps the sequence of contributions also
needs to be indicated in some way.
Also, interestingly there was anecdotally more convergence of
tunes between participants with the decay version i.e.  they
started to make similar tunes within a group more quickly than
they did with the persistent version. This indicates that decay
may encourage quicker convergence of musical patterns after a
period of experimentation.
In terms of organization, participants found that with the
decay of notes the division of labor was more egalitarian. That
is, there was no longer the typical emergent leader of the piece,
instead participants contributed what they could, with the
tendency to converge quickly on a musical theme (if one could
quickly be established).
Finally, from analyzing the logs it is clear that participants
contributed notes more frequently with the decay version (e.g.
one group made approximately twice as many contributions
per minute with decay versus  persistence). This is clearly
because of the amount of contributions that are needed to keep
a tune going when the notes disappear.
4.3 Implication of Decay for Design
The key implication with respect to the decay of contributions
is that contributions should only start disappearing once
people have learnt how to usefully make them. We had
expected the converse to be true – that when contributions
decay it would be easier to learn the effects of the interaction
through experimentation. So, we suggest that in order for
creative experiences to become more engaging people’s
contributions should become more transient as they become
more experienced, whilst support for the logistics of
collaboration remain constant e.g. mutual awareness of actions
should not change. We can usefully relate this to
Csikszentmihalyi’s analysis of flow and its relation to skills
and challenges [5]. In the case of Daisyphone we believe that
with persistence people became bored of the interaction as the
challenge was no longer sufficient for their skills, whereas
with decay participants were initially anxious, but some did
increase their skills enough to experience flow. We suggest
that as people become more skilled with the interface the rate
of decay should gradually increase so that the challenge is
sufficient for a flow experience. Doing so would provide
people with an experience of music in which their initial low
skills are supported by persistence of contribution, so not
being too anxiety provoking, whilst boredom is abated by
increasing the challenge (decay). Moreover, we suggest that by
keeping the collaboration support constant the participants
will become more engaged with each other as well as the
product at hand. We would expect to see more convergence of
music, and hopefully more reliance on others’ contributions in
the joint production. Furthermore, we believe that the decay of
contributions by skilled users could be usefully employed to
engender mutual engagement in other group creative tools
such as brainstorming, problem solving, and so on.
5. CONCLUSION
This paper presents observations on the use of a group music
improvisation tool in two versions: one where musical
contributions persist, and one where they decay. We suggest
that allowing variable amounts of decay in an interface will
allow the challenge of an interface to change to reflect the
skills of participants and so hopefully more flow experiences
will occur. Moreover, it will support increased engagement
between people as indicated by more convergence and
borrowing of other people’s ideas. These are useful features for
other creative applications.
Additionally, we feel that the ‘messy’ nature of Daisyphone
provides a useful interaction metaphor which informally
supports many aspects of the logistics of collaboration
including identity, awareness, history, localization, and the
development of communicative conventions. We argue that
the introduction of explicit support for these features of group
interaction is unnecessary and instead suggest that more
messy support will encourage people to intuitively develop
their own conventions.
6. ACKNOWLEDGEMENTS
Supported by Queen Mary, University of London and EPSRC
grant GR/S81414/01. Thanks to all those who have taken part.
Daisyphone is currently hosted at: gouda.dcs.qmul.ac.uk
7. REFERENCES
[1] Blaine, T., and Fels, S. Contexts of Collaborative Musical
Experiences. In Proceedings of NIME-03, 129-134, 2003.
[2] Bryan-Kinns, N., Healey, P., Thirlwell, M., and Leach, J.
Designing for Group Creativity. In Supplementary
Proceedings of HCI International 2003 (Crete, 2003).
[3] Bryan-Kinns, N., and Healey, P. Daisyphone: The Design
and Impact of a Novel Environment for Remote Group
Music Improvisation. Proceedings of DIS 2004.
[4] Burk, P. Jammin' on the Web - a new Client/Server
Architecture for Multi-User Musical Performance.
Presented at ICMC 2000.
[5] Csikszentmihalyi, M. Flow: The Psychology of Optimal
Experience. Harper Collins. 1991.
[6] Hankins, T., Merrill, D., and Robert, J. Circular Optical
Object Locator. In Proceedings Of NIME 02, 2002.
[7] Jordà, S. (2001). Improvising with Computers: A Personal
Survey (1989-2001). In Proceedings of 2001 Int’l
Computer Music Conference. La Habana.
[8] Leach, J. MetaTone: Shared Environment for musical
collaboration . MSc IT Thesis, Queen Mary, University of
London. 2001.
[9] Levin, G. Painterly Interfaces for Audiovisual
Performance. MSc. Thesis, MIT, USA. 1994.
[10]  Marks, P. Will Jamming be the New Texting? New
Scientist, 180, 2418 (25 Oct 2003), 25.
[11]  Patten, J., Recht, B., & Ishii, H. Audiopad: A Tag-Based
Interface for Musical Performance. In Proceedings of
NIME 2002.
[12]  Sawyer, R. K. Group Creativity: Music, Theater,
Collaboration . Lawrence Erlbaum Ass. 2003.
[13]  Vogt, F., McCaig, G., Adnan Ali, M., Fels, S. Tongue ‘n’
Groove: An Ultrasound based Music Controller. In
Proceedings of NIME-02, 24-26, 2002
[14]  Wright, M., & Freed, A. Open SoundControl: A New
Protocol for Communicating with Sound Synthesizers.
Presented at ICMC 97. 1997.
[15]  Young, D. The Hyperbow Controller: Real-Time Dynamics
Measurement of Violin Performance. In Proceedings of
the 2002 Conference on New Instruments for Musical
Expression (NIME-02), Dublin, Ireland, May 24-26, 2002.