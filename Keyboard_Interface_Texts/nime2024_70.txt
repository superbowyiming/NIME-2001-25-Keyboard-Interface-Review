Pharosphones: interactive audience participation using
light
Zhengyang Ma
The Hong Kong University of
Science and Technology
Hong Kong SAR
zmaaf@connect.ust.hk
Iurii Kuzmin
The Hong Kong University of
Science and Technology
Hong Kong SAR
ikuzmin@connect.ust.hk
Duan Ruilei
Zhejiang Conservatory of
Music
Zhejiang, China
DRL@zjcm.edu.cn
Raul Masu
Computational Media and Art
The Hong Kong University of Science and Technology (Guangzhou)
Guangzhou, China
raulmasu@hkust-gz.edu.cn
ABSTRACT
This paper presents a novel approach to live performance
thatblendsaudienceparticipationthroughtheuseofmobile
phone light tracking with music conduction. Drawing from
the history of audience engagement in the arts and leverag-
ing advancements in digital technology, we foster a dynamic
and immersive interactive model that complements tradi-
tional musical conduction techniques. The performance was
designedfora270-degreeconcerthall, allowingtheaudience
to see one another. In this setting, we explore the symbi-
otic relationship among the various actors in a performance
by employing mobile phones not only as communication
devices but also as light emitters. To achieve this, we de-
veloped a computer vision system designed to translate au-
dience participation into shaping the performance’s sonic
landscape. This process, underpinned by considerations of
cybernetics and the feedback loop between human partic-
ipants and technological systems, challenges conventional
power structures within performance spaces. Through this
work, we aim to expand the boundaries of interactive music
creation, offering insights into the potential for technolog-
ically facilitated audience entanglement and advancing the
discussion within the context of music ecology.
Author Keywords
AudienceParticipation, Cybernetics, InteractiveMusicSys-
tems, Light-based Interaction, Mobile Phones, Performance
Ecosystem, Computer Vision
CCS Concepts
•Applied computing → Sound and music comput-
ing;
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’24, 4–6 September, Utrecht, The Netherlands.
1. INTRODUCTION
This paper presents an interactive system that allows for
audience participation by using light. The work is based
on a reflection on cybernetic thought [30] as a lens to con-
ceive performance ecosystems [28], which highlight recur-
sivity and reciprocity among their various actants.
Different forms of audience participation have been ex-
plored over the past two decades [10, 31, 5, 33, 4, 16, 29, 1],
primarily using mobile phones to send messages as a means
of interaction with computer music performance systems.
At the same time, light as an input method to control in-
teractive music systems has been widely explored [6, 2, 13,
21]; however, it has rarely been investigated as a means to
enableandfosteraudienceparticipation. Wefindlighttobe
a valuable medium which can generate poetic and theoreti-
cal sparkles. Light is visible, it illuminates (or highLIGHTs)
the other, thus it is not just a means of interaction with the
sound and the stage, as often done in audience participation
pieces with mobile phones, but also renders the individual
actions of each audience member visible to others.
The use of light is particularly interesting from the per-
spective of investigating performance ecologies [28] as it im-
plicitly creates a “network” of visible “connections” among
all the actants involved in the performance, facilitating the
creation of recursive loops of mutual exchange among all
the actants involved. In particular, we conceive this visible
and audible ecosystem as a cybernetic circuit, with cyber-
netics being the study of “control and communication in an-
imal and machine” [30], particularly investigatingfeedback
loops. Composing a piece that encompasses various activi-
ties (writing code, fabricating materials, engaging with the
audience, and the act of composition itself) is recognized in
the language of cybernetics as apurposeful activity[30].
We embrace cybernetic thinking to conceptualize the mu-
sical ecosystem wherein the initial goal-directed impetus is
dispersed into a mosaic of autopoietic processes. In other
words, the overall design of the system functions as apur-
poseful activity that works by establishing feedback loops
in a complex cybernetic circuit. A recording of the perfor-
mance can be found at:https://zmk5566.github.io/res/
pharosphones.mp4.
2. BACKGROUND
2.1 Music Ecosystems as Cybernetics of Cy-
bernetics of Cybernetics
The concept of performance ecosystems has emerged re-
cently as a way to understand the complexity of intertwined
connections in the context of a music performance. Simon
Waters in his topical essay analyzed performers, instru-
ments, and environment as part of a performance ecosystem
[28]. Similarly, Gurevich and Trevino proposed considering
the “relationships between composers, performers, and lis-
teners as a part of a system,” [8] In line with this reasoning,
Rodger and colleagues have recently pointed out that “in-
strumentsarebetterunderstoodintermsofprocessesrather
than as devices, while musicians are not users, but rather
agents in musical ecologies” [24].
We propose that cybernetics offers an interesting way of
looking at performance ecologies, supported bythe fact that
both belong to a shared theoretical lineage [11]. Cybernet-
ics provides a systematic analysis of complex phenomena
specifically looking atfeedback loops as a way of establish-
ing circular causality [11]. Within NIME, the notion of
cybernetics has been previously used in the context of a
critique of aesthetic and relational hierarchies [22] and in
the analysis of feedback musicianship tracing how the con-
cept of feedback that emerged as a technical endeavor has
been subsumed as a cultural idea [18].
In this paper, we render our performance ecosystem as a
cybernetic circuit which generates recursive and reciprocal
loops of entanglements among its various actants: both hu-
man and technological. We explore this setting in a perfor-
mance that we developed where we combine audience par-
ticipation with music conduction and light based in interac-
tion. Ourplayfulnotionof music ecosystems as “cybernetics
of cybernetics of cybernetics” humorously underscores the
recursive nature within our system as well as the role of the
music ecosystem in the designed performance context. By
framing music ecosystems within second-order cybernetics
(the cybernetics of observing systems), and then extending
it to a third layer which we wish to highlight the intricate
feedback loops not only between components within a single
system but also across multiple levels of systemic interac-
tion and observation, with a tease on the recursivity.
2.2 Audience Participation
Audience participation has a long history in performance
arts and music that can be traced back to the avant-garde
(particularly relevant being the Fluxus movement [9]). In
the past couple of decades, audience participation in live
performances using digital technology was largely investi-
gated over almost two decades. A large number of works
rely on audience participation through the use of mobile
phones and web communication. For instance, Egozy and
Lee use mobile phones in “12” to enable an engaging and in-
dividualized experience. Similarly, Zhang et al. developed
“Open Symphony,” a web-based application enhancing col-
laborative contribution by allowing audience voting in fa-
vor of certain musical attributes during live performances.
Likewise, Freeman et al. conceived “massMobile,” a client-
server system that facilitated mass audience participation
through smartphones. The adaptable nature of this system
allows for real-time communication across different settings
and venues. Distribution mechanisms for enabling audience
participation have also been a focal point, with Lee et al.
proposing the use of Mobile Ad-hoc Networks (MANETs)
to simplify the distribution process of mobile music applica-
tions. By decreasing user configuration and infrastructure
dependency, they aimed to increase accessibility and en-
courage broader engagement. The cloud has emerged as a
powerfultoolforscalinginteractiveperformances. Carvalho
Junior et al. showcased how cloud services could facilitate
large-scale audience participation with their work “Crowd
in C[cloud],” emphasizing the importance of understanding
network transactions and scalability.
Recently, based on a large corpus of examples, Xambó et
al. contributed a framework for composing network music
using mobile phones for audience participation, proposing
compositional dimensions that consider various roles and
feedback types. Their work underlined the aesthetic consid-
erations crucial to designing audience-centric performances.
While most of the works allowing for audience participa-
tion rely on network communication, other examples do ex-
ist. For instance, installations such as “Performance With-
out Borders” and “Embodied iSound” integrated real-time
movementtrackingandindoorpositioningsystemsaffecting
audio parameters, to enrich the participatory environment.
We have seen that mobile phones are often used as means
to support audience participation. In most cases, they are
used as interfaces relying on network communication. In
this short paper, we describe a performance that comple-
ments these approaches by using conduction in combination
with mobile phone light tracking as a means to promote au-
dience entanglements with real-time interactive music cre-
ation.
2.3 Music Conduction
Rooted in experimental aleatoric works from the sixties
and seventies, such as those by Cage and Stockhausen [12]
among others, the practice of conduction refers to a per-
formative improvisation practice where a leading figure (a
sort of conductor) directs the improvisational choices of the
other members of an instrumental band. The term, which
originated with Butch Morris, is derived from physics; with
this practice, Morris conducts an improvisation of an en-
semble by relying on codifiedistill open to interpretation
imusical gestures [14]. Another important example of this
practice is “Cobra” by John Zorn, designed as a ludic com-
positional system. In “Cobra”, Zorn extended the con-
cept of conduction by employing a series of notated cues
or “game pieces” that serve both as conducting gestures
and compositional elements, guiding the improvisation flow
while leaving room for performers’ interpretation and inter-
action, thus creating a dynamic structure of performative
improvisation1 .
2.4 Light and Musical Interaction
The use of optical media in the design of musical instru-
ments has a long history, from the early 20th-century avant-
garde to contemporary practices in sonic arts. Among re-
cent works, for instance, is the ’light instrument’ conceived
by Eyes and Jongejan, which allows performers to dynami-
cally manipulate audio elements, relying on a visual method
of interaction that directly influences the sonic outcome [6].
Similarly, Cassinelli et al. introduced scoreLight, employing
a laser to translate visual patterns into sound [2].
Moving towards participatory installations, Kobori et al.
created LINE, where interactivity is catalyzed by light [13].
Audiences engage with the installation, using their move-
ments to affect both the audio and visual outputs, thereby
contributingtotheperformativeaspectthroughlight-mediated
interactions [13].
Pak explored the use of light to augment musical expres-
sion in The Light Matrix [21]. This interface integrates
controlled lighting effects that resonate with the musical
1 A small documentary on the piece is part of Derek Bai-
ley’s film “On The Edge” (1992), available athttps://www.
youtube.com/watch?v=yp-oZbmsQVw
performance, crafting a synchronized multisensory experi-
ence that strengthens the connection between the artist and
the audience [21].
These contributions collectively underscore the signifi-
cance of light as not merely a stage effect but a power-
ful medium for interaction. Through the manipulation of
light, thesetechnologiesenablearicher, moreimmersivelive
music experience, showcasing the boundless possibilities for
audience engagement and interactive performance art.
3. PHAROSPHONES
Figure 1: The stage setup.
A new contemporary concert hall at the Zhejiang Con-
servatory of Music had been built by the time this work
was created. Although we were not involved in the venue’s
design, we, as creators, observed something special about
this concert hall. It has a 270-degree circular structure
with three audience areas adjacent to the stage. Audience
members seated at different angles can watch the stage per-
formance from distinct perspectives and see other audience
members, thus becoming a part of the performance land-
scape themselves.
By examining this specific setting from the perspective
of performance ecosystem and cybernetics and using
lightasamedium, wedesignedaliveperformancewherethe
audience, without needing a background in musical train-
ing, actively participates, becoming part of the loops in the
recursive performance system.
3.1 Roles in The Performance
There are three roles involved in this performance: the con-
ductor, the participating audience holding light points, and
the system designers on stage. At the beginning of the per-
formance, the conductor signals everyone to turn on the
lights of their phones and raise them up, then put them
down, and then the performance begins without further
communication or training. During the performance, the
conductor directs the movement of the lights in the hands
of the audience below through his gestures. At this point,
through a computer vision system, the condition of the light
points in the performance scene is fed back and mapped into
sounds. The system developer can monitor the performance
through both a data visualization system on the laptop and
direct observation of the stage performance.
3.2 Concept of The Performance
Based on cybernetics thinking outlined above, the core con-
cept of our performance is grounded in recursivity and feed-
back loops. The innovative architecture of the venue in-
spired us to explore the power dynamics between the stage
and the audience. We envisioned an audience interaction
system modeled on cybernetic structures. In particular, we
were directly inspired by one of the first examples of cyber-
netics - Wiener’s development of a machine “designed with
the purpose of impinging upon a moving luminous goal”
- originally a moving torpedo - where designing a system
that relies on feedback loops to guide and modify its own
behaviors to follow the light was considered a “purposeful
activity” [25].
Based on foundational cybernetic principles, the overall
design of our performative ecosystem is apurposeful activity
that works by establishingfeedback loops among audience
members, light, a conductor, and a computational system.
To do so, we aimed at capturing changes in different areas
of the audience on stage. However, unlike traditional uses of
cybernetics ([17]), we strived to facilitate audience interac-
tions but aimed not to control the final result. The behavior
and specific choices that constitute audience participation
(as performers) are uncontrollable and unknowable, barring
any possibility of rehearsal; therefore, the conductor needs
to improvise and communicate with the audience through
gestures that are not commonly defined. Meanwhile, the
audience participates based on the conductor’s actions, re-
actions from other audience members, and sound. At this
moment, the system developer on stage paradoxically be-
comes an “audience” of the concert performance, reflecting
on the entire performance and the system itself.
3.3 Technical Implementation
Figure 2: The overview of the Pharosphones Sys-
tem.
For the integrated system’s design, we utilized the open-
source Robotics Community’s toolset, the Robot Operating
System (ROS Kinetic)[23], to support our implementation
and experimentation efforts. Our hardware setup included
a laptop with Ubuntu for visual processing, a fisheye cam-
era, a MacBook for sound output, and a 5G router for con-
nectivity.
3.3.1 Input
Regardingvisualinput, weemployedafisheyecameraalong-
side the OCamCalib visual algorithm[26] to achieve a cor-
rected Panoramic view. We segmented the performance
area into three zones based on their actual physical seat-
ing, which served as regions of interest for the algorithm.
3.3.2 Processing Input
Through thresholding techniques for graphic segmentation,
weprocessedthereal-timelightconditionsfromusers nflash-
lights in each zone. Before the performance, scenes showing
audience members toggling their phone flashlights provided
reference frames. By comparing current bitmap frames to
these references, we established a mapping function.
3.3.3 Sound Design
The visual data from audience phone lights was intricately
converted into three precise floating-point values, represent-
ing the performance areas. These values were sent in real-
time via the Open Sound Control (OSC) protocol2 to a
granular synthesizer in Max/MSP3 , driving sound genera-
tion. Given the reliance on mobile phones for audience in-
teraction, we leaned heavily into using phone-related audio
materialsiahomage to McLuhannsinsight, “the medium is
the message”[20]. We included vibrations, ringtones, busy
signals, and other concrete sounds, stored for granular syn-
thesis.
Based on stage setup, we divided the audience into three
zones, each linked to specific sample sets. Light intensity
levels from these zones modulated sampling parameters: re-
versing, granular density and rate, and filtering. Each per-
formance zone had its set of phone-related samples, with
the conductor free to switch between them via keyboard
interactions.
3.3.4 Pilot Setup
During development, ten volunteers from the venue assisted
in recording movement data across different areas in an ex-
perimental phase. Using ROSBAG[27], we captured these
movements, enabling us to refine the computer vision algo-
rithm for our final setup.
4. DISCUSSION
The approach of considering music ecosystems as second-
order cybernetic circuits introduces a novel perspective on
analyzing audience participation. Additionally, the way
this specific interactive piece of music is conceived and pre-
sented as a cybernetic circuit adds another possible reading
of participation in large interactive ecosystems. Overall,
this work contributes a fresh perspective to the current de-
bate on interactive music systems, with audience participa-
tion conceived as performance ecosystems.
We will follow the discussion based on the experience
of the performance throughout the process and then talk
about how this overall process can be linked with concep-
tual analogy.
Figure 3: The photo of the live performance of
Pharosphones.
2 https://ccrma.stanford.edu/groups/osc/index.html
3 https://cycling74.com/products/max
4.1 A Retrospective Reﬂection on the Roles in
the Performance
For the performer conducting on stage, the experience is
unique: faced with a large audience (200+), and with the
audience area lights turned off, it is impossible to discern
any hint of individual audience member’s features. Yet,
during this process, the conducting performer (third au-
thor of this paper) still experienced a sense of organismic
feedback from the audience both visually (as moving light
points) and acoustically (as changes in sound). This sensory
feedback loop directly informed the technical implementa-
tion, as the real-time visual data captured and processed
by our computer vision system not only guided but was
shaped by these improvisational interactions, highlighting
the interplay between technology and human response in
a performance evolving over time. Consequently, while on
stage, theperformerwouldrespondtotheaudience(ortheir
perception thereof) with improvisational choices in response
to such sensations. We noticed that the audience members
would also interact with others in a similar manner.
These spontaneous phenomena formed a recursive loop
for improvisation as the performance would evolve into a
successor of itself during its runtime. The recursivity does
not only stop there: as the system designer (first author)
observed the performance from his position on stage with
bare eyes and observed data streams from the control sys-
tem development tool (visualization system/command-line
tools), thereby analyzing the performance of the technical
system and encouraging further exploration.
4.2 Some Final Remarks on Music and Cy-
bernetics
By retrospectively analyzing this project, the main lesson
we learned is that such complex performance ecosystems,
whichengendermultipleroles(technician-performer, conductor-
performer, and audience-participants), multiple feedback
loops emerge. While other studies have aimed to analyze
these loops in a formal way ([19]), in this work, we embrace
these feedback loops as integral parts of the artistic vision.
This allowed us to use light in a new way that complements
the work on audience participation presented at NIME [5,
33, 29, 15, 3, 32, 7].
Framing our work in cybernetic terms represented a fun-
damental step in embracing the circular causality estab-
lished by feedback loops [11] as part of the aesthetic dis-
course rather than as an analytical post hoc study of the
performance ecology. This has been done before with feed-
back musicianship [18], but still is new in the design of
audience participation systems. Indeed, the overall design
was grounded in the conceptual language of cybernetics and
conceived as apurposeful activity that works by establishing
feedback loops.
5. CONCLUSION AND FUTURE WORK
In this article, we discussed a live performance designed
for a unique concert hall that utilizes light as a medium
and encourages audience interaction. Through a computer
vision system developed with cybernetic principles, the au-
dience, the conductor, and the system designers collabora-
tivelyshapedanexperientiallandscapethatextendsbeyond
traditional cybernetics. By employing mobile phones as
sound sources, we stimulated audience reflections on tech-
nology and its intrinsic challenges. We aim for this paper to
inspire further research into the recursive processes within
music ecosystems, drawing upon and expanding beyond ex-
isting cybernetics literature.
6. ETHICAL STANDARDS
The software code underpinning the robotics used in this
project adheres to open-source principles. Audience en-
gagement was highlighted and recognized in the program
materials before the performance started, and no data were
collected from the audience. Although the primary atten-
dees were faculty and students from the Zhejiang Conser-
vatory of Music, the event was open to the general public,
promoting wider societal participation.
7. REFERENCES
[1] K. C. Baird. Real-time generation of music notation
via audience interaction using python and GNU
lilypond. InProceedings of the International
Conference on New Interfaces for Musical Expression ,
pages 240–241, Vancouver, BC, Canada, 2005.
[2] A. Cassinelli, Y. Kuribara, A. Zerroug, M. Ishikawa,
and D. Manabe. scorelight : Playing with a
human-sized laser pick-up. InProceedings of the
International Conference on New Interfaces for
Musical Expression, pages 144–149, Sydney,
Australia, 2010.
[3] A. D. de Carvalho Junior, S. W. Lee, and G. Essl.
Understanding cloud support for the audience
participation concert performance of crowd in c[loud].
In Proceedings of the International Conference on
New Interfaces for Musical Expression , pages
176–181, Brisbane, Australia, 2016. Queensland
Conservatorium Griﬀith University.
[4] J. Eaton, W. Jin, and E. Miranda. The space between
us. a live performance with musical score generated
via emotional levels measured in EEG of one
performer and an audience member. InProceedings of
the International Conference on New Interfaces for
Musical Expression, pages 593–596, London, United
Kingdom, June 2014. Goldsmiths, University of
London.
[5] E. Egozy and E. Y. Lee. *12*: Mobile phone-based
audience participation in a chamber music
performance. In T. M. Luke Dahl, Douglas Bowman,
editor, Proceedings of the International Conference on
New Interfaces for Musical Expression , pages 7–12,
Blacksburg, Virginia, USA, June 2018. Virginia Tech.
[6] B. J. Eyes and L. E. Jongejan. How to stop sound:
Creating a light instrument and ‘interruption’ a piece
for the mimerlaven, norberg festival 2015. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , pages 373–374,
Brisbane, Australia, 2016. Queensland
Conservatorium Griﬀith University.
[7] M. Gimenes, P.-E. Largeron, and E. Miranda.
Frontiers: Expanding musical imagination with
audience participation. InProceedings of the
International Conference on New Interfaces for
Musical Expression, pages 350–354, Brisbane,
Australia, 2016. Queensland Conservatorium Griﬀith
University.
[8] M. Gurevich and J. Treviño. Expression and its
discontents: toward an ecology of musical creation. In
Proceedings of the 7th international conference on
New interfaces for musical expression , pages 106–111,
2007.
[9] H. Higgins.Fluxus experience. Univ of California
Press, 2002.
[10] T. Hopkins, E. Doherty, N. Ofer, S. C.-C. Weng,
P. Gyory, C. Tobin, L. Hirshfield, and E. Y.-L. Do.
Stringesthesia: Dynamically shifting musical agency
between audience and performer based on trust in an
interactive and improvised performance. May 2023.
[11] Y. Hui, editor.Cybernetics for the 21St Century V ol.1
Epistemological Reconstruction. Hanart Press, Hong
Kong, 2024.
[12] M. Iddon.New Music at Darmstadt: Nono,
Stockhausen, Cage, and Boulez . Cambridge University
Press, 2013.
[13] D. Kobori, K. Kagawa, M. Iida, and C. Arakawa.
Line: Interactive sound and light installation. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , pages 110–113,
Paris, France, 2006.
[14] C. Larkin. The guinness who’s who of jazz.(No
Title), 1992.
[15] S. W. Lee, G. Essl, and Z. M. Mao. Distributing
mobile music applications for audience participation
using mobile ad-hoc network (MANET). In
Proceedings of the International Conference on New
Interfaces for Musical Expression , pages 533–536,
London, United Kingdom, June 2014. Goldsmiths,
University of London.
[16] S. W. Lee and J. Freeman. echobo : Audience
participation using the mobile music instrument. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , pages 450–455,
Daejeon, Republic of Korea, May 2013. Graduate
School of Culture Technology, KAIST.
[17] G. Lovink. Cybernetics for the twenty-first century:
An interview with philosopher yuk hui. 2019.
[18] T. Magnusson, C. Kiefer, and H. Ulfarsson. Reflexions
upon feedback. InProceedings of the International
Conference on New Interfaces for Musical Expression ,
The University of Auckland, New Zealand, jun 2022.
[19] R. Masu, M. Bettega, N. N. Correia, and T. Romão.
Investigating performance ecologies using screen
scores: a case study.Personal and Ubiquitous
Computing, 27(5):1887–1907, 2023.
[20] M. McLuhan. The medium is the message. In
Communication theory, pages 390–402. Routledge,
2017.
[21] J. Pak. The light matrix: An interface for musical
expression and performance. InProceedings of the
International Conference on New Interfaces for
Musical Expression, pages 342–345, Paris, France,
2006.
[22] P. J. Preece, M. Jack, and G. Lepri. Oscillations:
Composing a performance ecosystem through a sonic
cyberfeminist lens. In M. Ortiz and
A. Marquez-Borbon, editors,Proceedings of the
International Conference on New Interfaces for
Musical Expression, pages 307–313, Mexico City,
Mexico, May 2023.
[23] M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote,
J. Leibs, R. Wheeler, A. Y. Ng, et al. Ros: an
open-source robot operating system. InICRA
workshop on open source software , volume 3, page 5.
Kobe, Japan, 2009.
[24] M. Rodger, P. Stapleton, M. Van Walstijn, M. Ortiz,
and L. Pardue. What makes a good musical
instrument? a matter of processes, ecologies and
specificities. InProceedings of the international
conference on New Interfaces for Musical Expression ,
pages 405–410. Birmingham City University,
Birmingham, UK, 2020.
[25] A. Rosenblueth, N. Wiener, and J. Bigelow. Behavior,
purpose and teleology.Philosophy of science ,
10(1):18–24, 1943.
[26] D. Scaramuzza, A. Martinelli, and R. Siegwart. A
toolbox for easily calibrating omnidirectional
cameras. In2006 IEEE/RSJ International Conference
on Intel ligent Robots and Systems, pages 5695–5701.
IEEE, 2006.
[27] D. Thomas, T. Field, J. Leibs, and J. Bowman.
Rosbag-ros wiki.URL: http://wiki. ros. org/rosbag,
2014.
[28] S. Waters. Performance ecosystems: Ecological
approaches to musical interaction.EMS:
Electroacoustic Music Studies Network, pages 1–20,
2007.
[29] N. Weitzner, J. Freeman, S. Garrett, and Y.-L. Chen.
massmobile -an audience participation framework. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , Ann Arbor,
Michigan, 2012. University of Michigan.
[30] N. Wiener.Cybernetics: Or Control and
Communication in the Animal and the Machine . MIT
Press, 1948.
[31] A. Xambó and V. Goudarzi. The mobile audience as a
digital musical persona in telematic performance. In
Proceedings of the International Conference on New
Interfaces for Musical Expression , The University of
Auckland, New Zealand, jun 2022.
[32] A. Xambó and G. Roma. Performing audiences:
Composition strategies for network music using
mobile phones. In R. Michon and F. Schroeder,
editors, Proceedings of the International Conference
on New Interfaces for Musical Expression , pages
55–60, Birmingham, UK, July 2020. Birmingham City
University.
[33] L. Zhang, Y. Wu, and M. Barthet. A web application
for audience participation in live music performance:
The open symphony use case. InProceedings of the
International Conference on New Interfaces for
Musical Expression, pages 170–175, Brisbane,
Australia, 2016. Queensland Conservatorium Griﬀith
University.