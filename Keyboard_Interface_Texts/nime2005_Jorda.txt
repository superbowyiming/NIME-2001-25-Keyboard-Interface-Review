Multi-user Instruments:  
Models, Examples and Promises  
Sergi Jordà 
Music Technology Group 
Universitat Pompeu Fabra 
Ocata 1 
08003 Barcelona, Spain 
+34 93 542 21 04 
sergi.jorda@iua.upf.es 
 
 
 
 
ABSTRACT 
In this paper we study the potential and the challenges posed by 
multi-user instruments, as tools that can facilitate interaction and 
responsiveness not only between performers and their instrument 
but also between performers as we ll. Several previous studies and 
taxonomies are mentioned, after what different paradigms 
exposed with examples based on traditional mechanical acoustic 
instruments. In the final part, several existing systems and 
implementations, now in the digital domain, are described and 
identified according to the models and paradigms previously 
introduced. 
Keywords 
Multi-user instruments, collaborative music, new instruments 
design guidelines. 
1. INTRODUCTION 
Music performance typically is a group activity. For Bischoff, one 
of the founders of the League of Automatic Composers, there 
seems to be no substitute “to bring into play the full bandwidth of 
communication, than the playing of music live” [3]. However, 
most of the traditional musical instruments have been mostly 
designed for an individual use. Even if some of them, as the piano 
or the drum kit can be easily used collectively, acoustic models do 
not really favor for the actual manipulation and control of each 
other’s explicit musical voice (such as one performer on ‘side’ of 
the instrument, directly affecting the other performer’s output). It 
is by designing and construc ting electronic communication 
channels among players, that performers can take an active role in 
determining and influencing, not  only their own musical output, 
but also their peers’ [21]. Besides, if one of the best assets of new 
digital instruments is the possibility to run several multiple and 
parallel musical processes in a shared control between the 
instrument and the performer [14], the possibility to have multiple 
performers seems as a logical and promising extension.  
2. NET MUSIC AND DISTRIBUTED 
INSTRUMENTS 
Thanks to the Internet, the study of network or distributed musical 
systems is a hot area nowadays and much research is being 
carried on. For an overview of the field, the reader can refer to [1 
or 21], which address from different perspectives topics such as 
the goals and the motivations, the technical constraints, as well as 
the perspectives, the topologies or the social implications of both 
online and local musical networks, proposing also taxonomies and 
describing many examples of im plementations. Still logically, 
these and other authors tend to concentrate their studies in the 
peculiarities brought by the net medium, such as time latency or 
physical displacement and disembodiment. 
2.1 Studies and Taxonomies 
In 1991, Wessel [22] already introduces several of the principles 
and paradigms further developed in the present article. More 
recently, Barbosa [1] proposes a classification space for 
computer-supported collaborative music mainly based on two 
axes: synchronous and asynchronous for the time dimension; 
remote and co-located for the space dimension. Weinberg’s 
taxonomy [21] also distinguishes between on-line and local 
networks (and, in the last case, between small and large scale 
systems depending on the typical number of participants) and 
describes possible topologies depending on the social 
organization of these networks and on the nature (centralized-
decentralized) of their connections. Blaine and Fels [5] study 
collaborative musical experiences for novices, concentrating on 
interactive, instrumental and playability aspects. My own work, 
FMOL [12] has often been referenced and studied as a model for 
different net-distributed musical paradigms [10, 19, 21], but in 
this article I want to concentrate in the aspects of shareable multi-
user instruments, which, as a resu lt of playing myself in shared 
environments, currently interest me more as a luthier. What 
follows should not be necessarily understood in the context of 
net-music or distributed musical systems; imagine instead a 
hypothetical acoustic instrument that would invite many 
simultaneous performers. 
3. SHARED COLLECTIVE CONTROL 
3.1 Some Multi-User Instruments 
Considerations and Properties 
3.1.1 User-number and user-number flexibility 
Some multi-user instrument can be played by a variable number 
of performers (some can even be naturally played by only one 
person). Others require fixed number of performers. 
3.1.2 User-role flexibility 
In some multi-user instruments, each performer is assigned a 
different role. Instruments with a very strict role assignment tend 
to be also stricter with its number of users (i.e. one 
performer/role). Some instruments offer different roles in a more 
flexible fashion, allowing for example performers to switch roles 
dynamically, to play several simultaneous roles, or even to 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
23
temporally ‘duplicate’ roles while leaving some other 
‘unattended’.  
3.1.3 Interdependencies / hierarchies 
What possibilities performers have in determining and 
influencing, not only their own musical output, but also their 
peers’? If no mutual interaction is allowed, the concept of multi-
user instrument is definitely debatable. Are all these 
interdepencies equilibrated? I.e. is the system a democratic 
system, with balanced rights and duties, or a hierarchical one? 
3.2 Some Multi-User Paradigms Based On 
Acoustic Instruments 
Although most of the aforementioned authors consider only 
digitally connected instruments, claiming that electronic 
communication channels among players are needed in order to 
achieve ‘real interconnected interactive multi-user instruments, 
we will illustrate the above properties with acoustic instruments 
examples. Mechanical communication channels may also permit, 
as we will show, the development of these concepts, and because 
we all have a better idea of what traditional instruments are and 
how they work, examples can be much clarifying. 
Let us consider a keyboard instrument such as a piano. The 
number of hands that can access a piano keyboard is quite 
flexible. The mutual interaction two or more player can exert on 
each other is however not that important, if we omit two facts: (a) 
while a key is taken it cannot be played by someone else; (b) the 
oscillation modes of each piano string are slightly dependent on 
the state of the other strings, which theoretically allows each 
performer to affect the timbre of the notes being played by other 
performers. When one performer plays the pedals, this timbre 
modification effect is stronger. In this case, the roles are also 
clearly differentiated, but the mutual interaction is not balanced: 
the pedal player affects the keyboard player much more than the 
inverse. Besides, the pedal player can do ‘much less’ than the 
keyboard peer. 
 
Figure 1. The piano: three multi-user paradigms 
But even a traditional instrument such as the piano allows for 
quite advanced interplay. Imagine a situation in which player A 
plays the keyboard while player B plays with the strings, in a harp 
fashion and/or dynamically ‘preparing’ the piano. This context is 
suitable for 2 to N performers. It shows two clear and well-
defined distinct roles, none of them being essential (each role is 
individually allowed to make sound). The interplay can thus 
become extremely intense. This example surely illustrates a quite 
desirable and inspiring situation. In my opinion, almost an ideal 
for multi-user instruments designers. Figure 1 illustrates the 
aforementioned three approaches to ‘multi-user pianos’. 
Let us pick another keyboard: an old-fashion humanly fuelled 
organ in which player A plays the keyboard, player B plays the 
register keys and player C ‘plays’ the pump. Both A and C are 
essential roles, although being essential seems not necessarily 
something enviable, especially when we consider player’s C 
potential expressivity. 
3.3 Multi-user instruments simple arithmetic 
• If there is strictly no mutual interaction, the output result of 
the multi-user instrument can be considered as the sum of all 
the individual contributions.  
• If some roles are essential, these roles multiply the previous 
contributions. 
• If all roles are essential, the result is the product of all the 
individual contributions. 
The more interplay and flexibility are allowed in a multi-user 
system, the more complex will the final expression - in terms of 
the individual contributions - turn to be, and the more exciting the 
collective interplay may result. 
4. MULTI-USER INSTRUMENTS 
EXAMPLES 
The list of true multi-user instruments that seek to explore 
different aspects of collective interplay is growing faster. In this 
section we will only briefly mention seven implementations we 
consider specially paradigmati cal. They are presented in rough 
chronological order. 
4.1.1 Imaginary Landscapes No. 4 (1951) 
John Cage’s Imaginary Landscape No. 4 is a piece for twelve 
radios and twenty-four performers. Every radio set had its own 
frequency-dial player and its volume-dial player who manipulates 
the final output gain. Although there can be no prior knowledge 
of what might be broadcast at any specific time of the 
performance, or whether a station even exists at any given dial 
setting, all the performers’ actions are carefully notated in a 
composition score that indicates the exact tuning and volume 
settings for each. As radical as this piece might have been, Cage 
makes no doubt about the role of the composer and that of the 
performers; using randomness for removing his sense of choice he 
was not allowing the musician to have any personal choice either. 
4.1.2 Mikrophonie I (1964) 
Stockhausen’s Mikrophonie I depicts a comparable model. It is a 
work for six performers scored  for tam-tam, two microphones, 
two filters, and potentiometers, in  which the tam-tam provides all 
the basic sound material. Two performers play the tam-tam, two 
others operate the two microphones on either side of it, and the 
two remaining performers operate the filters. The sounds of the 
tam-tam are passed through filters, manipulated, and then 
amplified. The process of performance and composition are thus 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
24
wed, as the sounds of the tam-tam are altered in real-time. Pitch 
and texture may be changed, extraneous sounds may be turned 
into pitched sound, and similarities and differences between 
musical gestures may be emphasized or de-emphasized by the 
electronic processes. The resulting sound world is not just the 
additive combination of sounds generated by the individual 
players [22]. 
4.1.3 The League of Automatic Composers (1978) 
The League of Automatic Composers , formed in 1978 by John 
Bischoff, Rich Gold, Jim Horton and later Tim Perkis, can be 
considered the first microcomputer band and also the first 
network band of history [4]. Each member of the group owned a 
microcomputer with its own sound output, either by means of a 
digital-to-analog converter (DAC) or through digitally controlled 
external electronic devices. All members programmed their own 
computers with music programs that should be able to produce 
music by themselves, but also able to receive data that would 
affect their musical behavior, and to output data that would affect 
other computers’ programs. They performed connecting their 
computers in different configurations. The League kept playing 
extensively until they disbanded in 1983. Two years later the 
former members Tim Perkis and John Bischoff, joined by Scot 
Gresham-Lancaster, Phil Stone, Chris Brown and Mark Trayle, 
formed a new computer-network band, The Hub, embracing this 
time the new technology that made all connections much easier, 
MIDI [7, 11, 17].  
The League’s importance cannot be overestimated. Not only it 
constituted the first microcomputer  band, predating by a quarter 
of a century today’s plethora of improvising laptop groups, they 
also established many of the basic principles and models of 
network music in use nowadays. The League itself understood 
their musical net both as a net of instruments and as a collective 
instrument that is indeed much more than the sum of its parts. 
When computers start sharing data between themselves, human 
performers are not anymore the only ones allowed to ‘listen’ to 
each other, which opens to a multiplicity of interaction and 
complexity networks. 
4.1.4 Sensorband’s SoundNet (1995) 
The Soundnet is a large scale multi-user sensor instrument 
constructed by Bert Bongers for Sensorband (Atau Tanaka, 
Zbigniew Karkowski, and Edwin van der Heide). It is a musical 
instrument that takes on an architectural dimension and 
monumental proportions. As shown in figure 2, it is a giant web 
measuring 11 meters x 11 meters, strung with thick shipping rope. 
At the end of the ropes are eleven sensors that detect stretching 
and movement and the three musi cians of Sensorband perform on 
the instrument by climbing it. All the ropes are interconnected, 
making it impossible to isolate the movement of one sensor. 
Limitations of the Soundnet are related to its physical scale and 
interconnected nature. Isolating individual sensor movement is 
nearly impossible, and one performer's movements take place in 
relation to the position and actions of the others. These effects 
combine to give the instrument its qualities of structural 
resonance and create a dynamic where pure control in the strict 
sense is put in question; the instrument is too large and complex 
for humans to thoroughly master [6, 18]. The SoundNet proposes 
no distinctive roles and admits a variable number of users. 
Performers interconnectivity is extremely high. 
4.1.5 The Squeezables (2001)  
Developed by Weinberg and Gan [20], the Squeezables are 
comprised of six squeezable and retractable gel balls that are 
played usually by three performers by holding the balls in their 
hands and using a set of squeezing and pulling gestures. Each of 
the five accompaniment balls shows a particular behavior. Three 
of them mainly control timbre-oriented parameters while the two 
remaining, offer higher-level accompaniment control. Some 
additional parameters are also controlled by average actions on all 
the balls. Like in traditional ensembles, each of the Squeezables 
shows a particular behavior a nd musical role. Unlike traditional 
instruments, these roles only make sense in a global context. The 
Squeezables constitute a highly organized and hierarchical 
distributed instrument that needs all of its components to work 
properly.  
4.1.6 The Tooka (2002) 
Exploration of intimate communication and attentive interplay 
between two performers are epitomised in the Tooka [8, 9]. The 
Tooka is a hollow flexible tube with three buttons at each end and 
with a pressure sensor in the center, which measures the air 
pressure on the tube. To play the Tooka, two players put their 
mouths over opposite ends forming a sealed tube, so that they 
both collectively modulate the tube pressure to control sound. The 
Tooka has clearly a fixed number of performers (2) and both share 
the same responsibility and role. It also represents a very special 
case, as possibly one of the few (if not the only) multi-user 
instruments which cannot be considered multithreaded. The team 
developing the Tooka is specially concerned by the physical 
communication channels and the intimacy new instruments can 
bring and has also designed several other two-player instruments 
that further explore this area. 
4.1.7 The reacTable* 
The reacTable* is a table-top instrument 1, which allows 
performers to share complete access to all the musical threads by 
moving physical wooden objects (representing generators, filters, 
etc.) on a table surface and constructing different audio topologies 
in a sort of tangible modular synthesizer or graspable flow-
controlled programming Max-like language (see figure 6) [13, 14, 
15]. The reacTable* supports a flexible number of users (from 
one to around half a dozen), with no preconfigured roles, and 
allows simultaneously additive (performers working on 
independent audio threads) as well as multiplicative behaviors 
(performers sharing threads). Because of the way physical objects 
are visually and virtually augmented (see figure 7), the 
reacTable* also constitutes a perfect example of the off-line and 
on-line all-at-once multi-user in strument. When two or more 
reacTables* are connected through the net, thus sharing the same 
virtual space, performers can only move the wooden objects on 
their corresponding table, but these movements may modify the 
shared audio threads, thus provoking interactions between 
displaced objects, so that one filter in Barcelona may process the 
output of a generator in Berlin. 
                                                                 
1 Other musical instruments exist that fall into this table-top 
category such as the The Jam-O-Drum [4], the Audiopad [16] or 
the Music Table [2]. Equally, “walls” or “carpets” could be also 
considered as variations of the table concept. 
 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
25
 
Figure 2. Two performers playing with the reacTable* 
5. SUMMARY 
Multi-user instruments seem a l ogical and promising extension of 
the multiprocess behavior of many digital instruments [14]. They 
offer many interesting possibilities while posing new design 
challenges; the goal now is not only to facilitate interaction and 
responsiveness between each performer and the instrument but 
also between the performers as well. The more interplay and 
flexibility are allowed in a multi-user system, the more complex 
will the final expression - in terms of the individual contributions 
- turn to be, and the more exciting the collective interplay may 
result. We have introduced different possible models and 
described several implementation examples which definitely 
bring new interplay promises to the scene. 
This research has been partially funded by the EU-FP6-IST-
507913 project SemanticHIFI. 
6. REFERENCES 
[1] Barbosa, A. (2003). Displaced Soundscapes: A Survey of 
Network Systems for Music and Sonic Art Creation. 
Leonardo Music Journal, 13. 
[2] Berry, R., Makino, M., Hikawa, N. & Suzuki, M. (2003). 
The Augmented Composer Project: The Music Table. In 
Proceedings of the Second IEEE and ACM International 
Symposium on Mixed and Augmented Reality (ISMAR ’03). 
[3] Bischoff, J., Gold, R. & Horton, J. (1978). Music for an 
interactive Network of Computers. Computer Music Journal, 
2(3), 24-29. 
[4] Blaine, T., & Perkis, T. (2000). Jam-O-Drum, A Study 
Interaction Design. In Proceedings of the ACM DIS 2000 
Conference. NY: ACM Press. 
[5] Blaine, T., & Fels, S. (2003). Collaborative Musical 
Experiences for Novices. Journal of New Music Research, 
32(4), 411-428. 
[6] Bongers, B. (1998). An Interview with Sensorband. 
Computer Music Journal, 22(1), 13-24. 
[7] Brown, C. & Bischoff, J. (2002). Indigenous To The Net: 
Early Network Music Bands in the San Francisco Bay Area. 
On-line available at http://crossfade.walkerart.org/ 
brownbischoff/IndigenoustotheNetPrint.html 
[8] Fels, S., & Vogt, F. (2002). Tooka: Exploration of two 
person instruments. In Proceedings of the 2002 International 
Conference on New Interfaces for Musical Expression 
(NIME02), Dublin, 116–121. 
[9] Fels, S., Kaastra, L., Takahashi, S. & McCaig, G. (2004). 
Evolving Tooka: from Experiment to Instrument. In 
Proceedings of the 2004 International Conference on New 
Interfaces for Musical Expression (NIME04), Hamamatsu, 
Japan, 1-6. 
[10] Föllmer, G. (2002). Musikmachen im Netz Elektronische, 
ästhetische und soziale Strukturen einer partizipativen 
Musik. Ph.D. thesis, Martin-Luther-Universität Halle-
Wittenberg. 
[11] Gresham-Lancaster, S (1998). The Aesthetics and History of 
the Hub: The Effects of Changing Technology on Network 
Computer Music. Leonardo Music Journal, 8, 39-44. 
[12] Jordà, S. (1999). Faust Music On Line (FMOL): An 
approach to Real-time Collective Composition on the 
Internet. Leonardo Music Journal, 9. 
[13] Jordà, S. (2003). Sonigraphical Instruments: From FMOL to 
the reacTable*. In Proceedings of the 2003 International 
Conference on New Interfaces for Musical Expression 
(NIME-03), Montreal, 70-76. 
[14] Jordà, S. (2005). Digital Lutherie: Crafting musical 
computers for new musics’ performance and improvisation. 
Ph.D. thesis. Barcelona: Universitat Pompeu Fabra. 
[15] Kaltenbrunner, M., Geiger, G. & Jordà, S. (2004). Dynamic 
Patches for Live Musical Performance. In Proceedings of the 
2004 International Conference on New Interfaces for 
Musical Expression (NIME-04), Hamamatsu, Japan, 19-22. 
[16] Patten, J., Recht, B. & Ishii, H. (2002). Audiopad: A Tag-
based Interface for Musical Performance. In Proceedings of 
the 2002 International Conference on New Interfaces for 
Musical Expression (NIME-02), Dublin, 11-16. 
[17] Perkis, T. (1999). The Hub. Electronic Musician Magazine, 
August 1999. 
[18] Tanaka, A. (2000). Musical Performance Practice on Sensor-
based Instruments. In M. Wanderley and M. Battier, eds. 
Trends in Gestural Control of Music. Paris: Ircam - Centre 
Pompidou. 
[19] Tanzi, D. (2001). Observations about Music and 
Decentralized Environments. Leonardo, 34(5): 431–436. 
[20] Weinberg, G., & Gan, S. (2001). The Squeezables: Toward 
an Expressive and Interdependent Multi-player Musical 
Instrument. Computer Music Journal, 25(2), 37-45. 
[21] Weinberg G. (2002). Interconnected Musical Networks – 
Bringing Expression and Thoughtfulness to Collaborative 
Music Making. Ph.D Thesis. MIT Media Laboratory, 
Cambridge, MA. 
[22] Wessel, D. (1991). Improvisation with Highly Interactive 
Real-Time Performance System. In Proceedings of the 1991 
International Computer Music Conference. San Francisco: 
Computer Music Association, 344-347. 
 
 
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
26