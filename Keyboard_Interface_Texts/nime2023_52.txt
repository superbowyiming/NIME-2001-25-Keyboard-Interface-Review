Laser Phase Synthesis
Derek Holzer
KTH Royal Institute of
Technology
Stockholm, Sweden
idholzer@kth.se
Luka Aron
KMH Royal College of Music
Stockholm, Sweden
llluka.aron@gmail.com
André Holzapfel
KTH Royal Institute of
Technology
Stockholm, Sweden
holzap@kth.se
ABSTRACT
This paper presents a new interface – Laser Phase Synthe-
sis — designed for audiovisual performance expression. The
instrument is informed by the historicalAudio/Video/Laser
system developed by Lowell Cross and Carson Jeffries for
use by David Tudor and Experiments in Arts and Technol-
ogy (E.A.T.) at the 1970 Japan World Exposition in Osaka,
Japan. The current work employs digital audio synthesis,
modern laser display technology, and close collaboration be-
tween sound and image composition to illustrate the har-
monic progression of a musical work. The authors present
a micro-history of audiovisual laser displays, a brief intro-
duction to the process of drawing visual figures with sound,
a description of the Pure Data software and laser display
hardware systems used for the Laser Phase Synthesis in-
strument, and a discussion of how this instrument shaped
the composition process of one audiovisual performance of
electroacoustic music. The paper concludes with specula-
tions on how the system can be further developed with other
kinds of live performers, specifically vocalists.
Author Keywords
media archaeology, reenactment, historical instruments, au-
diovisual synthesis, Pure Data, ILDA, laser, Lissajous, vi-
sualization
CCS Concepts
•Applied computing → Sound and music computing; Per-
forming arts; •Social and professional topics → History of
hardware;
1. INTRODUCTION
In 1970, David Tudor composed sound for an audio-controlled,
four color laser display system designed by Lowell Cross and
Carson Jeffries. The system was installed in the pavilion
created by Experiments in Arts and Technology (E.A.T.)
for Pepsi Cola at the Japan World Exposition in Osaka.
Cross locates the genesis of this large-scale work in a feeling
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’23, 31 May–2 June, 2023, Mexico City, Mexico.
of dissatisfaction which he experienced with the visual com-
ponent of electronic music presentations as a young student
during the mid 1960’s [3]. This desire for a stronger con-
nection between sound and image was common during the
60’s and 70s, and drove composers such as Iannis Xenakis
[21], computer animators such as John Whitney Sr. [18] [20]
and Larry Cuba [19], and video artists such as Steina and
Woody Vaˇ sulka [4] all to push against the edges of existing
analog and digital technologies.
When describing the electronic possibilities of the Ex-
perimental Television Center studio, Hank Rudolf describes
four ways in which sound and image can be related [11]. In
the first case, sound can be analyzed and used to modulate
imagery (visualization). In the second case, imagery can
be analyzed and used to modulate sound (sonification). In
the third case, both sound and imagery can be controlled
by an external source of information (i.e. MIDI or OSC).
However, this paper is primarily concerned with the fourth
situation, where sound and image are derived from the same
signal source. We argue that establishing this direct rela-
tionship between sound and image in a single electronic in-
strument creates a feedback loop in the interaction process,
within which sounds are crafted specifically for their visual
effect alongside their musical expressiveness.
We have found the concept of reenactment, particularly
as discussed within the field of performance art, incredi-
bly useful towards understanding historical electronic in-
struments. Rather than seeing a reenactment as a faithful
repetition or high fidelity imitation of an original work, one
can approach reenactment as a process of working from the
original piece as a reference [5], while allowing for radically
different outcomes to take place [1].
What holds for historical events and performances holds
equally well for audiovisual instruments of the past. By
reenacting the processes through which such instruments
were developed and employed, one gains unique insights into
why those instruments function the way that they do, and
subsequently how those objects shaped and channeled the
creative expressions of their users into the forms which they
took [8].
This paper describes a reenactment of one specific, his-
torical audiovisual instrument — Tudor, Cross, and Jeffries’
Audio/Video/Laser system — using contemporary technolo-
gies. We begin with a micro-history of the context from
which this laser instrument emerged, alongside a brief tech-
nical introduction to the use of lasers for creating realtime,
interactive visual displays. We then describe a software li-
brary created by the principle author for controlling laser
display technology with sound, and a specific implemen-
tation of that library optimized for working with musicians
for live performance. Following this, we present the findings
of two sets of experiments involving collaborations with an
electroacoustic composer and with several vocalists. Finally,
we discuss how these findings contribute to our concept of
an audiovisual instrument.
2. BACKGROUND
2.1 A Micro-history of Audiovisual Laser Dis-
plays
Cross’ first student experiments with visualizing electronic
sounds involved hacking a television set in order to ma-
nipulate its electron beam using recorded music and signal
generators, in a manner similar to Ben Laposky’s use of os-
cilloscopes to create visual artworks starting in the 1950’s
[9]. In 1966, Cross collaborated with Tudor on two audio-
visual works which exploited the phase differences in the
acoustics of the bandoneon (a concertina-like reed instru-
ment from Argentina and Uruguay which emits sound from
both its ends) to create Lissajous patterns on a cathode
ray tube display [3]. By 1969, Tudor had abandoned the
bandoneon in favor of a table full of self-made electron-
ics. Meanwhile, Cross had approached physicist and kinetic
sculptor Carson Jeffries to assist in the construction of a set
of galvanometer-controlled mirrors to deflect the beam of a
krypton ion laser system using audio signals.
Tudor and Cross premiered this instrument at Mills Col-
lege on May 9 of 1969, presented it shortly after at the Pepsi
pavilion in Osaka, traveled with the performance through
the 1970’s, and gave their final laser concert at Ars Elec-
tronica in Linz, Austria in 1980. As source material, Tudor
would use manipulated field recordings and long chains of
electronic instruments connected through feedback into a
“giant oscillator” [10]. The latter would either be played
live or from prepared tapes sent directly to both speakers
and laser galvanometers. This way, the audience would see
and hear the same signals manifested in two different do-
mains — those of both sound and sight — and undoubtedly
the visual forms created on the laser inspired Tudor towards
different combinations of sonic elements and tools.
Donna Haraway cautions us against repeating time-worn
narratives of “[a]utopoietic, self-making man” — narratives
whose basis in neoliberal individualism she finds wholly un-
suitable for life on a planet in crisis [6]. Thus, rather than
casting Cross and Jeffries as self-sufficient and isolated in-
novators, it is important to understand that they conceived
and designed their laser control system within a rich ecosys-
tem of the sciences and arts of the time. In an adjacent
pavilion at the same Osaka Expo, for example, Rockne
Krebs presented laser light sculptures developed during his
residency with Hewlett Packard through the auspices of the
Art and Technology Program of the Los Angeles County
Museum of Art [15]. Nor was Krebs the only other laser
artist shown in Osaka that year. The New York Times re-
ported that “[a]t least half a dozen pavilions [had] works of
art incorporating laser beams and reflecting surfaces” at the
Exposition [13].
Likewise, by the end of the 1970’s a burgeoning scene
of laser visuals design had emerged in southern California
under the initiative of scientist and former E.A.T. mem-
ber Elsa Garmire alongside filmmaker Ivan Dryer. Their
Laserium light shows entered popular culture through venues
such as planetariums, concert halls, and football stadiums.
A key difference is that, while Tudor controlled the move-
ments of the laser beam directly with his sound output and
reveled in the resulting chaotic unpredictabilities [10], the
Laserium shows played as choreographed visual accompa-
niment to more traditional classical, pop, and rock mu-
sic. Similarly, Xenakis’ use of lasers in his Polytopes of
the 1970’s functioned alongside other architectural lighting
effects “to compose movement and evolve forms” [21] for the
musical performances, rather than being integral to them.
While the earliest laser animations were created by ana-
log consoles which shared a great deal of functionality with
modular synthesizers, these consoles were gradually replaced
as microcomputers became more accessible during 1980’s.
This resulted in laser shows consisting predominantly of the
pre-programmed imagery and effects currently found in ap-
plications such as Pangolin QuickShow1, further separating
the processes of sound and image making. In recent years, a
number of artists have challenged this established aesthetic
by bringing direct audio control of the laser back into live
performance. The works of Germany’s Robert Henke 2 and
Australia’s Robin Fox [12] both stand as exemplary in this
new field. In a similar vein, software like Modulaser 3 and
hardware such as the Neon Captain Radiator 4 both take
direct inspiration from the early, manually controlled ana-
log systems to enable realtime interaction with animated,
geometric laser figures (referred to as “abstracts” within the
laser art community) created from the waveforms of basic
signal generators.
2.2 Reenacting Tudor and Cross
A complete reconstruction of Tudor and Cross’ laser perfor-
mances proves challenging, since only photographs of Tu-
dor’s equipment [10] and audio recordings of it being used
without the laser [16] are publicly available. However, their
work does provide rich possibilities for reenactment using
contemporary means and with different outcomes. Not only
have the possibilities for audiovisual synthesis increased sub-
stantially since Tudor’s rat-nest of cables and boxes, but the
cost and complexity of laser display equipment has signifi-
cantly decreased.
As we demonstrate in this paper, a common multichan-
nel audio interface can easily provide control over a laser
projector employing an audiovisual programming environ-
ment such as Pure Data, while simultaneously outputting
stereo audio for loudspeakers. Additionally, modern au-
dio softwares are capable of precise control over frequency,
amplitude, and phase almost unimaginable in Tudor’s day
— even though Tudor himself preferred the chaos of his
own constructions to the precision offered by sophisticated
synthesizers such as the Moog modular [10]. The use of
free software and consumer hardware offers an entry to this
practice at a substantially lower cost than most specialized,
commercial laser display packages.
We believe that these possibilities offer us new methods
to engage with laser display technology in novel and artis-
tically invigorating ways. We have chosen to investigate
them through the reenactment of Tudor and Cross’ instru-
ment, with a special emphasis on the use of a unified signal
source for both sound and image. Our current work in-
volves the digital synthesis of harmonic waveforms for the
continuous modulation of laser-drawn figures. This requires
careful consideration, since interesting sounds do not always
produce interesting laser visuals. Nor are the sounds which
produce interesting laser visuals always interesting by them-
selves.
Designing a sound to produce clear laser visuals requires
careful control of frequency, amplitude, and phase relation-
ships between two or more channels of audio. In fact, in-
1https://pangolin.com/pages/quickshow
2https://roberthenke.com/concerts/lumiere.html
3https://modulaser.app/
4https://www.neoncaptain.com/
jecting most stereophonic, musical audio signals into the
laser can result in figures which appear random at best,
and which are physically dangerous to the mechanics of the
laser at worst. Additionally, monophonic sounds, such as
those from vocalists or many solo instruments, cannot be
used by themselves to create laser visuals which normally
require two independent signals.
These concerns can add quite an additional burden to the
creative process of a musical composer, particularly if they
are not familiar with techniques for XY vector graphics.
Therefore, by providing for a monophonic input signal, and
reducing the technical considerations for the laser to a sim-
ple harmonic relationship, we set out to create an audiovi-
sual synthesis instrument which simplifies the requirements
for a composer, instrumentalist, or vocalist to use. Fur-
thermore, it contains possibilities which can be expanded
to be played in tandem with a visual artist for more com-
plex visual effects. The following sections detail how this
was achieved by first explaining how modern laser hardware
functions, then discussing the Vector Synthesis software li-
brary created for audiovisual synthesis with the laser, and
finally detailing the Laser Phase Synthesis instrument cre-
ated with that library.
3. METHODS
3.1 How to Draw a Sound with Light
Figure 1: Galvanometers and mirrors in a laser display.
A laser display works by deflecting the beam of a laser to
create repeating patterns. Deflections recurring below the
flicker fusion threshold of approximately 25 Hz will be un-
even in their intensity, while deflections faster than that will
produce the illusion of a continuous line. The deflections
themselves are produced by mirrors mounted on galvanome-
ters (“galvos”) which respond to an AC voltage by swing-
ing back and forth. There is one mirror and galvanome-
ter for each axis of movement — horizontal and vertical —
mounted at ninety degree angles to each other, and the laser
beam’s trajectory is altered by each in series (Figure 1). A
DC voltage offset sent to a galvanometer can be used to
reposition the beam to draw a shape in a different location.
The International Laser Display Association (ILDA) spec-
ification [14] provides for the use of balanced, analog signals
to control all the parameters of a laser. The horizontal and
vertical signals are a±10V differential voltage, while each of
the three signals to the color diodes (red, green, and blue)
is a 0 to +5V voltage. These levels are compatible with
DC coupled computer audio interfaces such as the MOTU
UltraLite or the Expert Sleepers ES-8, allowing the use of
digital audio softwares to generate high resolution, contin-
uous analog control signals for the laser galvos. The ILDA
voltage levels are also compatible with signals produced by
EuroRack format analog modular synthesizers and other
consumer electronic sound instruments.
The shapes drawn by a laser display follow the principles
of Lissajous figures, which display instantaneous differences
in frequency, amplitude, and phase between a pair of signals
as a two dimensional, linear figure drawn by a single point.
Signals with integer harmonic ratios (Figure 2) will display
a stable figure. Signals with inharmonic relationships will
be unstable and appear as visual noise. Signals with fre-
quencies close to a harmonic relationship will appear to ro-
tate in space at a rate equal to that of an acoustic beating
frequency (i.e. the absolute difference in Hz between the
two).
Figure 2: Harmonic and phase relationships of Lissajous fig-
ures.
Amplitude modulation of the signals drawing a figure can
be used to impress one waveform’s shape upon another, for
example by modulating the size of a circle with an addi-
tional audio signal. Phase is the more complicated param-
eter, however. Two signals of the same frequency, and in
phase with each other, appear as a diagonal line, as does a
monophonic sound sent to both galvos. Changing phase dif-
ferences of between 0 and 180 degrees produces the illusion
of a figure rotating in three dimensional space. This princi-
ple explains Tudor’s use of a variety of phase-shifting signal
processors to obtain Lissajous figures from monophonic in-
put signals [10], a practice likely informed by his early use
of the out-of-phase signals captured from the bandoneon.
While French physicist J.A. Lissajous’ 1855 experiments
employed mirrors attached to tuning forks to deflect a beam
of sunlight focused through a lens onto the wall of a dark
room, most contemporary artists interested in producing his
namesake figures employ more technological means such as
oscilloscopes, vector monitors, and ILDA lasers. However,
many frugal alternatives to these sometimes rare and of-
ten expensive devices have been crafted by members of the
DIY audiovisual arts community. One finds many exam-
ples of televisions modified to accept external XY signals
[2], as well as laser projectors constructed by using laser
pointers, speakers, mirrors, and even balloons to deflect the
laser beam into shapes driven by audio signals (Figure 3).
So while the methods described in this paper may not be
particularly frugal on their own, the underlying principles
could otherwise be implemented using free and open source
software or simple analog electronics.
Figure 3: An inexpensive DIY monophonic laser projector
using a balloon stretched over a loudspeaker and a mirror
to deflect Lissajous-type figures onto photosensitive paper.
Photos and device by Pablo Guerra/polwor.cl, reproduced
with kind permission.
3.2 The Vector Synthesis Pure Data Library
The primary toolkit used in creating the Laser Phase Syn-
thesis instrument is the Vector Synthesis 5 library for the
free and open source Pure Data programming environment.
The project evokes seminal graphics technology from the
1960’s such as Ivan Sutherland’s Sketchpad, or vector video
games from the 1980’s such as Battlezone, reimagining these
primarily visual environments as opportunities for audiovi-
sual synthesis [7] . Additionally, by using the GEM exter-
nal in Pure Data, the library can reenact key affordances
of historical scan processing animation computers from the
1970’s, such as the Rutt/Etra Video Synthesizer and the
Scanimate [8]. Taken together, this collection of tools was
conceived as a media archaeological investigation of early
computer animation techniques using more contemporary
means.
In functional terms, the library allows the creation and
manipulation of vector-based graphics, using audio signals
to display these graphics on XY displays. A number of
useful tools in a modular, patchable form allows users to
quickly build up complex, interactive audiovisual anima-
tions. It contains modules for drawing two and three di-
mensional shapes, scaling them in size, translating them in
location, rotating them in three dimensions, morphing be-
tween two or more shapes, multiplexing a number of shapes
by splitting up the time the CRT or laser beam spends
drawing each figure, and projecting a three dimensional fig-
ure into two dimensions with perspective applied. Finally,
the library also provides a module for manipulating and
modulating the RGB color values and overall brightness of
an ILDA laser beam, as well as some safety features which
deactivate (or “blank”, in laser terminology) the beam when
it travels outside of a predefined area (called the “zone”), or
when the beam is not in motion (referred to as a“scan fail”).
All of these transformations can either be adjusted manu-
ally, modulated slowly by low frequency oscillators (LFOs)
with a number of waveforms, or modulated at audio fre-
5https://github.com/macumbista/vectorsynthesis
quencies by faster oscillators. Modulations at slow periods
produce singular or repetitive movements associated with
traditional animation, while modulations at audio rates can
produce entirely new shapes depending on their harmonic
relation to the fundamental drawing frequency. The re-
sulting audio signals are sent simultaneously to display and
loudspeakers through a balanced, DC coupled audio inter-
face, providing a direct, non-symbolic relationship between
sound and image.
3.3 The Laser Phase Synthesis (LPS) Instru-
ment
Figure 4: A patch using the Vector Synthesis library for Pure
Data, which forms the basis of the Laser Phase Synthesis
instrument.
The core of the Laser Phase Synthesis (LPS) instrument
relies on a fairly simple arrangement of Vector Synthesis li-
brary modules. Figure 4 shows a simple patch for drawing
a circle at 25 Hz using the vs-circle-gui module, modulating
its size ( vs-scale-gui) with an external audio signal ( adc ),
rotating it with LFOs in three dimensions ( vs-rotate-gui),
cycling through the RGB color space ( vs-ilda-throw-gui),
and sending it to the audio interface as ILDA standard sig-
nals (vs-ilda-gui). This creates the visual effect of a multi-
colored circle of light drawn by the laser, whose size and
shape is changed by the audio waveform of the input audio
through a fairly straightforward process of amplitude mod-
ulation. A MOTU UltraLite digital audio interface both
captures audio from a source such as a performer, and sends
a complete set of ILDA signals to the laser, with additional
stereo outputs which can be sent to a pair of loudspeakers.
The musical and laser performers are all located facing the
projection surface in order to see how the laser responds to
the sound input.
The LPS patch is simplified and plotted in Figure 5, using
primitive objects from the Pure Data environment. In this
example, the circle itself is drawn by a pair of phase-locked,
200 Hz sine waves which are offset by 90 degrees. The first
sine wave represents the movement on the X axis, and the
second represents the movement on the Y axis. The ampli-
tude of these two sine waves is modulated by a third sine
wave at a frequency six times that of the oscillators draw-
ing the circle. The amplitude modulator is scaled by the
size modulation amount (here described as a percent) and
summed with a fixed size constant to control the depth of
the modulation. Modulator waveform peaks in the positive
domain expand the visual shape outwards, while waveform
peaks in the negative domain contract the figure inwards.
The modulated X and Y signals are plotted linearly in the
time domain in the vs-seeme module, alongside the modu-
lator waveform. The resulting figure is plotted in Cartesian
space with an oscilloscope simulator, where we can clearly
see the six positive peaks of the modulator signal. A video
demonstration of the LPS multiplexing several laser figures
together can be found in the first part of the supplementary
video to this paper 6.
Figure 5: A simplification and plotting of the Laser Phase
Synthesis patch, showing the effects of harmonic amplitude
modulation on the X and Y carrier waves.
4. RESULTS
4.1 Experiment I: Audiovisual Composition
The first practical experiment with the LPS system was a
collaborative, light and sound composition between audiovi-
sual artist Derek Holzer and electroacoustic composer Luka
Aron. This collaboration began in a quite free form manner,
and eventually crystalized into a strict harmonic framework
used to produce sound and image for a work entitled Laser
Phase Synthesis[XXI VII III I] . Once this framework had
been agreed upon ahead of time, each artist developed el-
ements of the work in their own medium before bringing
them together for a live performance.
The harmonic framework underlying the compositional
method employed is a network of closely related harmonic
series, whose fundamentals are derived from the subhar-
monic series. Certain combinations of harmonic series will
have several partials in common, giving way to the possi-
bility of modulating between them. It is a just intonation
system of varying complexity, derived from the observation
of certain auditory and acoustic phenomena, such as differ-
ence tones and (non)-beating, as well as the periodicity of
composite sound waves.
6https://youtu.be/PURQxFVX3F0
In the case of Laser Phase Synthesis[XXI VII III I] , the
fundamental 1/1 was first assigned to 25 Hz, which matched
the initial drawing frequency of the laser forms. Three other
subordinate fundamentals, each containing their own sub-
set of unique harmonic partials, were chosen (4/3: 33.333
Hz, 8/7: 28.571 Hz, 32/21: 38.095 Hz). Subsequently, their
order was determined by calculating their respective closest
relative. An excerpt of the resulting sequence is illustrated
in Figure 6. Each fundamental is held for a given amount of
time, while the common partials overlap. It is important to
note that the octave identity of each fundamental and par-
tial may be changed, depending on the timbre used. During
Figure 6: A timeline of the fundamental and partial frequen-
cies, derived from a laser drawing frequency of 25 Hz, during
the first section of audiovisual composition“Laser Phase Syn-
thesis[XXI VII III I]”.
the performance of the piece, the drawing frequency of the
laser remains matched to the 1/1 fundamental frequency of
the partials, even as this fundamental changes through the
musical composition. This allows for a wide range of move-
ment, both visually and audibly, while maintaining a close
harmonic alignment. The primary timbres used as sonic
material for Laser Phase Synthesis[XXI VII III I] were sine
waves, and samples of several gongs and bells. While the
sine waves were tuned to precision in the Pure Data envi-
ronment, they interacted with the inharmonic spectra of the
percussion instruments, resulting in rich interference pat-
terns apparent in both sound and image.
Beyond the basic amplitude modulation of the LPS patch
using a monophonic mixdown of the audio composition as
modulator of a circular form, three dimensional rotations
and color modulations of the figure added additional visual
complexity. The signals driving the laser were not mixed
back into the performance audio, only seen in the shape
of the laser, and smoke was used to create a volumetric
illusion with the laser beam. A selection of some of the
resulting patterns can be seen in Figure 7. A video excerpt
of the live performance can be found in the third part of
the supplementary video to this paper.
4.2 Experiment II: Vocal Improvisations
During the development process of the LPS, a number of
experiments were conducted with vocalists to investigate
how the bodily interaction of singing through the laser could
create new audiovisual expressions. For these experiments,
the basic LPS amplitude modulation patch was used, with
the voice of the singer captured with an SM58 microphone
as the modulating signal. The RGB color of the laser beam
was also affected by the amplitude and polarity of the input
sound.
The participants in these experiments were provided with
Figure 7: A selection of laser patterns from the live electroa-
coustic performance “Laser Phase Synthesis[XXI VII III I]”.
a MIDI keyboard, with which they could select the funda-
mental frequency which draws the laser circle, and which
could be heard as a tone over a pair of loudspeakers. They
were also instructed that if they made sounds which were
harmonic to the fundamental they heard, the visual shapes
they saw would be fairly stable. Conversely, the more in-
harmonic their sounds, the more unstable the figure would
be. They were also told that neither approach was prefer-
able, and that they were free to experiment however they
chose. Finally, a camera made a video recording of the laser
shapes alongside an audio recording of the singer’s voice and
subsequent conversations.
Participants were encouraged to comment freely during
their experiments according to the think aloud protocol,
and were verbally asked several open ended questions about
the quality and character of the interaction after the exper-
iment. Five participants were interviewed in total. Four
singers identified as female and one as male, of which four
were trained professional vocalists while one was a trained
amateur. They held diverse backgrounds in classical, opera,
Nordic folk, and experimental styles. Transcripts of these
sessions were later analyzed for thematic similarities.
Even with such a small sample size, several observations
could be made regarding common techniques, the visual re-
sults which they produced, and the quality of the feedback
the results provide in helping the vocalist understand the
interaction between the laser image and the vocal improvi-
sation. Table 1 summarizes observations on each technique.
A video demonstration of some of these techniques can be
found in the second part of the supplementary video to this
paper.
5. DISCUSSION
The two experiments with the LPS instrument employed
quite different methods to structure the interaction between
sound and image. The first relied on a pre-arranged series of
harmonic partials to ensure controlled visual effects, while
the second encouraged freeform improvisation to establish a
bodily relationship with the laser image. However, in both
Figure 8: Laser patterns resulting from surveyed vocal tech-
niques (see Table 1).
cases one can observe an interaction process feeding back
from the resulting laser images into the process of sound
production.
In the case of the electroacoustic composition, even if the
composition itself was not occurring in a realtime relation-
ship with the laser visuals, the composer was mindful of
the effects on the laser which he had previously witnessed.
His experience with those effects led him to choose specific
partials and progressions in the work, and furthermore to
introduce metallophone sounds with complex timbres and
waveforms for more visual variety and complexity. As is the
case with many reenactments, the resulting work diverged
substantially from the aesthetics of Tudor and Cross’ orig-
inal performance. Where Tudor’s wild electronic feedback
systems constantly teetered on the edge of chaos, Aron’s
composition applies a high level of control to delicate and
subtle changes of timbre and harmonic which slowly unfold
over the duration of the piece.
In the case of the vocal improvisations, the feedback hap-
pened in real time and facilitated a much faster negotiation
of the sound/image relationship. At first, experiment par-
ticipants employed vocal techniques from their own reper-
toire and tradition in order to explore how the laser visuals
would react to the sound. However, all the participants
became very interested in aspects of predictability, repeata-
bility, and mastery of the laser image. During each session,
their search for points of control over the image started to
strongly affect both their choice of technique and the de-
livery of their chosen vocalizations. Most participants re-
flected that this exploration was highly demanding in men-
tal and physical ways, but that the process was very akin
to learning any instrument, and started to become intuitive
after some amount of practice.
This feedback is precisely what prevents the LPS instru-
ment from remaining a simple visualization tool. Because
the results of a sonic interaction with the laser can directly
affect what sounds are chosen next, the LPS becomes an
active agent in the creation of sound, and therefore an au-
diovisual instrument. Furthermore, since the parameters
of sonic interaction with the instrument are fixed and lim-
Table 1: A survey of vocal techniques and their visual results with the Laser Phase Synthesis instrument.
TECHNIQUE MEANS RESULTS NOTES
Melodic singing
Repetition of existing
song melodies; only
non-improvisational
technique surveyed
Stability of visual figures
dependent on harmonic
relationship of sung melody
to laser fundamental
Poor interaction feedback;
participants felt they were
only “driving” visuals rather
than interacting; results
unpredictable
Harmonic singing
(Figure 8a)
Sung fundamental at
whole number harmonic
ratios to laser
fundamental
Very stable and predictable
Lissajous figures; visible
lobes indicate exact harmonic
ratio; perfect unison gives
only phase distortion
Excellent interaction
feedback; very intuitive;
dependent on skill of vocalist
Inharmonic singing
(Figure 8b)
Sung fundamental not
at whole number
harmonic ratios to
laser fundamental;
by error or intention
Multi-lobed, unstable
Lissajous figures which
appear to spin rapidly
Poor to fair interaction feedback;
unintuitive; not easily predictable
or reproducible
Glissando singing
(Figure 8c)
Sweeping sung
fundamental through
varying harmonic
ratios to laser
fundamental
Multi-lobed Lissajous
figures which transition
between stable and
unstable states
Good interaction feedback; a
dramatic visual effect,
particularly with skilled
vocalist
Vibrato singing
(Figure 8d)
As harmonic singing;
with small, regular
changes in pitch
Visual pulsing or
shimmering of stable
Lissajous figures
Good interaction feedback;
dependent on skill of vocalist
Harmonic humming
(Figure 8e)
As harmonic singing;
with closed lips and
air expressed through
the nasal cavity
Reduced higher
harmonics soften
and stabilize shapes
of Lissajous figures
Good interaction feedback;
requires less vocal skill
than harmonic singing for
similar results
Overtone singing
(Figure 8f)
As harmonic singing;
with timbral
manipulations made
by throat, tongue, lips
Added waveforms to peaks of
the figures; no change to
fundamental singing frequency
Good to excellent interaction
feedback; requires high level
of vocal skill
Plosives
(Figure 8g)
Explosive bursts of
breath and sound; i.e.
the sounds ba or pa
Unstable figures; extremely
short time duration; resemble
fireworks or flashbulbs
Fair to good interaction
feedback; easy effect; short
duration prevents better
feedback
Sibilants
(Figure 8h)
Sustained noisy sounds;
breath passed through
lips or teeth; i.e. the
sounds sh or fff
Highly unstable figures;
character determined by
density and amplitude rather
than pitch
Very good interaction
feedback; easiest and most
reproducible effect
Inhaling singing[17]
(Figure 8i)
Inhalation combined with
tightening of vocal folds;
higher sung fundamentals than
exhaling singing
Increased number of visual
nodes and density of lines;
interesting phase distortions
Very good interaction
feedback; physically
demanding; can be harmonic
or inharmonic
ited to harmonic ratio, amplitude, and timbre, the system
can easily be integrated with existing musical performance
practices. This allows the LPS to be understood, learned,
and eventually mastered to a degree that skilled live perfor-
mance becomes possible.
6. CONCLUSIONS
Through the design, experimental testing, and live perfor-
mance Laser Phase Synthesis instrument, we have reenacted
the development process of Tudor, Cross, and Jeffries’ Au-
dio/Video/Laser system during the late 1960’s, as well as
further the ambitions they held for their own audiovisual
laser system. This is done through the historically informed
use of contemporary digital audio and laser display tech-
nologies alongside close collaboration between music and
visual composition and performance. We believe this pro-
cess offers new insights into potential relationships of sound
and image within a musically expressive context, and fore-
see developing the LPS further in collaboration with other
composers, vocalists, and instrumentalists.
7. ACKNOWLEDGEMENTS
The authors would like to thank Julie Martin and You Nakai
for their historical references during the writing of this pa-
per, Rikhard Lindell and H ¨ogskolan Dalarna for the oppor-
tunity of first presenting this performance work in 2022,
and Susanne Rosenberg, Tone ˚Asa, Kelsey Cotton, Joris
Grouwels, and Astrid Bergdahl for their feedback regarding
the vocal experiments.
This work was partially supported by the Wallenberg AI,
Autonomous Systems and Software Program – Humanities
and Society (WASP-HS) funded by the Marianne and Mar-
cus Wallenberg Foundation (Grant 2020.0102), and by the
Swedish Research Council (2019-03694).
8. ETHICAL STANDARDS
The research in this paper has taken place within the con-
text of Derek Holzer’s doctoral research at KTH Royal In-
sititute of Technology in Stockholm, which has been funded
by the Swedish Research Council (2019-03694). Other re-
search partners include KMH Royal Academy of Music and
the Swedish Performing Arts Agency. Informed consent was
practiced in all experimental work involving participants.
We declare that there are no conflicts of interest. Any re-
search or performance utilizing laser equipment carries the
risk of eye damage as a result of accidental exposure to laser
radiation. We have ensured that every precaution – meet-
ing and exceeding legal requirements – has been taken to
avoid such accidents on the part of the experiment partici-
pants, performance audience, venue staff, other performers,
and ourselves.
9. REFERENCES
[1] R. Blackson. Once More . . . with Feeling:
Reenactment in Contemporary Art and Culture. Art
Journal, 66(1):28–40, Mar. 2007.
[2] J. Connolly and K. Evans. Cracking Ray Tubes:
Reanimating Analog Video in a Digital Context.
Leonardo Music Journal, 24:53–56, Dec. 2014.
[3] L. Cross. Audio/Video/Laser. In L. Austin, D. Kahn,
and N. Gurusinghe, editors, Source: Music of the
Avant-Garde, 1966-1973. University of California
Press, Berkeley, 2011.
[4] L. Dolanov´ a, T. Ruller, W. Vasulka, and S. Vasulka.
A Dialogue with the Demons of the Tools: Steina and
Woody Vasulka. Center for New Media Art, Brno,
first edition edition, 2021.
[5] T. Fiske. White Walls: Installations, Absence,
Iteration and Difference. In A. Richmond and
A. Bracker, editors, Conservation Principles,
Dilemmas and Uncomfortable Truths , pages 229–240.
Elsevier, Amsterdam, 2009.
[6] D. J. Haraway. Staying with the Trouble: Making Kin
in the Chthulucene . Experimental Futures:
Technological Lives, Scientific Arts, Anthropological
Voices. Duke University Press, Durham, 2016.
[7] D. Holzer. Vector synthesis: A media archaeological
investigation into sound-modulated light. Master’s
thesis, Aalto University, Department of Media, Espoo
Finland, 2019.
[8] D. Holzer. In Search of the Plastic Image: A Media
Archaeology of Scan Processing. Proceedings of the
ACM on Computer Graphics and Interactive
Techniques, 5(4):1–8, Sept. 2022.
[9] B. F. Laposky. Electronic abstractions: Mathematics
in design. Recreational Mathematics, (4):14–18, Aug.
1961.
[10] Y. Nakai. When Tudor Went Disco: The No-Audience
Laser Concert Without the Laser at Xenon. In
Monobirds: From Ahmedabad to Xenon, 1969 / 1979 .
TOPOS Media, 2021.
[11] H. Rudolf. ETC’s System. In K. High, S. M. Hocking,
and M. Jimenez, editors, The Emergence of Video
Processing Tools: Television Becoming Unglued,
volume 2, pages 473–484. Intellect, Bristol Chicago,
[Illinois], 2014.
[12] A. Salvad´ o. Robin Fox: Sculpting with voltage.
https://metalmagazine.eu/en/post/interview/robin-
fox-sculpting-with-voltage, 2019.
[13] P. Shabecoff. Glittering, Clicking, Clanking Expo ’70,
in Japan, Emphasizes the Practical Use of Modern
Technology. New York Times, Mar. 1970.
[14] I. L. D. A. Technical Committee. The ILDA Standard
Projector, Revision 002, 1999.
[15] M. Tuchman. Art & Technology: A Report on the Art
and Technology Program of the Los Angeles County
Museum of Art, 1967-1971 . Los Angeles County
Museum of Art, 1971.
[16] D. Tudor. Monobirds: From Ahmedabad to Xenon,
1969 / 1979, 2021.
[17] F. Vanhecke, M. Moerman, F. Desmet, J. Six,
K. Daemers, G.-W. Raes, and M. Leman. Acoustical
properties in inhaling singing: A case-study. Physics
in Medicine, 3:9–15, June 2017.
[18] J. Whitney. Digital Harmony: On the
Complementarity of Music and Visual Art . Byte
Books, Peterborough, N.H, 1980.
[19] G. Youngblood. Calculated Movements: An Interview
with Larry Cuba. Video and the Arts Magazine , 1986.
[20] G. Youngblood. Expanded Cinema. Fordham
University Press, New York, fiftieth anniversary
edition edition, 2020.
[21] Y. Yu. Towards a Morphogenesis: Light in Xenakis’s
Work. In Proceedings of the Xenakis 22: Centenary
International Symposium, Athens & Nafplio, May
2022.