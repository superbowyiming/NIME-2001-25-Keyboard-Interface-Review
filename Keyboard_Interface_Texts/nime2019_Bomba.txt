Somacoustics: Interactive Body-as-Instrument
Maros Suran Bomba
Dept. of Communication and Psychology
Aalborg University, Denmark
marosbomba@gmail.com
Palle Dahlstedt
Dept. of Computer Science and Engineering
Chalmers/Univ. of Gothenburg, Sweden
Dept. of Communication and Psychology
Aalborg University, Denmark
palle@chalmers.se
ABSTRACT
Visitors interact with a blindfolded artist’s body, the mo-
tions of which are tracked and translated into synthesized
four-channel sound, surrounding the participants. Through
social-physical and aural interactions, they play his
instrument-body, in a mutual dance. Crucial for this work
has been the motion-to-sound mapping design, and the
investigations of bodily interaction with normal lay-people
and with professional contact-improvisation dancers. The
extra layer of social-physical interaction both constrains
and inspires the participant-artist relation and the sonic
exploration, and through this, his body is transformed into
an instrument, and physical space is transformed into a
sound-space. The project aims to explore the experience of
interaction between human and technology and its impact
on one’s bodily perception and embodiment, as well as
the relation between body and space, departing from a
set of existing theories on embodiment. In the paper, its
underlying aesthetics are described and discussed, as well
as the sensitive motion research process behind it, and the
technical implementation of the work. It is evaluated based
on participant behavior and experiences and analysis of its
premiere exhibition in 2018.
Author Keywords
embodiment, motion tracking, dance
CCS Concepts
•Human-centered computing → Gestural input;
•Applied computing→Performing arts; Sound and
music computing;
1. INTRODUCTION
Expression through sound is inherent in our human nature
throughout our lives. Screaming, crying, whistling, laugh-
ing, clapping, and singing are all expressive sounds and
noises that originate from and are produced by the use of
our bodies. When our physical capabilities no longer match
our desire we invent technology. From studies of music ar-
chaeology that uncover usage of primitive ancient sound-
producing tools to contemporary experimental development
of new electronic and algorithmic instruments, we can recog-
nize historically perpetual invention and innovation of such
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’19, June 3-6, 2019, Federal University of Rio Grande do Sul,
Porto Alegre, Brazil.
objects. The invention of new technologies accelerate this
process and pushes it into the investigation beyond what is
known. Kevin Kelly [7] suggests that technology is not only
natural but also driven by the same evolutionary forces that
had impacted on the creation of humankind. He sees the
potential in the technology as it gives us new possibilities
to understand ourselves and the world around us, to open
up for new interactions and experiences. This has been a
guiding thought behind this project.
Somacoustics is an interactive participatory performance
artwork, where the blindfolded artist’s body is transformed,
through motion tracking technology, mapping and sound
synthesis, into an instrument. Participants (visitors) inter-
act with this instrument-body, inﬂuenced by social bodily
interaction patterns, sonic responses and by their own per-
ception of themselves and of the interaction/performance.
The project combines experience design, human-computer
interaction, interaction design, wearable technology, and
performance art that, with artistic, somatic and concep-
tual practices. The central aim has been to, through a
designed instrument-body in mixed reality space, explore
the experience of interaction between human and technol-
ogy and to investigate if such interaction, within its artistic
and performative framework, has transformative eﬀects on
the subject’s embodiment and perception. Also, we want to
contribute to the diﬃcult questions of the relationship be-
tween humans and technology, and how body and technol-
ogy can be combined in an aesthetic interactive experience.
A video about the project is attached to this paper, and
can also be viewed online.1 See Fig.1 for action photos from
the exhibited work.
The contributions of the two authors are as follows: The
ﬁrst author has a background in interactive arts and per-
formance, and is the primary author and coder of the art-
work, as well as performing the instrument-body. The sec-
ond author is a musician, sound artist, and researcher who
has functioned as supervisor and adviser throughout the
project, and thus has contributed artistic input, techni-
cal solutions, and mapping approaches at all stages of the
project. The paper is written in collaboration.
2. BACKGROUND
Experience from an earlier experiment with soniﬁcation of
an object’s movement, together with an engagement in con-
tact improvisation practice, triggered the question: What
if we could apply the similar interactive technology to ones
own body, thus creating an instrument-body, which could
be performed on by other people?
Soma means body in Greek, and Somacoustic became
our word for experiencing body through sound. It com-
bines body and technology through the application of VR
1https://youtu.be/CQjY8mXHm2o
95
technologies, in combination with sound synthesis software,
turning the body into a musical instrument. When par-
ticipants project their own movements on the body of the
performer, it engages them in a dynamic exploration of a
virtually augmented soundscape.
2.1 Aesthetic and theoretical background
In this section, we will present theories and aesthetics
that has served as framework for the project, forming
a sequence of connected concepts, together focusing
the project: body–somaesthetics–aesthetic experience–
technology–interaction–mixed reality.
In Merleau-Ponty’s Phenomenology of perception [9], he
presents his thoughts on existential perception with a focus
on the body, towards an understanding of the embodied
experience of human existence in the world: “I cannot un-
derstand the function of the living body except by enacting
it myself, and except in so far as I am a body which rises
towards the world” ([9], p. 87). We try to understand the
physiological function of the body through cognitive pro-
cesses which retroactively inﬂuence its mechanics that even-
tually appears eﬀective toward the world and our thinking
in it. The body is our vehicle of being in the world.
A use of embodied practice and perceptional aware-
ness of the artists own body represents a vital element
in this project. Here, Richard Shusterman’s theory of
somaesthetics can help to analyze embodied experi-
ence throughout the process of project development and
performance/exhibition. Shusterman presents a philo-
sophical discipline deﬁned as “the critical, meliorative
study of the experience and use of one’s body as a locus
of sensory-aesthetic appreciation (aisthesis) and creative
self-fashioning” ([12], p.302). The body has the role of a
mechanism that strengthens our sensorial perception of
the world around us. If somatic practices can improve our
sensory richness, muscle mechanics, and bodily awareness,
it could productively contribute to the more profound
appreciation of diﬀerent (non)art forms and enhance our
experience of the environment in which we, entities with
our bodies, live.
But what does it mean to have an experience? Does an
interactive technology allow for having an appreciated ex-
perience as an outcome of interaction? Pragmatist philoso-
pher John Dewey [4] distinguishes between ordinary expe-
riences and those that have a potential aesthetic value. In
his terms, “an experience”has gained the aesthetic and emo-
tional properties because of its fulﬁllment. “Such an expe-
rience is a whole and carries with it its own individualizing
quality and self-suﬃciency. It is an experience“ ([4], p.36).
In this context, we might be able to determine that some
parts of the experience were much more eﬀective then the
others deﬁning the experience as a whole. An experience is
a process of balancing the relationships between conscious
doing and undergoing from which an experience can achieve
speciﬁc value and meaning. Nevertheless, referred experi-
ences are undergone through the interaction with technol-
ogy. Our lives are intertwined with many kinds of inter-
active technologies, they exist with us, they exist for us,
they shape us. But how do we clarify the importance of
technology’s impact onto our lived, aesthetic, experience?
McCarthy and Wright propose that it is because the in-
teraction with technology can evoke emotions, impression,
ideas, meanings, it is profoundly embedded in our living ex-
perience [8]. They argue that to see“technology as aesthetic
experience requires that we see any boundaries between hu-
mans and technology as constituted by the dialogical rela-
tions sustaining them...” ([8], Ch.3). As we see this project
as an ongoing experience of the relationship between human
and technology, we ﬁnd the pragmatic views presented by
Dewey, and by McCarthy and Wright as relevant analytical
tools for theorizing about the experience of this project.
Interaction is the driving force of the experience in
Somacoustics. Here, we can apply Dalsgaard and Koefoed
Hansen’s theory [3] concerning the experience of user and
observer within user-system interaction and the chains of
acts and roles that it implies. The user not only perceives
the outcomes from the interaction with the system but also
her act of interaction, thus her perception is inﬂuenced by
the knowledge that her own interaction with the system is a
performance for others. This deﬁnes the three acts in which
the user is simultaneously engaged: interacting/operator –
perceiving/spectator – performing/performer. This helps
clarify the classiﬁcation and analysis of the experience
of human-computer interaction because it deﬁnes diﬀer-
ent modes of experience, as well as it allows to frame
performative qualities of the experience.
Somacoustics interaction and experience takes place in a
mixed realityspace. Benford and Giannachi [1] advocates
that new digital technologies (such as Virtual Reality) opens
up for inclusion into the artistic practices and performances,
which leads to new kinds of experience. They refer to these
experiences “as mixed reality performances, a term that is
intended to expresses both their mixing of the real and vir-
tual as well as their combination of live performance and in-
teractivity” ([1], p.1). In relation to Milgram and Kishino’s
taxonomy of mixed reality display, a “virtual continuum” as
a spectrum from a purely physical environment to a fully
virtual one, they propose a theory based on trajectories,
which expresses how participant experience such mixed re-
ality “in terms of multiple interleaved trajectories through
complex hybrid structures of space, time, interfaces, and
roles that establish new conﬁgurations of real and virtual”
([1], p.1). A participant maps this environment, in terms of
the information gained during the experience. “They map
in that they reconstruct, often collaboratively, predesigned
journeys by using physical and digital signposts not only to
orient themselves in a given mixed reality environment but
also to design it at the same time” ([1], p.20).
Our project aims to explore the experience of interac-
tion between human and technology through the use of
instrument-body. However, the instrument-body within it-
self constitutes the relationship between human and tech-
nology. Marco Donnarumma has explored this relationship
[5], proposing that the performer and instrument are in a re-
lationship of conﬁguring, which allows us to analyze the cor-
poreality of the technological body, which consists of such
relationships.
Referencing Shilling [11], Donnarumma explains the tech-
nological body as “contemporary technology has moved in-
ward. [. . . ] Through technical methods and applied knowl-
edge, technology has modiﬁed the body’s organic proper-
ties by literally occupying its own space on and within it”.
Our bodies have opened up for artiﬁcial organs, chips and
implants. Therefore the technological body can also be re-
ferred to as the current state of the relation between human
and technology and that it is precisely “human-technology
relationships, that is, their physical contact and exchange
of informational data, which enacts new corporealities in
sound performance, new ways of experiencing and express-
ing sound and music” ([5], p.17). Hence, we can under-
stand the performer-instrument relationship, where they
constantly inﬂuence each other, as an ”ecology of things,
energies and strategies forming the particular embodiment
of the player-instrument,” thus conﬁguration.
These theoretical frameworks will be brought back into
the discussion about the work in the analysis section.
96
2.2 Previous works
Many artists within the ﬁeld of digital art, performance art,
sound art and instrument design have tackled the notion of
human-technology relationship by merging the technology
with a body in various art forms, on account of which they
challenge and confront diﬀerent forms of interaction. We
will only be able to mention some of the most relevant artists
and artworks that have serve as an artistic, inspirational and
conceptual standpoint in relation to our project.
As the most notorious body-technology artist, Stelarc
challenges the biological body through extending it with
technology. He argues that the body is obsolete and that
it needs to be considered as an extendable evolutionary
structure which is enhanced by the technology that is in-
herently better, more powerful, eﬃcient. Throughout his
works (e.g., Ping Body (1995) 2 and Exoskeleton (1997) 3),
by deliberately merging the body with technology, in terms
of extending and enhancing its qualities, to illuminate the
importance of the human-technology relationship, he de-
veloped several modes of interactions and embodiments.
More recently, Marco Donnarumma constructs his artworks
through merging his body with biotechnology, biophysical
sensors, AI, and neuro-robotics to produce immersive, sen-
sual and confrontational experiences. The main medium in
his artworks is sound that through the application of tech-
nology encompasses body’s physicality, bio-structure, and
depth. Through his artworks, he questions a traditional use
of the electronic instrument and proposes new thinking on
a performer-instrument relationship [5].
Joseph Malloch has, in his work The Spine , presented
a digital prosthetic instrument that attaches to the per-
former’s spine. It was developed for the collaborative
project Les Gates, in which the artist attempted to design
a new instrument that enables soniﬁcation of performer’s
movement. Technically, it is realized through utilization of
inertial and magnetic-ﬁeld sensors that track and report
its orientation, shape, and angle in which it bents, which
to some extent, correspond to orientation and position of
the dancer’s spine as well as to particular dancer’s impro-
visational or choreographed moving patterns. Real-time
data, gathered from the instrument, are then mapped to
speciﬁcally designed soundscape thus giving a reﬂection of
action immediate audio-feedback4. The piece demonstrates
the usage of technology to sonify the movements and that
the relationship between performer and technology inhabits
performative qualities.
Another work that has inspired the design of Somacous-
tics was OtoKin by Dahlstedt and Sk˚ anberg[ref anon]. In
this performance (also exhibited as an interactive installa-
tion), the skeleton coordinates of two dancers are tracked
using Kinect2 sensors, and this data is subsequently mapped
to realtime synthesis, transforming the whole stage into a
multi-dimensional soundspace, which combined with the ac-
tual physical space forms an augmented reality experience
for the dancers or participants, and deeply synchronized
movement and sound – as they emanate from the same
data set. In this work, the design of the sound space guides
the improvisatory exploration by the dancers. Like Soma-
coustics, it contains a social dimensions, where participants
touching each other transforms the sound character com-
pletely, forming an inherent narrative of solitude, searching
and togetherness.
2https://aboutstelarc.weebly.com/ping-body.html
3https://aboutstelarc.weebly.com/alternate-interfaces.html
4https://josephmalloch.wordpress.com/tag/spine/
Figure 1: Visitors interacting with the instrument-
body during exhibition.
3. EV ALUATION AND METHOD
We emphasize the use of the body and its sensual percep-
tion that in combination with interactive technology fos-
ters performative characteristics. Here, Pelias’ method of
“Performative Inquiry” [10] can be applied. He asserts that
performance has a power to convey meaning-making and
understanding of human behavior that impacts on social
sphere, as a way of knowing the world around us. Hence, it
must employ embodiment, and embodied practice fuels the
method of performative inquiry. As the performer acquires
more knowledge, the body start to inhabit qualities of the
exploratory instrument. In contrast to the more theoret-
ical works presented earlier (Merleau-Ponty, Shusterman),
Pelias’s’ method demonstrates a direct methodological ap-
proach towards using a body as a location of knowing about
your audience in a particular performative framework.
An improvised contact between participant and per-
former occurs naturally during manipulation of the
instrument-body. It employs spontaneous exploration
of diﬀerent manipulation approaches, kinetic inputs and
bodily communication, which fades in to diverse movement
patterns and interaction of two or more bodies. Contact
improvisation is a contemporary dance genre which ex-
plores the kinaesthetic possibilities of body movements
through contact with another body. It not only opens up
97
for exploration of dynamic interaction between bodies,
but it also examines individual body physical and agile
condition, posture, balance and muscular system, that is
to say, body research. Attending these practices, the artist
was able to reﬂect on most peculiar posture his body could
generate and hold without losing the balance, to adjust to
the shifts of posture as well as to distribute the weight of
the body accordingly to avoid falling. Although it did guide
him through exploration of his own body’s capabilities,
it did not establish particular scenarios relevant to the
desired interaction within Somacoustic. During contact
improvisation practices, he was not only being moved
by other practitioners but he was actively and willingly
engaged in moving them as well, while in Somacoustics, he
is expected to be primarily reactive to participant input,
thus entirely submissive to their initiatives.
In reaction to that, we conducted two individual re-
search sessions with two diﬀerent groups of people: two
non-dancers, and ﬁve contact improvisation practitioners.
In these sessions the artist’s body was presented to them as
being an object which they are allowed to manipulate. At
that point, the interface was not yet fully developed, there-
fore they were told to imagine that any body manipulation
would leave audio feedback – this was important to clarify
since it could impact on their manipulation approaches.
Both sessions were recorded on video 5, as well as the ﬁnal
exhibition which delivered a rich set of data for further
analysis.
3.1 Mapping
This project is based around a mapping from motion track-
ing data to sound synthesis, thereby transforming the ex-
perience of one’s movement and of the space. Movement
soniﬁcation as a method has, aside from the arts, also been
used in rehabilitation or sport techniques for motor control
learning and improvement (e.g., in [13]). Through conver-
sion of movement into auditory feedback, it enhances per-
ceptual awareness of the body motorics.
Hunt & Wanderley [6] refer to mapping in instrument
design as “mathematical process of relating the elements of
one data set onto another”more explicitly“[. . . ]act of taking
real-time performance data from an input device and using
it to control the parameters of a synthesis sound.” They
mention two approaches to mapping, generative and ex-
plicit, where the former relies on algorithms such as machine
learning to deduce a mapping from training data, while in
the latter the mapping is deﬁned explicitly by hand. We
chose the latter approach, but with a twist. Explicit map-
pings can be described in terms of how input variables are
assigned to output variables [6]: one-to-one, one-to-many ,
or many-to-one. A combination of these can be referred
to as many-to-many, as is the case in many acoustic instru-
ments, where, e.g., the pitch in a wind instrument is aﬀected
by several input parameters (air and lip pressure, ﬁnger-
ing), and simultaneously a single input parameter (say, the
air pressure) aﬀects a number of output parameters (pitch,
timbre, amplitude, etc.). In our approach, we were also in-
spired by Dahlstedt’s work on randomized all-to-all vector
mappings [2], which in a sense is a hybrid between gener-
ative and explicit mappings – not designed by hand, but
using a randomized translation matrix providing a complex
translation between input and output, where each param-
eter is aﬀected by every other, while retaining control over
gestural contour and magnitude through a few explicit map-
ping choices. This has shown very suitable for situation
5Excerpts can be seen in the video linked in the Introduction
section.
where there is no obvious connection between input and
output parameter sets.
4. DESIGN AND IMPLEMENTATION
4.1 Interface
For motion tracking, we chose to use he HTC Vive. Orig-
inally designed for VR applications, it consists of a head-
mounted display, two hand controllers and an optional set
of point trackers. It provides millimeter precision track-
ing of all devices, which is crucial for capturing expressive
movement, and low latency and high data rate, which is
important in musical applications. Ideally, we would like
to track a large number of points of the instrument-body,
but the Vive point trackers are quite bulky, so we had to
limit ourselves to tracking the 3D coordinates of ﬁve points,
in addition to tracking coordinates and angular direction of
the head-mount. The hand controls were not applicable
in a dance environment. Trackers were mounted on elastic
bands allowing for ﬂexible placement on limbs.
In the movement research sessions, participants tended
to both change the position and the speciﬁc posture of the
instrument-body. Based on this, we chose to place the track-
ers according to the following: One on the chest for cap-
turing the trajectory of whole body, one on each hand for
capturing oscillating motion that tended to appear during
manipulation, and one on each foot. Even though the feet
were not explicitly manipulated as frequently as the upper
parts of the body, it increased control possibilities.
Also, the two test groups behaved very diﬀerently. The
ﬁrst group were very gently activated the parts they wanted
to move, as well as directing its trajectory. In contrast, the
second group (experienced contact improvisers) approached
the manipulation more dynamically, being in complete and
continuous control over the artist’s body. This resulted in
two distinct levels of submissiveness in which to perform.
Because of the blindfolding and cabling, expected inter-
actions were not supposed to result in big movements across
the ﬂoor, so we chose to use a square space of 3x3m, marked
on the ﬂoor with tape, and tracking coordinates were scaled
accordingly. For the Y axis, the Vive covered the whole
range of a human body height.
4.2 Sound
In this project, we focused on the aesthetics of the inter-
action, with less emphasis on the aesthetics of sounds, so
sound engines were kept quite simple. Both sound synthe-
sis and mapping were implemented in the data-ﬂow pro-
gramming environment Pure Data, which received coordi-
nate data over the OSC protocol, as gathered by a small
custom Python program using the OpenVR library. Sound
was projected through four speakers located in the corners
of the square performance space.
The sound synthesis part consists of three smaller sound
engines, each mapped to a range of the ﬂoor area, divided
in concentric squares, based on the ﬂoor coordinates of the
chest sensor (see Fig. 2). This means that only one of the
synthesizers is sounding at any moment, depending on the
position of the instrument-body. Each synthesizer consists
of a small set of oscillators and ﬁlters, utilizing standard syn-
thesis techniques such as subtractive synthesis, frequency
modulation, waveshaping, ring modulation, and feedback
through modulated short-time delays. The three synthesiz-
ers were designed based on a spatial narrative, going from
smooth sounds in the middle (the supposed starting point),
towards gradually more intense, rich and harsh sounds to-
wards the edges, to be explored as the bodily interactions
progressed.
98
Figure 2: A map of the space use for Somacoustics,
and the distribution of sound engines.
The Y value from the chest tracker, i.e., as an indicator of
the degree of being upright, was generally mapped to audio
ﬁlters allowing higher frequencies to pass when body was up
and lower when body was closer to the ground, to somewhat
mimic a sense of increased intensity when standing up.
For the other synthesis parameters (diﬀerent for each syn-
thesizer), the mapping was more complex. The three coor-
dinates of one limb were scaled and subjected to a linear
transform (with initially randomized coeﬃcients), in order
to avoid only mapping in parallel to the axes. Then this
transformed value was mapped to a single synthesis pa-
rameter. In this way, x, y and z values of this particular
tracker all contributed to a parameter change. In addition,
for core synthesis parameters, input from another limb (sim-
ilarly transformed), to achieve increased complexity and ex-
pression. Combined, they form a non-trivial many-to-many
mapping from limb coordinates to synthesis parameters. In
this way people did not recognize immediately what they
were controlling, but instead remained in a constant state
of investigation.
Additionally, having four channels oﬀered the possibility
of surround panning the resulting sounds according to the
ﬂoor coordinates of the chest tracker, so that the sound
followed the position of the body.
4.3 Exhibition
During the development, the interface was informed by
the initial movement research workshops, and continuously
tested by ourselves. The ﬁnal exhibition was meant to serve
as a chance for both evaluation of the interface as well as
obtaining further research material about the response in
relation to the aesthetic goals that were set at the start of
the project. Regarding the evaluation, we choose to devise
the two-day exhibition into two parts, ﬁrst with the artist
as instrument-body, second with visitors oﬀered to try to
be instrument-body themselves.
5. ANALYSIS
In this section we analyze the project in the light of the
theoretical frameworks presented earlier.
While the body is being our vehicle, it also gives us senses,
and a chance to have pleasure for something. Therefore, we
consciously direct our appreciation, driven by our own sen-
sory experiences [12]. We argue that participants during the
experience, employing sensory embodiment, thus through
the bodies, were able to perceive particular appreciation
acquired from the interaction with Somacoustics. For in-
stance, most of the participants who tried to interact were
very keen to explore the possibilities of interaction; there-
fore also fully invested in the use of their body. Not only
that, but their sensory perception enabled them to vary the
approach and manipulation as they were seeing and hear-
ing the reaction of their input. Therefore they were able to
direct their perception and ﬁnd appreciation. Their bodies
as sensory medium fueled the appreciation accordingly. It
enhanced their perspective on the experience.
The participant enters the room, sees the body, ap-
proaches it, interacts with it, reﬂects upon it and leaves.
He/she undergoes a particular process from beginning to
end. The process of experience contains structure within
which the participants do and undergo things through
which the experience become fulﬁlled (according to Dewey
[4]). The participant moves the body, which changes the
audio. It happens because of the application of interactive
technology, and through interaction with technology the
participants do and undergo modes of perceiving, creation,
reﬂection, not in alternation, but simultaneously, related.
This relationship creates new processes and structures that
constitute the experience and convey new outcomes and
meanings. It happens simultaneously, and it is precisely
through this constant balancing between modes of interac-
tion that the experience can achieve speciﬁc meaning that
gives us true experience [8]. We argue that the interaction
with the technology, designed by us, evokes meanings,
emotions and impressions which gives the experiences
the aesthetics and quality of a whole and enhance the
experience of appreciation.
To support these arguments, we will examine a particular
scenario which happened during the exhibition. One of the
participants is a puppeteer by profession. His embodiment
in such a process incorporates his bodily perception which
eventually reﬂects on the mechanics of the puppet, thus his
appreciation towards the experience of moving the puppet
is enhanced, stronger than it would be when it is still. His
body fuels the experience of appreciation. However, the in-
teraction with technology indicates the same quality. When
he started to manipulate the artist’s body, and this action
oﬀered him audio feedback, he suddenly acquired another
perception from his interaction that gave him new sense and
meaning of what he is doing. It reﬂected on his appreciation
towards his action besides the one that his body enabled
him. The technology increased his bodily perception of ac-
tions as well as his environment in a diﬀerent, enhanced way.
His perception gained auditory stimuli. Thus we would ar-
gue that interaction with technology, within the use of body,
allowed him to undergo a stronger aesthetic experience.
Scenarios with more than one participant occurred fre-
quently. At some point, it spontaneously turned into a per-
formance with diﬀerentiated performers and an audience.
Here, through the application of Dalsgaard and Hansen’s
theory [3], we argue that the participant (user) became a
performer because of his performing perception. The inter-
action is socially situated, which is perceived by the par-
ticipant. In other words, the participant’s interaction with
the instrument-body is aﬀected by being aware that the
way he perceives the instrument-body is a performance for
the other people who are only observing, not interacting.
It engages the participant in three roles, through acts of
interaction, perception and performance.
The experience of Somacoustics is located in a physical
environment overlaid by virtual information, thus creating
an augmented reality. In this case, what is augmented is
the soundscape, which can be explored through the interac-
tion. However, we argue that the experience of Somacous-
99
tics can be referred as mixed reality performance because
the performance is combining the real and virtual as well
as live performance and interactivity, according to Benford
and Giannachi’s theory of trajectories [1]. A participant
can experience mixed reality when he undergoes a particu-
lar process of changing his journeys through, perspectives on
and durations in hybrid space while interacting in it, which
establishes a new conﬁguration of trajectories between real
and virtual, simultaneously mapping it. Similarly, the par-
ticipants in Somacoustics through the interaction explored
and mapped the augmented soundscape driven by their cu-
riosity to design new sound expression. They varied their
trajectories through the physical space overlaid by virtual
information in the sonic dimension, derived from the phys-
ical movements of the instrument-body, and their reactions
towards what happened. Once they moved the instrument-
body out of the square, they could easily distinguish that it
is a virtual layer that makes the augmented sound. Because
they were shifting through hybrid space we argue that they
have experienced mixed reality.
5.1 Discussion
Throughout the investigation the chief aim was to explore
the experience of interaction between human and technol-
ogy and its impacts on embodiment and perception. How-
ever there are some aspects that were not addressed above.
The interaction with the technology not only occurs be-
tween instrument-body and participant but also between
instrument and body. The artist merged with technology –
he was a performer and technology was an instrument. His
embodiment allowed the instrument to be expressed.
Therefore we ask: How do we constitute such a combined
identity which is instrument-body that participants interact
with? Does a technology become part of the subject or does
the human become object? Perhaps both, which constitutes
not a subject-object relationship but rather a relation of
conﬁguration. As Donnarumma proposed [5], it is because
constant exchange of information, energies and forces that
perform through each other that we are in relationships of
conﬁguration. Our actions are in correspondence with each
other. This is not only a concern in the world of music
performance, but could be adapted to any situation were
human merges with technology, which is more and more
the case in society.
Additionally, there was a scenario, where the trackers
were distributed to several people. It became an instru-
ment with a particular agency. In this case, the technol-
ogy created a relationship between participants, through
which they communicated and performed. The fact that the
tracker mapping is co-dependent was reﬂected on the partic-
ipants by means of inﬂuencing each others actions and per-
ceptions, and invisible relationships were formed. It showed
interesting performative potential and it could potentially
be applied into the theater sphere as both interactive prop
and perhaps a performance of its own. However, this would
require further research.
There are many ways to further develop the project,
regarding the design of the interface as well as project
re-conceptualization. In regards to interface design, more
precise, and perhaps more complex mappings and sound
engines could enhance the system’s expressiveness. This
would then reﬂect onto both aesthetics of interaction
and its perception, and more expressive outcome of the
exploration of the soundscape.
Somacoustics could also be considered as a suitable inter-
face for visuals. Initial experiments with visualizations of
gestural data in using the vvvv programming environment
showed great potential.
6. CONCLUSIONS
By designing an interactive body instrument and
instrument-body, located in mixed reality space and
experienced by active participation in bodily interaction,
we were able to explore the experience of interaction
between human and technology and investigate the interac-
tion’s transformative eﬀects on subject’s embodiment and
perception. We argue that through creative and artistic
interaction with technology, we humans can change the un-
derstanding of ourselves in the world. Because we perceive
through our bodies and sense what technology oﬀers us,
as utilized within artistic practices, we can experience not
only ordinary things but also things that give much more
profound and sublime emotions and feelings. Technology
can fuel our meaning-making by enhancing our perception
towards the living and nonliving. With the rise of new
technologies, we can experience new forms of embodiment
in our environment and appreciate what we perceive.
The experience of Somacoustics inhabits humble but
creative and artistic ways of how can we see the future of
human-technology coexistence. It fosters the relationships
that we should care about, wonder about, instead of being
bored and annoyed by. Somacoustics interconnects them
and shines a little light on what it might be in the future.
Merging with technology, not in the way that we cannot
live without but in the way we can enjoy it.
7. REFERENCES
[1] S. Benford and G. Giannachi. Performing mixed
reality. The MIT Press, 2011.
[2] P. Dahlstedt. Dynamic mapping strategies for
expressive synthesis performance and improvisation.
In LNCS 5493, pages 227–242, 2009.
[3] P. Dalsgaard and L. K. Hansen. Performing
perception - staging aesthetics of interaction. ACM
Transactions on Computer-Human Interaction
(TOCHI), 15(3):13, 2008.
[4] J. Dewey. Art as experience. Penguin, 2005.
[5] M. Donnarumma. Conﬁguring corporeality:
Performing bodies, vibrations and new musical
instruments. PhD thesis, Goldsmiths, University of
London, 2016.
[6] A. Hunt and M. M. Wanderley. Mapping performer
parameters to synthesis engines. Organised Sound,
7(2):97–108, 2002.
[7] K. Kelly. What technology wants. Penguin, 2010.
[8] J. McCarthy and P. Wright. Technology as
Experience. MIT Press, 2007.
[9] M. Merleau-Ponty. Phenomenology of Perception.
Psychology Press, 1962.
[10] R. J. Pelias. Performative Inquiry. Handbook of the
Arts in Qualitative Research: Perspectives,
Methodologies, Examples, and Issues. SAGE, 2008.
[11] C. Shilling. The body in culture, technology and
society. Sage, 2004.
[12] R. Shusterman. Somaesthetics: A disciplinary
proposal. The journal of aesthetics and art criticism ,
57(3):299–313, 1999.
[13] K. Vogt, D. Pirr´ o, I. Kobenz, R. H¨oldrich, and
G. Eckel. Physiosonic-movement soniﬁcation as
auditory feedback. In Proceedings of the 15th
International Conference on Auditory Display,
Copenhagen, Denmark. Georgia Institute of
Technology, 2009.
100