A Customizable Sensate Surface for Music Control 
 
 
Nan-Wei Gong 
MIT Media Lab 
75 Amherst Street 
Cambridge MA 02142, USA 
nanwei@media.mit.edu 
 
Nan Zhao 
MIT Media Lab 
75 Amherst Street 
Cambridge MA 02142, USA 
nanzhao@mit.edu 
 
Joseph A. Paradiso 
MIT Media Lab 
75 Amherst Street 
Cambridge MA 02142, USA 
joep@media.mit.edu 
 
 
ABSTRACT 
This paper describes a novel music control sensate surface, 
which enables integration between any musical instruments 
with a v ersatile, customizable, and  essentially cost-effective 
user interface. This sensate surface is based on c onductive 
inkjet printing technology which allows capacitive sensor 
electrodes and connections between electronics components to 
be printed onto a large roll of flexible substrate that is 
unrestricted in length. The high dynamic range capacitive 
sensing electrodes can not only infer touch, but near -range, 
non-contact gestural nuance in a music performance.  With this 
sensate surface, users can “cut” out their desir ed shapes, 
“paste” the number of inputs , and customize their controller 
interface, which can then send signals wirelessly to effects or 
software synthesizers. We seek to find a solution for integrating 
the form factor of traditional music controllers seamlessly on 
top of one’s music instrument and meanwhile adding 
expressiveness to the music performance by sensing and 
incorporating movements and gestures to manipulate the 
musical output.  We present an example of implementation on 
an electric ukulele and provide several design examples to 
demonstrate the versatile capabilities of this system.    
 
Keywords 
Sensate surface, music controller skin, customizable controller 
surface, flexible electronics  
1. INTRODUCTION 
For years, researchers have been working on exploiting 
standard input devices to develop new electronic music 
controllers with intuitive interfaces and ways to enable people 
to play synthesizers [1-2]. Controlling sound with more 
precision but less complexity has long held the interests of 
musicians especially in live performances. A common problem 
among many music controllers is the lack of interface that is 
specifically designed for integrating and simplifying different 
interfaces, especially with traditional instruments. Imagine if 
you have an expensive handcrafted violin, you would never 
want to change the shape nor add knobs and switches on it.  
 One of the major challenges for an understaffed live 
performance is to multitask on s tage between controlling 
switches, knobs, effects, pedals and, at  the same time, focus on 
musical expression.  
 T his project seeks to provide a customizable wireless music 
controller surface that can be easily adapted by musicians and 
seamlessly integrated with any existing music instrument.  
 Our goal is to create a skin -like sensate surface which allows 
users to bui ld their desir ed controller without changing the 
geometry of their instruments. We believe that this approach is 
an efficient and cost-effective method to create a user interface  
for music since our platform is highly adaptive and can be 
custom-designed by users.   
 To achieve this goal, we explore the use of a r ecently 
available technology, conductive inkjet printing, as an enabler 
for building low -cost sensate surfaces. To illustrate this, we 
used an electric ukulele as example and show ed circuit 
implementation and pattern design  tailored for specific musical 
gestures. We printed different designs  and explore d how the 
addition of integrated instrument effect controller could benefit 
a live performance and how it is possible to have an electronic 
surface that can add something to the aesthetic to a m usical 
instrument. Besides sending basic control signals, we also 
explore the possibilities of embedding sensors in areas where 
extended hand gestures during a performance can be detected 
and use that information to contribute expressiveness to the 
musical outputs.   
2. MOTIVATION AND RELATED WORK  
Performing live on s tage and simultaneously using various  
controllers has never been an easy task. Although the days of 
manipulation of knobs and switches from rack of synthesizers 
are now replaced by touchscreens on tablets and laptops, it is 
still not easy to switch back and forth between a traditional 
instrument and a s oftware interface. It can be difficult to 
modify an existing instrument since the shape design is 
commonly optimized for playing.  Our motivation is to create a 
sensate “skin” for extra control inputs which allow musicians to 
implement their desired sensing components on the surface of 
their instruments and replace extra movements with additional 
control inputs (figure 1). 
 Previous work related to adding extra control through 
embedding sensing components into musical instruments  for 
alternative control such as the Starr Labs “ZTAR” [3], a guitar-
like digital instrument with a touch sensitive fingerboard, string 
triggers, hotkeys and a joystick, Stepp’s DG-1 analog guitar 
synthesizer [4], Donald Buchla’s Thunder percussion controller, 
which replaced keyboards with flat pressure and position-
sensitive capacitive touch plates [5]. These examples 
demonstrate the potential of extending the possibilities in music 
expression through adding additional tactile sensing 
components and create new ways to interact with digital control. 
However, there is no existing option  for an average user to 
implement sensing capabilities besides purchasing control 
surfaces like a Korg's Kaossilator as a building block.  
 We would like to  cr eate a system that allows users to modify 
their instrument in an elegant way without changing the 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
n
ot made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers o r to redistribute to lists, 
requires prior specific permission and/or a fee. 
NIME’12, M ay 21 -23, 2012, University of Michigan, Ann Arbor. 
Co
pyright remains with the author(s). 
 
original shape and design of the ir instruments. Inspired by the 
Chameleon Guitar [6], a hybrid acoustic and digital instrument 
with a replaceable acoustic resonator which preserves the 
traditional acoustic values while capable of digital manipulation 
abilities, we attempt to create a digital interface that preserves 
the physical shape and properties of an instrument.   
 In this paper, we use an electric ukulele (Eleuke SC-100) as 
an example to demonstrate the possibility of adding more 
controlling power to a small surface and the potential impact on 
future live performances. Figure 1  shows one  of the 
implementations of our design.  
 
 
Figure 1. Implementation of our system1 with additional 
control inputs to send the most commonly used commands 
and reduce movement path during a live performance.  
 
Previous works on bui lding pressure sensitive surface s with 
printed FSRs and capacitive sensing for generic surface for 
musical expression include Koehly et al. [7], Jones et al. [8]  
and Freed [14] . These novel sensing surfaces were designed as 
a new instrument for playing music.  Our design, however, is 
not purposed for serving as a standalone musical instrument.  
Our surface is built specifically for increasing the 
expressiveness of an existing instrument. 
 
Our motivation and major contribution for the field of musi c 
controllers and interfaces can be summarized as follows:  
 
1. Create a low -cost and customizable capacitive sensing based 
hardware toolkit for music user interface development.  
2. Dynamic range detection from capacitive sensing can infer 
not only touch, but near-range gestural nuance. 
3. Provide working examples of the combination graphic design 
and circuit design which enables a physical manipulation 
of software interfaces. 
3. SYSTEM OVERVIEW 
We built a sensate surface controller prototype and provided 
three design examples on an electric ukulele. The surface 
detects gestures and touch  and transmits its intensity and 
location wirelessly via Bluetooth to a software host on a  
computer, which then converts the signal into MIDI messages.  
These MIDI messages were then mapped, based on the location 
of the gesture, to control signals such as tap tempo , pitch, 
distortion or simpler commands like volume change or 
record/stop.     
 
3.1 Design and Functionality  
Our design principal is to embed extra control input ability in 
spaces that are normally too small or not suitable for 
implementing extra components such as knobs and 
sliders. 1Figure 2(a) is an illustration of different potential areas 
for adding control inputs on our example instrument. Based on 
the gesture of playing this instrument, the three zones are 
mapped to different functionalities in our design. Figure 2(b) 
shows how extra control inputs could be implemented in a 
traditional design and we demonstrate the same functionality 
could be achieved with an aesthetic or deco rative sensate 
surface input in figure 2(c). 
 
 
 
Figure 2. (a) Potential spaces (blue zones) for extra control 
inputs. (b) Illustration of traditional implementation of 
additional control inputs (c) Control surface design pattern 
with the same effect as (b) without physically change the 
original instrument. 
 
3.2 Hardware Design  
There are two parts in the hardware design. First, a f lexible 
sensate surface printed with sensor patterns and limited 
components for capacitive sensing. And second, a PCB for data 
processing and wireless communication.  
 Our prototype sensate surface is based on pr inting copper 
patterns onto a thin plastic substrate using conductive inkjet 
printing technology. With this technology, it is possible for us 
to print complex conductive patterns for electromagnetic field 
sensing [9-10]. The total cost for our design per ukulele is less 
than 10 US dollars (~$7 for the printing and ~$3 for 
components). The sensing method is capacitive sensing, which 
relies on Loading Mode [ 11-12] – measuring the  capacitance 
change between a h uman hand and a m etal electrode. By 
measuring the time between several charge and  discharge 
cycles, the distance between a user’s finger from  the surface 
can be measured. While it is possible to attach surface- mount 
components directly to the surface with low temperature solder 
or conductive adhesive, this process takes more time and the 
mechanical connection is not as strong as regular solder joints. 
Therefore, we minimized the component s required for the 
flexible surface and only placed the critical parts, which are the 
capacitive sensing circuit and connections for communication 
with the microcontroller. 
  Figure 3 (a) shows the printout of our example designs and 
figure 3(b) shows the surface mount component attached to the  
flexible surface. We implemented CY8C20x CapSense 
capacitive sensing IC from Cypress semiconductor, which is 
capable of supporting up to 28 CapSense I/O touch channels 
with two wire communication protocol and 16 bits of 
resolution. The device address of CY8C20 can be changed 
manually, which allows multiple CapSense slave devices on the 
same bus. The device uses a seven bit addressing protocol 
                                                                 
1  Pattern design adapted from the artwork , Soulgazer, of 
Evgeny Kiselev  
where the last bit in a byte indicates read or write. This means 
there can be 27 addresses on the same two wire bus line – a total 
of 7168 (28 times 256) inputs, if designed properly.   
 Also, this device supports  two different filtering methods to 
reduce noise from different sources  - the DTS filter to discard 
samples acquired while data communication takes place, and  
the averaging filter to  improve CapSense system noise 
immunity. 
 
Figure 3. (a) Printout of our example designs. (b) Capacitive 
sensing buttons (indicated by orange arrows) and 
associated circuit with surface mount components (CY8C20) 
attached to the flexible surface. 
 
 For the PCB part, we used an off -the-shelf AT mega 328P 
(http://www.atmel.com/) development board with 8 MHz 
external oscillator and Bluetooth radio chip (RN -42) from 
Roving Networks  ( http://www.rovingnetworks.com/). We 
wanted to design a modular and highly adaptive system that 
allows the sensate surface customization to be versatile yet 
intuitive for novices with minimum wiring. T herefore, we 
selected sensor  ICs that support  two-wire communication 
where only 4 c onnections were needed between the PCB and 
the flexible surface – power, ground, data (SDA) and clock 
(SCK). Once the capacitive sensors are triggered by touch or 
movements above the surface, data is t ransmitted to the host 
microcontroller, then processed locally and wirelessly 
transmitted to software which converts sensor information into 
MIDI signals according to the mapping design. 
 In our study, we used a MIDI library from Processing.org and 
sent MIDI commands to Propellerhead Reason 6.0, a d igital 
music synthesizer platform, to generate sound and create a 
mapping to trigger effects and change the pitch and modulation 
of our instrumental input.  
 
4. MAPPING STRATEGIES  
The mapping strategies depend high ly on t he application and 
physical construction of specific instrument and the location 
where sensor units are placed. Here, we discuss mapping 
strategies both from the physical and signal point of view. 
Again, we used a ukulele as example to explain the r elationship 
of sensor placement, hand gestures, and output mapping. 
4.1 Physical Mapping 
Our mapping strategies are designed for demoing the variety of 
sound effects that can be achieved via an on-body control 
surfaces for a stringed instrument such as a guitar or an ukulele. 
The pattern construction was built around three zones that have 
different impacts on gestures, such as finger picking or 
strumming. These three areas are trigger area, movement area 
and command area (figure 4).      
 The trigger area inclu des the most commonly covered right 
hand movement - ranging from strumming patterns by rhythm 
guitarist to fingerpicking from playing bluegrass -style banjo 
music (where clips are wore on one ’s thumb, middle and index 
fingers and one or two fingers rest on the instrument). In this 
area, the sensor inputs are mapped to pitch and modulation 
control so the player can either change the sound  or add 
modulation while plucking the strings. T he second area is the 
trigger area. During a finger style guitar performance, players 
pluck the strings with their fingertips, add fingernails and rest 
their thumbs on the side. We use this area as the trigger area, 
where precise controls are made to trigger loops, instruments or 
pre-composed tracks. The last area is the command area, which 
is less likely to be triggered accidentally during a performance. 
In this area, we place inputs that have critical functions such as 
“play”, “record”, “stop”. 
 In the mapping design, we also considered the possibility of 
detecting extended hand  gestures during a performance and 
how to use that information to add expressiveness to the 
musical outputs. One of the advantages of capacitive sensing 
over pressure sensing is that we can detect proximity. Therefore, 
it is possible to  map gestures, such as strumming,  to beat  
generation.   
 In our first prototype, we did not design patterns specifically 
for sliders. Instead, we post -processed the data on the software 
end and were able to map a continuous motion trajectory from 
the button inputs to a slider motion. Besides sliders and buttons, 
inputs for continuous velocity control are also very important 
for musical expression. Therefore, a layer of silicon e on top of 
copper pads was included in our design as a way to generate 
continuous velocity control. The distance between one’s finger 
and the copper pad (the distance between two conductors) is 
controlled by force applied on the silicone.  
 T his sensate surface can be applied to essentially any 
instrument, and our mappings are designed only for demoing 
one of the many possibilities.     
 
Figure 4. Potential mapping on a plucked string instrument 
based on gestures such as finger tapping, picking and 
strumming. 
5. CUSTOMIZATION 
Since the process of printing flexible circuit is similar to using a 
printer, it is possible to draw out the circuit the same way as 
drawing with any graphic editing tool that allows you to export 
a bitmap file. We invited three users to design their control 
surface with the same process of creating an artwork with 
Adobe illustrator. We  provided the design guidelines and 
several circuit layout  images required to process capacitive 
sensing signals, control LEDs for indications and to connect to 
the PCB for data transmission. Our hope was to not only enable 
people to implement a sensor circuit on their instrument, but 
also design an artwork that is aesthetically appealing. Figure 5 
shows the three different designs. Figure 5(a) is a design with 
whole body coverage and has sensor components covering all 
three interaction zones. Figure 5(b) a nd (c) are designs for 
partial coverage - (b) includes only the trigger and the 
movement area while (c) covers the command and trigger area. 
Two of the designs, (a) and (c), placed the circuit on top of the 
surface while (b) hid all the wiring and components in the back. 
The advantage of having traces close the pads reduce the risk of 
broken connection due to folding, especially when some of the 
stress points were designed very close to surface mount 
components which can easily cause connection issues. The 
disadvantage was having less space for touch inputs.    
 T he combination of graphic design and circuit design creates 
a new art form itself that allows each sensate “skin” controller 
to represent the music genre this controller is mapped to. We 
envision a musician with a wardrobe of different surface 
controllers that are interchangeable similar to switching 
between effects or synthesizer racks. 
 
Figure 5. Three example designs for different coverage and 
input locations.  
 We realize that the complexity of  drawing, mapping and 
routing can be difficult and time -consuming. Therefore, our 
future work is to develop a software toolbox for optimizing the 
sensor design (such as error check ing for reducing signal to 
noise ratio or short circuit) which allows any musician to draw 
out the shape and customize their desired patterns for their own 
control surfaces. The design should be able to be integrated 
with anything in one’s environment or on top of any object with 
minimized signal to noise ratio.  
 
6. CONCLUSIONS AND FUTURE WORK  
In this paper, we presented a novel music control sensate 
surface based on conductive inkjet printing technology which 
enables customizable integration between any musical 
instrument with a versatile and cost-effective user interface. We 
provided design examples and corresponding physical mapping 
strategies for different finger techniques for plucked string 
instruments.   Our main interest lies in developing a sy stem 
for producing  new forms of performances and instruments 
through empowering mus icians with the ability to improve, 
modify, and extend the capabilities of traditional instruments. 
 Fu ture work includes creating more sophisticated toolkits 
with multiple sensing modalities and better capacitive sensing 
capabilities (such as sensing for longer range). We also plan on 
developing a software toolbox which will allow users to drag 
and drop sensor inputs and create the link to MIDI signals for 
software mapping and synthesizer manipulation.  In addition to 
music applications, we are interested in applying this 
technology to other fields as well. Potential areas include 
Natural User Interface design, interactive media and smart 
architecture.  
7. ACKNOWLEDGMENTS 
The authors wish to thank our colleagues of Responsive 
Environment Group at the MIT Media Lab. Special thanks to 
Amit Zoran and Mark Feldmeier  for their design suggestions  
and Valentin Heun who helped with the sensor construction. 
We would also like to thank Dr. Nick Gillian for his advice on 
mapping algorithm.    
 
8. REFERENCES 
[1] Wright, M, D. Wessel, and A. Freed “New Musical 
Control Structures from Standard Gestural Controllers” In 
Proc. of the International Computer MusicConference, pp. 
387-390. Thessaloniki, Greece: ICMA, 1997. 
[2] Gong, N.-W., Laibowitz M., Paradiso J.A. MusicGrip: A 
Writing Instrument for Music Control, in Proceedings of 
NIME 09, 74-77, 2009 
[3] Rodriguez, B. J., Starr, H. The "Ztar" MIDI Controller. 
FORML conference, 1998 
[4] Curves, D. The art of the guitar, ISBN: 0878464786, 
MFA Publications, 2000 
[5] Paradiso, J. A. Electronic music interfaces: new ways 
toplay. IEEE Spectrum Magazine, 34(12), 18-30, 1997 
[6] Zoran, A., and Paradiso, J.A. The chameleon guitar—
guitar with a replaceable resonator. Journal of NewMusic 
Research, 40, 59–74, 2011 
[7] R. Koehly, D. Curtil, and M.M. Wanderley. Paper FSRs 
and latex/fabric traction sensors: Methods for the 
development of home-made touch sensors. In Proc. of the 
2006 Conf. on New Interfaces for Musical Expression 
(NIME-06), pages230–233, Paris, 2006. 
[8] Jones, R., et al. 2009. "A Force-Sensitive Surface for 
Intimate Control." In Proceedings of the International 
Conference on New Interfaces for Musical Expression 
(NIME). New York: Association for Computing 
Machinery, pp. 236-241 
[9] Gong, N.-W., Hodges, S. and Paradiso, J. A. Leveraging 
conductive inkjet technology to build a scalable and 
versatile surface for ubiquitous sensing. In Proceedings of 
the 13th international conference on Ubiquitous 
computing (UbiComp '11). ACM, New York, NY, USA, 
45-54. 
[10] conductiveinkjet.com 
[11] Wimmer, R. Capacitive Sensors for Whole Body 
Interaction In: David England (Ed.): Whole Body 
Interaction. Springer, Berlin, Germany, 2011, 121-133. 
[12] L. Baxter, Capacitive Sensors: Design and Applications. 
Instituteof Electrical & Electronics Engineers (IEEE), 
1997. 
[13] Murray-Smith, R. Williamson, J. , Hughes, S. and Quaade, 
T. Stane: synthesized surfaces for tactile input, Proceeding 
of the twenty-sixth annual SIGCHI conference on Human 
factors in computing systems, April 05-10, 2008, Florence, 
Italy 
[14] F reed, A. Application of new Fiber and Malleable 
Materials for Agile Development of Augmented 
Instruments and Controllers. In Proceedings of the 2008 
Conference on New Interfaces for Musical Expression, 
Genova, Italy 2008