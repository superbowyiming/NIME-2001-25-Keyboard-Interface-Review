Exploring the Effect of Interface Constraints on Live
Collaborative Music Improvisation
Hazar Emre Tez
Media and Arts Technology CDT
School of EECS
Queen Mary University of London
Mile End, London
h.e.tez@qmul.ac.uk
Nick Bryan-Kinns
Media and Arts Technology CDT
School of EECS
Queen Mary University of London
Mile End, London
n.bryan-kinns@qmul.ac.uk
ABSTRACT
This research investigates how applying interaction con-
straints to digital music instruments (DMIs) aﬀects the way
that experienced music performers collaborate and ﬁnd cre-
ative ways to make live improvised music on stage. The
constraints are applied in two forms: i) Physically imple-
mented on the instruments themselves, and ii) hidden rules
that are deﬁned on a network between the instruments and
triggered depending on the musical actions of the perform-
ers. Six experienced musicians were recruited for a user
study which involved rehearsal and performance. Perform-
ers were given deliberately constrained instruments contain-
ing a touch sensor, speaker, battery and an embedded com-
puter. Results of the study show that whilst constraints can
lead to more structured improvisation, the resultant music
may not ﬁt with performers’ true intentions. It was also
found that when external musical material is introduced
to guide the performers into a collective convergence, it is
likely to be ignored because it was perceived by performers
as being out of context.
Author Keywords
DMI design, interaction, live music collaboration, constraints,
performance studies
ACM Classiﬁcation
H.5.5 [Information Interfaces and Presentation] Sound and
Music Computing, H.5.2 [Information Interfaces and Pre-
sentation] User Interfaces—Input devices and strategies.
1. INTRODUCTION
Group music making is often a challenging activity in which
the musicians are bounded with a set of limitations and they
need to work together with others [6]. The limitations orig-
inate from the instruments themselves as well as from the
environment, musical genre and audience expectation. As
musicians are subject to many constraints during live music
performance, they usually enjoy being in a creative box that
challenges them, so that they collaborate and tackle these
challenges together.
In recent years, both qualitative and qualitative methods
from HCI have been applied for studying DMIs, but it has
been stated that such methods are limited [20]. The experi-
mental approaches which involve case studies help perform-
ers develop and explore creative practices [20]. Rather than
evaluating an existing DMI, this study is about speciﬁcally
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’17,May 15-19, 2017, Aalborg University Copenhagen, Denmark.
designing a purpose-built instrument to support research.
Like the case studies of Marquez-Borbon et al., a DMI is
designed to explore the phenomena underlying digital mu-
sic interactions [20].
Although constraints and aﬀordances have been a major
topic in HCI [23] and constraints have been investigated in
recent years [15, 28], the inﬂuence of constraints in collab-
orative music making is yet to be explored. This paper in-
vestigates how experienced musicians collaboratively make
music together given a speciﬁc set of constraints. To ex-
plore this subject, six experienced music performers were
recruited to take part in a study of how they improvise
together with DMIs with diﬀerent interaction constraints.
This study was based upon the ﬁndings of the studies of
Zappi and McPherson [28] and Gurevich et al. [15] with
the following aims in mind:
• To identify the relationship between collaboration and
design limitations.
• To explore the appropriate ways of applying design con-
straints for collaborative creation.
• To study the inﬂuence of transparent and hidden con-
straints.
2. BACKGROUND
Nijs et al. suggests that symbiosis between musician and
musical instrument, in time, leads to the integration of the
two, in turn leading to the transparency of the musical in-
strument which becomes akin to a body part and disappears
from consciousness [22]. Referring to the core concepts from
ecological philosophy, activity theory [2] and ﬂow/presence
research [3], which state that this musician-instrument con-
nection determines the interaction between the musician
and the live musical environment, arranges the directions
in structure of music performance and is strongly related
to the musician’s subjective experience during performance
[26]. However, these components are only available through
dealing with the challenges of both aﬀordances and con-
straints [23].
Boden describes constraints as ’a territory of structural
possibilities which can be explored and perhaps transformed
to give another one’ and claims that they are one of the
fundamental sources of creativity [5]. In music making,
they can be both limiting and liberating [9]. They bring
boundaries that cannot be crossed, but also create tensions
between conﬂicting demands, which can lead the creator to
new ideas or in new directions and so change the creative
outcome to a great extent. Norman proposes a model of
constraints [23]: Physical, logical and cultural constraints.
Physical constraints determine what is physically possible
[23, 19]. From a music perspective, Pearce and Wiggins cat-
egorizes constraints as stylistic constraints relating to genre
342
or style, internal constraints that deﬁne the logical possibil-
ities of the progressions of a piece and external constraints
imposed by the physicality of the instrument and performa-
bility [24, 19].
2.1 DMI Design
An important aspect of DMI design is mapping (correspon-
dence between control parameters and sonic output param-
eters [17]) and its dimensionality. As Zappi and McPherson
state [28], it is a common assumption that increasing the
number of dimensions to control an instrument leads to a
wider range of expression from the musician’s side. They
studied the eﬀect of dimensionality on performers’ creativity
with very simple cube-instruments and found that adding
a dimension of control reduced the exploration of hidden
aﬀordances of the instrument [28].
In the study of Gurevich et al. [15], nine performers were
given a one-button instrument, which had a simple two-state
design (tone or no tone). Despite its simplicity, perform-
ers developed a wide variety of musical interaction styles.
Although an expected use for the instrument was creat-
ing rhythmic patterns, many performers came up with un-
conventional techniques. Several participants reported that
they have not mastered it despite the simplicity. The au-
thors argue that ’ the instrument was so constrained helped
to make space for this personal element to emerge ’ [15].
This paper focuses on physical/external constraints of
DMIs and internal constraints perceived by the user to be
embedded into the system. In HCI, aﬀordance is the per-
ceived possibility that a system oﬀers a certain action [23].
It is a feature that is to be acted upon. On the other
hand, constraints are not immediately visible and perceiv-
able. They have to be engaged with, experienced and un-
derstood [19]. As Magnusson argues, the musician is con-
cerned with the aﬀordances of the interface in learning an
instrument and engaging with its expressive potential at
ﬁrst [19]. However, they spend most time appropriating
the constraints of the instrument as it is these that deﬁne
the primary characteristics of what is possible.
2.2 Multi-user Interaction and Collaboration
Making music is one of the key forms of human collabo-
ration. Musicians share sonic and visual information by
diﬀerent means, such as sounds from their instruments and
themselves [12], their bodies [16] and -if available- recorded
audio/video [21].
Group improvisation in music is a great example of col-
laboration and it requires shared working knowledge [26].In
group improvisation, interaction between co-located per-
formers happens immediately during the performance and
each performer contributes something original to the evolv-
ing emergent in each act [26]. The process of group cre-
ativity is coincident with the moment of reception and in-
terpretation by other participants. In terms of structure,
improvisation is always unpredictable for both performers
and the audience. This introduces a risk: As the form gets
more free, the variability in quality increases.
In the last decades, collaborative music making has shaped
and evolved around the technology. In the early years, net-
work music was the focus [13]. For example Gurevich’s
JamSpace is an interactive music environment to support
real-time jamming over a network [14]. As the NIME evolved,
much more research was carried out [27, 6, 18]. In particu-
lar, Blaine and Fels analyze a number of collaborative mu-
sic systems in terms of constraint over a variety of design
elements of the interfaces [4]. More recently The Bucket
System [10], The Smartphone Ensemble [1] and Moodiﬁer-
Live [11] have been introduced in NIME. Using the Daisy-
phone, [6] Hamilton and Bryan-Kinns found that awareness
of identity in group music making increases mutual engage-
ment [7]. In this regard, mutual awareness and engagement
-when people creatively spark together- [7] are important for
understanding music collaboration with and through DMIs.
2.3 Experimental Contexts and Performance
Music performance is an interdependent art form [27]. Real-
time acts of the performers are constantly aﬀected by what
they hear from the others. This interdependency has unique
social consequences such as the formation of leaders and
followers or alterations in individual players’ dynamics and
timing in correlation to group synchronization [25].
Marquez-Borbon et al. [20] states that regarding perfor-
mance, experimental methodologies have been increasing
in NIME. However, very few studies involve systems that
are speciﬁcally tailored to examine group synchronization
behaviours in performance. Instead, they either carry pure
artistic purposes or rely on an existing DMI. They discarded
usage scenarios in experimental contexts and instead, enable
users to develop their own styles according to their identi-
ties (i.e. musical backgrounds). This was only possible with
a minimalistic design, which is also a design approach that
this research adopts [20].
3. STUDY DESIGN
This study aims to explore: i) how introducing hidden con-
straints aﬀects collaborative music making ii) what results
from the introduction of external musical material (beats)
is introduced. To do this a constrained DMI was developed
whose interaction could be manipulated by the researcher.
3.1 Instrument Design
A simple, physically constrained, cube-shaped DMI, C-Box
(Connected Box), was designed to be used in the study. It is
based on the cube-instrument study of Zappi and McPher-
son [28]. C-Box consists of 15cm laser-cut wooden panels,
embedded electronics, a battery, full range speaker facing
outside and a touch sensor on the top. The idea behind
C-Box is straightforward: touching, tapping or pressing on
the touch strip on the box triggers and manipulates sound
from a simple synthesizer.
In addition to the physical constraints, hidden constraints
were build in to C-Box: i) solo rule on the network forces
one member to play solo for 10 seconds if they have been
playing louder relative to the others. This was implemented
to see if the players would develop a certain composition
structure, turn-taking behavior among themselves or a com-
petitive attitude towards each other; ii) beat rule in which
8 beats are played from the average tempo of the players
is used to explore the reaction of the performers to conver-
gence of tempo.
3.2 Hardware: Bela
Inside the plywood box, there is a Bela 1 cape -an ultra-
low latency embedded system for real-time audio process-
ing with sensor connectivity-, BeagleBone Black2 with 8GB
micro-SD card attached, a small breadboard, connectors, a
5V rechargeable battery for Bela, and a USB wireless net-
work adapter. Bela was chosen due to its low latency, as
the networking were expected to increase response time.
There is a TouchKeys3 sensor on top of the box and two
FSRs underneath the TouchKeys sensor, so that the system
1http://bela.io/
2http://beagleboard.org/black
3http://touchkeys.co.uk/
343
Figure 1: The C-Box instrument used in the study.
can continuously receive the location of a user’s touches, size
that a ﬁnger occupies on the sensor, and the applied force.
3.3 Software, Mapping and Hidden Constraints
C-Box runs optimised C code on Bela. All the interac-
tion information received by the sensors is used for con-
trolling the synthesizer. As Hunt et. al suggest, the map-
ping between musicians’ input and the musical output are
cross-coupled [17]. Pitch range of 3 octaves is mapped to y-
position of the ﬁnger on the TouchKeys sensor. If the player
applies a lot of force on the sensor, the pitch can be detuned.
This relation exists in many traditional instruments such as
pulling/pushing the neck of an electric guitar.
The timbre is cross-controlled using ﬁlters and distortion
depending on the force applied, ﬁnger size, and current
pitch. The loudness is mapped to both the force applied
to the sensor and the ﬁnger size. The output levels are
calibrated.
Only one ﬁnger is registered for sound making. If mul-
tiple ﬁngers are placed on the sensor, only the last ﬁnger’s
position is accepted, but the size is still the combined area
of all placed ﬁngers up to the sensor’s limit. Therefore, us-
ing multiple ﬁngers only increases the size parameter which
can add the distortion as intended.
3.3.1 Heavy API, Pure Data and Networking
The Heavy Audio Tools from Enzien Audio4 use Pure Data5
(PD) as a front-end to generate optimised C code. Using
Heavy API was beneﬁcial, as it is computationally more
eﬃcient than using libpd 6. Heavy API analyses the con-
nections between objects in a PD patch and produces high-
performance C code that suits well to use on the BeagleBone
Black. The downside of this way is that you are limited to
using objects supported by Heavy.
The Heavy API was used to code the network communi-
cation among C-Boxes. Message objects in PD were used to
pack the information needed to be sent or received over the
network using a dedicated wi-ﬁ router. First, a communi-
cation protocol was deﬁned in PD in the form of messages.
Then, one master-all slave (deﬁning the master as a slave
as well) relationship is deﬁned, so that the calculations are
only performed in one of the C-Boxes, commands are sent
to the router, and distributed over the network. All mes-
sages are stored and only executed, when a change made by
the master. All boxes have individual ID numbers which
deﬁne their role, so that there was no need to write diﬀer-
ent patches for each box. The messages that are sent by the
slaves are ignored, unless the receiver is the master. This
4http://enzienaudio.com/
5http://puredata.info/
6http://puredata.info/downloads/libpd
master/slave relationship and networking avoided having to
compile patches one by one which saved a lot of time. The
communication frequency is set to 50ms.
3.3.2 Network Rules
The hidden constraints are deﬁned for multi-user interac-
tion on the network. The two rules are: i) beat rule and ii)
solo rule . Beat rule is implemented for understanding the
tendencies of the group, when some external musical mate-
rial is introduced. A series of beats in a certain tempo is
played to see if the group would use these beats to converge
to a collaborative behaviour. Solo rule is implemented to
understand the consequences, when a player is allowed to
play solo (forced by the system). These rules are also inte-
grated in the PD patches and they are only triggered when
multiple people are using C-Boxes.
1. Beat rule: This rule is for playing 8 beats from one
of the boxes with the average tempo of the three boxes.
The tempo value is calculated as beats per minute, however
there is no complex beat detection algorithm because as the
Heavy API does not support external libraries. Therefore,
a much simpler way of tempo detection was chosen - the
beats are generated by simple ﬁltering of a sine wave. Here
is how this network rule works step by step:
• Whilst playing, the number of total touches are calcu-
lated over 40 seconds a for each instrument and simply
converted to beats per minute.
• These values are sent over the network at the end of this
40 seconds, then immediately the master box calculates
the average and commands the box that has the closest
BPM value to this average BPM value to play 8-beats
with that average tempo.
• After playing 8-beats, another 40s window opens and this
continues until the end of the performance.
2. Solo rule: The solo rule is implemented for allow-
ing a user to play solo by muting all others for 10 seconds
based on the average loudness value produced by a user for
a duration, compared to the average loudness produced by
all of the users for that duration. Here is how it works:
• The algorithm calculates the average loudness value in
dB(RMS) of an instrument’s audio output over a 10-
second window.
• If that value is at least 10 percent higher than the average
10-second value of all the C-Boxes, then that instrument
will allow it’s user to play solo for 10 seconds: basically
the other instruments are muted.
• The calculation window is toggled on and oﬀ for each 10
seconds, so that it does not clash with the Beat Rule.
• Also, there is a threshold to trigger this rule: If the 10-
second average value is below 60 dB(RMS), then the rule
is not triggered, even if that box is at least 10 percent
louder than the average. Therefore, the solo rules does
not kick in, if the performers choose to stay silent.
4. USER STUDY
Six instruments were built. The software inside the Bela
capes were coded to write all interaction data and the audio
outputs to binary ﬁles.
4.1 Participants
Six experienced music performers took part in this study.
The participants are chosen to be active performers who
has on stage experience. The proﬁles of the participants are
such: (1) 25, M, bass guitar, indie/electronic, formal educa-
tion, 13 years of performance experience. (2) 24, F, piano,
344
classical, self-taught, 16 years of performance experience.
(3) 28, M, guitar, alt rock/no wave, self-taught, 10 years of
performance experience. (4) 43, M, laptop, noisefunk, for-
mal education, 36 years of performance experience. (5) 28,
M, computer, electronic/house, formal education, 5 years
of performance experience. (6) 26, M, drums/violin, rock,
self-taught, 8 years of performance experience. Participants
no.2 and 4 have also performed professionally. Participants
were divided into two groups of three based on their back-
grounds, experience and musical styles to do rehearsals and
perform together.
4.2 Practice and Rehearsals
Each participant was met by the researcher for a brief expla-
nation of the study, a short demo and introduction to C-Box
and to complete the initial questionnaire for musical back-
ground information.Following this, participants were asked
to practice with the C-Box everyday, record a video of them-
selves practicing and ﬁll in a practice diary after each ses-
sion. To fulﬁll the requirements of the practice, they were
asked to ﬁnish at least six practice sessions on diﬀerent days.
The practice diaries were intendend to capture and track
their personal approach, experience and level of expertise.
When the practice period ended, the researcher met with
each group separately. Each group was asked to undertake
two group rehearsal sessions, each including one rehearsal
with network rules (case-a) and one without them (case-b),
in order to capture the inﬂuence of these hidden constraints.
Then, a short group discussion took place in which the net-
work rules and diﬀerences between cases were explained by
the researcher. Finally, the performers were asked to re-
hearse once more with and without network rules. The or-
der of the cases were switched between the groups to elim-
inate any possible order bias. The participants were not
directed to achieve, convey or express anything during the
rehearsal or performance.
4.3 Performance with Audience
A performance night was arranged for both groups to per-
form with the prepared instruments in the same order that
they did the rehearsals: Case-a and case-b from the ﬁrst
group, then case-b and case-a from the second. The per-
formance night was publicly advertised and was audio and
video recorded. An audience of 17 people attended.
During the study questionnaires were collected in the
form of practice diaries and more focused questionnaires
collected after the rehearsals and on the performance night.
These questionnaires were aimed to understand participants’
self-rated level of mastery, interaction with the instrument,
personal approach to performing with it, exploration of af-
fordances, style and group interaction. Semi-structured group
interviews were also undertaken which were audio and video
recorded, after rehearsal sessions and at the end of the per-
formances. These interviews contained open-ended ques-
tions about participants’ thoughts, feelings, collaboration,
performance experiences, agreements/disagreements and mu-
sical approaches.
5. RESULTS
5.1 Diversity of Style and Difference between
Individual and Group Playing
Aﬀordances of this instrument were even more limited than
the version used in the cube-instrument study [28], as it
has a ﬁxed synthesizer. This is one of the biggest physical
constraints. The participants reacted to this limitation by
focusing more on the techniques they could use on C-Box,
as reported in the questionnaires. According to the observa-
Figure 2: A picture of the second group taken dur-
ing the performance.
tions, they focused more on what the can play rather than
how they can play it.
Individually, the participants showed a diversity in the
playing styles. The inﬂuence of coming from diﬀerent mu-
sical backgrounds and performing diﬀerent kinds of music
could be seen in their individual and group playing. Ac-
cording to the observations, participants with a classical
music background focused mostly on the pitch and com-
municated through it such as playing sequence of intervals,
short melodies etc. Noisefunk performer was mostly trying
to create large envelopes of noise using a multiple ﬁnger
technique he developed during practice sessions.
Players were observed using the individual video record-
ings taken during self-practice sessions as well as the video
recordings of rehearsals and performances. Due to technical
problems during the performance night, multi-cam record-
ing failed and only one camera recorded the performances,
capturing only part of the stage.
All of the participants sat during the self-practice ses-
sions, rehearsals and the performances, therefore the pos-
ture variety was low. During the performance and the re-
hearsals, all the participants sat in a triangular shape with-
out any directions and aligned themselves towards the cen-
ter of this triangle. They kept the box on their laps.
It has been seen on the video analysis that some of the
interaction techniques were more favored by some partici-
pants than others. For instance, the noise artist kept both
hands on the sensor almost all the time, because that was
causing the synth to get loud, distort and produce drone-
like timbres. Four of the six participants reported that they
learnt at least one new technique during the rehearsals. 1
participant reported something that he could not achieve
using the aﬀordances of C-Box: ” I would like the sensor
just to be 4 times longer so I can control the pitch!”
Participants agreed that they enjoyed the group playing
much more. This appears to be due to the element of so-
cial interaction and exploration of what can be done with
others. A performer can set her mind to play exactly the
same gestures in the same sequence in every performance,
but the music will most likely be diﬀerent each time when
there is a group around her and they unaware of her musical
intention. Thus, the more interesting aspect of this study
for participants was the group music: ” It was not very sat-
isfying for me to play solo at home, because of the nature of
the synth. So, the interesting thing was to play and create
things with others.”
It was observed that there was a noticeable tension and
movement in what was being played such as getting louder
and more silent together. Some roles emerged, e.g. lead,
percussionist etc. It has been reported in the interviews
that the simplicity of C-Box created a cohesion, because
the diﬀerent techniques were audible and easy to reproduce
345
by others.
In the group performance, the most dominant modes of
interaction were observed and the characteristics of the sounds
were observed to be more eﬀective than visual interaction.
Individual timbre and loudness were observed to be the
most dominant ways of inﬂuencing the whole group play-
ing, because the timbral variations and loudness were more
easily noticed and reacted to by the other players. These
created the signiﬁcant dynamic changes that shaped the
structure. Video recordings and interviews indicate that
the participants used eye-contact and body language very
minimally to convey intention, ideas or a new direction. One
common behavior was looking at each other at the verge of
a resolution to an end, as they were trying to conﬁrm with
each other that they are ﬁnishing the session: ” Pitch was
less apparent to me as the performance was highly atonal,
and I felt that the tension and release in the performance
came entirely from rhythm, dynamics and timbre.”
5.2 Non-networked vs. Networked Case and
Their Inﬂuences on the Performance
One of the focuses of this study was understanding the inﬂu-
ence of the hidden (network) constraints. Questionnaires,
observations, semi-structured interviews and ethnographic
analysis of the video recordings were used to explore the
inﬂuence of hidden constraints as discussed below.
The questionnaires indicate that participants found the
non-networked case more liberating, where the networked
one was sometimes perceived as obstructive, for example:
” Non-networked was freedom to express ideas, so I could
actually focus on my rhythmic structure and take turns with
my own decision.”
Overall, participants found the networked version mostly
very limiting. Most of them reported that it brought struc-
ture and dynamics, but it often disrupted what they want
to do. One participant felt that it was more like playing a
game.
In contrast, 3 participants stated that the networked ver-
sion made the performance more connected between the
performers: ” Rules made it easier to interact, because it
made all the relationships between techniques and sounds
more transparent, ... coherent.”
Participants also reﬂected upon what happened on stage
between one another. The solo rule was found to bring co-
herence, but because of the fact that it was rather forced,
it did not align with what was in participants’ minds: ” The
solo sections forced focus on one performer and resulted ul-
timately more attention and interaction. However, some-
times what system brought didn’t coincide with other per-
formers’ intentions.”
The participants almost totally ignored the beat rule both
during the rehearsals and the performances. Even after they
understood how it worked, they did not react to it or use it
as a way to modify their musical intention. Interviews also
showed that they found the beats unimportant as they were
easy to ignore.
The interviews also showed that they found the network
constraints imposing and obstructive. They reported that
it lead to more structured and varied composition: ” I don’t
do percussions at all, so when I’m cut out, only thing I can
do is something percussive and it is a mental leap! Maybe
more engaging, but sometimes, I just want to continue to
play, but it may not let me!” Two of the participants agreed
that they thought the networked case was better for the
audience, since it yielded a more structured form of musical
material.
Regarding the C-Box, most of the participants reported
that they found the timbre variation very limited as they
could only distort it and change the tune of the additive
synthesizer a tiny bit by pressing too hard. One participant
particularly wanted to be able to control the pitch better:
” I would like the sensor just to be 4 times longer, so I can
control the pitch.”
Interestingly, the analysis of the video recordings and the
interviews showed that the players’ loudness were synchro-
nised, when the system was non-networked. From individ-
ual loudness levels of each C-box log, it could be seen that
the loudness of the individual players was increasing and
decreasing in accordance with the overall average loudness.
However, in the networked case, this seemed much less ap-
parent, because the solo rule was being triggered and par-
ticipants then played along with it. Often times the players
mimicked each other for the rhythmic parts. Also when a
player started to do something very diﬀerent, this was re-
ﬂected by other players as they changed their gestures after
a short period of time.
5.3 Audience Feedback
Figure 3: The results of audience questionnaires.
An audience of 17 people attended the performances in
a performance space with a total capacity of 30. A short
audience questionnaire was left on each chair so that feed-
back could be provided voluntarily. The questions and com-
ment sections were aimed at obtaining feedback about the
audience perception of the styles, coherence, creativity of
the musicians, and whether the spectators liked the con-
straints of the C-Boxes (see Figure 3). Only 8 of the ques-
tionnaires were completed fully, however, common feedback
about the constraints was that ”the non-networked case felt
more planned ” and the networked case was perceived as
more unstable.
6. DISCUSSION
Nijs et al. argue that the experience of a musical instrument
becoming part of the body is necessary for expressive com-
munication of musical meaning [22]. Arguably, there were
two reasons that the appropriation [28] and embodiment
did not happen in the study reported here: i) the amount
of time the performers had to practice (one week) and ii)
the design of the instrument itself which some performers
reported could be improved by having more elaborate tim-
bral control.
Another contributing factor may be that all the instru-
ments are exactly the same and are not ﬂexible or malleable
to each performer’s unique capabilities and background. As
Buxton argues [8], a one-size-ﬁts-all general purpose inter-
face design approach does not let the musicians use their
talent to a full extent. On reﬂection, the instrument de-
signs should have reﬂected players’ diversities.
We observed that in the domain of free improvisation
346
it is counter-intuitive to restrict the performers’ freedom
with forced unnatural interventions. If the constraint is
something really abrupt, such as the solo rule, or abstract,
such as such as the playing of beats top-down, it results in
frustration instead of challenge for the performers. Instead,
the constraints should be designed and implemented in more
ecologically valid ways.
According to the observational analysis and the inter-
views, the most dominant modes of interaction in the group
performance depended on the performers’ musical back-
grounds and interface constraints. Performers focused more
on the timbre and loudness of each other’s contributions in
order to shape the main compositional structure of the per-
formance, whereas pitch and rhythm were the main cues
for musical phrasing among the individual performers due
to the design of the instrument: Having a pitch range al-
most as wide as of a guitar, allowing sharp attacks, limited
timbre and eﬀortless pitch control. Furthermore, it may be
that introducing both transparent limitations on a physical
level and hidden constraints as musical rules results in a
form of cognitive overload for performers.
7. CONCLUSION
Results of this study indicate that network constraints can
lead to more structured improvisation, although the resul-
tant music may not ﬁt with performers’ true intentions.
Furthermore, it was found that when series of beats are
introduced to guide the performers into a collective conver-
gence, it is likely to be ignored, because it is perceived by
performers as being out of context.
In this study, we relied heavily on self-reporting by the
participants. More objective methods of analysis should be
explored for future research such as analysis of the patterns
of interaction between performers.
8. ACKNOWLEDGMENTS
This research was support by the EPSRC+AHRC Media
and Arts Technology Centre for Doctoral Training at Queen
Mary University of London (EP/L01632X/1).
9. REFERENCES
[1] J. J. Arango and D. M. Giraldo. The smartphone
ensemble. exploring mobile computer mediation in
collaborative musical performance. In NIME, pages
61–64, Brisbane, Australia, 2016.
[2] S. A. Barab, M. Barnett, L. Yamagata-Lynch,
K. Squire, and T. Keating. Using activity theory to
understand the systemic tensions characterizing a
technology-rich introductory astronomy course. Mind,
Culture, and Activity, 9(2):76–107, 2002.
[3] F. Biocca. Inserting the presence of mind into a
philosophy of presence: A response to sheridan and
mantovani and riva. Presence, 10(5):546–556, 2001.
[4] T. Blaine and S. Fels. Contexts of collaborative
musical experiences. In NIME, pages 129–134.
National University of Singapore, 2003.
[5] M. A. Boden. The creative mind: Myths and
mechanisms. Psychology Press, 2004.
[6] N. Bryan-Kinns. Daisyphone: the design and impact
of a novel environment for remote group music
improvisation. In Proc. DIS, pages 135–144. ACM,
2004.
[7] N. Bryan-Kinns and F. Hamilton. Identifying mutual
engagement. Behaviour & Information Technology,
31(2):101–125, 2012.
[8] B. Buxton. Artists and the art of the luthier. ACM
SIGGRAPH Computer Graphics , 31(1):10–11, 1997.
[9] L. Candy. Constraints and creativity in the digital
arts. Leonardo, 40(4):366–367, 2007.
[10] P. Dahlstedt, P. A. Nilsson, and G. Robair. The
bucket system. 2014.
[11] M. Fabiani, G. Dubus, and R. Bresin. Moodiﬁerlive:
interactive and collaborative music performance on
mobile devices. 2011.
[12] N. V. Flor and P. P. Maglio. Emergent global cueing
of local activity: covering in music. In Proc. CSCL,
pages 47–54. International Society of the Learning
Sciences, 1997.
[13] S. Gresham-Lancaster. The aesthetics and history of
the hub: The eﬀects of changing technology on
network computer music. Leonardo Music Journal,
pages 39–44, 1998.
[14] M. Gurevich. Jamspace: designing a collaborative
networked music space for novices. In NIME, pages
118–123. IRCAM-Centre Pompidou, 2006.
[15] M. Gurevich, P. Stapleton, and A. Marquez-Borbon.
Style and constraint in electronic musical instruments.
In NIME, pages 106–111, 2010.
[16] P. G. Healey, J. Leach, and N. Bryan-Kinns.
Inter-play: Understanding group music improvisation
as a form of everyday interaction. Proc.
LessisMore2005, 2005.
[17] A. Hunt, M. M. Wanderley, and M. Paradis. The
importance of parameter mapping in electronic
instrument design. Journal of New Music Research ,
32(4):429–440, 2003.
[18] S. Jord` a, G. Geiger, M. Alonso, and
M. Kaltenbrunner. The reactable: exploring the
synergy between live music performance and tabletop
tangible interfaces. In Proc. TEI, pages 139–146.
ACM, 2007.
[19] T. Magnusson. Designing constraints: Composing and
performing with digital musical systems. Computer
Music Journal, 34(4):62–73, 2010.
[20] A. Marquez-Borbon, M. Gurevich, A. C. Fyans, and
P. Stapleton. Designing digital musical interactions in
experimental contexts. contexts, 16(20):21, 2011.
[21] S. Nabavian and N. Bryan-Kinns. Analysing group
creativity: A distributed cognitive study of joint
music composition. Proc. of Cognitive Science, pages
1856–1861, 2006.
[22] L. Nijs, M. Lesaﬀre, and M. Leman. The musical
instrument as a natural extension of the musician. In
the 5th Conference of Interdisciplinary Musicology ,
pages 132–133. LAM-Institut jean Le Rond
d’Alembert, 2009.
[23] D. A. Norman. Aﬀordance, conventions, and design.
interactions, 6(3):38–43, May 1999.
[24] M. Pearce and G. A. Wiggins. Aspects of a cognitive
theory of creativity in musical composition. In Proc.
ECAI02 Workshop on Creative Systems , 2002.
[25] R. A. Rasch. Timing and synchronization in ensemble
performance. Generative processes in music: The
psychology of performance, improvisation, and
composition, pages 70–90, 1988.
[26] R. K. Sawyer. Group creativity: Music. Theater,
collaboration, 214, 2003.
[27] G. Weinberg. Interconnected musical networks:
Toward a theoretical framework. Computer Music
Journal, 29(2):23–39, 2005.
[28] V. Zappi and A. McPherson. Dimensionality and
appropriation in digital musical instrument design. In
NIME, pages 455–460, 2014.
347