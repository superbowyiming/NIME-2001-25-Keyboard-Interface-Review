A T axonomy of Spectator Experience Augmentation
Techniques
Olivier Capra
CRIStAL, CNRS,
University of Lille, France
olivier.capra@univ-lille.fr
Florent Berthaut
CRIStAL, CNRS,
University of Lille, France
ﬂorent.berthaut@univ-lille.fr
Laurent Grisoni
CRIStAL, CNRS,
University of Lille, France
laurent.grisoni@univ-lille.fr
ABSTRACT
In the context of artistic performances, the complexity and
diversity of digital interfaces may impair the spectator ex-
perience, in particular hiding the engagement and virtuos-
ity of the performers. Artists and researchers have made
attempts at solving this by augmenting performances with
additional information provided through visual, haptic or
sonic modalities. However, the proposed techniques have
not yet been formalized and we believe a clariﬁcation of
their many aspects is necessary for future research. In this
paper, we propose a taxonomy for what we deﬁne as Specta-
tor Experience Augmentation Techniques (SEATs). We use
it to analyse existing techniques and we demonstrate how
it can serve as a basis for the exploration of novel ones.
Author Keywords
audience experience, augmentation techniques, taxonomy,
performance
CCS Concepts
•Applied computing → Sound and music comput-
ing; Performing arts; • Human-centered computing
→ Mixed / augmented reality;
1. INTRODUCTION
While digital interfaces open numerous possibilities for artis-
tic expression, they may have a negative impact on the ex-
perience of spectators. In particular, previous research has
shown that digital interfaces, in particular Digital Musical
Instruments (DMIs), may diminish the perceived liveness
[23], the attributed agency [5], the perception of error [8]
and the perception of the performer’s skill [16]. A ﬁrst so-
lution to this issued is to shift the audience focus towards
the aural aspect of electronic performances [24]. A second
solution is to take into account the audience experience in
the design and evaluation of DMIs [3, 18] and to ensure
that instruments are suﬃciently transparent [14]. As an
alternative solution, artists and researchers have designed
techniques whichaugment performances with additional in-
formation for the audience without requiring changes in the
design of DMIs, therefore preserving their expressive power.
The goal of these Spectator Experience Augmentation Tech-
niques (SEATs)[12] is not necessarily to ” explain”the instru-
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’20, July 21-25, 2020, Royal Birmingham Conservatoire,
Birmingham City University , Birmingham, United Kingdom.
ments and ” demistify the apparatus” [2] but to enrich the
performance for spectators who wish it. They range from
textual information [4] and pre-performance demos [7], to
augmented reality displays [6, 20] and haptic feedback de-
vices [1, 25]. These techniques may be essential in order
to ensure the accessibility and enjoyment of performances
with existing and future interactive systems. However, to
our knowledge no formal analysis has been conducted yet,
restraining the development of such techniques.
In this paper we propose a taxonomy for Spectator Expe-
rience Augmentation Techniques (SEATs). This taxonomy
is aimed at artists and researchers as it can help inform the
design of performances with the experience of spectators in
mind.
1.1 Related work
Most classiﬁcations related to DMIs are deﬁned from the
musician or instrument designer point of view, such as the
dimension space proposed by Birnbaum et al. [9].
Previous work on audience experience has led to classiﬁ-
cations such as challenges for the design of DMIs from an
audience perspective [17] and to a 2D space for the analy-
sis of action and eﬀect perception [21]. In non-performance
contexts, previous work has explored the use of visual and
haptic displays to enhance the listeners experience. In par-
ticular Nanayakkara et al. [19] compare haptic and visual
representations of music. More speciﬁcally on techniques for
augmenting the audience experience, Capra et al. describe
a number of strategies for augmentation (visual, haptic) but
do not provide a formal analysis [10]. Bin et al. provide the
evaluation of a technique which uses a pre-concert demo
to increase the level of comprehension [7] . Benford et al.
discuss the eﬀect of diverse techniques (before, during and
after the performance) on the audience journey [4].
However to our knowledge, no formal classiﬁcation of ex-
isting techniques for the augmentation of spectator experi-
ence, nor analysis of their components has been performed.
1.2 Contribution
In this paper, we describe a taxonomy of Spectator Experi-
ence Augmentation Techniques, which constitutes the ﬁrst
formal analysis of the strategies that researchers and artists
use to compensate for the alteration of audience experience
in performances with digital interfaces. We demonstrate
how it can be used to analyse, extend or create techniques,
and how it can be useful for artists and researchers.
2. SPECT A TOR EXPERIENCE AUGMEN-
T A TION TECHNIQUES
It is essential to point out that, by using the term augmen-
tations, we focus on techniques which have no impact on the
design of the performer’s interface, i.e. they do not change
the way performers interact . Rather, they provide addi-
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
327
a
 b
c
 d
Figure 1: Spectator Experience Augmentation
Techniques: a) pre-performance explanation, b)
textual information on mobile, c) haptic wearables,
d) visual augmentations
tional information to the audience on various components
of the performance, such as performer’s equipment, gestures
or intentions. They are also not imposed on spectators, who
should be able to attend the performance without the aug-
mentations. SEATs may be designed with various goals in
mind : pedagogical, with a focus on helping spectators un-
derstand the performers’ interactions; aesthetic or engaging,
with a focus on increasing the implication of the audience;
or even disruptive, so that performances appear as magical
or secretive [22]. Although SEATs may be combined with
an interface that allows for audience participation in the
performance, i.e. the music produced is altered by specta-
tors, we chose to keep this aspect outside our taxonomy to
focus on transmission of information to the audience.
Thus, the values chosen for each dimension of our taxon-
omy may have an impact on multiple aspects of the audi-
ence experience. For genericity reasons, our taxonomy does
not take the display technology into account. For instance,
visual augmentations with the same dimensions could be
achieved through projection mapping, with video AR on a
smartphone or with an optical see-through head-mounted
display. Our aim is that this taxonomy will remain usable
by designers of performances with future technologies.
Our taxonomy is composed of eleven dimensions, described
below. For each of them, we provide the range of possible
values and discuss their potential impact.
2.1 Spatial Alignment
This dimension describes how augmentations are spatially
aligned with the performance components. Possible values
include :aligned, when the augmentations are perceived
as coming from the component itself; co-located when they
can be perceived while maintaining the focus on the per-
formance;distant when there is a shift in focus required
to access them. For instance, visual augmentations of a
music performance can be aligned if using a Pepper’s ghost
augmented-reality display, co-located if projected on a screen
behind the musician, or distant if displayed on the specta-
tors’ mobile devices. While aligning augmentations seem
ideal because it preserves the focus on the performance, the
presentation of complex information might cause sensory or
cognitive overload for the audience, in which case a more
distant presentation is preferable.
2.2 T emporal Alignment
This dimension pertains to when spectators can access to
the augmentations:before, during or after the performance.
For instance, in the case of verbal explanations, they may
be provided as a pre-performance demo, as comments dur-
ing the performance, or as a post-performance discussion. If
presented before the performance, augmentations may pro-
vide cues for the audience without any alteration to the
performance. However if they are too complex or given too
long before, some of the information may not be remem-
bered when needed. If presented during, the information
is given when needed but it might distract or overwhelm
the audience. If presented after, the information might be
lacking to understand events when they happen, but the
magical aspect [22] of the performance is preserved.
2.3 T emporal Density
This dimension relates to the temporal range that the aug-
mentations cover. It can be broadly deﬁned as alow, medium
and high. For example, augmentations of a music perfor-
mance can range from displaying only the last played note
to displaying the whole score. While a high density will help
the audience forge a stronger sense of performer’s intentions
or actions over time, and may help them in perceiving virtu-
osity or errors, providing too much information might also
distract them from the current actions.
2.4 T emporal Control
This dimension describes the possibility for the audience to
control the temporal range covered by the augmentations,
i.e. on which part of the performance they will access infor-
mation. It ranges fromnone to full. An example would
be textual explanations provided one by one either syn-
chronously with events of the performance or on request,
with spectators being able to freely scroll through them.
From a design perspective, allowing for temporal control
may help spectators build a better understanding of the
performance, but it might also lead them to miss augmen-
tations that should be perceived at a speciﬁc time.
2.5 Semantic Density
This dimension relates to how much information is provided
by a SEAT. It can also be seen as the information level-of-
detail. Like temporal density, it can be broadly classiﬁed
low, medium and high. For instance, augmentations on a
digital musical instrument may range from only showing
which synthesizer is being played, to showing the detailed
audio graph including the activity of all synthesis param-
eters. This dimension is essential as one needs to ensure
that the density is suﬃcient to provide useful information
but not too high so that it does not result in sensory or
cognitive overload for the audience.
2.6 Semantic Control
Symmetrically to temporal control, this dimension indicates
if the level of semantic detail can be chosen by the audience,
allowing for a personalized access to narrative elements [4]
or for information that matches the expertise of the specta-
tor [11]. It ranges fromnone to full. In the case of textual
explanations, it can for example go from a single level of de-
tail given to all spectators to multiple versions targeted at
diﬀerent levels of expertise, e.g. children / adults or novices
/ experts. This level may also be automatically selected ac-
cording to emotional or cognitive states measured through
wearable physiological sensors [10]. Regarding the acces-
sibility of the augmentations, increasing the control helps
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
328
Spatial
Alignment
Temporal
Alignment
Temporal
Density
Temporal
Control
Semantic
Density
Semantic
Control
Pres.
Nature
Pres.
Modality
Content
Nature
Content
Reactivity Agents
Perrotin
[20] co-located during medium none medium none abstract /
conceptual visual technical /
gestural / reactive avatar /
origin
Benford
[4]
co-located /
distant
before /
during /
after
high full medium limited abstract /
linguistic visual technical /
intentional semi-ﬁxed —
Armitage
[1] distant during low none low none ﬁgurative haptic gestural reactive —
Turchet
[25] distant during low none low none ﬁgurative haptic gestural reactive —
Bin [7] aligned before medium none low none linguistic auditory /
visual
technical /
gestural ﬁxed —
Berthaut
[6] aligned during low none medium none abstract visual
technical /
gestural /
causal
reactive —-
Table 1: Analysis of Spectator Experience Augmentation Techniques along the dimensions of our taxonomy
avoiding too simple or too complex information depending
on spectator’s expertise, but it also increases the complexity
of implementation for the performance designers. One also
needs to ensure that the control interface is not too diﬃcult
or that it does not distract spectators from the performance.
2.7 Presentation nature
This dimension relates to the form given to the information
provided to the audience. Possible values includeﬁgurative,
abstract, conceptual, and linguistic. For instance, to indi-
cate that a certain key was played by a musician the aug-
mentation can display respectively a close-up of their hands
and the keyboard, a colour changing shape, the note on a
scale or the note name. This dimension involves a trade-
oﬀ between the information explicitness, maximised with
linguistic or ﬁgurative augmentations, and its compactness
which can be optimised with abstract or conceptual aug-
mentations showing only essential information. It also has
implications on the aesthetic integration of the augmenta-
tions in the performance.
2.8 Presentation modality
This dimension describes how the augmentations are dis-
played. The modality can bevisual, auditory and haptic.
For example, the subtle gestures of a performer on a sen-
sor can be ampliﬁed using changes in a visual shape that
represents the sensor or through vibrotactile feedback re-
producing the gestures. The choice of modality depends on
the type of performance and its scalability. While visual
and auditory displays can be generalised, haptic ones imply
more restrictions as individual devices need to be designed.
2.9 Content nature
This dimension pertains to the nature of the content dis-
played by the augmentations, i.e. on which aspects of the
performance the SEAT provides information. We identiﬁed
four possible aspects:technical to reveal the mechanisms of
the interface [6]; gestural, to amplify subtle/hidden move-
ments [20]; intentional, so that the audience understand
what performers are trying to accomplish [15]; causal, so
that spectators have a clear perception of who from the
performer or autonomous processes is responsible for vari-
ations in the sound. The choice of content nature depends
strongly on the aim of the augmentations. Showing the in-
tention can highlight the performer’s virtuosity or aﬀect the
audience emotional response, while technical augmentations
may increase the level of comprehension of the audience.
2.10 Agents
This dimension describes the representation a SEAT can
give of the agents in a performance and of their interactions.
Agents are entities that can interact with instruments and
interact together, like 3 musicians on stage or a composite
crew including virtual agents. We envision 4 values for this
dimension.Origin, so that spectators perceive who is the
source of events in the performance, for example amongst
members of an orchestra [20] or between the performer and
automated processes.Avatar indicates the use of represen-
tations of the agents to provide additional information. This
modality can be used in performances where the musicians
are not physically located in the same place or when an
agent is virtual.Communication when musicians exchange
information not directly linked to sound production, such
as synchronisation or support signals.Interactions indicates
when the SEAT augments the interactions between agents.
This can be useful for instruments with shared controls and
rich musician-to-musician interfaces such as bf-pd [13].
2.11 Content reactivity
This dimension describes the relation between the augmen-
tations and the performance. It can beﬁxed when the
augmentations are pre-deﬁned and do not change with the
performance,semi-ﬁxed when some elements of the aug-
mentations change according to the performance, and re-
active when augmentations are generated from informa-
tion extracted in realtime during the performance. For
instance, visual augmentations can be pre-recorded videos
provided at pre-deﬁned moments or synthetic graphics trig-
gered and adapted dynamically based on the performers
actions. While a reactive content guarantees that the aug-
mentations will adapt to changes in the performances, it
involves a technical complexity not always achievable. For
example performers intentions can not be extracted dynam-
ically during the performance. It may also lead to informa-
tion being provided in a less accessible way than ﬁxed con-
tent if it is not designed carefully, e.g. with multiple visual
indications overlapping.
3. ANAL YSIS OF EXISTING SEA TS
Table 1 provides a decomposition of the following SEATs
from the literature. Perrotin et al. [20] use visual augmen-
tations projected behind a digital orchestra to display the
musical parameters (e.g. notes) played by each musician.
Benford et al. [4] use visual augmentations, both conceptual
and textual, projected on stage and available on spectators’
mobile devices to provide an overview of the structure and
intentions in a musical performance. Armitage [1] uses hap-
tic augmentations to provide the audience with vibrotactile
feedback that ampliﬁes the performer’s key presses in a live
coding performance. Berthaut et al. [6] use visual aug-
mentations to reveal the mechanisms of a DMI (including
sensor values, sound processes activity and sensor to pro-
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
329
cesses mappings) to the audience with an augmented reality
display. Bin et al. [7] uses pre-concert explanations of the
instrument to increase the spectators’ level of enjoyment
and comprehension. Turchet et al. [25] use a wearable hap-
tic device to provide vibrotactile feedback to the audience
to amplify the musician’s gestures.
4. USING THE T AXONOMY FOR DESIGN
When creating SEATs for a performance, our taxonomy can
be used to explore designs with various eﬀects on the audi-
ence experience. Starting from a common visual display of
information behind the performer, the following directions
could be chosen, depending on the desired eﬀect:
In order to improve the perception of the performer’s con-
trol, i.e. the audience’s attributed agency [5], value of the
Spatial Alignmentdimension can be increased, for example
using augmented reality displays which would place the in-
formation directly on top of the performer’s gesture, there-
fore improving the causal link between actions and eﬀects.
However, attention must then be paid to the quantity of dis-
played information, so as not to overload visually the perfor-
mance and reduce the visibility of the performer’s gestures.
In order to increase the audience engagement in the perfor-
mance, thePresentation Modality dimension can combine
visual and haptic feedback, through the use of belts or wrist-
bands providing vibrotactile feedback. This direction how-
ever poses issues for implementation, as it requires to equip
each spectator with a device or constrains them to ﬁxed
positions (e.g. seats) with built-in feedback. Finally, one
can choose to adapt the augmentations to spectators with
levels of expertise. In that case, the value of theSemantic
Control dimension can be increased. This would however
require an individual or grouped device for the selection of
the level of information provided by the augmentations.
5. CONCLUSION
Spectator Experience Augmentation Techniques (SEATs)
are techniques that add information to digital performance
interfaces in order to enrich the audience experience. In this
paper, we proposed a taxonomy for these techniques, we de-
tailed its dimensions and showed how it can be used for the
analysis and design of SEATs. As future work, we believe
a formal evaluation should be conducted which would pre-
cisely determine the impact of each of these dimensions on
the audience experience, and how they would be appropri-
ated by artists and researchers.
6. REFERENCES
[1] J. Armitage. Revealing timelines: Live coding and its
gestures. Proceedings of ICLC , 2016.
[2] P. Auslander. Liveness: Performance in a mediatized
culture. Routledge, 2008.
[3] J. Barbosa, F. Calegario, V. Teichrieb, G. Ramalho,
and P. McGlynn. Considering audience’s view towards
an evaluation methodology for digital musical
instruments. InProceedings of NIME , 2012.
[4] S. Benford, C. Greenhalgh, A. Hazzard,
A. Chamberlain, M. Kallionp ¨a¨a, D. M. Weigl, K. R.
Page, and M. Lin. Designing the audience journey
through repeated experiences. InProceedings of ACM
CHI, 2018.
[5] F. Berthaut, D. Coyle, J. W. Moore, and H. Limerick.
Liveness through the lens of agency and causality. In
Proceedings of NIME, 2015.
[6] F. Berthaut, M. Marshall, S. Subramanian, and
M. Hachet. Rouages: Revealing the mechanisms of
digital musical instruments to the audience. In
Proceedings of NIME, 2013.
[7] S. Bin, A. McPherson, N. Bryan-Kinns, et al. Skip
the pre-concert demo: How technical familiarity and
musical style aﬀect audience response. InProceedings
of NIME , 2016.
[8] S. A. Bin, F. Morreale, N. Bryan-Kinns, and A. P.
McPherson. In-the-moment and beyond: Combining
post-hoc and real-time data for the study of audience
perception of electronic music performance. In
Proceedings of INTERACT, 2017.
[9] D. Birnbaum, R. Fiebrink, J. Malloch, and M. M.
Wanderley. Towards a dimension space for musical
devices. InProceedings of NIME , 2005.
[10] O. Capra, F. Berthaut, and L. Grisoni. Toward
augmented familiarity of the audience with digital
musical instruments. InProceedings of CMMR , 2017.
[11] O. Capra, F. Berthaut, and L. Grisoni. All you need
is lod : Levels of detail in visual augmentations for
the audience. InProceedings of NIME , 2020.
[12] O. Capra, F. Berthaut, and L. Grisoni. Have a seat on
stage : Restoring trust with spectator experience
augmentation techniques. InProceedings of DIS , 2020.
[13] L. Dahl, F. Berthaut, A. Nau, and P. Plenacoste.
bf-pd: Enabling mediated communication and
cooperation in improvised digital orchestras. In
Proceedings of CMMR. Springer, 2017.
[14] S. Fels, A. Gadd, and A. Mulder. Mapping
transparency through metaphor: towards more
expressive musical instruments.Organised Sound ,
7(2):109–126, 2002.
[15] A. C. Fyans, M. Gurevich, and P. Stapleton.
Spectator understanding of error in performance. In
Proceedings of ACM CHI, 2009.
[16] A. C. Fyans, M. Gurevich, and P. Stapleton.
Examining the spectator experience. In Proceedings of
NIME, 2010.
[17] M. Gurevich and A. C. Fyans. Digital musical
interactions: Performer–system relationships and
their perception by spectators.Organised Sound ,
16(2):166–175, 2011.
[18] W. T. Hsu and M. H. Sosnick. Evaluating interactive
music systems: An hci approach. In NIME, 2009.
[19] S. C. Nanayakkara, L. Wyse, S. H. Ong, and E. A.
Taylor. Enhancing musical experience for the
hearing-impaired using visual and haptic displays.
Human–Computer Interaction, 28(2):115–160, 2013.
[20] O. Perrotin and C. d’Alessandro. Visualizing gestures
in the control of a digital musical instrument. In
Proceedings of NIME, 2014.
[21] S. Reeves. Designing interfaces in public settings:
Understanding the role of the spectator in
Human-Computer Interaction. Springer Science &
Business Media, 2011.
[22] S. Reeves, S. Benford, C. O’Malley, and M. Fraser.
Designing the spectator experience. In Proceedings of
ACM CHI , 2005.
[23] W. A. Schloss. Using contemporary technology in live
performance: The dilemma of the performer. Journal
of New Music Research , 32(3):239–242, 2003.
[24] C. Stuart. The object of performance: Aural
performativity in contemporary laptop music.
Contemporary Music Review, 22(4):59–65, 2003.
[25] L. Turchet and M. Barthet. Haptiﬁcation of
performer’s control gestures in live electronic music
performance. InProceedings of Audio Mostly , 2019.
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
330