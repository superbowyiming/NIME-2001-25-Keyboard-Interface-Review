Augmenting the iPad: the BladeAxe
Romain Michon, Julius O. Smith, Matthew Wright, Chris Chafe
Center for Computer Research in Music and Acoustics (CCRMA), Stanford University
Stanford, CA 94305-8180, USA
{rmichon,jos,matt,cc}@ccrma.stanford.edu
ABSTRACT
In this paper, we present the BladeAxe: an iPad-based
musical instrument leveraging the concepts of “augmented
mobile device” and “hybrid physical model controller.” By
being almost fully standalone, it can be used easily on stage
in the frame of a live performance by simply plugging it
to a traditional guitar ampliﬁer or to any sound system.
Its acoustical plucking system provides the performer with
an extended expressive potential compared to a standard
controller.
After presenting an intermediate version of theBladeAxe,
we’ll describe our ﬁnal design. We will also introduce a sim-
ilar instrument: the PlateAxe.
Author Keywords
Novel musical instruments, Novel controllers and interfaces
for musical expression, Mobile music technology and per-
formance paradigms, Embedded musical instruments and
embedded sound art installations
ACM Classiﬁcation
H.5.5 [Information Interfaces and Presentation] Sound and
Music Computing, H.5.2 [Information Interfaces and Pre-
sentation] User Interfaces—Graphical user interfaces (GUI),
J.5 [Arts and Humanities] Music.
1. INTRODUCTION
While physical modeling of musical instruments has been an
active ﬁeld of research since the beginning of the 1970s [7],
the use of physical-model-based instruments in real-time be-
came seriously pursued only at the end of the 1980s with the
discovery of the waveguide synthesis technique [21]. Thanks
to its eﬃciency and simplicity and by combining forces with
modal synthesis [1], dozens of musical instruments were
modeled by the middle of the 1990s [5, 17] and the elec-
tronic music community was seeing it as“the next big thing”
[16]. Indeed, unlike other sound synthesis techniques, the
expressive potential of physical models seemed almost limit-
less. While most commercial products focused on modeling
existing acoustic musical instruments, researchers in com-
puter music saw it as an opportunity to quickly prototype
and create novel instruments that would often transcend
the laws of physics [4, 10].
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’16,July 11-15, 2016, Grifﬁth University, Brisbane, Australia.
.
However, one of the main challenges with waveguide-
based physical models is to control them in a coherent and
expressive way [23]. Unlike instruments using traditional
sampling techniques where the expressivity is embedded
(or not) in the sample, with physical models expressivity
has to come from the diﬀerent parameters controlling the
instrument and is therefore still the performer’s responsi-
bility. While this is not a big problem for instruments that
don’t have a lot of continuous parameters, such as the pi-
ano, it is a major issue for instruments needing constant
parameter adjustments (such as wind instruments). For
live performances, this problem has been partially solved
by creating interfaces providing more continuous control to
the performer, such as the position and pressure sensitivity
of the ROLI Seaboard1 or the breath sensor on the Yamaha
VL1 (just to mention a few). However, things are more
complicated when the performer is “virtual” [11].
In a previous publication [12], we introduced theBladeAxe
(see Figure 1) – a “hybrid controller” for guitar (and more
generally plucked string instrument) physical models. This
instrument leverages the idea that a great part of the ex-
pressivity translated from performer to instrument is often
embedded in the excitation used to drive it [15, 14, 2, 3,
18, 24]. Indeed the strings and the body of the BladeAxe
belong to the virtual world while the surface of the strings is
“materialized” through small plastic (polycarbonate) plates
(the “blades”) that can be used to drive the virtual strings.
Those blades were made to have the same elasticity and
texture as real guitar strings. A piezo glued to each blade
picks up vibrations that are then digitized, preprocessed,
and fed directly into the digital waveguide representing the
string (as detailed in [12]).
Pressure Sensor
Replaceable Neck
Plucking System Preamps
ADC
Figure 1: The ﬁrst version of the BladeAxe.
The plucking system of the BladeAxe provides an ex-
tended expressive potential to the performer by using acous-
tic excitations to drive virtual strings. Indeed, even the
acoustical properties of the materials used to pluck the
strings (skin, plastic, wood, etc.) are captured and impact
the resulting sound. The excitation signal also naturally
embeds the pluck position along the edge of the blade: for
1https://www.roli.com/ Accessed: 2016-01-18.
247
example, Figure 2 shows more energy below 1KHz and less
energy above 4KHz when one of the blade is plucked at
the middle rather than at one end. The pluck position uni-
formly aﬀects the spectra of the virtual strings, for example
the relative amplitude of the fundamental (typically below
1KHz) versus the higher harmonics, as shown in Figure 3:
the virtual strings sound like they are plucked at diﬀerent
positions.
1000 2000 3000 4000 5000 6000 7000 8000 9000 10000
−50
−45
−40
−35
−30
−25
−20
−15
−10
−5
0
Frequency, Hz
Power, dB
1/2
1/4
0
Figure 2: Frequency responses of one of the blades
when plucked at diﬀerent locations with a pick
where 0 is the bottom of the blade (towards the
bridge) and 1/2 the middle.
1000 2000 3000 4000 5000 6000 7000 8000 9000 10000−60
−40
−20
0
Frequency, Hz
Power, dB
1000 2000 3000 4000 5000 6000 7000 8000 9000 10000−60
−40
−20
0
Frequency, Hz
Power, dB
1000 2000 3000 4000 5000 6000 7000 8000 9000 10000−60
−40
−20
0
Frequency, Hz
Power, dB
Figure 3: Frequency responses of a virtual string
when excited by the signals from Figure 2 (1/2, 1/4
and 0 from top to bottom).
In this paper, we present the ﬁnal version of theBladeAxe2.
It leverages the concept of “augmented mobile device” and
it is quite diﬀerent from the ﬁrst version of this instrument
introduced in [12]. Its design was greatly simpliﬁed by using
an iPad both as a controller and to implement the virtual
part of the instrument. This enabled us to make this instru-
ment fully standalone reinforcing its “physical and virtual
coherence.” After presenting an intermediate version of the
2Demo and concert videos featuring the BladeAxe can
be found here: https://ccrma.stanford.edu/~rmichon/
bladeaxe/ Accessed: 2016-01-18.
BladeAxe, we’ll describe our ﬁnal design. We will also
introduce a similar instrument: the PlateAxe.
2. AUGMENTING THE IPAD
Mobile platforms have been used a lot during the past ten
years as musical instruments [8, 22]. They provide a fully
self-contained/standalone environment with built-in speak-
ers, various sensors (touch screen, accelerometer, etc.), and
processing power capable of computing complex DSP algo-
rithms in real-time. While a programmer or instrument de-
signer might be limited by the sensor technologies available
on such devices, they can be easily upgraded/augmented by
mounting more sensors or elements on them. Doing so puts
mobile devices at the heart of the musical instrument, im-
plementing both its digital elements and some of its physical
controllers (sensors). This section shows how we used this
approach to make an intermediate version of theBladeAxe
where an iPad greatly simpliﬁes the design of this instru-
ment by implementing the idea of an “ iPad augmented as
a guitar”.
As we wanted to keep the same plucking system as the
ﬁrst version, we used the iPad as the neck of the guitar
(see Figure 4). This implied major design modiﬁcations
and also a totally diﬀerent approach to the way this in-
strument was controlled. Indeed, while the various necks
presented in [12] prioritized guitar playing skills transfer,
this new version of the BladeAxe cannot be controlled in
the same way as a traditional guitar because of the shape
of the touch screen. We also mounted an acrylic plate with
laser engraved textures to the front face of the BladeAxe,
with its own attached piezo disc, allowing the performer to
drive the virtual strings through a variety of interactions.
Each texture creates a diﬀerent sound excitation and im-
plies a speciﬁc gesture: rubbing, scratching, tapping, etc.
(see Figure 7).
We wanted this instrument to be fully standalone and
self-powered. Running the guitar physical model on the
iPad forced us to do a series of optimizations detailed in
the next section.
The most technically challenging problem that we had
to solve with this instrument was to ﬁnd a way to send
the seven independent audio channels of the plucking sys-
tem (the six blades plus the textured plate) to the iPad.
We could have used a custom ADC (Analog to Digital Con-
verter) just like we did for the ﬁrst version of theBladeAxe
(see [12]) , but this would have required the use of an exter-
nal power supply such as a battery, greatly complicating the
design of the instrument. Thus in order to use the built-in
stereo ADC of the iPad, we had to ﬁnd a way to diﬀerenti-
ate the six blades; we used the capacitive touch sensors of
the plucking system (see [12] ) to detect which blade was
plucked to route the excitation to the corresponding virtual
string (see Figure 5). While this system worked ﬁne if the
performer was playing slow, it was hard to control in the
frame of a piece involving fast playing.
Another challenge was to ﬁnd a way to connect the Ar-
duino retrieving the touch sensing data from the plucking
system to the iPad. Indeed, iOS devices let other devices
connect to them only if they are approved by Apple. There
are a couple of exceptions to that including MIDI con-
trollers. We used Dimitri Diakopoulos’ work [6] as a basis
to replace the serial USB driver of the Arduino with a MIDI
USB driver making it usable with the iPad. Indeed, while a
series of microcontrollers such as the Teensy3 now provide
built-in MIDI support, they didn’t exist when this version
of the BladeAxe was built. A proximity sensor was also
3https://www.pjrc.com/teensy/ Accessed: 2016-01-18.
248
embedded in the body of the BladeAxe (see Figure 4) to
control some of the eﬀects applied to the model such as a
wah pedal.
iPad 2
Tapping System Plucking System
Proximity Sensor
Microcontrollers
Figure 4: Intermediate version of the BladeAxe us-
ing an iPad.
Piezos
Copper Tape for Capacitive
Touch Sensing
Arduinos + Electronics
Figure 5: Plucking system of the intermediate ver-
sion of the BladeAxe presented in Figure 4.
3. FINAL VERSION
The ﬁnal version of the BladeAxe can be seen as a sim-
pliﬁed version of the instrument presented in the previous
section. The way the performer interacts with it was to-
tally rethought and the number of blades was reduced from
six to two (see Figure 6) allowing us to use a simple USB
stereo ADC/DAC. We didn’t use the built-in ADC/DAC of
the iPad since it only has a mono input. The redesigned
tapping/scratching surface hides the ADC/DAC. A switch
mounted on the front face of the instrument makes it possi-
ble to route the signal from the two blades of the plucking
system or from the tapping surface to any of the two in-
put channels of the ADC. The USB ADC/DAC is directly
connected to the iPad through the lightning connector since
there is no microcontroller in this version of theBladeAxe.
The chestnut wood body of the instrument was CNC ma-
chined and laser engraved (see Figure 6). The built-in iPad
sleeve is mounted on a rotating axis in order for the per-
former to be able to adjust its inclination. It is fully powered
by an iPad Air 2 and can be used for more than eight hours
without charging the battery. The DAC’s single stereo 1/4”
jack output with adjusted impedance makes it compatible
with any guitar amp, pedal, etc.
Several pieces speciﬁcally composed for this instrument
can be listened to on the BladeAxe webpage4.
4https://ccrma.stanford.edu/~rmichon/bladeaxe/ Ac-
cessed: 2016-01-18.
Tapping Surface
Plucking System (2 plates)
Ipad Air 2
Rotation Axis
ADC Input Switch
Figure 6: The ﬁnal version of the BladeAxe.
Figure 7: The textured plate of the BladeAxe.
249
3.1 Control
While the overall shape of the ﬁnal BladeAxe is quite sim-
ilar to its previous version presented in§2, the way it is con-
trolled/performed is very diﬀerent, mainly because of two
versus six blades. Indeed, since we were using aniPad as the
neck to control parameters such as the pitch of the strings,
we thought that the paradigm where strings can be driven
independently from the plucking system became obsolete.
Instead, the performer is now able to drive any string with
a single blade. Pitch is controlled using a chromatic key-
board interface on the screen of the iPad (see Figure 8). If
one key is pressed, only one virtual string is used. If sev-
eral keys are touched, several virtual strings are allocated
and the excitation from the single blade is routed to these
strings.
The BladeAxe guitar physical model gives access to a
pool of ten virtual strings. When the performer presses a
key on the screen of the iPad, an available string is allo-
cated and its input is activated. If a glissando is performed
or if the performer plays an interval smaller than a major
third, the same string is used, otherwise, a new string is
selected. If several keys are pressed at the same time, then
the excitation from the blade is sent to all the activated
strings.
The chromatic keyboard of the BladeAxe covers four
octaves and is arranged as “an S” (see Figure 8) to facilitate
slides across several octaves. Thus the lowest key is the one
on the top right corner of the interface and the highest one
is in the bottom right corner. While this keyboard allows
vibrato and sliding between keys, it also “rounds” the pitch
of a note when the ﬁnger of the performer is not moving.
This is very important to make sure that the instrument is
not out of tune. The diﬀerent keys of the keyboard can be
highlighted and locked in a speciﬁc scale by using the scale
selector at the bottom right area of the screen.
The second blade can be used to strum a set of six virtual
strings. When an excitation is created, it is progressively
sent to the strings with diﬀerent short delays corresponding
to the amount time it would take for the exciter (ﬁnger,
pick, etc.) to go from one string to another. The duration
of this “inter-string-delay” is calculated according to the ex-
citation’s RMS amplitude: the louder the excitation, the
faster the strum. Chords can be selected on a table located
at the bottom of the interface (see Figure 8) by choosing
their root and their type.
Some parameters related to the expressivity of the phys-
ical model such as the decay time (T60), brightness, de-
tuning, and material of the strings can be controlled using
the “movable dots” located on the right side of the screen.
A button located on the bottom of the screen can be used
to damp the strings. Finally, each parameter of the phys-
ical model can be accessed independently in a parameters
menu that can also be used to save presets. More details
about the diﬀerent parameters of the physical models of the
BladeAxe are given in the next section.
3.2 Physical Model
The electric guitar physical model of theBladeAxe is based
on a modiﬁed version of the Extended-Karplus-Strong algo-
rithm [9, 19, 20] and is fully implemented in Faust5 [13]. It
contains a set of ten virtual strings that can be controlled
from the iOS layer. They are connected to a series of ef-
fects that are directly taken from theFaustlibraries (guitar
amp simulator, ﬂanger, phaser, chorus, echo, reverb, distor-
tion, wah pedal, etc.). The virtual strings can be both ex-
cited with a signal coming from the plucking system of the
5http://faust.grame.fr Accessed: 2016-01-18.
Chord Table
Polyphonic 4 
Octaves Keyboard
Scale Selector
Continuous Parameter
Controllers
Figure 8: User interface of the iPad app of the
BladeAxe.
BladeAxe and with a synthesized excitation. The signal
coming from the plucking system is lowpass ﬁltered in func-
tion of the pitch of the string (lower notes require a lower
cutoﬀ frequency than higher notes). Each string waveguide
implements a set of two coupled strings using two parallel
delay lines (see [20]). Their length can be oﬀset to create
harmonics. The amount of oﬀset can be controlled dynam-
ically from the GUI by using the dots interface (see §3.1).
The length of the delay lines can also be modulated by a sine
oscillator to create very expressive eﬀects. The frequency
of the modulation and its amplitude can be controlled from
the dots interface as well.
The pitch of the virtual strings can be changed using a
“slide mode” or a “discontinuous mode”. In slide mode, the
frequency values are interpolated to create a smooth con-
tinuous change. The discontinuous mode can be used to
abruptly change the pitch of a string without creating a
click. To do that, two parallel delay lines are used. When
the pitch of a string is changed, the length of the second
delay line is altered and a fast crossfade is carried out to
switch from the ﬁrst delay line to the second one creating a
very natural transition.
The model and its associated eﬀects were compiled as
a C++ code using the vectorization option of the Faust
compiler. This is very important as this allows us to run
all these elements in real-time by utilizing the iPad Air 2 ’s
multi-core processor.
4. THE PLATEAXE
For our most recent instrument, we wanted to create an
interface compatible with the iPad app of the BladeAxe
but having a diﬀerent form factor. Thus the PlateAxe is
intended to be a percussion instrument providing the same
kind of laser engraved tapping surfaces as the BladeAxe
and a small plucking interface where a circular polycarbon-
ate disc with variable diameter can be used to generate the
sound (see Figure 10). A series of switches and knobs can
be used to route the signals of these elements to the dif-
ferent input channels of the BladeAxe app. Thanks to
its non-uniform diameter, the polycarbonate disc creates
excitations with diﬀerent spectra depending on where it is
plucked.
5. EV ALUATION/DISCUSSION
Our ﬁrst approach [12] consisted in creating an interface
as close as possible from the one provided by the origi-
nal instrument. While we think that we partially achieved
this goal with “the right hand” and the plucking system, we
struggled much more with the neck. Finding a design of-
250
Polycarbonate Plate 1 Piezo Film
Polycarbonate Plate 2 Piezo Film
Plucking System
Tapping Surface
Switch ADC
Channel 1
Channel 2
Channel 1
Channel 2
Channel 3
Chromatic Keyboard Chord Selector Dots Interface Parameters Menu
String Selector & 
Parameters Formating
Virtual Strings
Delay Lines
Effects Chain
Strumming
Solo
DSP (Faust)
Delay Duration
Estimation
User Interface
iPad
BladeAxe
DAC
Audio Out
USB
USB
Figure 9: Overview of the implementation of the BladeAxe.
Tapping Surfaces
Plucking System
Switches / 
Gain Control
Figure 10: The PlateAxe.
fering the same kind of interactions and sensations than an
actual guitar neck prove to be hard. Also, by getting too
close to the original instrument, we realized that we lost
part of its novelty and that it would never be as good as
its purely acoustical counterpart. With the iPad version of
the BladeAxe, we think that we found a good compromise
between expressivity, skills transfer and novelty.
The ability to control several virtual strings with a single
blade made this instrument very intuitive to play. We be-
lieve that we could even remove the strumming blade and
transfer its functionality to the touch screen interface, al-
lowing to strum and play independent notes with the same
blade.
While the textured plate (see ﬁgure 7) signiﬁcantly in-
creases the expressive potential of the BladeAxe, we think
that it could be improved by expanding the diversity of
sounds it can produce, perhaps via 3D printing. Indeed, al-
though the current textures all sound diﬀerent, their spec-
tral content are nonetheless very similar. Varying the shape
and the thickness of the plate could help solve this issue.
The ﬁrst author of this paper has been performing with
the latest version of BladeAxe for about one year. The
iPad provides a level of stability and robustness competing
with professional keyboard synthesizers. After dozens of
performances, the BladeAxe never crashed or ran out of
power. Even though the combined latency of the touch
screen and the DAC is about 35 ms (this value is relatively
constant), we ﬁnd it not to be an issue especially after some
practice.
Finally, one of the main limitations of using the iPad is
sweat! Indeed, it often happens during a frenzied perfor-
mance that the ﬁngers of the performer get clammy or even
worse, that a drop of sweat ends up on the touch screen
preventing it from working properly.
6. FUTURE WORK
While mobile platforms have been used to create simple mu-
sical instruments for almost ten years, we believe that only
the latest devices allow the creation of instruments having a
comparable expressivity and playability than more sophisti-
cated/standard instruments. However, mobile devices were
never meant to be used for this task and are missing crucial
elements to make them as playable as a violin, as a guitar, or
even as a digital keyboard, etc. We believe that by augment-
ing those devices using digital fabrication (such as 3D print-
ing) and external sensors (connected passively to the device
through the audio jack input or actively by using a micro-
controller), we’ll be able to design fully standalone mobile-
device-based instruments competing with traditional ones.
For example, the instrument presented in Figure 11 aug-
ments a smart phone with a 3D-printed case integrating a
passive acoustic ampliﬁer for its built-in speakers and han-
dles to comfortably play the instrument.
For our next project, we plan to further explore the idea
of augmented mobile devices by providing a methodology
and a framework to facilitate the design and the creation of
such instruments.
7. CONCLUSIONS
The BladeAxe is an iPad based musical instrument lever-
aging the concepts of “augmented mobile device” and “hy-
brid physical model controller.” By being almost fully stan-
dalone, it can be used easily on stage in the frame of a live
performance by simply plugging it to a traditional guitar
ampliﬁer or to any sound system. Its acoustical plucking
system provides the performer with an extended expressive
potential compared to a standard controller.
We believe that it opens the way to a new class of “mobile
device based hybrid musical instrument” – closer to tradi-
tional ones thanks to their acoustical exciters and their gen-
eral form factor – but also having the advantages oﬀered by
digital audio synthesis, in particular physical modeling.
251
Figure 11: A smartphone augmented with a 3D
printed case.
8. REFERENCES
[1] J.-M. Adrien. The missing link: Modal synthesis. In
Representations of Musical Signals , chapter The
Missing Link: Modal Synthesis, pages 269–298. MIT
Press, Cambridge, USA, 1991.
[2] R. M. Aimi. Hybrid Percussion: Extending Physical
Instruments Using Sampled Acoustics . PhD thesis,
Massachusetts Institute of Technology, USA, 2007.
[3] E. Berdahl. Application of Feedback Control to
Musical Instrument Design . PhD thesis, Stanford
University, USA, 2009.
[4] C. Chafe. Case studies of physical models in music
composition. In Proceedings of the 18th International
Congress on Acoustics, Kyoto, Japan, 2004.
[5] P. Cook and G. Scavone. The Synthesis Toolkit (stk).
In Proceedings of the International Computer Music
Conference (ICMC-99), Beijing, China, 1999.
[6] D. Diakopoulos and A. Kapur. Hiduino: A ﬁrmware
for building driverless usb-midi devices using the
arduino microcontroller. In Proceedings of the
International Conference on New Interfaces for
Musical Expression (NIME’11), Oslo, Norway, June
2011.
[7] L. Hiller and P. Ruiz. Synthesizing musical sounds by
solving the wave equation for vibrating objects.
Journal of the Audio Engineering Society ,
19(7):542–551, July/August 1971.
[8] D. Holzborn. Building Mobile Instruments for
Improvised Musical Performance. PhD thesis,
Columbia University, USA, 2013.
[9] D. A. Jaﬀe and J. O. Smith. Extensions of the
karplus-strong plucked-string algorithm. Computer
Music Journal, 7(2):56–69, 1983.
[10] J. Kojs, S. Seraﬁn, and C. Chafe. Cyberinstruments
via physical modeling synthesis: Compositional
applications. Leonardo Music Journal, 17:61–66, 2007.
[11] E. Maestre. Modeling Instrumental Gestures: An
Analysis/Synthesis Framework for Violin Bowing .
PhD thesis, Universitat Pompeu Fabra, Spain, 2009.
[12] R. Michon and J. O. Smith. A hybrid guitar physical
model controller: The BladeAxe. In Proceedings of
ICMC|SMC 2014, Athens, Greece, September 2014.
[13] Y. Orlarey, D. Fober, and S. Letz. An algebra for
block diagram languages. In Proceedings of the
International Computer Music Conference
(ICMC-02), Gothenburg, Sweden, 2002.
[14] M. Puckette. Infuriating nonlinear reverberator. In
Proceedings of the International Computer Music
Conference (ICMC-11), Huddersﬁeld, UK, 2011.
[15] M. Puckette. Playing a virtual drum from a real one.
The Journal of the Acoustical Society of America ,
130(4):2432, 2011.
[16] E. Rideout. Yamaha vl1 virtual acoustic synthesizer.
Keyboard Magazine, 20:104–118, June 1994.
[17] M. Russ. Yamaha VL1 - virtual acoustic synthesizer.
Sound on Sound, July 1994. URL
http://www.soundonsound.com/sos/1994_articles/
jul94/yamahavl1.html. Accessed: 2015-09-16.
[18] D. Schlessinger and J. O. Smith. The Kalichord: A
physically modeled electro-acoustic plucked string
instrument. In Proceedings of the 9th International
Conference on New Interfaces for Musical Expression
(NIME-09), Carnegie Mellon Univeristy, USA, June
2009.
[19] J. O. Smith. Making virtual electric guitars and
associated eﬀects using Faust. This series of
laboratory exercises is concerned with building virtual
stringed instruments and associated eﬀects in the
Faust programming language.
[20] J. O. Smith. Virtual electric guitars and eﬀects using
Faust and Octave. In Proceedings of the Linux Audio
Conference (LAC-08), pages 123–127, KHM, Cologne,
Germany, 2008.
[21] J. O. Smith. Physical Audio Signal Processing for
Virtual Musical Instruments and Digital Audio
Eﬀects. W3K Publishing, 2010.
[22] G. Wang. Ocarina: Designing the iphone’s Magic
Flute. Computer Music Journal , 38(2):8–21, Summer
2014.
[23] G. Widmer, D. Rocchesso, V. V ¨alim¨aki, C. Erkut,
F. Gouyon, D. Pressnitzer, H. Penttinen, P. Polotti,
and G. Volpe. Sound and music computing: Research
trends and some key issues. Journal of New Music
Research, 36(3):169–184, 2007.
[24] A. Zoran and P. Maes. Considering virtual & physical
aspects in acoustic guitar design. In Proceedings of the
2008 Conference on New Interfaces for Musical
Expression (NIME08), Genova, Italy, 2008.
252