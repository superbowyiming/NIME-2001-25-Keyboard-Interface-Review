Vibrotactile Feedback-Assisted Performance
Lauren Hayes
Department of Music
University of Edinburgh
Alison House
12 Nicolson Square
Edinburgh
EH8 9DF
laurensarahhayes@gmail.com
ABSTRACT
When performing digital music it is important to be able to
acquire a comparable level of sensitivity and control to what
can be achieved with acoustic instruments. By examining
the links between sound and touch, new compositional and
performance strategies start to emerge for performers using
digital instruments1. These involve technological implemen-
tations utilizing the haptic 2 information channels, oﬀering
insight into how our tacit knowledge of the physical world
can be introduced to the digital domain, enforcing the view
that sound is a ‘species of touch’ [14].
This document illustrates reasons why vibrotactile inter-
faces, which oﬀer physical feedback to the performer, may
be viewed as an important approach in addressing the lim-
itations of current physical dynamic systems used to medi-
ate the digital performer’s control of various sorts of musical
information. It will examine one such method used for per-
forming in two diﬀerent settings: with piano and live elec-
tronics, and laptop alone, where in both cases, feedback is
artiﬁcially introduced to the performer’s hands oﬀering dif-
ferent information about what is occurring musically. The
successes of this heuristic research will be assessed, along
with a discussion of future directions of experimentation.
Keywords
Vibrotactile feedback, human-computer interfaces, digital
composition, real-time performance, augmented instruments.
1. INTRODUCTION
Being arguably the most highly developed of the senses
[5], the importance of touch is often, it will here be sug-
gested, erroneously overlooked in human-computer musical
systems. This paper examines some possible advantages in
exploring the audio-tactile link for practitioners of digital
music, and will propose introducing vibrotactile feedback
as a new strategy for improving performance in the ﬁeld.
An assessment will be presented of what has been lost, in
terms of interaction, in the move from traditional acoustic
1Instrument is used here to encompass the entire system
which may include: human-computer interface(s), com-
puter, bespoke software, loudspeakers and so on.
2Related to the modality of touch.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’11,30 May–1 June 2011, Oslo, Norway.
Copyright remains with the author(s).
instruments to commercial interfaces for digital music. This
will be followed by a discourse on using vibrotactile signals,
directly applied to the performer’s hands, as a means of
communicating information about the music and score dur-
ing a performance. The theoretical ideas are put forth in
relation to the creative practice of the author; the output of
this work being original compositions and improvisations.
Links to audio3. and video 4 examples of these works have
been provided for reference.
2. SOUND AND TOUCH
2.1 Haptics
When hungarian psychologist Revesz ﬁrst introduced the
word haptic, from the Greek haptesta (to touch), in 1931
[3], it was used to describe the process of actively explor-
ing a shape or spatial dimension with the hands, discussed
in the context of his research on blindness and its pro-
found eﬀects on the other senses. He contrasted this process
with the event of indirectly sensing something on the skin
(ibid.), such as experiencing diﬀerences in temperature or
feeling something brush against the body. However, when
discussed in terms of human-computer interfaces, the word
haptics is often used as an umbrella term encompassing both
the active information gathering that Revesz described, as
well as the tactile sensations that he classed separately, and
additionally, kinaesthetic information about the body in re-
lation to space [12].
Haptic devices are carefully designed interfaces that usu-
ally involve some type of actuator or mechanical device,
such as small vibrating motors. Their purpose is to im-
prove the translation of gesture between the physical world
and the digital realm by considering both the body’s ki-
naesthetic system, which detects position and motor control
of muscles and joints, as well as the tactile sensors in the
skin, which are extremely sensitive and capable of detecting
highly complex patterns of information [6].
2.2 Instruments
2.2.1 Acoustic Instruments
The skin’s sensing nerves are most densely collected in the
lips and hands [9], [12]; since most acoustic instruments are
constructed to be played with the mouth or ﬁngertips, this
distribution of sensors in the skin allows for the maximum
amount of information exchange. During engagement with
the instrument, the performer receives feedback in the form
of various resistant forces and vibrations (for example, the
3Audio recording of improvisation for lap-
top using vibro-tactile feedback device:
http://soundcloud.com/elleesaich/multiﬁngeredbodyparts
4Video of kontroll for prepared piano, self-playing snare and
live electronics: http://www.vimeo.com/13493035
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
72
vibration of guitar strings, along with the force of the ﬁngers
on the strings).
This haptic information supports the auditory feedback
received through the ears as sound is made. Hence a closed
feedback loop is created: the performer makes a sound,
which is heard and also perceived physically, judged, and
considered before the next sound is made. This process
occurs in a very short space of time and is constantly on-
going throughout musical play: the auditory and haptic
feedback is immediate, with the latter signals received per-
haps almost subconsciously. Certainly while the amount of
force used to strike keys while playing the piano is a con-
scious consideration, vibrations received through the feet
may not be consciously perceived, but are no doubt signif-
icant in creating the collective feedback information being
received. As Cadoz claims, this bidirectional information
exchange ‘provides us with manipulation possibilities and
even signals the nature of the sound phenomenon itself.’ [1]
Furthermore, this entire process is uniquely private to the
performer, compared to noticeablevisual exchanges that
may occur within a group performance setting.
2.2.2 Digital Musical Interfaces
In general, digital interfaces generally oﬀer signiﬁcantly less
feedback to the performer. A MIDI keyboard may fea-
ture weighted keys, but cannot reveal any other information
about the physicality of the sound being produced, com-
pared to the great resonating body of an acoustic piano.
2.3 Tactile Feedback Principle
In 1978, Claude Cadoz proposed the tactile feedback prin-
ciple in conjunction with his work at ACROE 5, Grenoble,
France, where along with Jean-Loup Florens, he developed
the ﬁrst Retroactive Gestural Transducers (haptic devices).
Their aim was to provide new insights into music creation by
focusing on the instrument-performer relationship as funda-
mental to both the learning of the instrument and the de-
velopment of the music itself, rather than simply providing
improved ergonomics of gestural control in sound synthesis
[1]. Cadoz claimed that any musical interface into the dig-
ital world must succeed on three levels: the gesture used
to manipulate the device must be genuine in that the per-
former must be familiar with the type of movements being
used with the controller. Secondly, the device must be able
to accurately sense the characteristic behaviour of the ges-
ture and information must not be lost. Finally, he claimed
that the device must oﬀer some resistance to the performer,
which is in relationship to the nature of the simulated ges-
ture process [1]. He calls this ﬁnal aspect feedback, and
deems it necessary to achieve mastery or perform with ﬁ-
nesse.
2.4 Types of Haptic Devices
Human-computer haptic interfaces may be described as any
device that incorporates an element of force feedback through
actuators: mechanical systems that can oﬀer a wide range
of accurate motion, such as motors. Rovan and Hayward
distinguish these devices from what they call tactile stimula-
tors [12], which consist of, for example, small groups of pins
that tap at the skin, vibrating at controllable frequencies
to achieve diﬀerent intensities. Thus Revesz’s distinction
between active and passive perception manifests itself in
these contrasting systems: the vibro-tactile systems allow
the user to passively experience sensations.
There is a huge amount of evidence to suggest that haptic
perception can speed up learning [3], [9], thus allowing the
5Association pour la Cr´ eation et la Recherche sur les Outils
d’Expression
relationship between performer and instrument to develop
at a much faster rate than without feedback present. When
describing his Modular Feedback Keyboard, Cadoz claimed
that the aim was to create a ‘synthesis of the instrument’ [1],
as well as the sound. Thus it would allow experimentation,
musical play and would successfully couple the performer,
instrument and space [1]. As Pedro Rebelo, researcher and
composer atSARC, Belfast claims, it is useful to view the
link between a performer and instrument as a ‘multimodal
participatory space (and not one of control)’ [11]. The fol-
lowing sections will discuss the author’s attempts to realise
this idea as both composer and performer.
3. FEEDBACK-ASSISTED PERFORMANCE
3.1 Developments
There have been a minimal 6 number of instruments de-
signed with vibrotactile feedback in mind. Marshall and
Wanderley, CIRMMT, McGill University, describe the Vi-
blotar and the Vibloslide[8] which each use small inbuilt
speakers to produce both vibration, as well as sound, as
feedback for the performer. As with acoustic instruments,
in both these examples the sound source is located within
the body of the physical instrument itself7, and not dislo-
cated in loud speakers: the physical feedback emerges con-
currently with the sonic.
The aim of using of the vibrations of the speakers was
to create “vibrations in a DMI [digital musical instrument]
that are produced in a similar way to those of an acoustic
instrument”. Certainly this approach is an important one,
in that it uses the paradigm of traditional instruments as
a starting point for introducing haptic information to new
digital instruments. The following two case studies oﬀer an
alternative approach where the vibrotactile feedback is not
intended to emulate the feel of playing acoustic instruments,
but rather as a signalling and suggestion system for the
performer.
3.2 Case Study: Composition for Prepared Pi-
ano and Live Electronics
This work arose out of several compositions for prepared
piano and electronics, for solo performer, where the per-
former would be in control of both the piano and the live
electronics. As Emmerson claims, digital music interfaces
should be both consistent in their response, as well as sen-
sitive, so that even subtle movements and gestures may be
accurately detected and used to aﬀect the sound [4]. Thus
it seemed plausible that using a touch-based acoustic in-
strument, namely the piano itself, as the interface into the
digital world could be the solution to achieving mastery of
the entire system 8. By controlling all processes from the
piano, the pianist may retain their touch-based sensitivity
whilst yielding enough useful control data, via various anal-
yses of the sound, to aﬀect the digital signal. From this
emerges what pianist Xenia Pestova describes as a ‘further
continuation of extended techniques’ [10].
3.2.1 Score Following
Building on previous work involving a machine-listening
system for prepared piano and live electronics, the goal with
the new piece,kontroll, was to create a situation where the
6Marshall found instances of vibrotactile feedback imple-
mentation in less than 6% of new instruments at NIME
from 2001 - 2008[7].
7Although external ampliﬁcation is also permitted to in-
crease sound quality.
8Rather than attaching MIDI controllers to the piano,
which may disrupt the performance.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
73
Figure 1: Simple glove with vibration motors, which
connects to a laptop via an Arduino.
need to look at a laptop screen for visual feedback would
be minimized or completely eradicated. In a previous com-
position, transient (2010) it was necessary to watch for the
clock, score position and whether various triggers had been
activated on the laptop screen. While certain trigger points
were ﬂexible in time, they had to occur within a certain
time-window, and thus the Max/MSP interface had to been
constantly checked. In the subsequent piece, these obstacles
would be overcome by sending haptic feedback, in the form
of vibrations, to the hands of the performer, providing the
required information via a diﬀerent modality.
3.2.2 Methodology
The score of the composition was created in Max/MSP,
where various preset stages were created which would en-
able or deactivate diﬀerent DSP modules, and change how
control data derived from analysis of the piano’s acoustic
signal was used. Advancing to a new section would, in most
cases, be triggered by the pianist (either performing a par-
ticular gesture at a speciﬁed dynamic, or by maintaining a
speciﬁed amount of silence). Other events would advance
according to a ﬁxed timeline. Using an Arduino 9 and three
small pager motors attached to the left hand via a simple
glove, vibrations were sent to the performer indicating:
• a ﬁve second warning for an approaching change in
score position, increasing in vibration intensity
• a strong short vibration when the performer had suc-
cessfully triggered a new section of the piece
• the guide tempo of a section.
The pager motors used were Samsung disk coin-type vi-
bration motors10. By selecting extremely light motors (0.99
grams each), no additional noticeable weight would be added
to the hands of the pianist. The motors were connected
directly across the ground and digital/pulse-width modula-
tion pins of the Arduino, as they operate at a meagre 1.5V.
Information was sent to the three motors using the Maxuino
helper patch11 for Max/MSP, allowing all computation to
9An open-source electronics prototyping platform board:
www.arduino.cc
10Available from www.pagermotors.com
11http://www.maxuino.org/
be contained inside a single programming environment. Us-
ing pulse-width modulation, a very apparent increase in in-
tensity could be experienced.
Motors were ﬁxed onto the glove (which was extremely
thin and elasticated), positioned on either side of the back
of the hand, with the third positioned directly below on the
wrist. This allowed for discreet observable information to
be accurately perceived whilst playing.
3.2.3 Outcomes
The result was extremely beneﬁcial to the execution of the
performance: the ease with which I could ignore the screen
and concentrate on the performance was immediately ap-
parent. The vibration signals were non-evasive and did not
distract from the actual playing. There was a strong sense
of being fully coupled to the system as a whole, as the score
of the piece was being applied directly to the body, oﬀer-
ing more security in the often unpredictable world of live
electronics, and allowing for a more focussed performance.
3.3 Case Study: Improvisation for Laptop and
Game Controller
As a trained pianist, most of my musical expressivity in-
volves working with the hands, and thus for laptop per-
formance I often repurpose generic game controllers as my
interface. For the second example, the vibrotactile feedback
system that was developed for kontroll was used in a more
active manner, worn in conjunction with a game-pad for
laptop improvisation. While used as a signaller of structure
in the previous work, the haptic information was now used
to direct the performer with more musical, and particularly
rhythmic information.
While many game-pads or rumble-pads do oﬀer resistant
force-feedback, this was not present in the one that was
used. Instead, it was sought to achieve a high level of con-
trol using only micro-movements of the hands and ﬁngers.
Thumbs pressed on the two joysticks could freeze and loop
the sound, but the slightest movement could throw this oﬀ.
3.3.1 Tactile Score
The device alone without haptics worked fairly well as a solo
improvisational tool, triggering samples within Max/MSP
which were sliced into segments of several milliseconds, and
then processed in various ways. Yet, to create a more in-
teresting deployment of the gestural rhythmic aspect, the
vibrotactile glove provided short pulses of 300 milliseconds
to the performer indicating that short sounds should be
played. The interval between these bursts was determined
algorithmically, and changed over time. Thus the illusion
of diﬀerent paces throughout the improvisation was created,
along with more unpredictable intervals between gestures.
Similarly, longer signals, which would increase with inten-
sity, were sent to indicate that a section should be repeated
for the duration of the physical sensation. A variable time-
line was established along which either of these two situ-
ations could occur, but this would not be known to the
performer prior to the start of the piece.
3.3.2 Development
The next part of this work will be to develop musical sug-
gestion which is dependent, at least in part, on what has
been, or is currently being played by the performer. Rhyth-
mic patterns would certainly be an obvious starting point
here, as these are perhaps the most easily repeatable events
when working with unpredictable digital musical instru-
ments. Furthermore, rhythms can be easily represented by
short bursts of vibrations. The problem with translating
more complex variables, such as spectral content, is not only
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
74
Figure 2: Vibrotactile feedback used in conjunction
with generic game controller.
the issue of how to most meaningfully map parameters, but
also where to draw the line between useful information and
sensory overload.
4. CONCLUSIONS
It is clear that there is a strong case for utilizing the dif-
ferent aspects of the modality of touch within digital music
practice in order to challenge ideas about musical creativ-
ity, as well as to address the limitations of current systems
used to mediate between the digital performer’s gesture and
sound synthesis. With careful experimentation and clever
coupling of instrument and performer, the possibilities for
new musical expression are certainly promising. From the
examples shown above, it is clear that using vibrotactile
feedback for performance strategies is a largely untapped
area that is worth proper exploration.
4.1 Future Developments
Further research in this area will examine diﬀerent parame-
ters that may be successfully used within this type of feed-
back system, including:
• testing on diﬀerent parts of the body
• exchanging information amongst a number of perform-
ers in an improvisational setting
• mapping other musical parameters to the feedback.
This last topic possibly deserves the most dedication, and
work is in progress to develop ways of representing a more
complete musical picture tangibly, looking at aspects such
as density and spectral shifts12, to assist with musical in-
terpretation. Indeed Schroeder et al. describe experiments
designed for group interaction, where these parameters are
represented visually as an abstract image[13]. Moreover,
Chang and O’Sullivan suggest looking toward audio-visual
theories, such as those proposed by Michel Chion, to de-
velop ways of linking both the tactile and auditory sensa-
tions; techniques such as masking and synchronization13 are
proposed [2].
12These are perhaps less consciously perceived, compared to
amplitude, frequency etc.
13For example, synchronization would involve the sound and
the sensation occurring at the same time.
4.2 Concerning the Listener
It is hoped that this type of vibrotactile interface can be
used with non-performers, who will listen to music, whilst
also experiencing it in the form of vibrations. Indeed Gun-
ther and O’Modhrain, implementing this idea with their
Cutaneous Groovesproject, go so far as to suggest that this
is a ‘potential new art form’ [6].
After developing the tactile feedback system and experi-
encing the ease with which signals can be transferred to the
skin, it is hoped to explore the idea of using this informa-
tion to enhance the listening experience, by coupling it with
various physical sensations.
5. REFERENCES
[1] C. Cadoz, L. Lisowski, and J.-L. Florens. A Modular
Feedback Keyboard Design. In International
Computer Music Conference, Glasgow, 1990.
[2] A. Chang and C. O’Sullivan. An Audio-Haptic
Aesthetic Framework Inﬂuenced by Visual Theory. In
T. I. Workshop, editor, Haptic and Audio Interaction
Design, Jyv¨askyl¨a, Finland, September 2008.
[3] P. W. Davidson. Haptic Perception. In
S. of Pediatric Psychology, editor, Journal of
Pediatric Psychology, volume 1(3), pages 21–25, 1976.
[4] S. Emmerson. ‘Losing Touch?’: The Human
Performer and Electronics. In S. Emmerson, editor,
Music, Electronic Media and Culture, pages 194–216.
Ashgate, Aldershot, 2000.
[5] M. Grunwald. Human Haptic Perception: Basics and
Applications. Birkh¨auser, Basel, 2008.
[6] E. Gunther and S. O’Modhrain. Cutaneous Grooves:
Composing for the Sense of Touch. In Journal of New
Music Research, volume 32(4), pages 369–381. Swets
and Zietlinger, 2003.
[7] M. T. Marshall. Physical Interface Design for Digital
Musical Instruments. PhD thesis, McGill University,
2008.
[8] M. T. Marshall and M. M. Wanderley. Vibrotactile
Feedback in Digital Musical Instruments. In
Proceedings of the 2006 conference on New Interfaces
for Musical Expression (NIME), 2006.
[9] S. O’Modhrain. Playing by Feel: Incorporating Haptic
Feedback into Computer-Based Musical Instruments.
PhD thesis, Stanford University, CA, 2001.
[10] X. Pestova. Models of Interaction in Works for Piano
and Live Electronics. PhD thesis, McGill University,
2008.
[11] P. Rebelo. Haptic Sensation and Instrumental
Transgression. In Contemporary Music Review,
volume 25(1/2), pages 27–35. Routledge,
February/April 2006.
[12] J. Rovan and V. Hayward. Typology of Tactile
Sounds and Their Synthesis in Gesture-Driven
Computer Music Performance. In M. Wanderley and
M. Battier, editors, Trends in Gestural Control of
Music, pages 297–320. Editions IRCAM, Paris, 2000.
[13] F. Schroeder, A. B. Renaud, P. Rebelo, and
F. Gualda. Addressing the network: Performative
strategies for playing apart. In International
Computer Music Conference, pages 113–140, 2007.
[14] S. Waters. Performance Ecosystems: Ecological
Approaches to Musical Interaction. In E. M. S.
Network., editor, EMS-07 Proceedings, Leicester: De
Montfort, 2007.
Proceedings of the International Conference on New Interfaces for Musical Expression, 30 May - 1 June 2011, Oslo, Norway
75