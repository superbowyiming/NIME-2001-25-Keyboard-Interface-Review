Between Garment and Prosthesis: The Design of an E-Textile
Musical Interface
Qiaosheng Lyu
qslyu2-c@my.cityu.edu.hk
City, University of Hong Kong
Hong Kong, China
Ryo Ikeshiro
ryo.ikeshiro@cityu.edu.hk
City, University of Hong Kong
Hong Kong, China
Abstract
This paper presents Noisy Flesh , an e-textile musical interface de-
signed to control sound through body movement in performance.
Unlike traditional wearable interfaces that function as garments,
this work reimagines the textile interface as a prosthetic exten-
sion that augments the performer’s body. The paper discusses
both the design of the interface and its sonification method, em-
phasising how the flexibility of e-textiles can transform bodily
movement and shape interactive experiences. This work explores
the potential of e-textile interfaces to challenge conventional
notions of wearability and embodiment in performance.
Keywords
E-textile, Body Instrument, Wearable Interface, Musical Prosthe-
sis
1 Introduction
E-textiles, as flexible materials, have expanded the possibilities
for interaction in musical interface design, especially in wearable
forms [11, 16]. Traditional designs often prioritize comfort and
efficiency by integrating e-textiles into garments. In contrast, this
research proposes a new approach: treating e-textiles as pros-
thetic interfaces that reshape the performer’s body and move-
ment. Here, interaction becomes an active negotiation rather
than passive control.
Inspired by feminist textile artworks such as Lee Bul’s wear-
able sculpture and Senga Nenegudi’s performative installation
[8, 12], this research explores how e-textile interfaces can repre-
sent, deform, and redefine the body alongside augmented audi-
tory perception. The interface employs knitted stretch sensors
resembling redundant body parts to encouraging the performer to
explore movement as a means of sound manipulation. Movement
data is sonified through audification and parameter mapping,
allowing the performer to create an auditory presence that ex-
tends self-perception. Rather than offering intuitive control, the
prosthetic interface promotes a process of negotiation, through
which performers gradually redefine their bodily expression.
Challenging conventional notions of movement and embodi-
ment, the e-textile prosthetic interface aligns with the concept
of entangled NIME by treating the interface as an active agent
in the performer’s interaction.. The performing body, prosthe-
sis interface, and the generated sound continuously inform and
reshape one another, enabling embodied expression and explo-
ration within this entangled system.
This work is licensed under a Creative Commons Attribution 4.0 International
License.
NIME ’25, June 24–27, 2025, Canberra, Australia
© 2025 Copyright held by the owner/author(s).
Figure 1: Extract from performance with the interface. Pho-
tography by Winston Yeung.
2 Background and Related Works
E-textiles are textiles modified to support sensing, communica-
tion, and power transmission [1]. With growing interest in novel
interface design, they have been increasingly adopted for musical
interaction and expression. Their flexibility makes them espe-
cially suitable for wearable computing, offering advantages over
conventional materials like metal and plastic.
In musical interaction, the e-textile interface has been explored
across various applications. E-embroidery interfaces were in-
tegrated as textile capacitive sensors into a jacket to function
as a musical keypad [14]. FabricKeyboard [17] reimagined key-
board interaction using textile sensors, enabling diverse input
gestures such as pressing, touching, sliding, hovering, and stretch-
ing. In wearable interface design, e-textiles offer a more flexible
and adaptable interaction experience [ 16]. Stretch sensors are
commonly employed in wearable applications [4]. Knit stretch
sensors are often positioned around joints to capture a broad
range of movement data, particularly in dance-music interaction
[11, 15]. When integrated into performance garments, they sup-
port embodied interaction by dynamically responding to bodily
motion.
However, compared to textiles in feminist art, the expressive
potential of e-textiles for investigating themes related to gender
or body in musical interfaces remains underexplored. For exam-
ple, Lee Bul’s wearable sculptures distort bodily proportions with
grotesque, exaggerated limbs that extend into the surrounding
space, demonstrating how textiles can transform the body[ 8]
Similarly, in R.S.V.P Activations, Nengudi explores bodily elas-
ticity through the tension between performer and textile, using
skin-like fabric stretched to extremes to provoke both fragility
and resilience [12]. These works establish a dynamic relationship
in which textile and body mutually influence movement, produc-
ing a delicate but balanced tension. While such representations
of bodily transformation and deformation have been noteworthy
NIME ’25, June 24–27, 2025, Canberra, Australia Qiaosheng Lyu and Ryo Ikeshiro
Figure 2: Individual sensors: A) tumour sensors; B) Intesti-
nal sensors with separated conductive sections.
in textile-based art, the potential remains largely untapped in e-
textile musical interfaces, which could further engage with sound
as an interactive medium. Although there are projects exploring
e-textile wearable instruments that have seen the potential of
creating a bodily metaphor in interaction and appearance, the
textile remains more decorative than interactive and has less im-
pact on the sound output as well as the projects leaving feminist
themes not fully explored [10].
This research distinguishes between e-textiles as garments and
as prostheses to propose an alternative approach to movement-
based musical interfaces. As garments, e-textiles serve as exten-
sions of the body, prioritizing comfort and seamless integration
with performance garments. The primary design goal is to mini-
mize interference with movement by keeping fabric sensors flat
and elastic, allowing them to conform to the body like a “second
skin” [3, 11].
By contrast, the prosthetic interface is designed to actively
reshape the body, encouraging the performer to negotiate con-
trol and explore exaggerated or unconventional movements. The
Visor, Ribs, and Spine of the Prosthetic Instruments series[5] exem-
plify how prosthetic interfaces can impose movement constraints
while simultaneously enabling new forms of interaction through
sonic feedback. Drawing on the influence of feminist textile art,
the e-textile prosthetic musical interface builds on this concept
by integrating sound as an active feedback mechanism within a
multisensory performance environment.
Figure 3: Extra limb sensors in two modes: A) With rings,
sensors move with the arm for controlled articulation. B)
Without rings, weighted sensors swing freely, causing dy-
namic deformations and sonic variations.
3 Design and Implementation
3.1 Conceptual definition
This research explores the design of an e-textile musical interface
for controlling sound through bodily movement. The initial con-
cept was inspired by the often-overlooked sounds of the moving
body. In civilized societies, verbal communication is prioritized
while sound-making through movement is typically suppressed
as a marker of civility [2]. This suppression has contributed to a
general unfamiliarity with the sounding body. To counter this,
the project employs an e-textile prosthesis to reclaim attention
to unrestrained bodily motion.
The interface is examined through a performance in which
the performer wears an upper-body costume embedded with
multiple e-textile sensors [ 9]. Designed as deformable, redun-
dant body parts, these sensors invite the performer to gener-
ate sound through movement. The interaction and sonification
design serves as a framework for investigating the prosthetic
interface, focusing on how it reshapes both physical movement
and sonic expression.
3.2 E-Textile interface
This wearable interface is made from knitted fabric embedded
with conductive elements for sensing. Compared to other textile
fabrication methods, knitting offers better stretchability, making
it well-suited for deformable, movement-controlled interfaces
[11]. The conductive material used in this design is 70D silver-
plated thread, intertwined with regular yarn. The textile sensor
is loosely knitted using a knitting machine using garter stitches.
When stretched, the conductive thread compresses, forming con-
tact points that reduce electrical resistance [13]. The deformation
Between Garment and Prosthesis: The Design of an E-Textile Musical Interface NIME ’25, June 24–27, 2025, Canberra, Australia
Figure 4: Design of performance costume
of each knitted stretch sensor produces fluctuations in resistance,
effectively capturing movement data.
The individual textile sensors were designed to resemble re-
dundant body parts, simulating the appearance of intestinal tracts,
tumours, and extra limbs (see Figure 2). Stuffed with cotton, these
sensors invite performer interaction through kneading, squeez-
ing, and stretching. Additionally, even gentle movements can
deform the sensors, producing subtle resistance variations that
influence the sound output.
The performance costume integrates three types of textile
sensors, each mimicking a specific bodily form, each designed
for distinct interactions (see Figure 4). The “intestinal” sensor
positioned around the neck consists of four conductive sections
separated by non-conductive fabric. As the performer bends their
neck to reach other body parts, these sensors are compressed, gen-
erating variations in data. The “tumour” sensors located around
the chest are designed to press against one another. Sound is trig-
gered when the performer applies pressure by pressing their body
against the ground or other body parts. More vigorous movement
causes sensor collisions, further influencing the sound output.
The “extra limb” sensors attached to the arms each contain a
metal ball as a weight. When the performer wears a ring at the
end of each extra limb sensor (see Figure 4), the sensors move
in sync with the body, producing subtle variations in data. With-
out the rings, the metal weights cause the sensors to swing and
stretch in response to movement intensity, generating greater
resistance variation. While all sensors respond to both stretch-
ing and compression, their placement on different body parts
produces distinct data outputs, even for similar movements.
3.3 Sonification
This interface employs two sonification methods – audification
and parameter mapping sonification – to mediate between gesture-
based input and sound output (see Figure 5). Audification inter-
prets sensor data directly as amplitude fluctuations over time,
enabling an audible representation of resistance fluctuations [6].
Compared to other sonification methods, audification was chosen
for its higher indexicality preserving the intrinsic characteristics
of the original data [7]. The interface transmits resistance fluc-
tuations via serial communication with Arduino Nano boards.
Figure 5: Diagram of the E-textile musical interface system
Since movement data typically falls within a lower frequency
range, the waveform is resampled to enhance auditory percep-
tion. Variations in sensor shape and the length of conductive
thread result in differing baseline resistances, producing distinct
control ranges.
In addition to audification, parameter mapping sonification is
used to manipulate sound characteristics. Data from the same
sensor is mapped to the resampling rate, while amplitude corre-
sponds directly to the sensor’s output. These mappings reinforce
a grotesque aesthetic, sonically suggesting an organic, living en-
tity composed of redundant body parts. A low-pass filter further
emphasises lower frequencies, resulting in a deep, roaring sound.
4 Discussion and Future Work
This paper introduces Noisy Flesh , an e-textile musical interface
designed for body movement control in performance. Leverag-
ing the inherent flexibility of textiles, e-textiles enable seamless
garment integration, adaptability in form, and dynamic deforma-
tion in response to movement. Inspired by feminist textile-based
artworks that investigate the body through representation, de-
formation, and redefinition, this project reimagines the role of
e-textiles in interface design, not merely as garments but as pros-
thetic extensions of the body.
A prosthetic interface is proposed not as a secondary addition
to the body, as in the case of garments, but as a transforma-
tive extension that reshapes bodily structure and inspires new
movements through negotiated control. This e-textile interface,
designed to resemble redundant body parts, challenges conven-
tional models of movement-to-sound translation. Rather than
NIME ’25, June 24–27, 2025, Canberra, Australia Qiaosheng Lyu and Ryo Ikeshiro
Figure 6: Performer folding the body to make contact, press,
or rotate, for generating varied sound outputs. Photogra-
phy by Winston Yeung.
offering direct, intuitive control, it invites the performer to invent
movement strategies specific to the interface’s unique material
and spatial properties in order to achieve desired sonic outcomes.
For instance, the performer may fold the body to establish contact
between different body parts, such as the chest and neck sensors,
and then modulate sound output by rotating or subtly shifting
weight (see Figure 6). The sonification of movement constructs
an auditory body, enabling the performer to perceive and engage
with the extended body. Through audification, sound is derived
directly from the physical state of the interface, reinforcing the
perception of the e-textile extensions as ’alive’ during perfor-
mance. This approach aligns with the concept of a prosthetic
interface, in which the extensions are not merely accessories but
integral representations of augmented bodily perception.
Rather than serving as a transparent medium for bodily expres-
sion, the e-textile prosthesis interface acts as an active agent in
shaping both movement and auditory experience. Through this
approach, This approach reconfigures the body with deformable
extensions, enabling the performer to perceive an intensified
relationship.
This project aims to incorporate additional interactions and
sound variations to capture different movements. The potential
for further development includes modifying the shape of the
interface to improve its affordance and support performers in
exploring new interaction strategies. Beyond mimicking natural
body parts, the design could also benefit from incorporating imag-
inary or bionic body parts, inspired by other creatures, thereby
expanding the possibilities in aesthetic, interactional, and sonic
possibilities.
Future work will involve interviews with performers to gain
insights into experiences with the prosthetic interface for im-
proving the design. Comparative analysis between the garment
interface and the prosthetic interface will help identify key de-
sign principles and highlight the value of using these interfaces
in performance contexts.
5 Ethical Standards
This research is conducted as part of the first author’s PhD stud-
ies funded through a university studentship. The work described
in this paper by Ryo Ikeshiro was partially supported by a grant
from the Research Grants Council of the Hong Kong Special Ad-
ministrative Region, China (Project No. CityU 11600523). There
are no financial or non-financial conflicts of interest to declare.
References
[1] Joanna Berzowska. 2005. Electronic Textiles: Wearable Computers, Reactive
Fashion, and Soft Computation. TEXTILE 3, 1 (Jan. 2005), 58–75. https:
//doi.org/10.2752/147597505778052639
[2] Karin Bijsterveld and Stefan Krebs. 2013. Listening to the Sounding Objects of
the Past: The Case of the Car. In Sonic Interaction Design , Karmen Franinović
and Stefania Serafin (Eds.). The MIT Press, 0. https://doi.org/10.7551/mitpress/
8555.003.0003
[3] Rachel Freire, Cedric Honnet, and Paul Strohmeier. 2017. Second Skin: An Ex-
ploration of eTextile Stretch Circuits on the Body. InProceedings of the Eleventh
International Conference on Tangible, Embedded, and Embodied Interaction .
ACM, Yokohama Japan, 653–658. https://doi.org/10.1145/3024969.3025054
[4] Rachel Freire and Courtney N. Reed. 2024. Body Lutherie: Co-Designing a
Wearable for Vocal Performance with a Changing Body. (Oct. 2024). https:
//doi.org/10.5281/ZENODO.13904800 Publisher: Zenodo.
[5] Ian Hattwick, Joseph Malloch, and Marcelo Wanderley. 2014. Forming Shapes
To Bodies: Design For Manufacturing In The Prosthetic Instruments. (June
2014). https://doi.org/10.5281/ZENODO.1178792 Publisher: Zenodo.
[6] Thomas Hermann, Andrew Hunt, John G. Neuhoff, and Europäische Zusam-
menarbeit auf dem Gebiet der Wissenschaftlichen und Technischen Forschung
(Eds.). 2011. The sonification handbook . Logos Verlag, Berlin.
[7] Ryo Ikeshiro. 2014. Audification and Non-Standard Synthesis in Construction
in Self . Organised Sound 19, 1 (April 2014), 78–89. https://doi.org/10.1017/
S1355771813000435
[8] Bul Lee. 1990. Sorry for suffering – You think I’m a puppy on a picnic.
[9] Qiaosheng Lyu. 2024. Noisy Flesh. https://vimeo.com/user106110998
[10] Vincenzo Madaghiele and Arife Dila Demir. 2024. Pain Creature: interdis-
ciplinary collaboration in the design of an embodied textile instrument for
interactive dance. (Oct. 2024). https://doi.org/10.5281/ZENODO.13904917
Publisher: Zenodo.
[11] Aline Martinez, Michaela Honauer, Hauke Sandhaus, and Eva Hornecker.
2018. Smart textiles in the performing arts. In Textiles, Identity and Innovation:
Design the Future (1 ed.), Gianni Montagna and Cristina Carvalho (Eds.). CRC
Press, 311–318. https://doi.org/10.1201/9781315100210-57
[12] Senga Nengudi. 2022. R.S.V.P. Activations.
[13] Hannah Perner-Wilson, Leah Buechley, and Mika Satomi. 2010. Handcrafting
textile interfaces from a kit-of-no-parts. InProceedings of the fifth international
conference on Tangible, embedded, and embodied interaction . ACM, Funchal
Portugal, 61–68. https://doi.org/10.1145/1935701.1935715
[14] E. R. Post, M. Orth, P. R. Russo, and N. Gershenfeld. 2000. E-broidery: Design
and fabrication of textile-based computing. IBM Systems Journal 39, 3.4 (2000),
840–860. https://doi.org/10.1147/sj.393.0840
[15] Afroditi Psarra. 2014. Soft^Articulations. https://afroditipsarra.com/work/
softarticulations
[16] Courtney N. Reed, Sophie Skach, Paul Strohmeier, and Andrew P. McPherson.
2022. Singing Knit: Soft Knit Biosensing for Augmenting Vocal Performances.
In Augmented Humans 2022 . ACM, Kashiwa, Chiba Japan, 170–183. https:
//doi.org/10.1145/3519391.3519412
[17] Irmandy Wicaksono and Joseph Paradiso. 2017. FabricKeyboard: Multimodal
Textile Sensate Media as an Expressive and Deformable Musical Interface .