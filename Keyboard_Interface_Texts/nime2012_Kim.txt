Interactive Mobile Music Performance  
with Digital Compass 
 
Bongjun Kim and Woon Seung Yeo 
Audio & Interactive Media (AIM) Lab  
Graduate School of Culture Technology, KAIST  
Daejeon, 305-701, Korea Republic  
bongjun@kaist.ac.kr, woony@kaist.edu 
 
ABSTRACT 
In t his paper we introduce  an interactive mobile music 
performance system using the digital compass of mobile 
phones. Compass-based interface can detect  the aiming 
orientation of performers on stage,  allowing us to obtain 
information on interactions between performers and use it for 
both musical mappings and visualizations on screen  for the 
audience. We document and discuss the result of a  compass-
based mobile music performance, Where Are You Standing, and 
present an algorithm for a new app to track down the  
performers’ positions in real-time.  
 
Keywords 
Mobile music, mobile phone, smartphone, compass, 
magnetometer, aiming gesture, musical mapping, musical 
sonification 
 
1. INTRODUCTION 
Modern mobile phone s, especially smartphones (i.e., high -end 
mobile phones with advanced features and computing power) 
have affected our life  tremendously in a number of areas, 
including music. With sensors such as m ulti-touch screen, 
accelerometer, microphone, camera, GPS sensor, proximity 
sensor, and magnetometer, a mobile phone has a huge potential 
as a new musical instrument (or, more generally, a music -
making device) . Also, mobile music instruments can be 
networked virtually anywhere without being tethered: this true 
“mobility” allows the performers to move around the stage 
(sometimes totally off the stage) freely while playing their 
instruments, thereby leading to more creative and profound 
interaction design not only with the audience but also between 
performers. 
 Innovative music performance s with creative mobile 
instruments have been suggested by many artists and 
researchers, as reviewed in  [4, 5]. Examples include t he 
Stanford Mobile Phone Orchestra (MoPhO) [6, 11], Michigan 
Mobile Phone Ensemble  [10], and the Helsinki Mobile Phone 
Orchestra [8]. At the Mobile Concert at NIME 2010 , Stanford 
MoPhO presented pieces with several instruments based on  
different interaction concepts, including Colors (multi-touch 
interface), interV (accelerometer), Wind Chimes (compass and 
microphone) [4], and Sound Bounce  (accelerometer and 
compass) [3].  
 In this paper, we suggest an interactive mobile music 
performance using the digital compass on mobile phones. This 
collaborative performance features multiple  performers that 
make sound by taking aim at other  performers: compass-
measured orientation of each aiming gesture  is mapped to a 
specific musical note depending on which player is aimed at . 
While this compass-based i nteraction method is partly similar 
to those examples mentioned above, we suggest a new method 
to “track down ” the position  of a moving performer without 
any extra device (e.g., optical sensors, webcams, etc.): this 
enables us to utilize the information on the on-stage formation 
of performers for musical purpose in real time , making digital 
compass an intuitive, interactive mobile musical instrument.  
2. SYSTEM DESIGN AND 
IMPLEMENTATION 
Figure 1 illustrates the system for our compass -based mobile 
music performance, which consists of multiple mobile phones 
(i.e., Apple’s iPhones) as performers’ instruments and a server 
computer for sound generation and visualization. Sound is 
projected through powered speakers connected to the computer, 
and current status of the performers is displayed on a big screen 
for the purpose of “sharing” the music-making process with the 
audience. 
2.1 Apps 
Mobile apps for this compass-based performance should  be 
able to measure the pointing direction of the iPhone (and send 
the information to the server , if required) . We first used the 
KAMPO App , an OSC controller for mobile music which can 
measure the iPhone ’s sensor data  (e.g., discrete/ continuous 
touchscreen input, microphone, accelerometer, and compass ) 
and transmit them via Wi-Fi [7].  
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
NIME’12, May 21-23, 2012, University of Michigan, Ann Arbor. 
Copyright remains with the author(s). 
 
Figure 1. System for compass-based mobile music 
performance.  
 
OSC Server
(Processing)
Virtual 
Instrument
(Logic Studio)
Server Computer
Musical 
Notes (MIDI)
Compass Data
(OSC messages)
Wireless
AP
Visualization Speaker
Mobile 
Phone 2
Mobile 
Phone 1
 HAM is the other  OSC controller  app used for prototyping 
our second performance. While both apps allow the performer 
to take aim by holding the iPhone horizontally and pointing it 
in any direction, the latter provides additional feature of “hold-
and-move” (hence the name HAM)  for tracing the position  of 
the performer on the move : m ore details  on HAM will be 
discussed in sec tion 3.2 . Both KAMPO App and HAM are 
powered by the Mobile Music (MoMu) Toolkit [2].  
2.2 Server 
The s erver computer  runs a program (written in Processing) 
that receives/analyzes compass data from the iPhones to detect 
any meaningful information, and manages data mappings for 
sound generation and visual display. Similar to  most other 
sensor measurements, compass data values are lowpass-filtered 
at this stage for enhanced stability and practical use in music 
(figure 2). The program can run automatically or  be controlled 
by an operator in order to handle unexpected needs (or 
emergency situations) of the performers in real-time.  
 Information on sound/music is then transmitted to Apple’s 
Logic Studio for sound synthesis by virtual instruments. 
3. PERFORMANCE IDEAS 
We present two cases of compass -based mobi le music 
performance. Both feature 1) multiple performers on stage 
interacting with each other by taking aim s, and 2) musical 
representation of various inter-performer interactions on stage.  
3.1 Case 1: Aiming Directions 
In this scenario, performers stand at fixed  positions (e.g., at the 
corner of a rec tangle in case of four members)  and move their 
iPhones as if scanning around . Each aiming action of a 
performer at other is detected as an “event.” For   performers, 
there are         distinct unidirectional events,          
bidirectional ones, and numerous combinations of those as well 
that can be used to trigger sound outputs and visual effects.  
Figure 3 illustrates possible events in a four-performer case.  
 Based on this mapping we created Where Are You Standing, a 
piece for the KAIST Mobile Phone Orchestra (KAMPO)  [9] 
with tape sound.  It was composed by Bongjun Kim, and 
premiered on June 16, 2011 at Sonic Phone -o-graph, a 
KAMPO mobile music concert held at Hyundai Capital 
Auditorium in Seoul, Korea  (figure 4) [1] (video excerpt from 
this performance can be found at [12]). The  piece is divided 
into four sections – introduction, development, turn, and 
conclusion: each section features different combinations of 
performers and/or harmonic characteristics. T he piece b egins 
with one performer taking aim at various directions to the  tape 
accompaniment in order to “demonstrate” the main gesture of 
the performance . Then in the second  section two other 
performers join the first one, stand at three corners of a triangle, 
and start playing piano sound of all “harmonic” notes (in C 
major scale) by aiming at others. This state of consonance is 
broken by the introduction of an additional (and the last) 
performer who represents conflict: the notes played by this 
performer, as well as the notes played by others when they aim 
at the performer, are assigned to be dissonant  to cause musical 
tension. Finally the last performer leaves the stage to  resolve 
the tension, and the piece ends with three performers back in 
congruity. 
 Table 1 s ummarizes the event -note mapping pairs used for 
the piece. Sound Bounce also featured similar direction-to-pitch 
mappings (in that each of the aiming orientations of performers 
is assigned to a unique pitch), but it was more like an auditory 
display for identification of performers. 
 
 It is noteworthy that current aiming directions of performers, 
not to mention every note event, were all visualized in real-time 
on a big screen as arrows and animated concentric circles 
(figure 5) in order to help the audience to understand the whole 
music-making process clearly and intuitively. 
3.2 Case 2: Aiming with Movement 
The performance mentioned above can be enhanced to be able 
to identify and utilize the position of each performer: in spite of 
certain limitations (e.g., directions of movement, number of 
performers for simultaneous tracking), the same system with 
HAM app allows us to keep track of  performers’ positions on 
stage in real-time.  
 Figure 6 illustrates the mechanism of position tracking. To 
move on stage, a performer should first take aim at the 
Unidirectional 
Event Note Event Note Event Note 
1 → 2 F4 1 → 3 B4 1 → 4 G3 
2 → 1 E4 2 → 3 C5 2 → 4 D#4 
3 → 1 D5 3 → 2 A4 3 → 4 A#4 
4 → 1 F#4 4 → 2 G#4 4 → 3 C#4 
Bidirectional 
Event Note Event Note 
1 ↔ 3 FX Sound 2 ↔ 4 FX Sound 
Table 1. Event-note mapping rules. 
 
Figure 2. Comparison of raw and filtered compass data.  
 
240
250
260
270
280
290
0 10 20 30 40 50
Angle
Time Frame
Original
Filtered
Figure 3. Possible events in a four-player setup.  
 
1 3
2
4
41 ~ : Performers
: uni-direction
: bi-direction
“reference” performer (i.e., the most adjacent performer on the 
left), then choose the direction – either horizontal ( ) or vertical 
(  ) into which he/she would move – by holding the 
corresponding button on screen (figure 7) to enter “changing 
formation” mode. While moving, the performer  should 
continue to point at  the reference so that changes in the aiming 
direction can be measure d, from which current position of 
performer 1         can be obtained by:  
 
                    
                    
 
Currently, only one performer can move at a time.  
 Figure 8 shows an example of change  in the formation of 
performers over time. This variation in positions can also be 
used for musical mappings . For example, distances between 
performers can be mapped to interonset interval  (IOI). In the 
initial formation, distances between adjacent performers are all 
equal and the musical notes assigned to  each performer are 
played at the same interval. As performers start to move, t he 
distances (hence the IOIs of notes ) are change accordingly, 
causing interesting (and complex) rhythmic variations.  
 The scale and the pitch of notes can be controlled by the 
position of the performers, too. Figure 9 illustrates an example: 
depending on the distance from the center of the circle, notes 
played by the performer get higher pitch (or are in a certain 
scale).  
Figure 4. Performance of Where Are You Standing by the KAIST Mobile Phone Orchestra (KAMPO).  
 
Figure 5. Visualization of performer’s aiming directions 
(arrows) and note events (concentric circles). 
 Figure 7. Screenshot of HAM iOS app. 
 
Figure 6. Tracing the location of a moving performer.  
 
1 3
2
4
θ1
(X1, Y1)
(X2, Y2)
n : Moving direction 
  of performers
: compass direction
4. CONCLUSION 
This paper presented an interactive, collaborative mobile music 
performance system based on the digital compass on mobile 
phones. The aiming gestures of performers  (and their 
orientations) not only generate musical events, but also allows 
the audience to appreciate inter-performer interaction s more  
intuitively, especially with real-time visualization of performers’ 
aiming directions on stage to share the “music-making” process.  
Also, by tracing the positions of moving performers only with 
compass, we can design a variety of real -time musical mapping 
strategies with the information on performers’ positions.  
 In addition to the upcoming premier of a new piece using 
HAM and the “aiming with movement ” scenario, we will 
continue our research on the potential of digital compass for 
mobile music, focusing on interaction (between performers) 
and more sophisticated gesture detection.  
5. ACKNOWLEDGMENTS 
The authors would like to thank Jeong-seob Lee, Hyunjung 
Kim, Xuelian Yu, and Seunghun Kim for their performance, 
and Mr. Changyong Eom for his continuous support and kind 
considerations. 
6. REFERENCES 
[1] Kim, B., and Yeo, W. Interactive musical performance 
system using compass sensor in smartphone (in Korean). 
In Proceedings of Korea HCI Conference, Pyeongchang, 
Korea, 2012. 
[2] Bryan, N. J., Herrera, J., Oh, J., and Wang, G. Momu: A 
mobile music toolkit. In Proceedings of International 
Conference on New Interfaces for Musical Expression 
(NIME), Sydney, Australia, 2010. 
[3] Dahl, L., and Wang, G. Sound bounce: Physical metaphors 
in designing mobile music performance. In Proceedings of 
International Conference on New Interfaces for Musical 
Expression (NIME), Sydney, Australia, 2010.  
[4] Oh, J., Herrera, J., Bryan, N. J., Dahl, L., and Wang, G. 
Evolving the mobile phone orchestra. In Proceedings of 
International Conference on New Interfaces for Musical 
Expression (NIME), Sydney, Australia, 2010.   
[5] Tanaka, A. Mapping out instrument, affordances, and 
mobiles. In Proceedings of International Conference on 
New Interfaces for Musical Expression (NIME), Sydney, 
Australia, 2010. 
[6] Wang, G., Essl, G., and Penttinen, H. Do mobile phones 
dream of electric orchestras? In Proceedings of the 
International Computer Music Conference, Belfast, UK, 
2008. 
[7] App Store - KAMPO. 
http://itunes.apple.com/us/app/kampo/id432526049?mt=8, 
recent visit: February 6, 2012 
[8] Helsinki Mobile Phone Orchestra – Helsinki MoPhO. 
http://www.acoustics.hut.fi/projects/helsinkimopho/, 
recent visit: January 31, 2012. 
[9] The KAIST Mobile Phone Orchestra. 
http://kampo.kaist.ac.kr, recent visit: February 5, 2012. 
[10] The Michigan Mobile Phone Ensemble. 
http://mopho.eecs.umich.edu/, recent visit: January 31, 
2012.  
[11] Stanford Mobile Phone Orchestra (MoPhO). 
http://mopho.stanford.edu, recent visit: January 31, 2012. 
[12] Where Are You Standing? 
http://kampo.kaist.ac.kr/pieces/where_are_you_standing, 
recent visit: February 5, 2012. 
 
Figure 8. Changes in on-stage formation of performers 
over time (from top left, clockwise).  
Figure 9. Position-based pitch/scale change.  
 
C
D
E
F
A
B
1 3
2
4
1
3
2
4
n
n : Initial position
: Formation changed