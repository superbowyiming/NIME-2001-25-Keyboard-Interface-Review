The T-Stick: From Musical Interface to Musical Instrument
Joseph Malloch and Marcelo M. Wanderley
Input Devices and Music Interaction Laboratory
Centre for Interdisciplinary Research in Music Media and Technology
McGill University – Montreal, QC, Canada
{joseph.malloch,marcelo.wanderley}@mcgill.ca
ABSTRACT
This paper describes the T-Stick, a new family of digital
musical instruments. It presents the motivation behind the
project, hardware and software design, and presents insights
gained through collaboration with performers who have col-
lectively practised and performed with the T-Stick for hun-
dreds of hours, and with composers who have written pieces
for the instrument in the context of McGill University’sDig-
ital Orchestra project. Each of the T-Sticks is based on the
same general structure and sensing platform, but each also
diﬀers from its siblings in size, weight, timbre and range.
Keywords
gestural controller, digital musical instrument, families of
instruments
1. INTRODUCTION
In addition to the challenges of the ubiquitous “mapping
problem,” Digital Musical Instruments (DMIs) often have
a number of other limiting characteristics. Even the more
robust are often fragile compared to traditional acoustic in-
struments, and almost always the designer/creator must be
present at all demos, practise sessions, and performances.
Of course, sometimes the designeris the performer, but it
is notable that this does not encourage the construction of
DMIs that are mature enough to “leave home.” Also, DMIs
are often unique, which makes for interesting demos, but
how does one learn to play them? Surely the process of
learning to play one new interface would help when learning
a second, leading to some useful pedagogical generalizations
(as in [13]), but what if the next DMI you picked up be-
longed to the same family as one you already knew how to
play?
In this paper we present the T-Stick, a new DMI designed
and built to explore and gain insight into some of these
problems. Like many DMIs, the T-Stick aims to be an in-
terface for “expressive” musical performance, engaging to
new users, but rewarding to practice. The diﬀerence with
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME07, New York, NY , USA
Copyright 2007 Copyright remains with the author(s).
the T-Stick, however, is that it is intended to be a family
of instruments, each of which varies from the others while
still conceptually belonging to a group. Some new interfaces
seem to belong to a family (theSqueezevoxen [2], for exam-
ple), yet often the members are essentially design iterations,
with each one aiming to improve on the last, rather than
coequal members of an ensemble or consort. Currently, two
T-Sticks have been completed, and two more are planned to
form an experimental quartet.
Two existing interfaces are similar in shape to the T-Stick:
Ray Edgar’s Sweatstick designed and built at STEIM [15]
and Rags Tuttle’s Musicpole [11]. This resemblance does
not carry over to sensing-methods, mapping, performance-
practice or design intention.
2. MOTIVATION
The Mapping Problem: Hunt et al., among others, point-
ed out that with DMIs, unlike acoustic instruments, map-
ping between gesture and sound parameters must be de-
ﬁned, and that this task is extremely diﬃcult [4]. There is
no doubt that the mapping largely deﬁnes the user inter-
action and experience, and can “make or break” a poten-
tially interesting user interface. The mapping used for the
T-Stick aims to use the familiarity of the physical world in
the same way that instrument-like and instrument-inspired
controllers are said to leverage pre-existing performer skill.
The T-Stick does not deliberately mimic any existing instru-
ment, but it does have a distinctive “feel” (weight, shape,
and texture). Can we augment this with audible feedback?
Can we use a logical approach to physical sensing of an ob-
ject to create a kind of inherent integrality [5] in the sensor
data output? Is it possible to implement mapping such that
the controller itself is suggestive of the interaction possi-
bilities and sound output? A long cylindrical object was
chosen, and seemed to suggest certain gestures that would
be consistent with excitation, modiﬁcation, and damping of
sound if the object were actually physically vibrating. Sens-
ing these gestures required subtle touch sensing: pressure,
area, pinching, damping, sweeping, striking, brushing would
all be possible if the entire length of the gestural controller
was able to sense multiple touches, and distinguish between
the touch of a hand and that of a single ﬁnger.
What constitutes a family of instruments? Some cite
spectral and temporal features of the sound as the most
important metric [3], where others might consider only the
user-interface (i. e. “keyboard instruments”). Choi focuses
on mapping as the key, considering the collection of local
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
66
relationships between movement-space and sound-control-
space, and the collection of idiomatic gestures learned to
navigate stable areas of these relationships, to be the deter-
mining factor [1]. There is not a consensus on this issue,
however we are more concerned with performer and audi-
ence perception than with terminology, and experimenta-
tion is planned in which mapping, synthesis, and sensing
are altered alone and in combination.
How does all this aﬀect performance practice? Suc-
cess would mean that a prospective performer could quickly
and easily begin to make sense of the interface, using only
their experience of the physical world. The next stage will
be to see if performers can transfer their learned skill to the
playing of another member of the T-Stick family.
Largely, design and construction of the T-Stick is aimed
at producing an interface that performers can take away
with them, connect with no supervision, and then practise
or perform for many hours a day without the device wearing
out or breaking.
3. CONSTRUCTING THE T-STICK
3.1 Hardware
Structurally, the T-Sticks are built using sections of ABS
plumbing pipe, with a 5-centimetre diameter, and varying
in length depending on the member of the T-Stick family
(the original prototype is 1.2m long). The pipes are cut
in half length-wise in order to place sensors, circuitry, and
wiring inside, with sensors aﬃxed to the inside and outside
of this base. The structural part of the interface is intended
to provide a robust platform that protects the sensors from
damage or wear: it is strong and a shrink-tubing cover makes
it mostly water-proof. Covering the sensors and circuitry
also makes the controller less intimidating to performers who
are not technically-savvy, since the only technology apparent
is a USB plug and a single power-status LED. If repairs need
to be made, it is simple to slice and remove the shrink-tubing
cover.
An adjustable steel spike of 0.5 metres in length was in-
stalled in the ﬁrst T-Stick model, enabling the controller
to be rested on the ﬂoor at a comfortable height and per-
formed in a posture somewhat similar to that of a ’cellist
(ﬁgure 1). When retracted, the spike slides smoothly into a
rubber sheath inside the controller, preventing it from rat-
tling or touching sensors or circuit-boards. Since it adds
considerable weight to the controller, the spike is also easily
removable if the performer does not wish to play in this way.
Figure 1: Xenia Pestova playing the T-Stick in
“cello” position during a concert.
3.1.1 Sensors
The T-Stick makes use of a variety of sensors to transduce
performer gestures. One half of the pipe (divided length-
wise) is covered with numerous discrete capacitive touch sen-
sors (48 in the ﬁrst prototype and 32 in the second) formed
with 1/2” copper tape electrodes and Quantum Research
Group QProx QT161 charge-transfer sensor ICs. Together,
these sensors form a low-resolution, completely multi-touch
position sensor spanning the length of the controller (ﬁg-
ure 2). Since the ﬁeld sensitivity of the QT161 ICs must
be set using external capacitors, and varies with the size,
shape, and thickness of the key electrodes, experiments were
performed using a T-Stick mock-up to ﬁnd the right capaci-
tance, and the ﬁeld sensitivity was set so that a touch would
be detected approximately one millimetre above the surface
of the copper tape electrodes. The QT161s are run using
20MHz crystal oscillators rather than the standard 10MHz
in order to increase the responsiveness of the controller.
Figure 2: Graph in Max/MSP showing multi-touch
data over time: two hands brushing the controller.
The circuit boards at each end of the controller each in-
clude an STmicro LIS3L02AS4 3-axis accelerometer. One of
the axes is left unconnected on one accelerometer, since it is
duplicated by the other sensor.
Two home-made paper-based pressure sensors (designed
and built by Rodolphe Koehly [6]) were ﬁxed to the other
half of the pipe, with enough space between them, and at
each end of the controller, for a hand to comfortably grasp
the pipe. The pressure sensors are covered with several thin
layers of closed-cell foam to provide proprioceptive feedback
from what are essentially isometric sensors.
Lastly, a simple piezoelectric crystal is used as a contact
microphone to sense acoustic jarring, bending, and twisting
of the pipe. It is ﬁxed with epoxy adhesive to the inside
of the front surface of the controller (that containing the
capacitive touch sensors).
Sensor outputs are wired to an Atmel ATMEGA16 mi-
crocontroller for sampling, data formatting, and USB com-
munication of the sensor data with a laptop computer [8].
The microcontroller also controls the multiplexers on each
capacitive-sensor circuit board.
Finally, the two sides of the ABS pipe are placed together,
and the entire structure is covered with shrink tubing, pro-
viding both increased strength and protection against wear-
and-tear on the copper strips.
3.2 Software
A framework for Max/MSP software design was developed
based on the “abstracted mapping layers” proposed in [16]
and [4] (ﬁgure 4). A more complete discussion of mapping
issues and a speciﬁcation of the implemented solutions is
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
67
Figure 3: A view of the circuitry inside the original
T-Stick prototype.
available [7]. It is easiest to explain the software developed
for the T-Stick in the context of this framework:
Gesture Information
"Arbitrary" Mapping
Musical Information
Synthesis 
Information
Sensor Information Data-logging & 
playback
Figure 4: The software framework used for the T-
Sticks and other McGill Digital Orchestra DMI’s.
Sensor Information: This layer simply acquires data from
the connected device and performs simple signal-processing
operations such as scaling and smoothing to remove jitter.
Since the digital signals from the capacitive sensors arrive
via USB time-multiplexed in six 8-bit bytes, it is necessary
to unpack them into the individual sensor outputs and route
them appropriately. Every third capacitive key on each half
of the controller is addressed simultaneously by the micro-
controller, and is read as a single byte.
Gesture Information: This layer corresponds to “body-
centred data” in [9] and is derived from the sensor data pro-
vided by the sensor layer. As an example: the sensor layer
outputs the demultiplexed capacitive sensing data, which
takes the form of a list of 48 digital values (0 or 1). The
gesture layer uses this information to calculate higher level
features, and outputs the centre, width, and velocity of each
“area” touched (a series of consecutive capacitive sensors
which have detected touch). This data indicates the move-
ment of the performer’s hands, rather than the state of the
sensing platform, and is also used to sense gripping, brush-
ing, and damping gestures.
Arbitrary Mapping: This layer is where the character of
the musical interaction is determined. Mapping inputs to
outputs in this layer is essentially arbitrary in that the data
itself does not contain information about what it should do.
Mapping at this level could be seen as a matter of personal
taste or bias, however in the case of the T-Stick a commit-
ment exists to make the mapping reﬂect a kind of physically-
informed interaction model, in which a user should be able
to quickly construct a personal model of “how it works”
– a task which is not trivial [4]. It should be noted that
mapping abstracted gesture- and music-layers, rather than
the sensing and synthesis parameters, intrinsically adopts a
many-to-many mapping strategy [4] [16]
Musical Information: This mapping layer makes abstract-
ed, higher-level musical parameters available as mappable
controls. Rather than dealing with frequencies, envelopes,
modulation indexes, this layer takes more abstract musical
parameters as input, such as pitch, timbre, and dynamics.
Synthesis Information: The last layer is responsible for
actually generating audio. Its inputs are speciﬁc to the syn-
thesis method used, and may be highly technical. For the
T-Stick, sound-synthesis has taken many forms during de-
velopment, including control of the Sculpture software syn-
thesizer [12] but more recently using custom-built granular
and modal software synthesizers.
Data-logging & playback: This area of the patch is not a
mapping layer, but rather a means to record the gestures of
a performer and then replay them through the other layers
for reﬁning and adapting the mapping. This allows “oﬀ-line”
editing of the patch when the performer is not present.
4. PERFORMER COLLABORATION
Much of the T-Sticks’ development took place in collabo-
ration with performers in the context of two organised ses-
sions: a seminar taught at McGill, and as part of a larger
project entitled theMcGill Digital Orchestra Project [10].
Many design decisions were made in consultation with per-
formers, such as decisions on the lengths of pipe to use, the
spacing of capacitive sensors, the foam thickness over the
pressure sensors, fret height, the location of fret markers,
and the length and location of the pressure sensors.
The performers also worked very hard helping to establish
notation standards and a vocabulary of gestures idiomatic
to the interface. They lost no time in discovering and mak-
ing use of new playing techniques: subtle twisting of the
gestural controller (which deforms the piezoelectric sensor
intended for sensing velocity of bumps and hits) has now
become a “standard” part of T-Stick performance practise
and pedagogy.
4.1 Performances
To date, the T-Stick has been performed publicly four
times in concert and numerous times in formal and informal
demonstrations. Most recently, on November 19th 2006,
percussionist Fernando Rocha performed a ten-minute piece
written for the T-Stick in a lecture-recital (ﬁgure 5). Rocha
also discussed his experience with the T-Stick in [14].
Three short pieces have been written for the DMI by stu-
dent composers, two by D. Andrew Stewart and one by
Aaron Lindh. Both worked with the performers to develop
standards for notating music for the T-Stick. The Digital
Orchestra Project (mentioned above) will culminate in per-
formances of new works during the 2008 MusiMarch Festival
in Montr´ eal, in at least one of which the T-Sticks will form
part of the ensemble.
5. DISCUSSION: DON’T FRET
The ﬁrst T-Stick featured small fret-like protrusions, be-
tween the positions of capacitive sensors, to allow tactile
navigation of the sensing surface. Some frets were marked
for quick visual navigation, similar to the way harps use red
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
68
Figure 5: Fernando Rocha performing the T-Stick in
concert. Note the diﬀerent playing technique com-
pared to ﬁgure 1.
and blue strings for the pitch-classes C and F. Many diﬀer-
ent materials were tested to ﬁnd the right feel through the
shrink-tubing cover, allowing easy tactile navigation without
preventing the use of smooth brushing gestures.
The second T-Stick does not feature these frets, however,
as it was deemed that their presence encouraged users to
perceive the capacitive-sensing surface as 48 discrete touch
sensors rather than a low-resolution multi-touch position
sensor. As discrete touch sensors, each capacitive sensor
is not very well suited to musical control, especially as they
lack independent velocity sensing - as a single multi-touch
sensor, however, mapping and performance becomes much
more interesting and potentially expressive. Without the
frets, the location of the copper strips is hidden from the
user by the covering of shrink-tubing.
It is hoped that removing the knowledge of sensor posi-
tions will beneﬁt future mapping implementations, as well
as encourage the performers to concentrate on the object
(the interface) or the resultant sound, rather than the sen-
sors. It may seem like a small issue, but considering that
the motivation for building the T-Stick was to use intrinsi-
cally integral sensor data (by attaching many sensors to one
simple object), using the 48 capacitive sensors separably is
essentially opposite to the design intentions.
An interesting dilemma arises: can the present performers
learn to forget their habit of viewing the multi-touch sen-
sor as a sort of slow, non-velocity-sensitive keyboard, or are
fresh performers required for studying interaction metaphor
and the T-Stick?
6. FUTURE DIRECTION
Although the T-Sticks are gaining maturity in that they
have been played for hundreds of hours in the lab, practise
room, and on the concert stage, there are many changes and
improvements to be made. On the purely technical front,
iterative improvements to sampling rates, data throughput
and position-sensing resolution will likely improve the perf-
ormer-experience greatly, without dramatically aﬀecting the
techniques they use. More profoundly, the future comple-
tion of the entire quartet of T-Sticks promises insight into
the portability of skill between members of the family. How
great a change can we make to one T-Stick before “break-
ing” the perception of family resemblance? Is it enough to
change one characteristic (i.e. size, shape, sensing, sound)?
The challenge becomes mapping and giving voices to the
members of the T-Stick family in such a way that they are
complementary musical instruments rather than redundant
copies with superﬁcial diﬀerences.
7. ACKNOWLEDGEMENTS
The authors would like to acknowledge the important con-
tributions of many people to this project, including Sean
Ferguson, D. Andrew Stewart, Fernando Rocha, Xenia Pest-
ova, and Mark Marshall. The ﬁrst author received research
funds from the Centre for Interdisciplinary Research in Mu-
sic Media and Technology, and the second author received
funding from an NSERC discovery grant.
8. REFERENCES
[1] I. Choi. A component model of gestural primitive
throughput. In Proc. of the 2003 Conf. on New Interfaces
for Musical Expression (NIME-03), pages 201–204,
Montreal, Canada, 2003.
[2] P.R. Cook. Real-time performance controllers for
synthesized singing. In Proc. of the 2005 Conf. on New
Interfaces for Musical Expression (NIME-05), pages
236–237, Vancouver, 2005.
[3] A. Eronen. Comparison of features for musical instrument
recognition. In Proc. IEEE Workshop on Applications of
Signal Processing to Audio and Acoustics, New Paltz, New
York, October 2001.
[4] A. Hunt, M.M. Wanderley, and M. Paradis. The
importance of parameter mapping in electronic instrument
design. In Proc. of the 2002 Conf. on New Interfaces for
Musical Expression (NIME-02), pages 149–154, 2002.
[5] R.J.K. Jacob, L.E. Sibert, D.C. McFarlane, and
M.P. Mullen Jr. Integrality and separability of input
devices.ACM Transactions on Computer-Human
Interaction, 1(1):3–26, 1994.
[6] R. Koehly, D. Curtil, and M.M. Wanderley. Paper fsrs and
latex/fabric traction sensors: Methods for the development
of home-made touch sensors. In Proc. of the 2006 Conf. on
New Interfaces for Musical Expression (NIME-06), pages
230–233, Paris, 2006.
[7] J. Malloch. Mapping and routing OSC messages in the
IDMIL. Technical Report MUMT-IDMIL-07-04, McGill
University, Music Technology Area, February 2007
[8] M. Marshall. Building a usb sensor interface. [Online].
Available: http://www.sensorwiki.org/
[9] M.T. Marshall, N. Peters, A.R. Jensenius, J. Boissinot,
M.M. Wanderley, and J. Braasch. On the development of a
system for gesture control of spatialization. In Proc. of the
International Computer Music Conference, New Orleans,
2006.
[10] The mcgill digital orchestra. [Online]. Available:
http://www.music.mcgill.ca/musictech/DigitalOrchestra/
[11] The MUSICPOLE MIDI Controller. [Online]. Available:
http://www.themusicpole.com/
[12] Sculpture. [Online]. Available:
http://www.apple.com/logicpro/sculpture.html
[13] S. Oore. Learning advanced skills on new instruments (or
practising scales and arpeggios on your NIME). InProc. of
the 2005 Conf. on New Interfaces for Musical Expression
(NIME-05), pages 60–65, Vancouver, 2005.
[14] F. Rocha and D.A. Stewart. Collaborative projects for
percussion and electronics. InProc. of the Roots and
Rhizomes Conference, San Diego, 2007.
[15] M. Waisvisz, J. Ryan, and N. Collins. Twenty-ﬁve years of
STEIM, an overture. report, 1993.
[16] M.M. Wanderley, N. Schnell, and J.B. Rovan., eds. Escher -
modeling and performing composed instruments in
real-time. In Proc. IEEE SMC’98, pages 1080–1084, 1998.
Proceedings of the 2007 Conference on New Interfaces for Musical Expression (NIME07), New York, NY, USA
69