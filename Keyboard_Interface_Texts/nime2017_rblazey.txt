Kalimbo: an Extended Thumb Piano and Minimal Control Interface    Rob Blazey Music Department/Culture Lab Newcastle University Newcastle, UK  robert.blazey1@ncl.ac.uk  
    
ABSTRACT Kalimbo is an extended kalimba, built from repurposed materials and fitted with sensors that enable it to function as a reductionist control interface through physical gestures and capacitive sensing.  The work demonstrates an attempt to apply theories and techniques from visual collage art to the concept of musical performance ecologies. The body of the instrument emerged from material-led making, and the disparate elements of a particular musical performance ecology (acoustic instrument, audio effects, samples, synthesis and controls) are juxtaposed and unified into one coherent whole. As such, Kalimbo demonstrates how visual arts, in particular collage, can inform the design and creation of new musical instruments, interfaces and streamlined performance ecologies. Author Keywords NIME, extended instrument, controller, collage, kalimba, thumb piano, reductionist, minimal  ACM Classification H.5.5 [Information Interfaces and Presentation] Sound and Music Computing. 1. INTRODUCTION Kalimbo is an amplified thumb piano, extended with an Arduino1, an accelerometer and a capacitive sensor. These enable it to act as a control interface that is reductionist in design (with no knobs or sliders etc. to interrupt the surface aesthetic) but wide-ranging in its potential control applications, actuated through physical gestures and touch. The work employs the collage techniques of visual artist Eduardo Paolozzi to develop Bowers’ [1] concept of Performance Ecologies: disparate elements of an ecology are combined into one instrument/controller (built from the ‘ephemera of everyday life’ [6]), which allows the player to trigger, abstract, juxtapose and manipulate fragments of live, synthesised and sampled audio into a constantly shifting audio-collage. 2. RELATED WORK Mainsbridge and Beilharz [5] have shown how gestural control interfaces can afford performers ‘sole responsibility over…signal processing,’ embracing rather than limiting physical movements.   Digital Musical Instruments such as Rémi Dury’s Karlax2 demonstrate how accelerometers can be effectively used in gestural control systems while addressing the ‘split between interface and sound engine’ that Magnusson [4] identified as problematic in electronic music performance.    The versatility of capactive sensor-based control systems has been explored by many members of the NIME community, including Gerhard and Park in their IIA project [3]. 
                                                                    1 Arduino / https://www.arduino.cc/  2 Rémi Dury / Da Fact: http://www.dafact.com 
 Amongst others, Bowers et al [2] have explored approaches to control interfaces that are reductionist in design, y e t  w i d e-reaching in scope of possible concurrent control applications.  Meng Qi3 h a s  d e v e l o p e d  s e v e r a l  k a l i m b a s  w i t h  b u i l t-in hardware audio effects and controls.   Kalimbo builds on these concepts, using accelerometer and capacitive sensor data to create a flexibly-mapped, reductionist control interface combined with a traditional acoustic instrument. A collage-based approach  is employed in unifying disparate elements of a musical performance ecology, thereby addressing the problematic interface/sound engine split identified by Magnusson.  3. INSTRUMENT DESIGN The instrument body was designed and built using collage-based, material-led techniques, repurposing parts with a complementary aesthetic that were either found or obtained cheaply from builder’s merchants.  
 Figure 1. Kalimbo and sensor system in progress. 3.1 Instrument Body The chrome-finished bicycle spokes that became the tines of the instrument informed the aesthetic of the rest of the build; the resonating body is a steel sandwich tin, mounted with three steel cupboard door handles that form a sturdy adjustable bridge. 3.2 Sensors and Electronics A humbucker guitar pickup provides a clean amplified signal from the tines. This was deemed preferable to a contact microphone as it eliminated unwanted t h u d s  a n d  s c r a p i n g  n o i s e s  c r e a t e d  b y  t h e  players’ hands in contact with the instrument body.    An Arduino mounted inside the body of the instrument is connected to a 3-axis accelerometer and a capacitive sensing wire, attached to the insulated upper bridge of the instrument in such a way that the exposed outer faces act as touch-sensitive triggers or controls.                                                                     3 Meng Qi / https://www.mengqimusic.com/ 
501
 
 Figure 2. Insulated capacitive-sensing bridge (left). 3.3 External Connections The instrument’s magnetic pickup links to an audio interface via a 1/4" jack socket and instrument cable. Sensor data is sent as OSC messages from the Arduino to a laptop through a USB 2.0 cable.  For the purposes of this performance project, a Korg NanoKontrol is used for additional control of audio outputs and delay lines. 4. Playing the Instrument The instrument is played like a standard thumb piano, holding the body between both hands and plucking the tuned tines with the thumbs. Actuating the sensors by moving the instrument throughout 360 degrees and touching the capacitive sensing bridge does not compromise this playing position, providing a wide range of gestural control applications with minimal interference to surface aesthetic and playability. Unique a f f o r d a n c e s  o f  t h i s  c o l l a g e-based approach are revealed as the player navigates archives of found-sounds, fragmenting and juxtaposing them to construct ever-shifting beats and soundscapes. In keeping with collage, the instrument promotes an exploratory, finding-through-making approach to improvisation. 4.1 Software and Control OSC messages from the Arduino are unpacked within a Pure Data patch, using the OSCuino4 library to separate the data into one stream for each axis of movement (x,y and z) and one for the c a p a c i t i v e  sensing bridge. These in turn are converted into midi triggers and controls for versatile mapping in Mainstage5. The most commonly used controls are as follows: -The capacitive sensor acts as a midi control and note-on message. -Tilting front-to-back manipulates another midi control. -Tilting left-to-right manipulates three midi controls (centre-left, centre-right and left-right) and triggers several ranges of midi notes (multiple octaves of pentatonic notes in tune with the physical instrument and a chromatic range to trigger drums or percussion).  Within Mainstage, several sound sets are made up of 3 channels/elements each; a midi synthesiser or tonal sampler channel, a drum or percussion-based sampler channel and an audio channel for the thumb piano pickup and/or other external sound sources. Each channel has a dedicated delay line and NanoKontrol assignments for volume, delay send, delay feedback and delay time.  Multi-mapping of midi controls allows for complex musical gestures to be performed through simple movements; in one instance, a midi synthesizer is triggered across a pentatonic scale by tilting the instrument left and right. Tilting forwards opens a low-pass filter and increases vibrato amount and rate. Touching the capacitive-sensing bridge sends the output to a multi-tap delay pitched up one octave. As such, synthesizer pitch, filter, vibrato and effects can all be manipulated separately or together through a range of simple movements that do not hinder playing of the physical instrument.  5. CHALLENGES AND LESSONS Due to the close proximity of the magnetic pickup, Arduino and sensors, digital interference with the audio channel proved difficult to                                                                     4 OSCuino / https://github.com/tambien/oscuino  5 Mainstage / http://www.apple.com/lae/mainstage/  
eliminate e n t i r e l y .  A  p i e z o  i n  p l a c e  o f  t h e  h u m b u c k e r  s o l v e s  t h e  problem, but results in increased body noise. However, this could be embraced to harness the percussive potential of the instrument.  Controlling volume levels and delays requires one hand to be removed from the main instrument to manipulate the NanoKontrol. All sensor controls can still be easily manipulated with one hand but playing the tines is difficult when doing so. A more elegant solution would be to incorporate slider and button controls into the body of the instrument at the players’ fingertips.  This particular setup is based upon a pentatonic tuning within one key. While this is complementary to the tuning of the physical instrument, it does limit the potential of harmonic variation. 6. FUTURE WORK Subsequent incarnations of Kalimbo will address the above issues and explore different objects and materials for the instrument. Bridge mechanisms are also being developed to enable easier tuning of tines. Mainstage mappings, sounds and samples for the p r o j e c t  a r e  a l s o  being developed, although an entirely embedded system (based in Pure Data, running on an internal single-board computer) could be beneficial in developing and streamlining the concept.  The OSC data transmitted from the Arduino is far richer than the 0-127 range of midi used in this instance. I am exploring further potential creative uses of this within Pure Data. For example, I found that multiple capacitive sensors in one instrument interact to give pleasantly unpredictable results, vastly increasing ranges of data as multiple sensors are touched at once. Control patches exploiting these characteristics will augment Kalimbo’s control capabilities.  Kalimbo’s simple sensor-based controls, in conjunction with a contact microphone, could be developed into a stand-alone ‘extender’ to furnish any instrument with gestural and touch-sensitive controls. Alternatively, the controls could be developed independently into an ergonomically designed minimal interface with multiple applications.  Future work will further interrogate affordances of collage-based approaches to performance; assembly of performance ecologies made from disparate materials and performance tools will become a vital performative act in itself, enhancing performance narrative and providing audiences a legibility of form. Combined with Kalimbo and other sensor-based controls, this will enable an approach in which a unique ecology is formed within each performance.  7. REFERENCES [1] J. Bowers: Improvising Machines - Ethnographically Informed Design for Improvised Electro-Acoustic Music. Norwich: University of East Anglia, 2002. [2] J. Bowers et al, “One knob to rule them all: reductionist interfaces for expansionist research,” in Proceedings of the international conference on new interfaces for musical expression, Brisbane, Australia, 2016, pp. 433-438.  [3] D. Gerhard and B. Park, “Instant Instrument Anywhere: a self-contained capacitive synthesizer,” in Proceedings of the international conference on new interfaces for musical expression, Ann Arbor, Michigan, 2012. [4] T. Magnusson. Designing constraints: Composing and performing with digital musical systems. Computer Music Journal, 34(4): 62–73, 2010. [5] M. Mainsbridge and K. Beilharz, “Body as instrument: performing with gestural interfaces,” in Proceedings of the international conference on new interfaces for musical expression, London, United Kingdom, 2014, pp. 110-113. [6] E. Paolozzi, “The Development of the Idea,” exhibition catalogue, 1979. 8. Appendices  Video abstract / https://www.youtube.com/watch?v=zyJFihBKXrE  Research blog / http://mrblazey.tumblr.com/
502