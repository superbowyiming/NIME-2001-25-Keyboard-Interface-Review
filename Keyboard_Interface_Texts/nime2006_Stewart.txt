SonicJumper composer
D.  Andrew Stewart
Schulich School of Music
McGill University
+1 514-845-0766
dandrew.stewart@mcgill.ca
ABSTRACT
This document describes the implementation of  the 
SonicJumper gestural controller bodysuit in a compositional 
context.  It is a tool for generating musical materials, which are 
then used to compose a piece of  music.  The emphasis is on 
integration of gestural controllers at the earliest stage of  the 
compositional process, rather than at the end.  That is to say, the 
following discussion centers on controllers as a tool for creating 
musical material, and not as instruments for a performance.  An 
effective compositional tool provides the composer with a 
manner of  producing materials that have an inherent musical 
quality lending themselves to the formation of  musical 
messages, which are then organized into a meaningful 
compositional whole.  The author regularly incorporates the 
SonicJumper into his compositional process, generating 
materials for mixed works—compositions for ensemble and 
electronics.
Keywords
composition, process, materials, gesture, controller, cross-
modal interaction
1.  INTRODUCTION
There has been a strong push to extend musicians’  potential for 
musical expression, via gestural controller technology.  
Amazingly, this propulsion has lead to a wealth of new research 
linking musical expression to such things as:  new instrument 
design and control;  redefining performance practice;  gesture 
analysis and classification;  gestural acquisition;  music 
cognition and other branches of psychology.  At the same time, 
the ultimate question still remains unanswered:  Can gestural 
controllers be successfully woven into a musical fabric, such 
that the technological aspect is far less significant than the 
overall musical experience?  Moreover, might the inclusion of 
gestural controller technology into a musical domain lead us to 
a new Art form?  These questions highlight the author’s 
principal focus.  He postulates that the answers lie in our ability 
to create a musical whole.  That is to say, electroacoustic 
elements and human expression are integrated—creating a 
musical whole—if  they are perceived as inextricable.  A 
successful composition, including work in other Art forms, is 
one in which the artist unifies materials.  Materials are all 
aspects of a work that are cognitively perceptible.  In particular, 
the manner in which materials are created, must be directly
Permission to make digital or hard copies of all or part of  this work for 
personal or classroom use is granted without fee provided that copies 
are not made or  distributed for proﬁt or  commercial advantage  and that 
copies bear this notice and the full citation on the ﬁrst page. To copy 
otherwise, or republish, to post on servers or to redistribute to lists, 
requires prior speciﬁc permission and/or a fee.
NIME 06, June 4-8, 2006, Paris, France.
Copyright remains with the author(s).
linked to their final presentation.  This is obvious to a great 
extent in the visual Arts.  Most music is also generated with 
clear evidence concerning its impetus—often drawn from 
codified stencils dictating formal design and pitch logic.  The 
inclusion of technology into a musical work, however, creates a 
number of dilemmas surrounding the initial generation of 
materials.  The immediacy at which technology so readily gives 
us an ‘output’ does not often encourage an exploration into 
where the output comes from or how it is generated.  This 
potentially drives a wedge between the materials of the work 
and the composition’s final form:  its presentation in the context 
of a public performance.  If  a ‘whole’ musical experience is to 
be created, the technological aspect must be a part of  work’s 
initial development.  It is the objective of this document to 
identify how the SonicJumper generates material in the earliest 
stage of  composing, unifying the piece right from  the get-go.
2.   MALLEABLE GESTURAL 
CONTROLLER
2.1  Components
Four accelerometers (± 2 G.), five potentiometers (measuring 
bend from 0° to 130°), one infrared proximity sensor (80 cm.) 
and an orientation sensor (360°) sense body movement.  
V oltage values from  these sensors are converted to MIDI.  Max/
MSP interprets and maps sensor data, controlling digital signal 
processing.  The sensors are held in place using various types of 
sport braces—stretchable bands of  fabric that comfortably fit 
around the body and do not limit movement.  The voltage to 
MIDI convertor rests in a belt pouch along with its portable 
power supply.  One long MIDI cable connects the convertor to 
a computer.  Sensor placement is somewhat different for each 
project.  It is for this reason that the jumper is considered a 
malleable controller—it shapes itself according to the 
movement requirements of each project. [1]
2.2  Synthesis Engine
Data from  sensors are sent to Max/MSP, for digital signal 
processing.  The sensors are not transmitting "one-off" triggers;  
rather, they are sending variable signals in real-time.  The Max 
patch is based on granularized, by les & zoax, in which a signal 
"scrubs" through a buffer~ object at a user-defined rate. [2]  
Common effects associated with granular synthesis are 
achieved (i.e.  time and pitch scaling).  In addition, the Max 
patch is expanded to include various filtering objects, which are 
used to balance signal output—as opposed to creating effects 
such as chorus and delay.  The engine is not necessarily meant 
to produce a specific style of  composition.  It is not meant to 
generate, say, 12-tone music or formulaic commercial music.  
The aim  is to tap into the composer’s expressiveness in a 
manner that is impossible with more traditional compositional 
tools (i.e.  piano), and to offer users a sound palette that is 
representative of the wide-open sound world of electronics—
both mimetic and abstract.
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
103
Figure 1.  The ﬁrst three feints.
2.3  Mapping the Movement Repertoire
Sparring rationale is used to develop the movement repertoire 
and sensor to signal processing mapping.  In this way, the 
SonicJumper is a symbolic immersive controller. [3]  There are 
five movement categories representing the tools of combat:  
feinting;  drawing;  leading;  infighting;  parrying.  Figure 1 
shows the first three feints.  Each category contains a collection 
of precise coordinated head, arm, hand, torso, etc., movements
—organized according to the expanse of  the gesture 
(see Table 1).  In total, there are 18 distinct movements.  
Mapping is derived to suit the movement repertoire.  That is to 
say, instead of tailoring the repertoire to a fixed, rigid 
association to sensor data, mappings vary for each movement. 
For instance, the subtle action of the first feint (F1) only entails 
mapping the scrub start and end position (within buffer~) to left 
hand rotation and left elbow bend, respectively.  On the other 
hand, the second feint (F2) entails a more complex mapping:  
start position to right elbow bend;  end position to left elbow 
bend;  lower limit of pitch-scaling to left hand rotation;  upper 
limit of  pitch-scaling to proximity of hand(s) to chest.  For the 
most part, mapping is one to one, with a few examples of 
divergent mapping.  For instance, the first parry (P1) involves a 
subtle rotation of  the head.  In this case, data from the 
orientation sensor is mapped to almost all granularization 
parameters.  
3.  SONIC-JUMPING
3.1  Cyclic Relationship
The core concept behind sonic-jumping is cross-modal 
interaction.  The composer is spurred on—in particular, by aural 
and proprioceptive stimuli—to digest and produce sound in a 
cyclic manner.  One can conceptualize the ‘path of sound’  as:  
out of an electronic system - into the human physiological 
system - returning to the electronic system.  For example, an 
electronic sound is produced by a computer.  Then, the ears 
receive the sound.  A meaningful message is perceived (through 
cross-modal sensory data).  Next, a movement impulse is 
manifested.  The computer interprets user movement (via a 
gestural controller bodysuit).  Movement data generates an 
electronic sound.  For the most part, a composer’s 
manipulation, or directing, of sound in this fashion, is 
unconscious.  They do not naturally analyze the gestures they 
make in relation to aural stimuli.
3.2  Sound Movement Combinations
A work of Art conveys a message that is more or less clear, 
based on the way the message's meaning is distilled, generally 
speaking.  Messages are anything that have either abstract or 
literal meaning for the onlooker.  The aspiration of any artist is 
to provide clarity so that an audience can extract and refine 
messages.  Providing clarity in a piece of music can be 
particularly difficult, because musical sounds are ephemeral.  
That is to say, music is a time-based Art form, with sounds only 
occupying enough time for them to be heard.  A sound does not 
rest in one place, as a painting hangs on the wall for the 
duration of  its exposition.  The SonicJumper approach to 
creating clarity involves attaching a gestural component to each 
sound, or a sound to each gesture (refer to Cyclic Relationship, 
above).  For the composer, the invention of  a movement 
element gives new meaning to the sound / movement 
combination.  The composer gradually establishes a somatic 
relationship between the two.  This is followed by the formation 
of musical messages as the composer organizes somatic 
meaning.  The suggestion here is that by infusing musical
Table 1.  Five movement categories showing minute movements to expanded movement from top to bottom.
Expanse
minute
expanded
Feint Draw Lead In ﬁghting Parry
F1 - subtle D1 - subtle P1 - subconscious, 
self-preserving
F2 - false start, stunted D2 - deceptive, with 
purpose
F3 - deceptive, with 
purpose
D3 - luring, enticing I1 - reactive
F4 - reactive D4 - expressive, 
engaging
L1 - expressive, 
engaging
I2 - expressive, 
engaging
P2 - evasive, escaping,  
disengaging
D5 - impressive, 
reﬁned
L2 - assertive, direct P3 - impressive, 
reﬁned
D6 - demonstrative, 
exaggerated
L3 - demonstrative, 
exaggerated
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
104
materials with a somatic significance, at the earliest stage of 
composition, the composer creates repercussions for the 
presentation of  the work, in front of  an audience.  They also 
create structural threads that are used to make the piece of 
music a unified whole.  The notion of music combined with 
movement, or visa versa, is currently under investigation;  and 
results are far from conclusive.  In explaining the origins of 
somatic meaning, while sonic-jumping, this author favors one 
of the oldest investigations in experimental psychology 
concerning the nature of  cross-modal sensory interactions—the 
degree to which information from  one sensory channel 
influences our interpretation of information arising through 
other sensory channels. [4]  Cross-domain mappings, enable us 
to perceive intensity, spatial location, tempo and rhythmic 
structure in an amodal manner.  These abilities, moreover, 
appear to be innate or develop early and rapidly in human 
development (Lewkowicz, 2000). [5]  There are other plausible 
explanations explaining our propensity to combine sound and 
movement.  One could begin with a Darwinian perspective, 
which suggests that our internal sense of self-motion may have 
evolved in early hominids to deal with sounds in the 
environment. [6]  We could also consider artistic emotion and 
expression.  Davies (1994), suggested emotions are presented 
directly in the musical work through dynamic parallels to 
human movement, behavior, physiognomy, the human voice, 
gait and the like. [7]  It is likely that all of  the above viewpoints 
play a role in establishing meaning in sound / movement 
combinations.  It is not the objective of  this paper to establish 
which opinion is accurate;  rather, the author wants to 
acknowledge the inextricable relationship between sound and 
movement, and state that this association is an intrinsic element 
of the SonicJumper.
3.3  Generating and Saving Musical 
Materials
Composers use different terminology to explain the earliest 
activity leading to an original work.  Some may refer to a 
formulaic approach.  Others might describe a rigorous pre-
compositional process.  Yet, other composers talk about the 
fruits of noodling on the piano, or improvising.  What is 
happening, at this early stage, is the initial concretization of 
creative thought in the form  of  musical materials.  The result is 
often a manuscript of  some sort.  Rigorous planning—much 
formulaic designing—goes into establishing the “voice” and 
“action” of the SonicJumper, before beginning to generate 
materials.  V oice is akin to the controller’s synthesis engine, 
while action is a result of mapping.  Once voice and action are 
established, the user produces and digests sound in the manner 
described above, making decisions on-the-fly based on musical 
intelligence and intuition.  The Max/MSP patch records both 
voice and action data, using a standard audio file format.  In 
this way, the sounds of the voice are audio files, while action 
data more resembles a wavetable—one for each sensor output.  
One consequence of recording action data, is that the user is 
able to take “snapshots” of a particular movement.  Then, the 
data can be used to duplicate signal processing (i.e.  granular 
synthesis) on several different audio files, without the user 
having to set up the SonicJumper controller.  This is 
comparable to transforming themes and harmonies via a 12-
tone row table.  The voice data—actual audio files—is 
transcribed into traditional musical notation either using the 
composer’s ear or via computer-assisted compositional software 
(i.e.  AudioSculpt by Niels Bogaards and others;  OpenMusic 
by Gérard Assayag and Carlos Agon).  It would be interesting 
to draw a comparison to other modes of  composing.  In some 
respects, SonicJumper composing is not far removed from 
traditional approaches, such as working out material while 
sitting at the piano.
4.  CASE STUDY
In the fall of 2005, D. Andrew Stewart was commissioned to 
create a work for the Dutch ROSA Ensemble—tenor 
saxophone;  electric guitar;  bass guitar;  piano;  percussion;  
processed audio and live-audio streaming.  Musical material for 
both pitch organization and processed audio was generated with 
the SonicJumper—based on sampled audio from early 1970s 
funk music.  The composer set himself  the task of ‘entering’  the 
SOUND WORLD of funk music, without necessarily evoking 
the funk idiom.  It is important to point out that entering the 
funk sound took place at the earliest stage of composition 
(generating materials with the SonicJumper).  The 
performances of the work remained in a similar sound world.  
The result, therefore, was a piece of  music with a sense of 
whole, from it’s inception to its realization.  
5.  CONCLUSION
There is no greater joy during the compositional process than to 
realize you have successfully captured what is in your head, in 
your ear or that which your creative spirit compels you to say.  
Indeed, composers make great effort over an entire lifetime—
often unsuccessfully—to manifest their true musical thoughts in 
an aural form.  The challenge is immense;  many fail because 
there is no exact music to capture an artist’s thought or feeling.  
On the other hand, we find ourselves in a unique position of 
being able to seize certain modes of communication, for the 
first time.  Technology that can catch, examine and reproduce 
gesture brings us a few steps closer to tapping into learned and 
unconscious behaviour.  If  a composer is willing to use 
technology, there is a strong argument for the use of  gestural 
acquisition for communicating creative thought;  or at least, one 
is able to examine the relationship between gesture and creative 
impulse.  In the early days of analog studio composition, Hugh 
LeCaine describes an interaction where the studio composer has 
intimate control of  the musical outcome—the composer is 
closer to sound. [8]  The SonicJumper reexamines the notion of 
proximity.  Not only does the jumper bring its user nearer to a 
desired sonic result, it also allows for immediate realization of 
the creative impulse.  If  one could derive a maxim  concerning 
gesture and creativity, the statement would go far in forwarding 
the idea that gestural controllers can be successfully woven into 
a musical fabric, such that the technological aspect is far less 
significant than the overall musical experience.
6.  REFERENCES
[1] Stewart, D.  Andrew, composer.  “Stewart Sonic Jumper,”  home 
page  <www3.sympatico.ca/andrew.stewart/pages/sj/jumper.html>  
March, 2005.
[2] Stuck, Les and Richard Dudas,  engineers, Cycling74.  
“granularized,”  Max/MSP patch designed for granular synthesis, 
2003.
[3] Mulder, Axel G. E..  “ Towards a choice of gestural constraints for 
instrumental performers,”  Trends in Gestural Control of Music  
CD-ROM,  eds.  Marcelo M. Wanderley and Marc Battier.  Paris:  
Ircam—Centre Pompidou, 2000.
[4] Vines, Bradley W. and others.  “Cross-Modal Interactions in the 
Perception of Musical Performance,”  This article was submitted 
in partial fulfillment of the requirements for the Ph.D. in 
Experimental Psychology from McGill University by the first 
author  (McGill University, April, 2005).
[5] Seitz, Jay A.  “Dalcroze, the body, movement and musicality,”  
Psychology of Music, 33(4),  2005.
[6] Ibid
[7] Ibid
[8] LeCaine, Hugh. “Synthetic Means”, The Modern Composer and 
His World, eds. John Beckwith and Udo Kasemets. Toronto: 
University of Toronto, 1961.
Proceedings of the 2006 International Conference on New Interfaces for Musical Expression (NIME06), Paris, France
105