Chimera: Prototyping a New DMI for Congenital One-Handed Musicianship Through an Autoethnographic Lens     Mat Dalgleish Games Institute  University of Staffordshire  Stoke-on-Trent, United Kingdom mat.dalgleish@staffs.ac.uk  
     
ABSTRACT Chimera is a Digital Musical Instrument (DMI) prototype developed through an autoethnographic lens. That is, a lens shaped by congenital one-handedness as well as extensive experience as both a disabled player of standard instruments and a designer of DMIs for other players. Leveraging Eurorack synthesizer modules as a flexible prototyping toolkit enables an iterative prototyping process that explores the distinctive possibilities of one-handed musicianship. Reflection on a three-month period of iteration and refinement highlights a series of design issues, but also the interconnectedness of physical impairments, and the difficulties of designing for a body in flux. Some directions for future work are outlined. Finally, by discussing the various entangled layers of this instrument prototype and starting to tease out what Koutsomichalis calls its “stories of a sort”, this paper contributes an until now underrepresented perspective to the dialogue around accessible and inclusive musical instrument design, and disability and musicianship more broadly. Author Keywords DMI prototyping, physical disability, Eurorack, autoethnography 1. INTRODUCTION The development of accessible digital musical instruments predates NIME [1] by almost two decades. Early examples include Gehlhaar’s SOUND=SPACE [2], first exhibited in 1985, and the related but simplified Soundbeam system, described by Swingler as an “elastic keyboard in space that allows sound to be created without the need for physical contact with any equipment.” [3] Accessibility-focused digital musical instruments have also regularly featured at NIME. However, Zayas-Garin and McPherson note that new instruments intended for disabled players have only rarely meaningfully involved disabled people in their creation [4], and thus fail the principle of Nothing About Us Without Us [5].  From the live electronics of David Tudor to the cybernetic instruments of Gordon Mumma, designer-performers emerged in the earliest days of live electronic music [6]. Digital musical instrument (DMI) designer-performers also substantially predate NIME.  Examples again include Gehlhaar [2], but also Waisvisz [7], Rokeby [8], and Sonami [9]. In addition to designer-performers being some of the first contributors to the NIME conferences, the “inside” perspective of the designer-performer [10] has continued to be a significant presence at NIME in subsequent years. While Marquez-Bourbon and Stapleton highlight that, regarding why many NIME remain one-offs that do not become more widely available, “[t]he ‘N’ in NIME itself is perhaps partially to blame” [11], the enduring prevalence of designer-performers is another likely factor. Designer-performers usually design new instruments solely for their own use, 
as an extension of their personal creative or performance practice [12], and as a result, these instruments are not more widely available.  Despite the prevalence of designer-performers more generally, McMillan’s autoethnographic accounts are notable in part because of a lack of accounts by other disabled people. Initially a non-disabled saxophonist studying at an Australian university, McMillan became a DMI performer and designer after an accident [13][14]. This paper is structured as follows. The next section explores the personal background and motivations that prompted and informed the development of a new instrument. Subsequent sections focus more specifically on one-handedness, prior to discussion and reflection on a Eurorack-based prototyping process. 2. BACKGROUND AND MOTIVATIONS Chimera, introduced in this paper, is rooted in the author’s musical, life, and research experiences. Given its personal nature, this section continues in the first person. A useful point of departure is to emphasize that my own perspective differs from that of McMillan [13] in that my disability is congenital rather than acquired. More specifically, I was born with only a right hand (along with a thumb-like digit near my left elbow) as well as complex orthopedic conditions affecting both lower limbs.  Retrospectively, I can see that many of my earliest experiences are rooted in the medical model of disability, also known as the functional limitations model [15]. The medical model contends that disability exists within the body or mind of the individual, and that people are disabled by medical conditions [16]. Thus, the individual requires treatment to ‘fix’ the disability and restore normality. Where this is not possible, the aim is to achieve functionality despite the disability [17].   At the age of two I underwent some 14 hours of orthopedic surgery, but contrary to typical treatment for bilateral fibular hemimelia, my lower limbs were not amputated below the knee. Following a year immobilized, I learned to walk with the aid of prosthetics and, for the next two decades, I experienced few medical issues. Although it went unquestioned at the time, reflecting now, this focus on my lower limbs meant that the implications of my one-handedness were overlooked.  With the condition of my lower limbs “stable and predictable” [18] for an extended period, social factors became more prescient. The social model of disability was developed by the disability rights organization the Union of the Physically Impaired Against Segregation (UPIAS) [19]. A reaction against the medical model, the social model argues that people are disabled by the barriers created by society [20]. It also initially emphasized that all bodies have impairments, but only some impairments are considered disabilities. The social model has been widely adopted by disability organizations, although some limitations have been identified [18].  While recognizing that congenital disability in general is often more stigmatized than acquired disability [21], I have long found it fascinating how certain musical instruments are also stigmatized differently in relation to disabled players. I started to play the trumpet at the age of six and received individual tuition at school. Although the trumpet was not necessarily my choice of instrument, I enjoyed most aspects and played in numerous school and regional ensembles. By the 

age of eleven, however, the trumpet no longer fully fitted with my burgeoning musical tastes, and the requirement for formal attire challenged a body that did not conform to conventional norms. Thus, I also started to learn the electric guitar. I could not find a local tutor, but a standard left-handed instrument was, unexpectedly, a very workable fit for my right hand and left thumb/elbow (Figure 1). I was struck by how playing the guitar in public often elicited disapproval, as similar responses never encountered while playing the trumpet.  
 Figure 1. The author playing electric guitar.  After three years studying sculpture, an MA in Media Arts unexpectedly reimmersed me in many of these issues. Supervised by composer Rolf Gehlhaar, I learned to code and, in meeting former trumpeter Clarence Adoo, discovered how instrument design can be transformative.  I have since designed musical instruments, interfaces, and interactive installations for a diverse range of players and participants, including those with physical and sensory disabilities. I didn’t set out to create an instrument for myself, but as my orthopedic conditions deteriorated and playing existing instruments became uncomfortable, my focus eventually shifted. Perhaps there is a degree of inevitability to this, for as Freire and Reed put it [22], “Like trees, our living bodies are inconsistent, dynamic, and unpredictable, taking on strange and often uncomfortable qualities. In shaping our experience of the world, so too do our bodies shape our musicking.” 3. ONE-HANDEDNESS Beyond the specifics of my own disability, Upper Limb Impairment (ULI) can be congenital or acquired, unilateral or bilateral, functional or structural, temporary or permanent [23]. Huisstede and colleagues found that the prevalence of ULI varied between 2% and 53%, depending on the population surveyed [23]. Historically, opportunities for one-handed players have been limited. Almost all traditional instruments assume the player has two dexterous hands. While many of these instruments evolved over extended periods [24], it is only after the design stagnation following the late 18th century [25] that these designs have mistakenly been considered optimal. Instead, their evolution has always been driven primarily by acoustical factors [26], and the physical and mental demands placed on players can be exclusionary.  Nevertheless, by chance, a few (unmodified) traditional instruments can be played effectively one-handed. Examples include the harmonica, melodica, and, arguably, the piano [27]. A small number of traditional instruments, for example the trumpet and trombone, are also relatively easily adapted for one-handed use [28]. There are also examples of one-handed musicians who have found ways to play standard instruments that are usually considered inaccessible. [29].  History offers several examples of (then) new instruments that initially found some success but eventually faded into obscurity. Repertoire is largely beyond the scope of this paper, but the availability of suitable repertoire is well established as an important factor in influencing which instruments survive in a social sense. As Vasquez 
et al. put it, “building and maintaining a repertoire for them reflects a historical practice to make this happen.” [30] While musical repertoires, like traditional instrument designs, almost all assume that players are two-handed [27], a notable excretion is the development of substantial one-handed piano repertoire in the late 19th and early 20th centuries [31].  Today, there are an increasing number of one-handed players, but they are likely significantly outnumbered by potential players. For instance, based on information sourced from the NHS, WHO, and relevant disability organizations, an Independent Society of Musicians (ISM) article estimates that “around 640,000 people in the UK alone would play an instrument if they could; that is, were it not for their [upper limb] disability.” [32] 4. DESIGN CONSIDERATIONS Chimera is a new instrument primarily designed for my own use. As such, it is shaped by my specific body and needs, but it will inevitably also reflect the music I want to make. At the same time, I cannot avoid its potential (however modest) to subsequently act as a vector for the other one-handed players and potential players mentioned above. With this duality in mind, the lines of design enquiry that underpin the new instrument include:  1. What are the distinctive possibilities of one-handed instrument use? 2. How can prototyping support malleability and exploration? 3. How do entangled layers of influence contribute to instrument narrative? 4.1 One-Handed Instruments It often goes unquestioned that an overarching aim of many new instrument intended for use by disabled players is to equal or get as close as possible to two-handed player-instrument relationships and associated performance techniques. Larsen et al. explicitly state that: “We purposefully aim our development at traditional guitar bodies, thus enabling users to develop skills that are as close to the normal techniques as possible” [33], but similar tendencies are ingrained elsewhere. For the author, this is (too) closely related to the propensity for narrative prosthesis identified by Mitchell and Snyder, whereby disability is framed as a disorder that must be “rehabilitat[ed] or fix[ed]” before a story can be considered fully resolved [36]. Looking at human-technology interaction more broadly, however, Buxton reminds that “there are many circumstances under which two-handed techniques can be worse than one-handed techniques.” [34] To draw on Feldman’s famous quote [35], what music might emerge organically from the one-handed performer’s interplay with the instrument, without pressure to mimic two-handed techniques? Thus, despite the potential for the baggage of traditional instruments to have lingering influence on DMIs, this project seeks to move beyond it to explore the distinctive potential of one-handed musicianship. 4.2 Eurorack as Prototyping Toolkit Buxton makes a useful distinction between sketching and prototyping, distinguishing sketches as early, evocative tools, and prototypes as later, more specific and testable [37]. Other researchers have emphasized the messiness of sketching compared to the iterative refinements of prototyping [38]. For example, Moussette and Dore’s concept of sketching in hardware (SiH) aims to blur the line between the two in some respects [39]. Typically relying on the use of prototyping toolkits, SiH emphasizes not only the rapidity and disposability of sketching, but also its material qualities.  Eurorack is a modular synthesizer format introduced in 1996 by Doepfer Musikelectronic with the A-100 system [40]. Thousands of compatible modules have since been developed [40]. In a production landscape dominated by effortless digital tools, a significant part of the renewed appeal of the modular synthesizer is how its tangible interface engages player sensorimotor skills and spatial memory [41]. 

From the perspective of a prototyping toolkit, the reconfigurability of modular synthesizers is as critical as their tangibility. After Moog’s introduction of voltage control [42], modularity has frequently been considered in terms of the potential for any module to act upon any other. However, the specific configuration and layout of a given system are also important. Thus, a further potential strength of Eurorack for prototyping is that players can rapidly add, remove, and reconfigure modules to subtly or radically modify the capabilities and playability of their system. This is especially valuable for the author, given the unclear ideal outcome of the instrument design process. 4.3 Entangled Layers as Narrative In the early years of NIME, Jordà noted that designers placed a strong emphasis on the interface or controller, often overlooking more balanced approaches that valued other aspects of the instrument equally. This prompted him to propose a more holistic design approach whereby interface and sound generation are integrated from the start [43], aligning with Miranda and Wanderley’s formula that a DMI = Interface + Mapping + Sound Generation [44]. Although the instrument is considered holistically, Chimera’s development intentionally embraces the separation of DMI form and function [43], aiming to circumvent constraining social expectations by avoiding the imitation of traditional instrument paradigms.  While its scope might eventually extend further, Chimera is primarily designed to support my personal musical aims of exploratory improvisation, whereby exploration aims to uncover a system’s unique possibilities, and improvisation embraces discovery through action [45]. McMillan observes that instruments and technology shape both human creativity and behavior [13], a view echoed by Frauenberger, who argues that “by configuring material conditions, we design humanity” [46], and by Armagno, who notes that we inevitably reproduce specific worldviews with ethical and political implications [47]. However, while my perspective as a physically disabled designer-player is currently underrepresented, any perceived weight of responsibility is eased by the notion that musical instruments have their own voice. Bates highlights the social lives of instruments beyond their creators [48], while Koutsomichalis argues that instruments can serve purposes beyond functional use and, to this end, carry “stories of a sort.” [49] Thus, it is hoped that the new instrument will embody the previously discussed layers of narrative and, ultimately, contribute to the ongoing discourse around musical instruments and disability. 5. RELATED WORK The NIME era has seen a range of developments targeting broad accessibility, tailored solutions for specific disabilities, and individual needs. Frid [50] offers a valuable survey of inclusive instruments showcased at NIME and other conferences, while Frid and Ilsar [51] provide a useful review of inclusive musical interfaces.  Only a few new instruments have been specifically designed for one-handed players, and two have been presented at NIME. The Actuated Guitar is an enhanced guitar instrument equipped with actuators, designed specifically for children with hemiplegia. A subsequent case study investigated if re-learning to play the guitar after a stroke increased motivation for self-rehabilitation or improved quality of life [52]. The adapted bass guitar developed by Harrison and McPherson is more heavily mechanized, incorporating a relatively complex string actuation system [27]. A user study found that all six participants quickly adjusted their initial playing techniques to embrace its main design limitation compared to a standard instrument.  Beyond NIME, the Kellycaster is another guitar-based instrument and a rare example of co-design. Intended to meet the specific needs of Disabled musician John Kelly, its development was supported by the Drake Music charity [53]. Since 2011, another UK-based charity, The OHMI Trust, has held a competition to find novel and adapted instruments that can be played one-handed [54]. Entries include the 
Trumpet Assist, a gaze-controlled, solenoid-actuated trumpet; Key Wi, an open-source, melodica-inspired electronic instrument; Mi.Mu Gloves, wearable devices for gestural music control; and the Bowed-string LinnStrument, a string-focused adaptation of the LinnStrument [54]. 6. 100 DAYS OF PROTOTYPES The prototyping process for Chimera was iterative and stage 1 involved the selection of modules from an existing modular synthesizer system (Figure 2), then subsequent refinement of this initial selection to distil it to its essential elements. 11 iterations were created and explored over a period of one hundred days (three months). During this period, a reflective log was kept alongside system documentation, patch notes, and audio recordings.  
 Figure 2. A Chimera iteration in front of the larger donor Eurorack modular synthesizer  Stage 1 prototyping ended at the 11th iteration. Technical descriptions for each stage and player reflections are outlined below. The final iteration subsequently formed the basis of a comparatively more fixed Stage 2 prototype. 
6.1 Prototyping Stage 1  Chimera prototyping Stage 1 had three starting points:   • A 2-D joystick as the primary input device. • A Xaoc Devices Leibniz Binary Subsystem [55] for sound generation and processing. • The use of stackable patch cables and an Expert Sleepers ES-9 module [56] to create physical and software mappings respectively. Joysticks are well established as a one-handed input device in a video games context and have also featured throughout post-1960 electronic music [57]. The joystick was chosen as the primary input device due to its established fit for the author’s right hand, and that it enables both small, finely controlled movements and wide, sweeping motions to be used as input. The X-Y outputs of the joystick are patched into the Expert Sleepers ES-9 module to enable real-time calculation of 2-D input velocity, and conversion to control voltage (CV).  The Leibniz Binary Subsystem by Xaoc Devices is a series of eight, 8-bit digital modules intended for signal processing, signal generation, and control voltage (CV) creation [55]. It was chosen for its near-complete lack of conventional instrumental traits.  The possibility of physically interconnecting synthesizer modules dates to Moog’s introduction of voltage control [42], while the use of stackable cables for sound synthesis was developed by Buchla [58]. The ES-9 extends mapping capability, supports bidirectional communication with Pure Data [59], and enables audio monitoring. 6.1.1 Iteration A  Sound generation in the first iteration was loosely inspired by the Sonic Charge Permut8, an “effect plug-in that embraces the sounds of primitive digital signal processing hardware.” [60] A simplified audio flow diagram can be seen in Figure 3. A one-to-many mapping, as defined by Hunt and Wanderley [61], couples the X axis of the joystick 

to system sampling rate, filter cutoff frequency, and modulation shape. The Y axis of the joystick is mapped to the rate of cross-coupled modulation sources, DAC sampling rate, and wavetable processing algorithm (Jena digital processing module). Joystick buttons are mapped to the router (route selection). At Audio Out, there is the option to route audio to Pd for additional real-time processing.  The fully one-handed constraint quickly hinted at a different kind of player-instrument relationship. Without the anchoring of a second arm, the experience felt more like freely ‘sculpting’ sound, at least compared to the more physical and effortfully coordinated actuation of sound on the trumpet or guitar.  
 Figure 3. A simplified audio flow diagram for iteration A. 6.1.2 Iterations B-D  Iteration B implemented sample rate quantization for pitched output, while Iterations C and D prioritized ergonomic enhancements and streamlined the interface by removing under-used features. A modification to the Pd patch incorporated granulation driven by simple analysis of the Eurorack audio.  Even after a few hours of practice, these early iterations exposed a tension between instinct and intention and subsequent system response. Additionally, despite useful added variety in sound output, the audio feedback provided to the player needed to be more immediate; a short but constant delay led to disorientation. 6.1.3 Iterations E-G  Iteration E used the bidirectional communication capabilities of the ES-9 module to explore dynamic mappings that warp the relationship between input and output to be less linear as input velocity increases.   
 Figure 4. Exploring a changed joystick mapping.  Iteration F made further adjustments to the joystick mapping (Figure 4), while iteration G attempted to explore the imposition of increased physical resistance on the Y axis of the joystick.  With the main technical and perceptual issues seemingly resolved, the limited input possibilities encouraged deeper exploration of rhythm, dynamics, and texture over melodicism. Increased physical resistance on the joystick Y axis made for more effortful interaction, but the development of more subtle mappings between gesture and sound more markedly helped maintain my interest; it felt like the 
topology could be trusted (in the sense of a readable and consistent response), but that there were sizeable details left to explore. 6.1.4 Iterations H-K  Iterations H and I represent small refinements of iteration G aimed at improving playability and comfort, before iteration J explored a more radical simplification of the basic patch that ultimately proved limited and unsatisfying to play.   
 Figure 5. Audio flow diagram for Iteration K.  The final iteration is based on iteration I but removed an underused filter/slew module. It also optimized the placement of available visual feedback from the ADC and DAC. The audio path for iteration K can be seen in Figure 5 above.  Table 1. Stage 1 Iterations A-K: additional details Iteration No. of modules used No. of modules added/rearranged No. of sessions Total duration of engagement A 19 19/0 3 190 minutes B 19 0/2 2 75 minutes C 17 -2/1 1 90 minutes D 16 -1/3 1 60 minutes E 16 0/3 1 60 minutes F 16 0/0 1 205 minutes G 16 0/0 2 90 minutes H 13 -3/2 1 40 minutes I 13 0/2 2 70 minutes J 9 -4/0 1 30 minutes K 12 3/9 2 200 minutes Each iteration was explored by the author until it was felt to be reasonably well understood, and no longer surprising. Thus, longer durations typically indicate more player interest and sustained attention. Iterations A-K were explored by the author for a total of 18.5 hours overall, but iterations A, F, and K collectively account for more than half of the overall time spent. Each iteration demanded a degree of re-learning, but it was notable that as I gained confidence, mistakes could be as interesting as intentional gestures, suggesting a place for serendipity. By iteration K, there was a conscious and sustained negotiation between control and letting go, effectively trusting the system to interpret and respond to more ambiguous input. At this point in development, it felt 

increasingly as if the initial prototyping phase had reached inertia, in that further modifications no longer led to significant improvements. 6.2 Prototyping Stage 2 A second prototyping stage saw the audio and control aspects of iteration K translated into a standalone device based around the Bela embedded audio platform [62].   
 Figure 6. The Stage 2 prototype based around the Bela embedded audio platform.  The Stage 2 prototype retained the joystick as its primary input device, while the audio and main control flows from Iteration K were replicated as closely as possible in a Pd patch (Figure 7) running on low-latency Bela hardware.   
 Figure 7. Part of the Pd patch that replicates the audio and main control flows from the Iteration K prototype.  In essence, this Stage 2 prototype serves as a playable snapshot of the final Eurorack iteration and represents the current stage of development. A touch sensor enables key parameters to be modified, while the Trigger and Gate buttons choose which parameters are currently active. 7. DISCUSSION While McMillan reflects on experiences as an able-bodied performer before his accident [13], my congenital disability offers a different set of reference points in that I have always been a disabled musician and always experienced musicianship through this lens.  As a prototyping toolkit, the use of Eurorack has enabled the iterative development of the new instrument over a three-month period. Many of the qualities used to define prototyping are identifiably present. Notably, changes can be made quickly, and unsuitable modules can be placed back into the donor system at zero cost. While access to a sufficiently large modular synthesizer may be 
prohibitively expensive for individuals, it is typically more feasible for institutions, where such systems are increasingly common [41].   The initial few iterations of the instrument only hinted at some of the possibilities of one-handed use, but, by iterations F and G, and more than eight hours of exploration, two possible strengths were revealed. Firstly, if care is taken to leave routes through the topology free from obstructions, a single hand can move more swiftly and delicately in three dimensions through tangled patch cables to adjust secondary controls or re-patch. Second, the player has reduced energy expenditure as movements are typically smaller compared to performance techniques for more traditional instruments, and fatigue accrues less quickly. While smaller input gestures might compromise perceived sound causality for any audience present, there may be advantages elsewhere. Although little discussed in NIME literature, many disabled people have multiple impairments or multiple disabilities. In my own case, the interconnectedness of these impairments has become more troublesome over time. For instance, if I play a standard trumpet, my left elbow is still needed as a passive support. Yet, because the body-instrument fit is imperfect, the posture imposed quickly causes significant back pain that restricts mobility. By contrast, as a fully one-handed instrument (no involvement of the left arm), Chimera has significantly reduced occurrences of this issue.  Nevertheless, designing for one-handedness involves some trade-offs. For example, increased spacing between interface elements can aid readability and help to provide improved physical access to and around controls such as knobs and sliders. It can also help to limit the potential for accidental interactions. However, even slight increases in stretching and reaching can worsen musculoskeletal issues. Given that my body (as, ultimately, all bodies) is “inconsistent, dynamic, and unpredictable” [22], most important of all is perhaps to acknowledge that an ideal interface or instrument may not exist: that ‘ideal’ (or even usable) can change from one period to the next. Nevertheless, flexible and reconfigurable prototyping processes such as those explored in this paper appear to be useful in adapting to these changing conditions. 8. CONCLUSIONS  This paper has detailed the prototyping of a new DMI called Chimera, the first instrument developed primarily for the author’s personal use. Indirectly, however, it is informed by more than three decades of experiences playing standard musical instruments as a congenitally one-handed musician, and almost two decades designing DMIs for others. Throughout development there has been an awareness that the author’s perspective as a congenitally disabled DMI designer-player is underrepresented. If instruments can tell “stories of a sort” [49], these additional layers of context, and their tensions, ultimately all contribute to the stories of this new instrument. A main goal throughout development was to explore the distinctive possibilities of one-handed use. The first iterations of the instrument prototype revealed some differences compared to two-handed instruments, but more started to emerge with later prototypes and as additional time had been invested. When compared to the extended periods of refinement experienced by many traditional instruments still in use today, Chimera remains at an early stage of development. Despite some encouraging signs, it remains too early to determine with any certainty whether its single-handed design gives rise to music that would not have emerged from two-handed instruments.  Future work includes producing multiple units of the latest prototype to facilitate extended testing with other players in situ. Given the limited availability (or complete unavailability) of many new instruments, there is also interest in making future developments open source to encourage external contributions. 9. ACKNOWLEDGMENTS Thanks to past and present colleagues at the University of Staffordshire and the University of Wolverhampton for their support 

and advice. Special thanks to Simon Holland, the late Rolf Gehlhaar and the late Nigel St John Dwyer. 10. ETHICAL STANDARDS The research has been carried out in line with the ethical standards of the University of Staffordshire and the NIME conference. The project is not externally funded. Since 2024 the author has been an unpaid trustee of The OHMI Trust. There are no other known potential conflicts of interest. 11. REFERENCES [1] S. Fasciani and J. Goode, “20 NIMEs: Twenty Years of New Interfaces for Musical Expression,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Shanghai, China, 2021.  [2] R. Gehlhaar. SOUND=SPACE: an interactive musical environment. Contemporary Music Review, 6(1):59–72, 1991.  [3] T. Swingler, “That Was Me: Applications of the Soundbeam MIDI Controller as a Key to Creative Communication, Learning, Independence and Joy,” in The California State University Northridge Conference on Technology and Persons with Disabilities, Los Angeles, USA, 1998. [4] E. Zayas-Garin, E. and A. McPherson, “Dialogic Design of Accessible Digital Musical Instruments: Investigating Performer Experience,” in Proceedings of International Conference on New Interfaces for Musical Expression, Auckland, New Zealand, 2022. [5] J. I. Charlton. Nothing About Us Without Us: Disability Oppression and Empowerment. Berkley, CA, USA: University of California Press, 1998. [6] P. Manning. Electronic and Computer Music (4th edition). Oxford, UK: Oxford University Press, 2013. [7] M. Waisvisz, “The Hands: A Set of Remote MIDI-Controllers,” in Proceedings of the International Computer Music Conference, 1985. [8] D. Rokeby. The Construction of Experience: Interface as Content. In Clark Dodsworth, Jr., editor, Digital Illusion: Entertaining the Future with High Technology. Boston, MA, USA: Addison-Wesley Publishing Company, 1998. [9] L. Sonami, Requiem for the Lady’s Glove. Sound American: The Maker Issue, 2(6):139–43, 2017. [10] M. Dalgleish. Wiring the Ear: Instrumentality and Aural Primacy in and after David Tudor’s Unstable Circuits. Leonardo Music Journal, vol. 26:73–74, 2016. [11] A. Marquez-Borbon and P. Stapleton. 2015: Fourteen Years of NIME: The Value and Meaning of ‘Community’ in Interactive Music Research. In A. Jensenius and M. Lyons, editors, A NIME Reader. Cham, Switzerland: Springer, 2017. [12] F. Morreale and A. McPherson, “Design for Longevity: Ongoing Use of Instruments from NIME 2010-14,” in Proceedings of the International Conference on New Interfaces for Musical Expression, 2017. [13] A. McMillan, “NIME Consortium Proposal: Developing a design framework for constructing an accessible musical instrument from an autoethnographic point of view,” in Proceedings of International Conference on New Interfaces for Musical Expression, Auckland, New Zealand, 2022. [14] A. McMillan and F. Morreale. Designing accessible musical instruments by addressing musician-instrument relationships. Frontiers in Computer Science, vol. 5, 2023. [15] S. Danforth. A Pragmatic Evaluation of Three Models of Disability in Special Education. Journal of Developmental and Physical Disabilities vol. 13:343–359, 2001. [16] A. Gough. Body/Mine: a chaos narrative of cyborg subjectivities and liminal experiences. Women’s Studies, 34(3/4):249–64, 2005. 
[17] S. Goering. Rethinking disability: the social model of disability and chronic disease. Current Reviews in Musculoskeletal Medicine, 8(2):134–138, 2015. [18] S. Wendell. Unhealthy Disabled: Treating Chronic Illnesses as Disabilities. Hypatia, vol. 16:17–33, 2001. [19] Fundamental Principles of Disability. https://the-ndaca.org/resources/audio-described-gallery/fundamental-principles-of-disability/. Last accessed: 2025-01-16. [20] T. Shakespeare. Just What Is the Disability Perspective on Disability? Hastings Center Report, 46(3):31–32, 2016. [21] K. R. Bogart, N. M. Rosa and M. L. Slepian. Born that way or became that way: Stigma toward congenital versus acquired disability. Group Processes & Intergroup Relations, 22(4):594-612, 2019. [22] R. Freire and C. N. Reed, “Body Lutherie: Co-Designing a Wearable for Vocal Performance with a Changing Body,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Utrecht, Netherlands, 2024.  [23] B. M. Huisstede and S. M. Bierma-Zeinstra, B. W. Koes and J. A. Verhaar. Incidence and prevalence of upper-extremity musculoskeletal disorders. A systematic appraisal of the literature. BMC musculoskeletal disorders, 7(7), 2006. [24] J. Montagu. Origins and Development of Musical Instruments. Lanham, MD, USA: Scarecrow Press. [25] T. Magnusson. Sonic Writing: Technologies of Material, Symbolic, and Signal inscriptions. New York, NY, USA: Bloomsbury Academic. [26] M. T. Marshall. Physical interface design for digital musical instruments, PhD thesis, McGill University, Canada, 2009. [27] J. Harrison and A. McPherson, “An Adapted Bass Guitar for One-Handed Playing,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Copenhagen, Denmark, 2017. [28] Brass. https://www.ohmi.org.uk/brass.html. Last accessed: 2025-01-25.  [29] M. Dalgleish, “Reconsidering Process: Bringing Thoughtfulness to the Design of Digital Musical Instruments for Disabled Users,” in Proceedings of International Conference on Live Interfaces, Lisbon, Portugal, 2014. [30] J. Vasquez Gomez, K. Tahiroglu and J. Kildal, “Idiomatic Composition Practices for New Musical Instruments: Context, Background and Current Applications,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Copenhagen, Denmark, 2017. [31] D. Patterson. One Handed: A Guide to Piano Music for One Hand. Westport, CT, USA: Greenwood. [32] The OHMI Trust: The One-Handed Musical Instrument Trust. https://web.archive.org/web/20220917233115/https://www.ism.org/features/the-ohmi-trust-the-one-handed-musical-instrument-trust. Last accessed: 2025-01-16. [33] J. V. Larsen, D. Overholt and T. B. Moeslund, “The Actuated Guitar: Implementation and User Test on Children with Hemiplegia,” in Proceedings of the International Conference on New Interfaces for Musical Expression, London, UK, 2014. [34] W. Buxton. Two-Handed Input in Human-Computer Interaction. Chapter 11 from: Haptic Input (unpublished book, in preparation). http://www.billbuxton.com/input11.2H.pdf, 2008. [35] B. H. Friedman, editor. Give My Regards to Eighth Street: Collected Writings of Morton Feldman. Cambridge, MA, USA: Exact Change, 2004. [36] D. T. Mitchell and S. L. Snyder. Narrative Prosthesis: Disability and the Dependencies of Discourse. Ann Arbor, MI, USA: University of Michigan Press, 2001. [37] B. Buxton. Sketching User Experience: getting the design right and the right design. San Francisco, CA, USA: Morgan Kaufmann, 2008. 
[38] G. Gómez and R. Lopez-Leon, R. “Impossible Design: fostering creativity by quick and dirty prototyping”, in Proceedings of Insider Knowledge, DRS Learn X Design Conference, Ankara, Turkey, 2019. [39] C. Moussette and F. Dore, “Sketching in Hardware and Building Interaction Design: Tools, Toolkits and an Attitude for Interaction Designers”, in Proceedings of Design and Complexity, Design Research Society International Conference, Montreal, Canada, 2010.  [40] J. Sterne and A. K. Stuhl. When a Format (Almost) Becomes an Instrument: Eurorack in a Logistical World. Journal of Cinema and Media Studies, 63(5): 400–427, 2023. [41] J. A. Paradiso, “The Modular Explosion-Deja Vu or Something New,” in Voltage Connect Conference, Boston, USA, 2017. [42] R. A. Moog. Voltage-Controlled Electronic Music Modules. Journal of the Audio Engineering Society, 13(3):200–206, 1965. [43] S. Jordà. Digital Lutherie Crafting musical computers for new musics' performance and improvisation. PhD thesis, Universitat Pompeu Fabra, Spain, 2005. [44] E. Miranda and M. M. Wanderley. New Digital Musical Instruments: Control and Interaction Beyond the Keyboard. Middleton, WI, USA. A-R Editions, Inc., 2006. [45] B. Watson. Derek Bailey and the Story of Free Improvisation. London: Verso. [46] C. Frauenberger. Entanglement HCI The Next Wave? ACM Transactions on Computer-Human Interaction, 27(1), 2, 2019. [47] G. Armagno, “The Role of HCI in the Construction of Disability,” in Proceedings of Human Computer Interaction Ethics, London, UK, 2012. [48] E. Bates. The Social Life of Musical Instruments. Ethnomusicology, 56(3):363–395, 2012. [49] M. Koutsomichalis. Instruments that are more than instruments (and other stories). Ricercare, vol. 15:76–106, 2022. 
[50] E. Frid. Accessible Digital Musical Instruments—A Review of Musical Interfaces in Inclusive Music Practice. Multimodal Technologies and Interaction, 3(3), 57, 2019. [51] E. Frid and A. Ilsar, “Reimagining (Accessible) Digital Musical Instruments: A Survey on Electronic Music-Making Tools,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Shanghai, China, 2021. [52] J. V. Larsen, H. Knoche and D. Overholt, “A Longitudinal Field Trial with a Hemiplegic Guitarist Using The Actuated Guitar,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Blacksburg, USA, 2018. [53] J. Harrison, A. Chamberlain and A. P. McPherson, “Accessible Instruments in the Wild: Engaging with a Community of Learning-Disabled Musicians,” in Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, New York, USA, 2019. [54] OHMI Competition. https://www.ohmi.org.uk/ohmi-competition.html. Last accessed: 2025-01-02. [55] Drezno. https://xaocdevices.com/main/drezno/. Last accessed: 2025-01-12. [56] ES9 USB Audio Interface. https://www.expert-sleepers.co.uk/es9.html. Last accessed: 2025-01-12. [57] G. L. Rocha, J. T. Araújo and F. L. Schiavoni, “Ha Dou Ken Music: Different mappings to play music with joysticks,” in Proceedings of the International Conference on New Interfaces for Musical Expression, Porto Alegre, Brazil, 2019. [58] D. Buchla. The Modular Electronic Music System. San Francisco, CA, USA: Buchla Music Associates, 1966. [59] Pure Data. https://puredata.info/. Last accessed: 2025-01-13. [60] Permut8. https://soniccharge.com/permut8. Last accessed: 2025-01-06. [61] A. Hunt and M. M. Wanderley. Mapping performer parameters to synthesis engines. Organised Sound, vol. 7:97–108, 2002. [62] Bela Systems. https://bela.io/products/bela-systems/. Last accessed: 2025-04-26.    