KnittedKeyboard: Digital Knitting of  
Electronic Textile Musical Controllers 
 
  
Irmandy Wicaksono and Joseph A. Paradiso 
Responsive Environments Group 
MIT Media Lab 
Massachusetts Institute of Technology 
75 Amherst St. 
Cambridge, MA, USA 
[irmandy, joep]@mit.edu 
   
   
ABSTRACT 
In this work, we have developed a textile -based interactive 
surface fabricated through digital knitting technolo gy. Our 
prototype explores intarsia, interlock patterning, and a collection 
of functional and non-functional fibers to create a piano-pattern 
textile for expressive  and virtuosic  sonic interaction. We 
combined conductive, thermochromic, and composite yarns with 
high-flex polyester yarns to develop KnittedKeyboard, both with 
its soft physical properties and responsive sensing and display 
capabilities. The individual and combination s of key s could 
simultaneously sense discrete touch, as well as continuous 
proximity and pressure. The KnittedKeyboard enables 
performers to experience fabric-based multimodal interaction as 
they explore the seamless texture and materiality o f the 
electronic textile. 
 
Author Keywords 
Keyboard, multimodal, e lectronic textiles,  digital knitting,  
continuous and discrete controls, interactive surfaces, 
deformable interfaces.  
 
CCS Concepts 
• Hardware →  Sensor applications and deployments; sensor 
devices and platforms; • Human-centered computing → Sound-
based input/output  
 
1. INTRODUCTION 
Textiles are ubiquitous in our daily life. They are h ighly 
formable and palpable materials with a broad spectrum of 
patterns, structures, and textures. Advances in electronic textiles 
(e-textile) since the 1990s have pushed forward the development 
of novel interfaces, particularly for musical interaction  [1, 2].  
Inspired by soft and deformable properties as well as aest hetic 
features of textiles, we envision an interactive textil e-based 
surface with a familiar layout of an existing instrume nt. We 
fabricated a piano -pattern fabric (Figure 1) that allows multi -
modal sensing for sonic physical interaction. As a second 
iteration of our previous work [3], KnittedKeyboard explores the 
realization and applications of interactive textiles fo r musical 
controllers with rapid and pers onalized digital knitting 
technology.  
 
 
Figure 1: Performing with the KnittedKeyboard. 
 
Knitting is an established textile manufacturing tec hnique that 
has been pervasive in the garment and technical fabrics industry. 
Current industrial knitting machines are optimized f or mass -
manufacturing of garments, socks, and shoes. In comparison to 
weaving, knitting has several advantages, including the ability to 
create intricate patterns, textures, and structures. With the 
growing areas of digital fabrication and computer-aided design, 
a new generation of knitting machines now enable  users to 
personalize and rapidly develop their textile design through a 
specialized visual programming environment and various types 
of functional and common yarns. We present a design principle 
for textile-based interactive surfaces starting from electronics at 
the fiber-level and towards their  integration into fabrics with 
digital knitting techniques. This process enables personalized, 
rapid fabrication, and mass -manufacturing of seamless 
intelligent textiles for novel interaction purposes, particularly for 
fabric-based musical controllers  and interactive surfaces . 
Connected to a hardware system and computer, the 
KnittedKeyboard can simultaneously detect touch, prox imity, 
and pressure, as well as control thermochromic change. It allows 
performers to play the discrete notes, harmonies, and 
soundscapes with virtuosity , while experiencing the unique 
visual and tactile properties of the knitted textile. 
 
2. RELATED WORK 
The history of conductive textiles dates back to the early modern 
period where gold and silver yarn were woven into tapestries or 
metallic organza for fashion, interior design, and d ecorative 
purposes [4]. However, it was not only after the late 20th century 
that the electrical properties of such textiles were harnessed, and 
 Adreas Eggenberger  
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
323
the concept of interactive textiles and e-broidery was introduced 
initially at the MIT Media Lab. Musical Jackets and Musical 
Balls [5,6], for instance, demonstrated the first embroid ered 
touch and pressure -sensitive textile sensors for performing 
music. Other recent work includes the Musical Skin  [7], a soft 
fabric sound controller for spatiotemporal pressure sensing 
across a two-dimensional space, and FabricKeyboard  [3], a 
multi-layer textile keyboard that could simultaneously detect 
discrete and continuous touch, proximity, pressure, stretch, and 
electric field hand gestures for expressive musical performance. 
MusiCushions [8], a set of interactive sofa cushions, also enables 
deformable inputs for explorations of music interaction at home. 
The work mentioned above explored attachment of conductive 
fabrics and yarns at the  fabric-level, by embroidery, iron -on 
melting, or sewing. As new t extile manufacturing techniques 
such as digital knitting and weaving become accessible to 
researchers, efforts start to emerge in integrating conducti ve or 
any other types of functional yarns to develop interactive textiles 
from electronic fibers [8,9]. Previous work in interactive textiles 
has also shown thermochromic or electrochromic properties that 
could provide display functions [11]. However, there has not 
been any effort in integrating electronic yarns with both sensing 
and actuation capabilities into fabrics with digital knitting 
technology.  
The inclusion of conductive material as capacitive touchpads in 
musical interface started in the mid-60s, as can be seen in Don 
Buchla’s modular synthesizer [12,13]. This was then followed 
by commercial keyboard synthesizers such as EMS Synthi AKS 
and EDP Wasp. As an effort to leverage hand and finger 
dexterity, Moog and Rhea designed an expressive multimodal 
sensor layer for discrete and continuous controls in the ir 
Multiply-Touch Sensitive Keyboard [14]. Previous work also 
focused on transforming the key’s surface and substrate, starting 
from The Continuum, an indiscrete keyboard layout for 
continuous finger gestures [15] to the recent Seaboard [16], a 
soft, rubbery, and wavy keyboard interface with its si gnature-
style polyphonic modulations. In this work, we program med a 
digital knitting machine and utilized functional (conductive, 
thermochromic, and melting yarns) and non-functional polyester 
yarns to seamlessly develop a knitted musical instrument digital 
interface (MIDI) keyboard. The fiber-based keyboard not only 
responds to contact and non -contact gestures such as pressure, 
touch, and proximity, but also changes its color with temperature 
to visualize various modes of play . It can be played on a flat 
surface or worn to explore on -body or wearable  musical 
performance as a keyboard tie, previously performed by Laurie 
Anderson in the “Home of the Brave” [17] 
3. FABRICATION 
3.1 Digital Knitting 
Digital knitting is a computer -aided, automatic process of 
building interlocked loops from multiple strands of yarns. It is a 
rapid process that is useful for large-scale, mass-manufacturing 
of textiles (Figure 2a). It employs an array of needles or hooks 
that goes up and down to catch the yarns based on an instruction 
file. Each yarn is fed to the machine from a cone, passing through 
a tensioning mechanism towards a yarn carrier. These yarn 
carriers move sideways as the needles grab the yarn to form new 
loops. The digital knitting programming interface consists of two 
grid sections. The left grid area is used to develop the shape and 
pattern of the knit fabrics through x-y color block programming, 
where each color and sign represents a specific knit  instruction 
(Figure 2c).  
 
 
Figure 2: a) Mass-manufacturing of KnittedKeyboard, 
b) Example of conductive, thermochromic, and polyester 
yarns, c) Digital knitting program in simplified (left) and 
machine (right) format, and d) KnittedKeyboard output 
from the digital knitting machine. 
We used a flat two-bed digital knitting machine (Super-NJ 212, 
Matsuya) and as shown in Figure 2b, fed this machine with the 
following yarns: two cones of silver -plated conductive yarns 
(150 denier,  Weiwei Line Industry), two cones of 
thermochromic yarns (150 denier, Smarol Technology), and two 
cones of high-flex polyester yarns (540 denier, 4-ply) combined 
with melting yarns (150 denier, 1-ply). We fed a cone of silver-
plated and thermo chromic yarns together on each of the two 
carriers.  Each cone connects to a different ya rn carrier, with a 
total of four carriers used. As illustrated in Figure 2c, each carrier 
knitted a different section of the fabrics. Intarsia knitting was 
instructed on sections where more than one yarn type is needed, 
such as in any line where the  piano key is plotted. Since it is a 
two-layer knitting machine, we performed interlock knitting to 
intersect the front and the back-fabric layers. It took the machine 
1 hour and 40 minutes runtime to knit the entire prototype, which 
has five octaves of diatonic piano-keys pattern (Figure 2d). The 
resulting knitted fabric was steamed at the end to activate the 
melting yarn, giving structural rigidity to the final prototype. 
3.2 Additional Structure 
The one layer, piano -patterned conductive and thermo chromic 
textile fabricated above could perform touch and proximity 
sensing, as well as color-changing display when heated. To 
complement the thermochromic  function, we assembled and 
embedded five textile heaters (one per octave ). In order to add 
pressure sensing capability for modulation, we also developed a 
fabric pressure sensor that we stacked at the back. It covers the 
entire active area of the keyboard and consists of a piezoresistive 
knit fabric (LG-SLPA 20k, Eeonyx) in between two conductive 
knit fabrics (Stretch, LessEMF). 
 
a 
 b 
c 
 d 
High-flex polyester 
yarns 
Melting yarns  
High-flex polyester  
yarns (4-ply)  
Thermochromic yarns  
Conductive yarns  
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
324
4. HARDWARE INTEGRATION 
4.1 Interconnections 
The KnittedKeyboard has a total of 60 keys for 5 octaves. Each 
octave’s key is connected to  one of the twelve  printed circuit 
board pads wired to a capacitive sensing chip  (MPR121, NXP 
Semiconductor) with highly-conductive silver-coated fibers 
(Liberator 40). Five capacitive sensing chip s and five heating 
elements are connected to the main microcontroller (Teensy 4.0) 
with thin insulated wires (32 AWG).  
 
4.2 Controller-Computer Interface 
Figure 3 demonstrates the various gestural inputs th at can be 
performed on the  KnittedKeyboard with their respective 
interface circuitry to the computer. Five MPR121  chips are 
connected to Teensy 4.0 through 4 -wire inter-integrated circuit 
(I2C) lines. Since an MPR121 can only have up to 4 different 
addresses (0x5a to 0x5d), we used two data (SDA) and clock 
(SCL) lines in the Teensy 4.0 microcontroller. The pressure 
sensing circuit consists of a potential divider with a r eference 
resistor of 500 Ω, connected to the  analog-digital converter  
(ADC) pin of the microcontroller through a voltage follower 
(TLV2374). The piezo -resistive pressure sensor resistance 
ranges from 1 to 3 k Ω. The heating circuit consists of an n -
channel Power MOSFET (IRLB8721, International Rectifier) 
with a load resistor and is powered by a 6 V external supply. 
Figure 3: System architecture of the KnittedKeyboard that 
enables various mode of interactions.  
 
 
The MPR121 performs constant direct-current ( DC) current 
charging and discharging for capacitive sensing. By varying the 
amount of charge current and time, we can engineer the 
sensitivity of each electrode. It also features the 13th electrode, 
where all of the twelve electrodes are multiplexed to gether in-
chip to represent a large capacitive sensing surface. This feature 
enables a near-proximity detection across an octave. We found 
that setting the charge current to 63 μA and the charge time to 1 
μs gave the most dynamic range for large -area proximity 
sensing, while still reliably detect ing touch events. The 
KnittedKeyboard, therefore, has 60 individual touch -sensitive 
keys that can be transformed programmatically to five 
proximity-sensing fields.  The thermochromic display change is 
activated when the proximity sensing mode is enabled. It informs 
the user of different modes of play based on the color of the keys. 
With all of the touch, proximity, pressure, and heating channels 
activated, the KnittedKeyboard runs with a frequency of 83 Hz. 
The longest latency for a touch event, without taking into an 
account the serial and software delay is therefore 12 ms. Each of 
the touch events, velocity, proximity, as well as pressure values 
are converted to their corresponding MIDI messages in the 
microcontroller before sending them to the computer through 
serial communication with a baud rate of 115200. Hairless MIDI 
is then used as a bridge from the universal serial bus (USB) Serial 
Port to MIDI Out and In of Ableton Live 9, which is a digital 
audio workstation software that allows users to MIDI map all of 
the messages (channels, notes, and control change) to any  of 
their instruments and effects libraries. 
 
4.3 Sensor Outputs 
Figure 4 shows the sensor outputs from various gestu ral inputs 
performed on the KnittedKeyboard before getting scaled and 
mapped into MIDI messages. As can be observed in Figure 4a, 
the keyboard can sense pressure exerted by the fingers, which is 
mapped to a MIDI channel expression (linked to an after-touch 
or a reverb for example) with a user-defined expression delay. 
The keyboard also has the ability to detect hand’s a pproach or 
hover up to 10 cm above the fabric surface. The output value 
drops as the hand gets closer to the capacitive sensing area 
(Figure 4b). Finally, Figure 4c illustrates a technique to measure 
finger velocity by calculating the capacitance’s slope of descent 
(∆t/∆val) in between a point where a touch event happens a nd 
the previous two  proximity values. This technique requires a 
temporary array o f variable in the program, that continuously 
stores capacitance values of each key before a touch e vent 
occurs.  
 
Figure 4: Signal response of a) touch events and pressure 
values from finger strikes and aftertouch, b) proximity 
values from hands approach, and c) touch event and 
capacitance value to determine note velocity. 
a 
b 
c 
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
325
5. MUSICAL MAPPINGS 
In Ableton Live 9, there are two active channels. We assigned the 
touch events and velocities to  Channel 1, which can be either 
synth keys and leads, such as suburban or brassicana lead or a 
classic piano rack. The pressure-sensing values as aftertouch or 
expressions are also mapped into Channel 1, for either track 
volume or filter frequency. A user can go into the  proximity 
mode for sensing  hand’s waving  and hovering, which we 
assigned to Channel 2 . In this case, we applied ambient and 
evolving sound effect s, such as spacefolder or cosmos scape. 
Amplitude modulation can also be mapped into this channel as 
our hands get closer to the surface. Figure 5 shows the possible 
modes of interaction enabled by the KnittedKeyboard.  
 
 
 
Figure 5: a) Modes of interaction: one hand’s hovering and 
the other playing keys, and b) thermochromic color change 
in action for proximity field sensing marker   
(from grey to pink). 
 
6. CONCLUSION AND FUTURE WORK 
We proposed  and developed KnittedKeyboard, a machine -
knitted, piano-patterned interactive textile surface with multi -
functional sensing and display capabilities. It consi sts of 60 
touch and velocity-sensitive keys that can be transformed into 
five proximity sensing pads. In addition, it has a pressure sensing 
layer underneath for aftertouch expression. The patterns are also 
thermochromic and can change color with applied heat ing to 
visualize different modes of play. Designed as a MIDI 
instrument, the piano-patterned electronic textile  can be 
connected to any audio synthesis or sequencer software, such as 
Ableton Live 9 or Garage Band and mapped to any instrument or 
sound effects. This work demonstrates the vision of seamless 
fabric-based interactive surfaces, that is not only applicable in 
novel musical controllers, but also in smart objects and 
responsive environments. The underlining tec hnology would 
enable further exploration of soft, malleable, and on -body 
musical interfaces that leverages the unique mechanical quality 
of the material, as well as the electrical property of the sensors. 
We are interested to collaborate with composers, sound artists, 
and keyboardists, in expl oring ways to compose and per form 
music with the KnittedKeyboard. Future work may also include 
simultaneous knitting of te xtile heating and pressure -sensing 
layers on top of the conductive and thermochromic layers, the 
design of flexible printed circuit board interface circuits for 
robust textile-hardware connection, and integration of an on -
board audio generation system. 
 
7. ACKNOWLEDGEMENTS 
We would like to thank the late Lyle Mays from the Pat Metheny 
Group for the original discussion and inspirations leading to this 
work, as well as Gavin Zhao, Angela Chen,  Jordi Montaner, 
Harry Chan, Zhiyu Yu, Andy Su, Andrew “Bunnie” Huang, Joi 
Ito, Diastika Lokesworo, the Responsive Environments group, 
and the MIT Media Lab Consortium. 
 
8. REFERENCES 
[1] R. Stewart, “Cords and chords: Exploring the role of e-
textiles in computational audio,” Frontiers in ICT. 2019. 
[2] V. Vazquez, C. Cardenas, F. L. Cibrian, and M. Tentor i, 
“Designing a musical fabric -based surface to encourage 
children with autism to prac tice motor movements,” in 
ACM International Conference Proceeding Series, 2016. 
[3] I. Wicaksono and J. A. Paradiso, “FabricKeyboard  : 
Multimodal Textile Sensate Media as an Expressive and  
Deformable Musical Interface,” Proc. NIME, 2017. 
[4] E. R. Post and  M. Orth, “Smart fabric, or `wearable 
clothing’,” in International Symposium on Wearable 
Computers, Digest of Papers, 1997. 
[5] E. R. Post, M. Orth, P. R. Russo, and N. Gershenfeld , “E-
broidery: Design and fabrication of textile -based 
computing,” IBM Syst. J., 2010. 
[6] G. Weinberg, M. Orth, and P. Russo, “The embroidered 
musical ball: A squeezable instrument for expressive 
performance,” in Proc. CHI, 2000. 
[7] M. Donneaud, C. Honnet, and P. Strohmeier, “Designing a 
Multi-Touch eTextile for Music Performanc es,” in Proc. 
NIME, 2017. 
[8] L. Stahlberg, “MusiCushions: Designing interactive 
cushions that integrate with the home environment,” 
Degree Proj. Comput. Sci. Eng., 2018. 
[9] J. Ou, D. Oran, D. D. Haddad, J. Paradiso, and H. Ishii , 
“SensorKnit: Architecting Textile Sensors with Machine 
Knitting,” 3D Print. Addit. Manuf., 2019. 
[10] L. Albaugh, S. Hudson, and L. Yao, “Digital Fabrication of 
Soft Actuated Objects by Machine Knitting,” 2019. 
[11] R. M. Christie, S. Robertson, and S. Taylor, “Design 
Concepts for a Temperature-sensitive Environment Using 
Thermochromic Colour Change,” Colour  Des. Creat. , 
2007. 
[12] J. A. Paradiso, “American Innovations in Electronic 
Musical Instruments,” New Music Box, 1999. . 
[13] J. A. Paradiso, “Electronic music: new ways to play,” IEEE 
Spectr., 1997. 
[14] R. A. Moog and T. L. Rhea, “Evolution of the keyboard  
interface. The Bosendorfer 290 SE recording piano and the 
Moog Multiply -Touch-Sensitive keyboards,” Comput. 
Music J., 1990. 
[15] L. Haken, E. Tellman, and P. Wolfe, “An Indiscrete Music 
Keyboard,” Comput. Music J., 1998. 
[16] R. Lamb and A. Robertson, “Seaboard  : a New Piano 
Keyboard-related Interface Combining Discrete and 
Continuous Control,” in Proc. NIME, 2011. 
[17] L. Anderson, “Home of the Brave,” Warner Bros., 1986. 
 
9. APPENDIX 
Video demonstration can be accessed in this link:  
https://www.media.mit.edu/projects/knittedkeyboard/overview/  
 
a 
b 
Proceedings of the International Conference on New Interfaces for Musical Expression (NIME-20), Birmingham, 2020
326