Women’s Labor: Creating NIMEs from Domestic Tools
Margaret Schedel
Stony Brook University
13304 Staller
Stony Brook, NY 11794
margaret.schedel@stonybrook.edu
Jocelyn Ho
University of California, Los
Angeles
445 Charles E Y oung Dr E
Los Angeles, CA 90095
jocelynho@ucla.edu
Matthew Blessing
Louisiana State University
340 E Parker Blvd
Baton Rouge, LA 70808
mbless@cct.lsu.edu
ABSTRACT
This paper describes the creation of a NIME created from an
iron and wooden ironing board. The ironing board acts as a
resonator for the system which includes sensors embedded in
the iron such as pressure, and piezo microphones. The iron
has LEDs wired to the sides and at either end of the board
are CCDs; using machine learning we can identify what
kind of fabric is being ironed, and the position of the iron
along the x- and y-axes as well as its rotation and tilt. This
instrument is part of a larger project, Women’s Labor, that
juxtaposes traditional musical instruments such as spinets
and virginals designated for “ladies” with new interfaces for
musical expression that repurpose older tools of women’s
work. Using embedded technologies, we reimagine domestic
tools as musical interfaces, creating expressive instruments
from the appliances of women’s chores.
Author Keywords
NIME, feminist, machine learning, domestic, virginals
CCS Concepts
•Human-centered computing →Sound-based input
/ output; •Computing methodologies →Supervised
learning by classiﬁcation;
1. INTRODUCTION
Women’s Labor encompasses several components from in-
strument building, through workshops (such as those for
the Csound instruments on stage) [8], to installations, com-
positions, and an evening-length production. We wish to
spark conversation between the artists and the public about
how and why we repurposed old domestic tools laden with
functionalities traditionally pertaining to women to become
new musical instruments. At heart, the project is a femi-
nist initiative to revalue traditional women’s work through
re-imagining feminine technologies. In the evening-length
production, Ho will juxtapose compositions by women for
three NIMEs with under-represented works by past women
composers written for historical instruments traditionally
designated as “feminine” (such as the clavichord, fortepi-
ano, and the pardessus de viole). At the premiere, a discus-
sion panel with collaborators and experts on feminist tech-
nologies will follow. By expressibly commissioning women
Licensed under a Creative Commons Attribution
4.0 International License (CC BY 4.0). Copyright
remains with the author(s).
NIME’19, June 3-6, 2019, Federal University of Rio Grande do Sul,
Porto Alegre, Brazil.
composers, Women’s Labor doubly addresses the gender in-
equality that exists in the music ﬁeld today. We bring at-
tention to female composers and also invite people from all
walks of life to play/perform with these haptic instruments,
encouraging them to reﬂect upon the social/feminist his-
tory of these tools in their own domestic lives especially in
the context of privilege [6]. In this paper we concentrate on
the construction of our ﬁrst instrument, an iron and ironing
board.
1.1 History
Creative director, Jocelyn Ho, conceptualized the initial
idea for Women’s Labor as an evening-length work com-
bining works by female composers for new instruments cre-
ated from older domestic tools used by women, combined
with pieces for virginal keyboard instruments written by
mainly forgotten female composers. She approached Mar-
garet Schedel to help design the instruments and become the
ﬁrst commissioned composer. Schedel brought in Matthew
Blessing as the technical director based on his previous work
JoyStyx [4] and his dissertation Musical Chairs . Blessing
created the programming structure for the sensor input,
and the initial programming of mapping variables for in-
teraction. We anticipate that each composer will reﬁne the
expressive capabilities of the instruments as they develop
a unique gestural and musical language for their composi-
tions. Blessing also designed the physical assemblage to be
reproducible by others by following instructions hosted on
our GitLab site [1]. These instructions include the schemat-
ics for 3D printing parts, a detailed bill-of-materials, and
a complete software package for the system. The iron and
ironing board are the ﬁrst instrument designed by the team.
1.2 Embedded Acoustic Instruments
The instruments for Women’s Labor are embedded acoustic
instruments (EAIs); all components (the sensors, the pro-
cessors and the speakers) are an integral part of the design.
The body of the instrument itself is the resonator. There are
no external elements, if needed the instruments can be am-
pliﬁed with microphones in the same way an acoustic instru-
ment can be ampliﬁed. Although they are self-contained,
the sonic proﬁles of unampliﬁed EAIs change dramatically
depending on the room they are in because the ratio be-
tween the strength of the direct sound and the strength
of the reﬂected diﬀuse aﬀect how reverberant the sound is
perceived to be [10].
Edgar Berdahl reﬁnes the concept of EAIs using the fol-
lowing ontology: 1) “sensors that are connected via a sensor
interface to an embedded computation unit;” 2) “a sound
synthesizer implemented in software;” 3) “an output audio
signal based on the sensor data;” and 4) “an audio ampli-
ﬁer [that] makes the output audio signal intense enough to
power an internal transducer” [2].
377
Figure 1: Ironing Board Sensing/Producing Schematic
Luca Turchet proposes a category called Smart Musical
Instruments (SMIs) that are similar, they have 1) a system
for capturing the user’s interaction with the instrument; 2) a
low-latency, highly reliable, and interoperable wireless com-
munication system interfacing with WLANs and WANs; 3)
an embedded computation unit implementing the intelligent
component; 4) memory; and 5) power supply. Optional fea-
tures include: 1) an embedded sound delivery system; 2)
acoustic sound source; 3) inputs/outputs for wired connec-
tivity; 4) a system for haptic display; 5) and a system for
visual display. There is some overlap between SMIs and
EAIs–our iron is not networked externally (it has a LAN be-
tween two boards) and we do use an acoustic sound source
of the iron on cloth, but we feel these instruments fall more
under the EAI designation [12].
The beneﬁt of both EAIs and SMIs embedding the pro-
cessing system in the instrument is that the computer is
only used for the gear; it will not experience state changes
from other uses. The drawback is that single-board comput-
ers have a much more limited processing power compared
to laptop or desktop systems. We decided the beneﬁts of an
embedded instrument outweighed the drawbacks. For this
instrument we are using two single-board computers, one
manages the inputs and machine learning, while the other
manages synthesis and audio output.
Figure 2: Exterior of Iron on Ironing Board.
1.3 Reproducibility
Beagle boards were one of the ﬁrst single-board computers
that could be used for embeddable systems. Both Bela [11]
and Satellite CCRMA [3] were among the ﬁrst developers to
address the issue of creating reproducible instruments be-
cause “in the DMI community, published papers typically
contain insuﬃcient detail to fully replicate an instrument
design, especially in regard to aesthetic choices and ﬁne de-
tails of craftsmanship which are important to the performer
experience but might not follow established scientiﬁc pro-
cesses... DMI [digital musical instrument] toolkits, by pro-
viding a common platform for designers, reduce the barriers
to exchanging fully functioning designs” [9].
It is important for us to fully document the creation pro-
cess of these instruments not only to provide instructions
for the workshops, but also to allow composers to build
their own versions of the instruments in order to work with
them while writing pieces. We also anticipate being able
to travel more easily by purchasing larger items (such as
ironing boards) and creating large 3D printable parts (such
as the iron enclosure) on-site, and hosting the entire soft-
ware distribution on Ho’s GitLab repository so we can easily
download the operating system and our programs onto new
boards.
2. IRON
Our system consists of an antique ironing board with trans-
ducers and speakers, and a 3D printed charcoal iron (see
Figure 2), an iron with a large cavity for coals or heated
slugs, with measurements taken from an antique iron that
was too heavy to manipulate expressively. To perform the
instrument, one simply irons diﬀerent pieces of cloth.
2.1 Sensing
In order to create an expressive instrument we designed
several inputs to the system. On the iron itself we have
three pressure sensors that allow us to measure how hard
the performer is pressing. There is one pressure sensor at
the tip, and two at the rear giving information about rocking
and tilting. The iron also has contact microphones that we
use to understand what kind of fabric is being ironed. On
the ironing board are two cameras which we use to track
LEDs on the iron itself allowing us to track X/Y-position
and angle of the iron. All inputs except the camera inputs
go into a Raspberry Pi inside the iron. The cameras are
wired into a second PI under the ironing board.
378
Figure 3: Pressure Sensor Assembly in-progress
2.2 Mapping
Creative director Ho decided that the interaction of the
ironing board should relate to a keyboard interface with low
sounds on the left and higher sounds on the right. In com-
bination with information from the pressure sensors con-
nected with an Arduino (see Figure 3), the Y-axis controls
the envelope shape, while the the rotation of the iron, de-
termined by the CV on the LED signals, controls distortion.
The pressure sensors, developed from Plusea’s Conductive
Thread Pressure Sensor 1, also control the volume which is
linked to timbre; the harder the performer presses the louder
and brighter the sound.
Finally we use Wekinator [5] on the sounds of the fabrics
being ironed to set the initial sonic palette. A piece of cloth
made from diﬀerent types of material changes timbre as the
iron passes over it while a single type of material without
seams retains a individual audio proﬁle. We designed the
system so that composers will easily be able to add reﬁne-
ment to enhance the expressivity of the instrument without
altering the fundamental relationships developed by the ini-
tial team.
2.3 Producing
The Raspberry Pi inside the iron (See Figure 4) commu-
nicates via a LAN to another Pi under the ironing board.
The ﬁnal audio signal is sent from the second Pi to audio
ampliﬁers and then to transducers mounted on the ironing
board, creating a unique signature for each ironing board,
as well as upward-facing speakers mounted to the underside
of the board with cutouts to allow the unﬁltered sound to
propagate freely.
1www.instructables.com/id/
Conductive-Thread-Pressure-Sensor
Figure 4: Interior of iron: showing Pi, battery, Ar-
duino, and USB audio interfaces.
Figure 5: Underside of Ironing Board: showing
speakers, transducers, USB audio interfaces, am-
pliﬁers, & battery.
379
Distortion is not created in software, rather we reserve the
highest volume for signals which cause the speaker cone to
rattle against the ironing board. In this way each board has
a unique distortion proﬁle, and we save processing power.
Performers control the mixing of the acoustic signal to the
four outputs (See Figure 5) through manipulating the pres-
sure on the iron; symmetrical pressure results in the signal
coming from the speakers while asymmetrical pressure adds
in the transducers. Panning subtly follows the location of
the iron along the X-axis. The input from the contact mi-
crophones can also be ampliﬁed into the synthesized signal
by changing the acceleration of the iron; a steady velocity
results in no microphone input. This signal is not prior-
itized and may be delayed, adding a layer of randomness
among all the carefully controlled sonic result.
3. CONCLUSION
The iron and ironing board are part of a larger group of
NIMEs built by Ho, Schedel and Blessing using the tools
of traditional women’s household work. The other instru-
ments will be made from a drying rack and an embroidery
stand [7] and have completely diﬀerent gestural control, em-
bodied acoustic properties and sonic proﬁles. In addition to
pieces for these solo NIMEs, we will encourage composers
to write for the instruments in multiples–a chorus of the
same instrument or a small chamber ensemble made up of
the diﬀerent NIMEs combined with acoustic instruments.
4. REFERENCES
[1] womenslabor.
https://gitlab.com/J_piano/womensLabor.
[2] E. Berdahl. How to make embedded acoustic
instruments. In NIME, pages 140–143, 2014.
[3] E. Berdahl and W. Ju. Satellite ccrma: A musical
interaction and sound synthesis platform. In NIME,
pages 173–178, 2011.
[4] M. Blessing and E. Berdahl. The joystyx: a quartet of
embedded acoustic instruments. In NIME, pages
271–274, 2017.
[5] R. Fiebrink and P. R. Cook. The wekinator: a system
for real-time, interactive machine learning in music.
In Proceedings of The Eleventh International Society
for Music Information Retrieval Conference (ISMIR
2010)(Utrecht), 2010.
[6] L. Hayes. Enacting musical worlds: Common
approaches to using nimes within performance and
person-centred arts practices. In Proceedings of the
2015 Conference on New Interfaces for Musical
Expression. Baton Rouge, LA , volume 31, 2015.
[7] J. Ho, M. Schedel, and M. Blessing. Women’s labor:
an installation and concert of new and old “feminine”
insstruments. In Proceedings of the Alliance of
Women in Media Arts and Technology Conference .
AWMAT, 2019.
[8] A. Hofmann, B. Waerstad, and K. Koch. Csound
instruments on stage. In Proceedings of the
International Conference on New Interfaces for
Musical Expression, volume 16, pages 291–294.
[9] A. P. McPherson and F. Morreale. Technology and
community in toolkits for musical interface design.
[10] J. Meyer. Acoustics and the performance of music:
Manual for acousticians, audio engineers, musicians,
architects and musical instrument makers . Springer
Science & Business Media, 2009.
[11] F. Morreale, G. Moro, A. Chamberlain, S. Benford,
and A. P. McPherson. Building a maker community
around an open hardware platform. In Proceedings of
the 2017 CHI Conference on Human Factors in
Computing Systems, pages 6948–6959. ACM, 2017.
[12] L. Turchet. Smart musical instruments: vision, design
principles, and future directions. IEEE Access,
7:8944–8963, 2019.
380