Sound guiding action: the effect of timbre on learning a new percussive DMI for beginner musicians    Olivia Bonnie Smith School of Psychology Queen’s University Belfast 15-18 Malone Road,  Belfast BT9 5HN osmith10@qub.ac.uk 
 Dr. Matthew Rodger School of Psychology Queen’s University Belfast 15-18 Malone Road,  Belfast BT9 5HN m.rodger@qub.ac.uk    Dr. Miguel Ortiz  Sonic Arts Research Centre Queen’s University Belfast Cloreen Park,  Belfast BT9 5HN m.ortiz@qub.ac.uk    
 Dr. Maarten Van Walstijn  Sonic Arts Research Centre Queen’s University Belfast Cloreen Park,  Belfast BT9 5HN m.vanwalstijn@qub.ac.uk    
ABSTRACT Learning to play a digital musical instrument (DMI) may be affected by the acoustic behaviour of that instrument, in addition to its physical characteristics and form. However, how the timbral properties of an instrument affect learning has received little systematic empirical research. In an exploratory study, we assessed whether timbral feedback from a physical model based percussive DMI influences beginner players’ performance in a musical learning task. We contrasted the timbral richness of a metallic plate physical model with an amplitude modulated pink-noise signal that was comparable in response to input controls but with relatively reduced timbral features. Two groups of participants practiced three sets of simple beats using their respective version of the instrument (physical model or pink noise), over the course of an hour. Their performance was recorded throughout and assessed in the form of rhythmic timing accuracy. Results showed that participants’ performance in both sound groups significantly improved throughout the task. Timing accuracy was significantly better in the physical model group for one out of three sets of beats. We argue that the timbral feedback of a musical instrument may influence beginner’s playing experience, encouraging further research into how this could benefit DMI design.   Author Keywords timbre, auditory-motor perception, digital musical instruments, control, musical learning, physicality, percussion  CCS Concepts •Human centred computing → Interaction design theory, concepts and paradigms; •Applied computing → Sound and music computing;  
1. INTRODUCTION While there is much interest in the NIME community around user-centered design and player experience, research in these areas has been largely based on the experiences of skilled musicians, with limited attention given to the needs of beginners learning DMIs [15].  This bias in methodology is important to address systematically, as research in performer-instrument interaction has shown that there are differences in the preferences, goals and experiences of musicians as result of musical expertise [9]. This is supported by findings in sensory-motor research, highlighting the significant effects of musical practice on motor coordination and auditory processing [8, 24, 25]. These effects imply that beginners may have a different perception of instrumental sounds and affordances compared to experts. As a result, DMI design choices such as the sound synthesis used or the action-to-sound mappings may affect the learning curve of beginner instrumentalists differently to those with more experience. As this effect had yet to be systematically studied, we took an exploratory approach to consider DMIs from the perspective of novice learners and the effects of differences in instrument design on the trajectory of learning for beginners. We focus on the effects of the instrument’s programmed timbre on the player’s performance in a percussive task, in an effort to observe how systematic changes in the auditory feedback of the instrument may affect the accuracy and playing skill of learners.  2. RELATED WORK 2.1 Auditory Feedback in performer-instrument interactions  Playing a musical instrument is widely considered a complex motor skill. It relies on the coordination of the player’s cognitive and sensory-motor control processes to create fluid sequences of musical gestures [30]. When interacting with an instrument, the musician’s actions translate into sound and haptic vibration. The player perceives this as auditory and kinaesthetic information 

caused by their movements, which we refer to throughout as sensory feedback.  Sensory feedback allows the player to make predictions about the instrument’s behaviour in response to action, and to consequently adapt their movements in real time [29]. Coherence between sensory feedback and action is therefore essential for instrumental control and fluidity of musical action. Research into how sensory feedback such as visual, kinaesthetic and auditory feedback influences and supports musical learning and performance is growing – although addressing all of these is beyond the scope of this paper. We will be focusing specifically on auditory feedback, defined as the perceived auditory consequences of one’s musical actions [17].  A review of the research on auditory feedback mechanisms involved in performer-instrument interactions by Nunes-Silva et al. [17] shows that much of the literature focuses on the effects of discrete note pitches and timing of auditory feedback for learning and performance. Although these are informative, studies are largely based on key-based instruments and few consider other features of auditory feedback, such as Timbre. Research has shown that timbre carries perceptual information about the characteristics of a sound’s physical source. It can allow one to discern of the size and shape of a sounding object as well as the materials that it is made of [1, 13]. It is therefore likely that timbre is an important dimension of auditory feedback in the control of the sound of a musical instrument, and consequently something that may play a role in the development of instrumental skill. We argue that it is worth applying these theories to musical learning as timbral cues about an instrument’s physical characteristics could help guide, predict and control movement. 2.1.1  Altered auditory feedback  A method of assessing the effects of auditory feedback on musical gesture and control is to systematically manipulate the auditory behaviours of an instrument [3]. These methods highlight how incoherent action-sound mappings can significantly hinder performance, and thereby provide empirical evidence of the importance of coherent action-sound feedback for aspects of performance. Pfordresher and colleagues have conducted a substantial amount of research using altered auditory feedback (AAF) to assess the effects of timing, pitch and loudness on performance [21, 23, 25]. Altering the contents of sound such as pitch and volume shows mixed results. Randomising pitch or inverting piano keys in musical learning tasks tends to negatively impact performance accuracy (increase in incorrect key presses) but has negligible effects on rhythmic timing [22, 23]. However, occasional and inconsistent pitch disruption in an otherwise predictable sequence hindered both timing and accuracy [12]. Results generally show that latency is the most disruptive to temporal performance, causing variability in rhythmic timing but doesn’t significantly affect errors in pitch selection in keyboard studies [22]. Similar effects have been observed in research on performer-instrument interaction in the context of DMIs, showing that even small durations of latency can have significant negative effects on the player’s quality assessment of the instrument, even if it doesn’t significantly affect performance accuracy [10]. This is in line with research by Couchman et al. [3], suggesting that incoherence and/or inconsistencies between sound and action reduces the player’s perceived control over the instrument and can bring into question their experience of “agency”. Whilst these studies are informative and highlight the tight coupling between auditory and motor systems, they are largely conducted on key-based instruments consequently limiting the scope of possible sound behaviours, such as timbre variations and types of sound- 
producing actions. Timbre has not been considered as a factor affecting timing or control accuracy and is significantly lacking in the literature. Efficiently controlling the sound production of an instrument, and perceived control over these dynamics, requires a process of familiarity and practice to develop knowledge of these mappings.  2.2 Musical Learning 2.2.1 Auditory feedback for Motor Learning In the context of skill development and learning, research by Dyer, Stapleton & Rodger [4] on movement sonification looked at the advantages auditory feedback for bimanual motor skill development. Sonification is defined here as the process of mapping sound to movement as a form of augmented feedback, to inform about movement properties such as velocity, trajectory, location in space, proximity to other objects, etc. This study focused on the differences in melodic and rhythmic sonification in a lab-based task, involving polyrhythmic bimanual shape tracing.  Participants were required to trace two different shapes with their left and right hand simultaneously at a set rhythm. They were divided into three groups which received either melodic feedback, rhythmic feedback or no auditory feedback to their hand movements. Results suggested that the presence of sequential note patterns reduced the number of coordination errors in the task and resulted in a faster learning rate, compared to the rhythmic feedback consisting of neutral bursts of white noise [4]. These findings highlight how information carried in sound can positively influence movement and learning outcomes at a fundamental science level, that is, measuring learners practicing the kind of movement task found in laboratory-based motor learning studies [5, 6]. However, how this applies to musical skill development has been relatively understudied.  2.2.2 Auditory feedback for Player Experience The relationship between learning and musician’s experiences with DMIs is also relevant to the present research. A common narrative within the NIME community is that increased richness of control and detail of feedback implies a better playing experience [28]. However, this has shown to not necessarily be the case for novice players [9].  Jack, Morreale & McPherson [9] conducted a study looking at levels of control and richness of auditory feedback on playing preferences of expert guitarists and non-musicians. They refer to Moor’s [14] concept of control intimacy, defined as how the richness and variation of performer’s actions are mapped to musical output. They compared player preferences of a guitar inspired DMI, with two levels of control intimacy. One version was based on a rich mapping, composed of audio-rate coupling between strings and synthesis, the other was a simplistic note- triggering version. The results of their interviews suggested that beginners had mixed opinions but tended to prefer simplicity, as opposed to experienced musicians who unanimously preferred the richer sound-gesture mappings. This is likely because experts could fully apply existing skills to explore and push the limits of the instrument’s affordances in the richer condition [9, 11]. Beginners preferred the simplistic mapping as it allowed them to play coherently with less effort, in a way that was a better match to their abilities and goals. Although this study provided insight into player’s opinions and preferences of instrument complexity at different stages of musical expertise, it could be furthered by questioning how the complexity of controls and feedback influences musicians’ skill development and ability to learn a new DMI.   
3. MOTIVATIONS FOR CURRENT STUDY This project is motivated by a desire to provide an initial insight into the sensory-motor processes underlying musical learning in the context of new digital interfaces. We hope to test whether differences in instrumental auditory feedback can be shown to affect learning of a technique at an early stage of musical skill development. With this we consider how design choices (sound synthesis in this case) may impact the learnability of DMIs for new players.  To answer these questions, we conducted an exploratory experiment looking at timing accuracy, in which two groups of non-musicians practiced playing novel rhythmic patterns on one of two versions of a percussion DMI, which varied in terms of timbral richness.   4. METHOD 4.1 The instrument The instrument used in this study can be simply described as a touch-sensitive rectangular pad using physical model sound synthesis, driven and damped by the player’s touch.  In more detail, it is composed of a Sensel Morph Plate (240mm x 138mm x 4.5mm; approx. 20 000 sensors; sensitivity range 1g- 5kg; tracking accuracy approx. 0.1mm) and a contact microphone (AKG C 411 PP), connected to a Macintosh computer (OSX Sierra version 10.12) using an audio-interface (Focusrite Scarlett 2i2 3rd Gen). Two monitors were positioned at 70cm on the left and right side of the participant. The Sensel Morph plate was positioned on a desk directly in front of the participant at a comfortable distance. The task and the physical model were running on MAX-MSP (version 8.1.2).   4.1.1 The Physical model The physical model synthesis algorithm is a re-configuration of the virtual-acoustic string-bridge-plate instrument model presented by VanWalstjin & Mehes [27], which was also used to build the Vodhrán [20]. The plate and string are modelled as linear distributed elements, and the bridge element that couples them can be configured to introduce nonlinear behaviour. The musician’s force input signal is captured with a contact microphone and fed as an input to the virtual-acoustic plate, and the output sound consists of the computed velocity at two plate positions. The timbre produced with this model depends on the nature of the force input signal as well as on the contact input coordinates, which are directly mapped from the Sensel pad to the real-time audio engine. The resonance characteristics imparted by the model, including its materiality (i.e. ‘metal- like’), are determined mainly by the plate parameters (e.g. plate dimensions, damping factors). Damping control is realised by mapping the total force sensed with the Sensel to additional plate damping.   Physical modelling was chosen for this study design as it allows for high control intimacy, due to its responsiveness, variability in sound range and realistic response to musical action [2]. As it is based on lawful mechano-acoustic relationships, it’s perceptual familiarity and physicality is built in, as opposed to some more contingent forms of sound synthesis. The percussive nature of the instrument enables play and exploration in the form of basic human gestures (i.e., hitting, scratching, pressing and tapping), encouraging embodied knowledge.  4.1.2. The Pink Noise Condition To compare the perceptual effects of timbral richness on performance, we created a second sound condition that was 
comparable to the physical model in response to input controls, but with reduced timbral features using pink noise. This was done by linking the “pink noise” object in MAX- MSP with an audio-follower, tracking the sound intensity envelope of the physical model, whilst blocking out the other spectral components. This sound condition can be likened to an additive synth hi-hat sound but lacking in physical characteristics and detail compared to the physical model.    
 Figure 1. Experimental set-up.   4.2 Study Design Using a Between x Within-subjects design, we randomly divided N=20 non-musicians into two groups. The participants were over 18 years old and had normal or corrected to normal hearing. There were no gender specifications for this study. Inclusion criteria required participants to self-report as being non- musicians using the Zhang & Schubert [31] musicianship classification scale.  Group 1 were allocated to the physical model version of the instrument, designed to have “rich” timbral characteristics of a metal plate or cymbal. The sensitivity and responsiveness of the model allowed for highly detailed and realistic auditory feedback. Group 2 interacted with the pink noise version of the instrument, which was comparable to the physical model in response to input controls, but with reduced timbral features.  Input control over the model for both groups was in the form of tapping to excite the percussion events and “damping”, or “muting” the output by pressing down on the Sensel surface. Measures were taken to ensure that the response rate and volume of the auditory feedback remained the same in both groups; a low latency filter was used in the pink noise condition to minimise processing time and the volume of feedback was balanced by an experienced musician and composer. The Gold-MSI questionnaire [16] was used to assess the participants’ musicality levels to assure an even distribution between the two groups.  4.3 Procedure Upon arrival, all participants completed the Gold-MSI Questionnaire [16]. They were given a few minutes to familiarise themselves with the controls of the instrument before beginning the task. The learning task required both groups to practice three short sequences of beats (5-7 beats per bar – at approx. 90 bmp) in their respective sound conditions. Participants would listen to pre-recorded templates of these beats at regular intervals and practice reproducing them. The templates were created by an expert drum instructor and deemed to be of appropriate difficulty 

for beginners. Three different beats were used to introduce variety as to avoid participants losing interest in the task. The task was automated to play the templates on a loop for 10 seconds. Participants then had a 30 second window to practice recreating the sequence before hearing the template again. The participants did this three times for each template, creating one Block of trials. They did three blocks in total over the course of one hour. The order in which they received the templates was counterbalanced. Their performance was recorded throughout the task, using the contact microphone and pressure data from the Sensel, measuring rhythmic timing accuracy. 
Figure 2. Templates 1, 2, 3. The templates were played with a swing feel.   4.4 Analysis  The contact mic data from the three blocks of the learning task was used to identify taps from onsets in the audio intensity signal, and this was then used to compare timing of taps with those of the respective pre-recorded templates. ‘Taps’ are identified from the rate-of-change of sound intensity signals as samples at which rate-of-change exceed 5% of maximal value. From these samples, intervals are calculated as durations between consecutive taps, and pressure values at these same samples are also extracted. Sets of n tap values, where n equals the number of taps in the template, are successively compared against the values in the template by subtraction. The mean difference of interval durations between the template and the trial is then calculated as the error for that trial. Three two-way ANOVAs were conducted, one for each template, to compare average timing error rates between block 1 (start of practice) and block 3 (end of practice) for both sound groups.  5. RESULTS Independent T-test of the Gold-MSI general sophistication levels suggested no significant differences in musicality levels between the two groups (t(19)= 1.524, p= .326).  ANOVA of participant’s performance in both groups showed a significant increase in rhythmic timing accuracy between Block 1 and Block 3 for Template 1 (F(1,19)=23.990, p<.001; n2p= .558), Template 2 (F(1,19)=5.673, p=.028; n2p= .230) and Template 3 (F(1,19)=5.611, p=.029; n2p= .228), as reflected in reduction of error.  Results of performance in Template 1 showed a significant main effect of group (F(1,19)=5.430, p=.031; n2p= .725). Participants in the physical model group had significantly fewer timing errors over time than those in the pink noise group. No interaction effects were observed between block and group (F(1,19)=2.725, p=.115). Templates 2 and 3 did not show any significant difference between groups. (For further explanation on interpreting analysis of variance (ANOVA) & statistical notation, see [7]). 
 Figure 3. Beginner’s Mean Timing Error for blocks 1 and 3 in Templates 1, 2, 3. Error bars represent standard error of the mean 6. DISCUSSION 6.1  Summary of Results  Results in section 5 show that overall timing errors in all three templates reduced as both groups progressed through the task, indicative of skill development. This also suggests that the study design was reliable in that it enabled learning to occur. Participants in the physical model group performed significantly better than those in the pink noise condition when playing Template 1. This could be due to the richness of feedback provided by the physical model. However, these effects did not show for templates 2 and 3.  It is of interest to note the overall higher error values in Template 1, suggesting that it may have been more difficult to perform than the other two templates, therefore leaving more room for improvement and a benefit of the physical model timbre for learning instrumental control.  6.2 Implications for learning One of the aims of this study was to understand how differences in instrumental timbre affect learning technique at an early stage of musical skill development.  Dyer et al. [4] showed that sound as augmented feedback, specifically pitch, had a positive effect on motor-learning learning outcomes in lab-based tasks. We built upon this approach by suggesting timbre as tool for guiding performance and applied it to a musical learning context.   Our findings showed mixed results as timbre had a positive influence on performance for only one out of three musical templates. In Template 1, the fine detail of variations in the timbre may have enabled more precision compared to the monotonous structure of pink noise when it came to timing musical “taps”. However, as the high levels of error in Template 1 imply that it was more difficult to perform than templates 2 and 3, this raises the question of timbral feedback becoming of use only when the task becomes more challenging. Template 1 did contain more components than the other two templates (see figure 2.), but it is not clear what characteristics are most likely the of cause errors for novice musicians. More research in this area is needed to determine under what conditions timbre actually influences learning, and what this means for instrumental design.  6.3 Implications for instrumental design  Research previously mentioned by Jack et al. [9], provided insight into player’s opinions and preferences of instrument complexity at different stages of musical expertise. An important finding was that simplistic instrumental design was preferred by novices as it allowed them to play in a satisfying way with 

minimum effort. However, how this applies to their ability to learn and develop musical skill had yet to be systematically researched.  Our study provides an initial evidence case that timbre richness may positively impact the player’s ability to learn and develop new skills with a percussive DMI. These early findings showed mixed results as the richer timbre condition only supported learning in one of the three templates. It is important to acknowledge that our findings are relevant in the context of physical modelling synthesis, but this may not be the case for other instrument designs. The model used in this study represents a percussion instrument controlled by tapping and pressure, which shares similarities in sonic response with familiar acoustics instruments. However, a more abstract instrument in terms of its design and mapping (e.g. one that has no physical relationship to sound) may not be as reliant on timbral feedback to guide performance.  It has been suggested in a review on DMI ecologies and specificities by Rodger, Stapleton, van Walstijn, Ortiz & Pardue [26] that there is no “one size fits all” rule for instrumental design or evaluation. It depends on many variables such as the type of instrument, the context and the player’s individual intentions and abilities. Further work will be required to unpack under what circumstances timbre does and does not make a difference to playing experience, and in turn on learning to play a novel DMI.   7.  FUTURE RESEARCH  Following this initial exploratory study, continued research into the role of timbre as auditory feedback for learning is needed. Future research could focus on assessing under which conditions timbre actually influences learning (i.e. different instrument types, constrains, sound synthesis and tasks), and what this means for different DMI designs.  In depth research into how action-sound mappings influence novice learners could be beneficial for the continued development of concepts such as Pardue’s [18] “complexity-management”, defined as the process of regulating the complexity of controls and feedback of DMIs to suit the abilities of the player [19]. As our study showed, timbre may be able to modulate timing accuracy, but they are many other aspects of musical action, such choice of technique and gesture control, that could be influenced by timbral-feedback. Ultimately, future research should continue evaluating the differences in needs between expert and novice musicians, to keep developing a range of DMIs suitable to the needs of all.   8. ACKNOWLEDGMENTS Many thanks to the participants and to the professional drummer, Henrique Ferreira Franco for the template recordings.   9. ETHICAL STANDARDS Informed consent was acquired from all participants. The procedures in this study were performed in accordance with the 1964 Declaration of Helsinki, adhering to the ethical standards of the British Psychological Society code of Ethics and Conduct, and approved by the Queen’s University Belfast School of Engineering and Physical Sciences Ethics Committee. Faculty REC Reference Number: EPS 20_227 – approved 22 October 2020.  The author O.B. Smith is supported by UK Department for the Economy (DfE) under PhD Grant Application no. 00575271.  
10. REFERENCES [1] M. Aramaki, M. Besson, R. Kronland-Martinet, and S. Ystad, Controlling the perceived material in an impact sound synthesizer, IEEE Trans. Audio, Speech Lang. Process., vol. 19, no. 2, pp. 301–314, 2011, doi: 10.1109/TASL.2010.2047755  [2] N. Castagné and C. Cadoz, 10 Criteria for Evaluating Physical Modelling Schemes for Music Creation, Proc. Int. Conf. Digit. Audio Eff., pp. 1–7, 2003.  [3] [J. J. Couchman, R. Beasley, and P. Q. Pfordresher, The experience of agency in sequence production with altered auditory feedback, Conscious. Cogn., vol. 21, no. 1, pp. 186–203, 2012, doi: 10.1016/j.concog.2011.10.007.B. Fröhlich and J. Plate. The cubic mouse: a new device for three- dimensional iput. In Proceedings of the SIGCHI conference on Human factors in computing systems (CHI ’00) (The Hague, The Netherlands, April 1-6, 2000). ACM Press, New York, NY, 2000, 526-531.  [4] J. F. Dyer, P. Stapleton, and M. W. M. Rodger, Advantages of melodic over rhythmic movement sonification in bimanual motor skill learning, Exp. Brain Res., vol. 235, no. 10, pp. 3129–3140, 2017, doi: 10.1007/s00221-017-5047-8.M.L. Sannella. Constraint Satisfaction and Debugging for Interactive User Interfaces. Ph.D. Thesis, University of Washington, Seattle, WA, 1994.  [5] J. Dyer, P. Stapleton, and M. Rodger, Transposing musical skill: sonification of movement as concurrent augmented feedback enhances learning in a bimanual task, Psychol. Res., vol. 81, no. 4, pp. 850–862, 2017, doi: 10.1007/s00426-016-0775-0.  [6] J. F. Dyer, P. Stapleton, and M. W. M. Rodger, Sonification as Concurrent Augmented Feedback for Motor Skill Learning and the Importance of Mapping Design, Open Psychol. J., vol. 8, no. 1, pp. 192–202, 2016, doi: 10.2174/1874350101508010192.  [7] A. Field, Discovering statistics using IBM SPSS statistics. sage, 2013. [8] M. Hosoda and S. Furuya, Shared somatosensory and motor functions in musicians, Sci. Rep., vol. 6, no. April, pp. 1–10, 2016, doi: 10.1038/srep37632.  [9] R. H. Jack, F. Morreale, J. Harrison, and A. McPherson, Democratising DMIs : the relationship of expertise and control intimacy, no. April, pp. 184–189, 2018.  [10] R. H. Jack, T. Stockman, and A. McPherson, Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument, ACM Int. Conf. Proceeding Ser., vol. 04-06-Octo, pp. 116–123, 2016, doi: 10.1145/2986416.2986428.  [11] R. H. Jack, T. Stockman, and A. McPherson, Rich gesture, reduced control: The influence of constrained mappings on performance technique, in ACM International Conference Proceeding Series, 2017, vol. Part F1291, doi: 10.1145/3077981.3078039.  [12] B. Mathias, C. Palmer, F. Perrin, and B. Tillmann, Sensorimotor Learning Enhances Expectations during Auditory Perception, Cereb. Cortex, vol. 25, no. 8, pp. 2238–2254, 2015, doi: 10.1093/cercor/bhu030.  [13] S. McAdams, A. Chaigne, and V. Roussarie, The psychomechanics of simulated sound sources: Material properties of impacted bars, J. Acoust. Soc. Am., vol. 115, no. 3, pp. 1306–1320, 2004, doi: 10.1121/1.1645855.  [14] F. R. Moore, The dysfunctions of Midi, Computer Music Journal, vol. 12, no. 1, p. 19, 1988.  [15] F. Morreale and A. P. Mcpherson, Design for Longevity : Ongoing Use of Instruments from NIME 2010-14, Nime 2017, 2017.  
[16] D. Müllensiefen, B. Gingras, L. Stewart, and J. J. Musil, Goldsmiths Musical Sophistication Index (Gold-MSI) v1.0 Technical Report and Documentation Revision 0.3, 2013.  [17] M. Nunes-Silva, T. B. Janzen, R. G. Rodrigues, and A. R. da Luz, Sensory feedback in music performer–instrument interactions, Psychol. Music, 2020, doi: 10.1177/0305735620928397.  [18] L. S. Pardue. Violin Augmentation Techniques for Learning Assistance. PhD thesis, Queen Mary University of London, 2017  [19] L. S. Pardue, A. McPherson, and D. Overholt, Improving the instrumental learning experience through complexity management, Proc. 15th Sound Music Comput. Conf. Sonic Crossings, SMC 2018, pp. 150–157, 2018.  [20] L. S. Pardue, M. Ortiz, M. van Walstijn, P. Stapleton, and M. Rodger, Vodhrán: collaborative design for evolving a physical model and interface into a proto-instrument, Proc. Int. Conf. New Interfaces Music. Expr., pp. 623– 625, 2020.  [21] P. Q. Pfordresher, Auditory Feedback in Music Performance: Evidence for a Dissociation of Sequencing and Timing, J. Exp. Psychol. Hum. Percept. Perform., vol. 29, no. 5, pp. 949–964, 2003, doi: 10.1037/0096- 1523.29.5.949.  [22] P. Q. Pfordresher, Auditory feedback in music performance: The role of melodic structure and musical skill, J. Exp. Psychol. Hum. Percept. Perform., vol. 31, no. 6, pp. 1331–1345, 2005, doi: 10.1037/0096- 1523.31.6.1331.  [23] P. Q. Pfordresher and J. D. Kulpa, The dynamics of disruption from altered auditory feedback: Further evidence for a dissociation of sequencing and timing, J. 
Exp. Psychol. Hum. Percept. Perform., vol. 37, no. 3, pp. 949–967, 2011, doi: 10.1037/a0021435.  [24] B. H. Repp, Sensorimotor synchronization and perception of timing: Effects of music training and task experience, Human Movement Science, vol. 29, no. 2. pp. 200–213, 2010, doi: 10.1016/j.humov.2009.08.002.  [25] B. H. Repp and Y. H. Su, Sensorimotor synchronization: A review of recent research (2006-2012), Psychon. Bull. Rev., vol. 20, no. 3, pp. 403–452, 2013, doi: 10.3758/s13423-012-0371-2.  [26] M. Rodger, P. Stapleton, M. Van Walstijn, M. Ortiz, and L. Pardue, What Makes a Good Musical Instrument ? A Matter of Processes , Ecologies and Specificities., NIME 2020, 2020.  [27] M. Van Walstijn and S. Mehes, An explorative string- bridge-plate model with tunable parameters, Proc. Int. Conf. Digit. Audio Eff. DAFx, no. c, pp. 291–298, 2017.  [28] D. L. Wessel and M. Wright, Problems and prospects for intimate and satisfying sensor-based control of computer sound, Time, pp. 1–4, 2002.  [29] D. M. Wolpert, J. Diedrichsen, and J. R. Flanagan, Principles of sensorimotor learning, Nat. Rev. Neurosci., vol. 12, no. 12, pp. 739–751, 2011, doi: 10.1038/nrn3112.  [30] R. J. Zatorre, J. L. Chen, and V. B. Penhune, When the brain plays music: Auditory-motor interactions in music perception and production, Nat. Rev. Neurosci., vol. 8, no. 7, pp. 547–558, 2007, doi: 10.1038/nrn2152.  [31] Zhang and E. Schubert, A single item measure for identifying musician and non-musician categories based on measures of musical sophistication, Music Perception, vol. 36, no. 5, pp. 457–467, 2019.     