Bangarama: Creating Music With Headbanging
Laszlo Bardos, Stefan Korinek, Eric Lee and Jan Borchers
Media Computing Group
RWTH Aachen University
52056 Aachen, Germany
{bardos, korinek, eric, borchers}@cs.rwth-aachen.de
ABSTRACT
Bangarama is a music controller using headbanging as the pri mary
interaction metaphor. It consists of a head-mounted tilt se nsor and a
guitar-shaped controller that does not require complex ﬁng er posi-
tions. We discuss the speciﬁc challenges of designing and bu ilding
this controller to create a simple, yet responsive and playa ble in-
strument, and show how ordinary materials such as plywood, t in
foil, and copper wire can be turned into a device that enables a fun,
collaborative music-making experience.
Keywords
head movements, music controllers, interface design, inpu t devices
1. INTRODUCTION
An essential part of the musical experience in rock music is i n
the body movements, and a very characteristic movement is th e
vigorous nodding of the head in sync to guitar strokes or the b eat,
also known as headbanging (see Fig. 1). This relationship between
body movement and music inspired us to create a music control ler
that uses headbanging to trigger sound samples, so that a hea d-
banger can inﬂuence the music with her movements instead of
merely reacting to the music passively.
As part of a graduate-level computer science course examini ng
new interaction metaphors for multimedia, our goal was to cr eate
a simple and intuitive music controller that is playable by n on-
musicians, but still retains enough ﬂexibility to be of inte rest to
musicians. Playing a classical musical instrument often re quires
executing complex hand and/or foot sequences, so we opted fo r a
more simpliﬁed interface that naturally maps movements to s ound
generation and provides immediate feedback to the headbang s for
increased playability.
In this paper we will provide an overview of Bangarama’s desi gn
and its interaction metaphors. Then we will discuss the indi vidual
hardware and software components in more detail. Finally, w e will
discuss the results of observing users using Bangarama and c ollect-
ing their feedback.
Permission to make digital or hard copies of all or part of thi s work for
personal or classroom use is granted without fee provided th at copies are
not made or distributed for proﬁt or commercial advantage an d that copies
bear this notice and the full citation on the ﬁrst page. To cop y otherwise, to
republish, to post on servers or to redistribute to lists, re quires prior speciﬁc
permission and/or a fee.
NIME05, V ancouver, BC, Canada
Copyright 2005 Copyright remains with the author(s).
F ig u r e 1 : “ H e a d b a n g in g ” r e f e r s t o t h e f a s t , a b r u p t m o v e m e n t s
o f t h e h e a d in t h e f o r w a r d d ir e c t io n .
2 . R E L A T E D W O R K
G u ita r - lik e c o n tr o lle r s w h ic h in tr o d u c e n e w m e th o d s o f m u s i-
c a l in te r a c tio n a n d e x p r e s s io n h a v e b e e n p r e s e n te d b e f o r e . J o r d `a ’s
Q W E R T Y C a s te r [ 4 ] a llo w s a u s e r a la r g e d e g r e e o f f r e e d o m in c r e -
a tin g M I D I m u s ic b y a tta c h in g a k e y b o a r d , tr a c k b a ll a n d jo y s tic k
to a s in g le , g u ita r - s h a p e d w o o d e n c o n tr o lle r. U n lik e Q W E R T Y -
C a s te r, B a n g a r a m a a llo w s th e u s e r to in te r a c t w ith th e s y s te m u s in g
o n ly o n e h a n d , le a v in g o p p o r tu n itie s f o r in te r a c tin g w ith a d d itio n a l
d e v ic e s . B a n g a r a m a ’s s ty le o f b u tto n s in p la c e o f f r e ts a ls o o f f e r
c le a r e r a f f o r d a n c e s to u s e r s w h o m a y h a v e s e e n a p e r s o n p la y in g a
g u ita r, b u t d o n o t k n o w h o w to p la y th e m s e lv e s .
M e r r ill u s e s v is u a l r e c o g n itio n o f h e a d n o d s a n d s h a k e s to
c h a n g e s o u n d a ttr ib u te s w h ile p la y in g g u ita r [ 6 ] , a s a n a lte r n a tiv e
to f o o t s w itc h e s , w h ic h c a n b e d if ﬁ c u lt to o p e r a te . I n h is s y s te m ,
h e a d m o v e m e n ts a r e u s e d to m o d u la te th e s o u n d o u tp u t f r o m a n
o r d in a r y e le c tr ic g u ita r. L y o n s ’ M o u th e s iz e r im p le m e n ts a s im i-
la r c a m e r a - b a s e d s y s te m w h ic h m e a s u r e s th e s h a d o w a r e a in th e
p la y e r ’s m o u th [ 7 ] . T h e s iz e o f th e a r e a is m a p p e d to M I D I c o n -
tr o l c h a n g e s . B a n g a r a m a , in c o n tr a s t to th e s e tw o s y s te m s , u s e s
a s im p le m e c h a n ic a l s e n s o r to m in im iz e la te n c y ; h e a d m o v e m e n ts
d ir e c tly tr ig g e r s o u n d s a m p le s .
S h e p p a r d ’s d ig ita l g u ita r [ 9 ] r e p la c e s s tr in g s w ith s e v e r a l in -
f r a r e d a n d to u c h s e n s o r s . F o u r in f r a r e d b e a m s s im u la te th e s a m e
n u m b e r o f s tr in g s a n d a r e tr ig g e r e d b y c r o s s in g th e b e a m s w ith th e
ﬁ n g e r s o f th e r ig h t h a n d , a n d a m a tr ix o f 4 x 1 2 to u c h s e n s o r s r e p -
r e s e n t th e f r e ts a n d a r e o p e r a te d w ith th e ﬁ n g e r s o f th e le f t h a n d .
T h is s e tu p a llo w s u s e r s to p la y th e d ig ita l g u ita r v e r y m u c h lik e
th e y w o u ld a r e a l in s tr u m e n t; th e d is a d v a n ta g e , h o w e v e r, is th a t th e
c o m p le x ﬁ n g e r p o s itio n s a s s o c ia te d w ith g u ita r - p la y in g m u s t a ls o
b e le a r n e d . B a n g a r a m a u s e s a d if f e r e n t a p p r o a c h , b y p r o v id in g a
s im p liﬁ e d in te r f a c e w ith a f f o r d a n c e s s im ila r to a s tr in g in s tr u m e n t,
a n d w ith th e a d d itio n o f h e a d b a n g in g .
H u o tt [ 2 ] c r e a te d a s k i- s h a p e d d e v ic e , p la y e d lik e a c e llo b y la y -
in g th e u p p e r p a r t o v e r th e s h o u ld e r a n d s e le c tin g n o te s b y p la c in g
th e ﬁ n g e r s o n th e “ n e c k ” o f th e d e v ic e . I n s te a d o f s tr in g s , th e d e -
v ic e h a s a r e c ta n g u la r p a tc h o f ta c tile s e n s o r s , c o v e r in g a n a r e a o f
a p p r o x im a te ly 2 0 s q u a r e in c h e s . S o u n d s a r e g e n e r a te d a n d m a n ip u -
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
180
Head sensor
Guitar-shaped
controller
Front
bracket
Pin
Figure 3: Bangarama player with head-mounted sensor and
guitar-shaped controller .
lated by touching and moving the ﬁngers on the patch. Again, B an-
garama also uses the string instrument metaphor, replacing strings
with touch sensitive sensors, but adds headbanging to the in terac-
tion.
3. DESIGN
Our system implements Wanderley’s abstract digital music i n-
terface representation [12], which separates the gestural controller
from the sound generation unit. Bangarama consists of three main
components. A sensor is used to recognize head movements, an d
a guitar-shaped controller for selecting sound samples. Th e input
is passed to a software subsystem created using Max/MSP , whi ch
selects the appropriate audio sample and plays it (see Fig. 2 ).
Bangarama uses a simple mechanical sensor mounted on a base-
ball cap to measure if the head is in an upright or downwards-t ilted
position. An upright-to-tilted transition triggers playb ack of a dig-
ital sound sample, selected by pressing one of the buttons on the
guitar. The software subsystem allows any arbitrary digita l audio
sample to be played. We decided to use digital audio samples,
rather than MIDI, to allow a wider range of sounds. For exam-
ple, while the standard half-tone scale for a particular instrument
can be used, other types of audio, such as speech, can be incor -
porated as well. We have also found that using audio samples o f
power chords makes it easy to create realistic sounding rock mu-
sic. Power chords are triads consisting of the root, the ﬁfth and
the octave. Power chords are often used in rock music, played by
distorted electric guitars.
We also tried using short sound bites from movies, played to
the accompaniment of popular music. This choice proved to be
an enjoyable alternative over standard music instruments,and is an
example of how using digital audio provided greater ﬂexibil ity than
MIDI music.
Bangarama offers two modes of operation. In freeplay mode the
user manually selects the sample to play using the buttons on the
45 ms
Figure 4: Measurement of Bangarama’s overall system latenc y.
We recorded the sound of the sensor pin hitting the bracket,
together with the audio output from Max/MSP, and measured
the latency in the resulting waveform.
guitar, while in automated mode , the sequence of samples is prepro-
grammed into the system, and the user simply controls the tim ing.
In both cases, the user has the choice of playing with a backgr ound
accompaniment in the form of a looped audio sample to simulat e
the experience of playing in a band.
In our design, we tried to minimize use of the mouse and key-
board, which is considered too technical and inappropriate for cre-
ating music [1]. In an earlier prototype of Bangarama, a keyb oard
was required to select the different sounds, which forced th e player
to sit in front of a computer while interacting with it. This p he-
nomenon is also called the “laptop musician problem” [6], an d in a
subsequent version we used a guitar-shaped controller inst ead.
4. IMPLEMENT ATION
Our original intention was to use an analog accelerometer fo r the
head sensor, connected to a Teleo USB analog-to-digital con verter
[5] for measuring pitch and intensity of head movements. Usi ng
an analog device such as the accelerometer would be advantag eous
because it offers more degrees of freedom; for example, we wa nted
to map intensity of the movements to the volume of the samples .
We also considered approaches based on head tracking and com -
puter vision such as the one used by Merrill [6]. However, due to
time and budget constraints, we decided to build a custom sen sor
that simply measures two states of head tilt. In retrospect, this solu-
tion turned out to be a better choice: compared to commercial head
trackers and computer vision systems, our custom-made sens or is
cheaper, less intrusive and easier to set up, factors which a ffect the
overall immersiveness a system provides [11].
An evaluation of playability in a system often involves a mea -
sure of latency, with 100 ms being an often quoted upper limit for
causality in user interfaces [3]. We measured the overall sy stem
latency by recording an audio clip of the sound when the pin hi ts
the front bracket, followed by the resulting audio output tr iggered
by this event. Examining the audio clip in a waveform editor, we
found our overall system latency to be approximately 45 ms (s ee
Fig. 4).
4.1 Head Sensor
The Bangarama sensor (see Fig. 3) is attached to a baseball ca p
using a V elcro strip, which allows each user to individually adjust
the alignment of the sensor. The sensor is made of wire and wor ks
like a physical seesaw. If the head is moved downwards, the se nsor
pin tilts towards the front bracket and eventually closes th e circuit.
The contact opens when the head is moved back to its normal po-
sition. This creates two different signals that are evaluat ed in our
software. In order to obtain better physical contact betwee n bracket
and pin, we weighed down the pin with a small coin and coated th e
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
181
Guitar-shaped controller
Head mounted sensor
Modiﬁed USB Keyboard Max/MSP Patch Speakers
Sample Trigger
Sample
 Selec
tion
Keyboard
Event
Audio
Figure 2: System overview. A head-mounted sensor triggers s ound samples selected using a guitar-shaped controller . Th ese devices
are connected by a ribbon cable to a modiﬁed USB keyboard, whi ch in turn passes the appropriate keyboard events to a Max/MS P
patch that outputs the speciﬁed sounds.
Figure 5: Each pair of contact surfaces is connected to a corr e-
sponding pair of contacts on the keyboard.
bracket with tin foil. We differentiate between open and closed
states, corresponding to the position of the pin.
4.2 Sample Selection
To enable the user to select the sample to play, we decided to u se
a guitar-shaped controller, following the D OMAIN A PPROPRIATE
D EVICES design pattern for interactive systems [1]. We cut out a
guitar-shaped piece of a plywood and attached 26 aluminum co n-
tact surfaces along the neck of the guitar, two for each “fret ”. These
contact surfaces are connected via ribbon cable to a USB keyb oard.
We removed several keys from the keyboard and directly solde red
the wires from each pair of contact surfaces to the electrica l con-
tacts underneath (see Fig. 5). Each pair of wires is a differe nt color,
which helps the user learn and memorize ﬁnger patterns. The h ead
sensor is connected in a similar fashion. While using Bangar ama,
the player must wear a strip of tin foil around his playing ﬁng ers,
and selects a sound sample by placing those ﬁngers on the appr o-
priate contact surfaces, which in turn close the circuit and trigger
the corresponding keys. We decided to include thirteen keys on the
interface, corresponding to an octave plus the ﬁrst note of t he next
octave, because popular songs often use the ﬁrst note from th is next
octave.
4.3 Software
We used Max/MSP [8], a graphical, real time signal and event
processing environment for MIDI and digital audio to output our
sound samples. Our patch is responsible for catching events from
the head sensor and Bangarama guitar. When the user selects a
sound sample on the guitar, the attached USB keyboard sends a
keyboard event, which causes the patch to switch to the speci ﬁed
sample. In a similar fashion, the patch receives a keyboard e vent
when the user’s head tilts downwards.
In our earlier prototypes, we encountered some stability pr ob-
lems with the head sensor: the pin of the sensor bounced when
it hit the front bracket, resulting in additional, undesired keyboard
events. This caused an irregular and quick repetition of the audio
sample. To ﬁx this issue, we implemented a time-based event l ock,
where subsequent events from the head sensor are ignored for the
next 250 ms. We predicted that typical users would not headba ng
faster than 240 beats per minute.
As mentioned previously, Bangarama offers two different mo des
of operation, freeplay mode and automated play mode . In freeplay
mode, the user selects the sound samples via the guitar-shap ed con-
troller, and in automated play mode, each headbang triggers a pre-
programmed sequence of sound samples. After each head senso r
event, the patch increments to the next stored sample.
The Bangarama patch also serves as the GUI for selecting the
mode of operation, changing the volume, and triggering the b ack-
ground music. Max/MSP offers many standard UI components,
such as buttons and sliders, so no working knowledge of Max/M SP
is required from the user.
5. EV ALUATION
We had the opportunity to demo and evaluate Bangarama at the
annual Computer Science exhibition at RWTH Aachen Universi ty,
where we received valuable feedback from visitors. Approxi mately
20 users of different age, experience level and professiona l back-
ground tried our system. Almost all of them could instantly g rasp
the functionality of Bangarama without extensive instruct ions. Of
the professional guitar players, some found Bangarama an in terest-
ing and entertaining alternative to their real instrument, but some
criticized its lack of ﬂexibility and spectrum compared to a real
electric guitar. As Jord` a points out in [4], musicians need compli-
cated tools with a high degree of freedom, but for casual user s, sim-
pler tools that convey the feeling of control and interactio n while
still producing satisfactory results are often sufﬁcient. Jord` a also
points out that these two classes of users are often mutually ex-
clusive. Feedback from a 10 year old seemed to conﬁrm that our
efforts to build a simple and intuitive interface for musica l inter-
action was going in the right direction, as he was instantly a ble to
successfully play in automated mode.
We were also surprised by the creativity of our users, who som e-
times used Bangarama in “multiplayer” mode, where one user w ore
the headbanging cap, and the other selected the samples usin g the
guitar. The potential for Bangarama to be used in such a colla bo-
rative environment was unexpected, and we hope to examine th is
phenomenon in more detail in future work.
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
182
During this demo session of Bangarama, we discovered two re-
curring problems that occurred during operation. The ﬁrst p roblem
arose because users would often look at the neck of the guitar while
playing, and thus bow their heads to the side a bit. Since the h ead
sensor was not designed to measure sidewise head movements, the
system would occasionally miss a sample. Our second, relate d,
problem occurred when users were too reserved in their head m ove-
ments, in which case their movements would not produce enoug h
kinetic energy to switch the sensor to the closed state. Perh aps they
were afraid of causing damage to the system; however, this co uld
also be due to the differing introvert versus extrovert pers onalities
of users [10]. Stronger head movements eliminated the probl ems
in both cases.
Some users also considered it slightly unnatural that sampl es
were not triggered until the head reaches the downward posit ion,
which is when the switch closes. We are currently evaluating
whether changing Bangarama such that samples are played at t he
beginning of head movements would increase usability. We fu r-
thermore shortened the sample lock time from 250 ms to 100 ms,
as our assumptions regarding the maximum playing speed of ou r
users turned out to be incorrect. The reduced lock time was st ill
long enough to debounce the pin signal, but allowed faster gu itar
play.
6. FUTURE WORK
Our current version of Bangarama is still at an early stage of de-
velopment; however, the initial feedback from testing with users
has enabled us to adjust some technical aspects and uncover n ew
possibilities for future development. We are currently eva luating
the possibility of replacing the current digital switch-ba sed sen-
sor with an electrical or mechanical accelerometer. These s ensors
could measure the intensity of the head movements, which cou ld
be mapped to volume or speed. Multi-dimensional accelerome ters
could also open up possibilities for mapping headbangs in va rious
directions to sample selection or other parameters such as d istor-
tion. Our current prototype also requires users to wrap a pie ce of
tin foil around their ﬁngers in order to play; in order to redu ce the
intrusiveness of the system the contact surfaces could be re placed
by different touch sensitive components, such as the one use d by
Huott [2]. It is also desirable to remove any dependence on th e
mouse and keyboard from the interface, perhaps by installin g the
necessary controls on the controller itself.
We are also exploring the possibility of extending Bangaram a for
a more collaborative music-making experience, perhaps by a dding
more head sensors or controllers.
7. CONCLUSION
In this paper, we presented Bangarama, a prototype musi-
cal instrument that uses headbanging as the primary interac tion
metaphor. We showed how new and unorthodox musical inter-
action can be supported using only very simple, common motio n
sequences with the aid of cheap and widely available sensors and
input devices. Bangarama offers the possibility to play gui tar riffs,
predeﬁned sound sequences, unusual sound samples, and even pro-
vides the possibility for a multiplayer experience. Despit e limited
resources, we managed to produce a device that offers an ente r-
taining and creative way of musical interaction for both ski lled and
unskilled musicians. We hope our project will serve as inspi ration
for others, and help them realize that expensive, complex ha rdware
is not necessary to produce an innovative musical controlle r.
8. ACKNOWLEDGMENTS
The authors would like to thank Stefan Werner for his valuabl e
advice and contributions during the development life-cycl e.
9. REFERENCES
[1] J. Borchers. A pattern approach to interaction design . John
Wiley & Sons, New Y ork, 2001. http://hcipatterns.org.
[2] R. Huott. An interface for precise musical control. In
Proceedings of the NIME 2002 Conference on New
Interfaces for Musical Expression , Dublin, 2002.
[3] J. Johnson. GUI Bloopers: Don'ts and Do's for Software
Developers and W eb Designers . Morgan Kaufmann, 1st
edition, March 2000.
[4] S. Jord` a. Improvising with computers: A personal surve y
(1989–2001). Journal of New Music Research , 31(1):1–10,
2002.
[5] Making Things. Teleo. http://www.makingthings.com.
[6] D. Merrill. Head-tracking for gestural and continuous c ontrol
of parameterized audio effects. In Proceedings of the NIME
2003 Conference on New Interfaces for Musical Expression ,
pages 218–219, Montreal, 2003.
[7] N. T. Michael J. Lyons, Michael Haehnel. The mouthesizer :
A facial gesture musical interface. In Conference Abstracts
of the SIGGRAPH 2001 , page 230, 2001.
[8] M. Puckette. Max at seventeen. Computer Music Journal ,
26(4):31–43, 2002.
[9] M. Sheppard. Digital stringless guitar. Master’s thesi s,
University of Queensland, 2003.
[10] B. Shneiderman. Designing the user interface . Pearson
Addison Wesley, 1997.
[11] M. Turk. Handbook of Virtual Environments: Design,
Implementation, and Applications , chapter Gesture
Recognition. Lawrence Erlbaum Associates, Mahwah, 2001.
[12] M. M. Wanderley. Gestural control of music. In International
W orkshop Human Supervision and Control in Engineering
and Music , Kassel, Germany, September 2001.
Proceedings of the 2005 International Conference on New Interfaces for Musical Expression (NIME05), Vancouver, BC, Canada
183