Orphion: A Gestural Multi-Touch Instrument for the iPad 
!
Sebastian Trump!
Hochschule für Musik Nürnberg!
Nürnberg, Germany!
sebastian.trump@hfm-nuernberg.de !
Jamie Bullock!
Birmingham Conservatoire!
Birmingham, UK!
jamie.bullock@bcu.ac.uk 
!!
ABSTRACT 
This paper describes the concept and design of Orphion, a new digit-
al musical instrument based on the Apple iPad. We begin by out-
lining primary challenges associated with DMI design, focussing on  
the specific problems Orphion seeks to address such as requirements 
for haptic feedback from the device. Orphion achieves this by incor-
porating an interaction model based on tonally tuned virtual “pads” in 
user-configurable layouts, where the pitch and timbre associated with 
each pad depends on the initial point of touch,  touch point size and 
size variation, and position after the initial touch. These parameters 
control a physical model for sound generation with visual feedback 
provided via the iPad display. We present findings from the research 
and development process including design revisions made in re-
sponse to user testing. Finally, conclusions are made about the effect-
iveness of the instrument based on large-scale user feedback. 
!
KEYWORDS 
multi-touch instrument, gesture, Orphion, iPad, physical modelling 
!
1. INTRODUCTION 
Malloch et al define a musical instrument as “a sound-producing 
device that can be controlled by a variety of physical gestures and is 
reactive to user actions” [8]. It could therefore be extrapolated that a 
digital musical instrument (DMI) falls into the subset of musical 
instruments that make use of digital technology. However, to under-
stand and design new DMIs, an more nuanced view is required. 
Miranda and Wanderley propose a model for DMIs whereby the 
instrument contains a “control surface” and a “sound generation unit” 
conceived as independent modules related to each other by mapping 
strategies [11]. This model is shown in figure 1. 
 D r u m m o n d  a d d s  q u a l i f i e r s  t o  t h i s  m o d e l ,  p r o p o s i n g  t h a t  t h e  
primary challenge facing the designers of interactive (digital) instru-
ments is to create “convincing mapping metaphors, balancing re-
sponsiveness, control and repeatability with variability, complexity 
and the serendipitous” [5].  W e  n o t e  a t  t h i s  p o i n t  t h a t  w h i l s t  t h e r e  i s  
an axiomatic understanding (at least in Western culture) of what 
“convincing” and “serendipitous” mean in this context, definitions 
are by no means clear cut or easily measurable.  
 A d d i t i o n a l l y ,  B l a i n e  a n d  F e l s  p r o p o s e  t h a t  “ o v e r  t i m e  a n d  w i t h  
practice, a player can continue to refine their range of musical ex-
pression and become an expert.” [2]. This implies the notion that 
(digital) instruments can offer the capacity for progression in discov-
ery and mastery of playing techniques over an extended period.  
A number of sophisticated commercially-available DMIs exist that 
have addressed some or all of the criteria described above. Examples 
include Eigenharp1, Seaboard2 and Reactable3, and Kaossilator4. All 
of these exploit the decoupling possible in DMI design, allowing for 
multiple timbral identities, or in some cases radically different sound 
production techniques within a single instrument. Some existing 
DMIs, for example Reactable also allow for flexible mapping of 
input gesture to sound production parameters. 
!
2. DESIGN PRINCIPLES 
2.1.Requirements for practical interfaces 
!
The aim of Orphion was to research and develop a self-contained, 
affordable and widely-available DMI with “long-term” potential for 
virtuosity as described by Wessel and Wright [14]. and virtu.  Addi-
tionally, a primary goal was to develop a DMI that had a distinctive, 
coherent and readily identifiable set of timbral qualities and a fixed 
mapping between input gestures and sound production. The aim was 
also to embrace a natural user interface (NUI) paradigm in creating 
an instrument that feels “natural” to someone familiar with the beha-
viour of existing acoustic instruments like drums and string instru-
ments [15][9]. 
 T h e  h i s t o r y  o f  i n s t r u m e n t  m a k i n g  s h o w s  t h a t  t h e  d e v e l o p m e n t  o f  
musical instruments had two major objectives: first, the expansion of 
the tonal possibilities (dynamics, timbre) and secondly to improve the 
playability of an instrument [4]. Unlike acoustic instruments, where 
these two factors are inherently coupled, electronic instruments have 
independent sound generation and control that can interact in a vari-
ety of ways depending on the design of the instrument. We define the 
requirements for musical instrument design in general as follows: 
!
• Allow virtuosity and expression 
• Ergonomic design 
• Traceability (to the public) 
• Predictability (for the player) 
• Visual (primary) and audible (secondary) feedback  
!
These factors are inherent in the design of acoustic instruments. With 
a ’cello, for example, the movements of the bow give traceability for 
the listener. Also, feedback for the player is created by the sounding 
body the of instrument itself as well as by the position of the bow on 
the string and the hand on the fingerboard. In contrast, due to the 
Permission to make digital or hard copies of all or part of this work for personal 
or classroom use is granted without fee provided that copies are not made or 
distributed for profit or commercial advantage and that copies bear this notice 
and the full citation on the first page. To copy otherwise, to republish, to post on 
servers or to redistribute to lists, requires prior specific permission and/or a fee. 
NIME’14, June 30 – July 03, 2014, Goldsmiths, University of London, UK. 
Copyright remains with the author(s).
Gestural
Controller
Sound
Production
INPUT
Gestures
Primary
Feedback
Secondary
Feedback
MAPPING
Figure 1: A possible approach to DMI representation [11]
 1  http://www.eigenlabs.com 
 2  https://www.roli.com/seaboard/ 
 3  http://www.reactable.com 
 4  http://www.korg.com/uk/products/dj/kaossilator_pro_plus 
Proceedings of the International Conference on New Interfaces for Musical Expression
159
decoupled nature of controller and sound generator in the DMI mod-
el, a standard MIDI keyboard used as an interface for an electronic 
instrument that runs as software on a laptop provides no perceptual 
cues about the sounds the visitor of a concert can expect to hear. It is 
equally difficult to provide feedback to the player who, for example, 
wants to play a long-lasting crescendo, but receives no feedback, 
whether the sound has already started or not. In this case the concrete 
task determines decisively the requirements of the interface. 
!
2.2. Musical instrument or controller 
Since its mechanical structure and the materials used for building the 
enclosure of electronic instruments normally do not contribute to 
their sound, which is especially true for software based instruments, 
these instruments need a strong logical link between the action of the 
player and the generated audio. This strong link between a very spe-
cific interface and the sound generation is what defines that structure 
as an instrument [7].  
 C o n v e r s e l y ,  a  h a r d w a r e  o r  s o f t w a r e  interface in isolation is an open 
structure whereby arbitrary mappings can be made between human 
input and resultant sound, and as such can  be considered  as a con-
troller rather than as an instrument [6]. Such an interface can work 
very well for a variety of situations, however the properties of an 
instrument we define above are hard or impossible to achieve with 
this setup. Additional layers of complexity arise if the interface does 
not control the sound generation directly but drives a time-varying 
process such as starting a sequencer. Such a “sequencing instrument” 
points in a new direction but also marks the strongest possible depar-
ture from a traditional musical instrument design. For our purposes 
Orphion therefore focusses on the idea of a strong coupling between 
interface and sound generation. 
!
3. ORPHION 
In order to address our primary goal of creating an “affordable and 
widely-available DMI”, it was decided that the design scope would 
be limited to existing consumer devices that could be “transformed” 
into a musical instrument through the addition of custom software. 
The aim of Orphion has therefore been to find a way to achieve vir-
tuosity and expressiveness within the constraints of a standard multi-
touch input device. Most commercial applications involving touch-
based interaction use the finger or stylus as a replacement for the 
mouse to control knobs and buttons. Since multi-touch has been 
established, new gestures were created, for example pinching two 
fingers to resize objects. In order to express musical ideas however, 
more specific gestures and input models have to be developed [6]. 
  
!
3.1. Concept and design 
Finding a logical interaction model and thus a suggested way of 
playing is a key component in the development of a new instrument. 
One of the design goals for Orphion was to allow polyphonic playing 
of defined pitches with different articulations (staccato, legato) and 
timbres for each individual voice. The following factors were there-
fore taken into account: 
!
• haptic properties of touchscreens (size and tactile or kinaes-
thetic ways of interaction) 
• musical playability ( r e c o g n i t i o n  o f  i n i t i a l  t o u c h  p o i n t  a n d  
matching of pitches), musical expression (dynamics, intona-
tion, vibrato, timbre) 
• intuitive and natural feel 
• technical possibilities ( p r e c i s i o n  o f  c o n t r o l  d a t a ,  p r o c e s s i n g  
power) 
!
As guiding models for the behaviour and gestures of Orphion these 
two types of instruments seemed to be most suitable: drums and 
string instruments. 
!
• drums: round playing area with different timbres, release time 
and damping depend on the velocity and duration of touch. 
• string instruments: multiple individually tuned strings plus 
ability to play the tuning via tapping the strings, control of 
tone and articulation during sustain-phase (intonation/vibrato, 
damping) 
!
3.2. User interaction 
The interface of Orphion therefore consists of virtual pads which are 
capable of sounding either plucked like a guitar string or produce 
timbres closer to a slap on a conga drum depending on the size of the 
touch point. The timbre changes when hit closer to the “rim” like on 
a real drum, and the sounding pitch is a function of distance from the 
centre hit point, in order to model something that comes close to 
“bending” a string (the range varies by the size of the touch point). 
Figure 3: Simplified diagram of interface   
and sound generation
Figure 2: Orphion interface with virtual pads indicating touch 
point size by colour
Proceedings of the International Conference on New Interfaces for Musical Expression
160
Each parameter-per-voice is controlled by an individual finger. The 
iPad currently supports up to eleven touch points, but polyphony is 
currently limited to 8 voices by the processing power of the device 
(Cf. figure 3 for the connection between the interface and the sound 
generation by different parameters). 
 T h e  v i s u a l  r e p r e s e n t a t i o n  i s  s t r a i g h t f o r w a r d  a n d  f u n c t i o n a l :  a  p a d  i s  
defined as an outlined blue circle with its note name written in the 
centre. When touching a circle, it is filled with colour, ranging from 
red to yellow depending on touch size, thus indicating the amount of 
damping (cf. fig. 2). A pad layout is defined as a set of pads with 
variable size and position. 
 T h e  d i f f e r e n t  s e t s  o f  p a d s  a l l o w  t h e  i n s t r u m e n t  t o  b e  a d a p t e d  t o  
multiple musical situations and genres, and to provide possibilities 
for virtuosity by the player. The arrangement structure with symmet-
rical intervals (e.g. fig. 4) in each axis can be used to find new har-
monic structures by advanced musicians. Pad layouts with only 
pentatonic tone material (e.g. fig. 5) or other simplified musical con-
cepts (e.g. fig. 6) make it potentially interesting for musical begin-
ners. Layouts with fewer pads can give the feel of a percussion in-
strument played with a fixed assignment between finger and pad (e.g. 
fig. 7). 
!
3.3. Research method 
A practice-based research methodology was adopted where the au-
thor’s own artistic practice was used as a means for continuous eval-
uation of a working prototype. The first concept study for Orphion 
used a trackpad interface to control physical modeling synthesis. It 
was realised as a Max/MSP patch using the fingerpinger external to 1
gain raw trackpad data. In order to evaluate the prototype, six test 
players were asked to experiment with the system and provide free-
form feedback on its operation and potential for improvement. 
 O n e  o f  t h e  m a i n  s h o r t c o m i n g s  i d e n t i f i e d  d u r i n g  t e s t i n g  w a s  t h e  
absence of direct visual feedback relating the haptic stimulus  to the 
resulting sound [1]. Various options were considered in order to ad-
dress this including the use of stickers or laser engraving on the 
trackpad. Eventually it was decided that basing the instrument on a 
tablet device would provide the most appropriate form factor for the 
instrument, allowing for the sound to be generated by the same phys-
ical device receiving haptic input, and for the same device to provide 
visual feedback in response to input.  
 T h e r e f o r e  a  n e w  p r o t o t y p e  w a s  d e v e l o p e d ,  u s i n g  t h e  i P a d  a s  a  
controller and visual display. Touch data from the iPad as well as 
Open GL drawing commands were obtained / set on the iPad via a 
modified version of the Fantastick application by Juha V ehviläinen. 2
The device communicated with the sound generating computer via 
wireless network. At this stage, the predefined layouts of pads (fig. 4-
7) were refined to achieve best ergonomic and expressive possibilit-
ies, taking the size of the iPad display into account. For a concert 
performance with this working working prototype a specific layout 
was designed to exactly meet the composer’s needs. The capabilities 
of the instrument were also extended by adding a new gesture for 
playing with very soft attack and allow ing continuous glissando 
between the pads.  
 F u r t h e r m o r e ,  c o n s t r u c t i n g  t h e  i n s t r u m e n t  u s i n g  a  t a b l e t ,  p l u s  a n  
“app” makes instrument production highly scalable—moving away 
from bespoke and ad-hoc device concepts, and providing the possib-
ility of ensemble performance using multiple instruments. Thus the 
final implementation of Orphion is a standalone application on Apple 
iPad. The device was chosen for its multi-touch capabilities, availab-
ility and integrated audio. Its sound generation is realized using libpd 
[3], which provides a Pd audio graph controlled via messages from 
iOS functions. 
 T h e  s o u n d  s y n t h e s i s  i s  b a s e d  o n  a  p h y s i c a l  m o d e l  t h a t  s i m u l a t e s  a n  
oscillating string (Karplus-Strong-like algorithm, [13]). It uses a 
combination of a pulse of filtered noise and a sustained excitation 
Figure 4:  Symmetrical major 3rds horizontally,  minor 
3rds and semitones vertically, 4ths and 5ths diagonally
Figure 5: Circle arrangement of a pentatonic scale   
in layered 4ths
Figure 7: Five-finger layout, e.g. as tuned bass drums
Figure 6: Blues-scale layout
 http://www.anyma.ch/2009/research/multitouch-external-for-maxmsp/1
 https://github.com/jusu/Fantastick2
Proceedings of the International Conference on New Interfaces for Musical Expression
161
sound created by a two-operator FM synthesis structure. The low-
pass filtering of the feedback path is controlled in real-time for lively 
articulation of the sound after the initial touch. The complex excita-
tion model allows a variety of different sounds from gently plucked 
strings to xylophone-like hits or damped attack of muted drums. As 
long as a finger is touching the surface of a pad the distance from the 
pad's centre controls slight detuning (intonation) and variation of 
timbre towards the “rim”. Synthesis parameters were determined and 
refined empirically through process of iterative development and 
testing.  
  
3.4. Evaluation 
The distribution of a musical instrument through an app store offers 
the opportunity to easily reach a large number of potential users and 
collect feedback through the integrated review mechanism. Thus a 
“deploy-use-refine” model as described by Miluzzo et al [10] was  
applied in order to iteratively improve the instrument’s capabilities. 
Furthermore this data can serve as a source for evaluation the overall 
user experience. Our data shows that this was perceived to be over-
whelmingly positive with an average of star rating of 4.5 from 822 
reviews. Figure 8 shows the 30 most frequently used words in review 
texts following lemmatisation and removal of stop words.  Whilst we 
cannot make precise conclusions about the quality of Orphion from 
this data, the prominence of semantically positive words such as 
“fun”, “love”, “great”, “cool” and “good” and the absence of negat-
ive ones, correlates with the high average star rating suggesting that 
overall reviewers wished to express a positive user experience.  The 
prominence of “sound”, “play”, “music” and “instrument” also cor-
relate with the design goal of creating a “musical instrument”. 
3.5. Further development 
After the first release of Orphion, many users provided very positive 
feedback about its performance capabilities and asked for a new 
feature to internally record and export audio files, which became 
possible in the first update. To accommodate the constant question 
for using its versatile interface as a controller for other synthesizers, a 
MIDI implementation was added after a few months, although this 
stands against the initial goal of a strong connection between gestural 
interface and sound generation To allow customization for any mu-
sical context, an editor for individual pad layouts with microtonal 
adjustment capabilities was also integrated. These custom layouts can 
also be shared through the internet. 
 M e a n w h i l e  O r p h i o n ’ s  i n t e r a c t i o n  m o d e l  h a s  a l s o  b e e n  p o r t e d  t o  t h e  
iPhone as a new instrument called Orphinio. To ensure playability 
with less screen space, adequate pad layouts had to be developed. 
Furthermore a “shaker mode” was integrated to make use of the 
smaller form-factor and allow new playing techniques. Its timbral 
quality has been slightly modified to accommodate the smaller 
device yet still keeping the relation to Orphion recognizable. In future 
it would be interesting to explore the possibility of vibro-tactile feed-
back for haptically sensing pad edges as a way of enhancing playab-
ility without constant visual feedback. 
!
4. CONCLUSION 
Orphion accomplishes its goal to create an expressive multi-touch 
musical instrument by providing a direct link between its interface 
and the sound synthesis with an easily understandable interface. It is 
now used by thousands of players around the world. By the availabil-
ity of custom pad layouts this instrument is suitable for many differ-
ent styles of music and musicians. Sufficient practice can allow mu-
sicians to become virtuosic and expressive, although it is a big chal-
lenge to play existing written music on it [12].  
 A s  w i t h  e v e r y  i n s t r u m e n t  i t  i s  m o r e  i n t e r e s t i n g  t o  c o m p o s e  o r  i m-
provise music, which makes full use of the unique possibilities in 
terms of expression, harmonics and voice leading. App store feed-
back shows that many musicians and composers already find the 
sound and interface of Orphion interesting and will hopefully pro-
gress in including it into their repertoire. 
!
5. REFERENCES 
[1] Arfib, D., Couturier, J-M., and Kessous, L. 2005. Expressiveness 
and digital musical instrument design. In Journal of New Music 
Research 34.1: 125–136. 
[2] Blaine, T., and Fels, S. 2003. Contexts of Collaborative Musical 
Experiences. In Proceedings of the International Conference on 
New Interfaces for Musical Expression. Montreal, Canada: Mc-
Gill University. 129–134. 
[3] Brinkmann, P. 2012. Making musical apps. O’Reilly Media. 
[4] Dickreiter, M. 1994. Musikinstrumente: moderne Instrumente, 
historische Instrumente, Klangakustik. Bärenreiter. 
[5]  Drummond, J. Understanding interactive systems. Organised 
Sound 14.2: 124-133. 
[6] Geiger, G. 2006. Using the Touch Screen as a Controller for 
Portable Computer Music Instruments. Proceedings of the Inter-
national Conference on New Interfaces for Musical Expression. 
61–64. 
[7] Hunt, A., Wanderley M.M., Paradis, M. 2002. The importance of 
parameter mapping in electronic instrument design. In Proceed-
ings of the 2nd international conference on New interfaces for 
musical expression. 
[8] Malloch, J., Birnbaum, D., Sinyor, E., & Wanderley, M. M. 2006. 
Towards a new conceptual framework for digital musical in-
struments. In Proceedings of the 9th International Conference on 
Digital Audio Effects. 49–52. 
[9] Mann, S. 2007. Natural Interfaces for Musical Expression: Physi-
phones and a physics-based organology. In Proceedings of the 
7th international conference on New interfaces for musical ex-
pression. 118-123. 
[10] Miluzzo, E., Lane, N., Lu, H., and Campbell, A. T. 2010. Re-
search in the App Store Era: Experiences from the CenceMe 
App Deployment on the iPhone. In Proc. of The First In-
ternational Workshop Research in the Large: Using App Stores, 
Markets, and other wide distribution channels in UbiComp 
research. Copenhagen, Denmark. 
[11] Miranda, E. R., & Wanderley, M. M. 2006. New digital musical 
instruments: control and interaction beyond the keyboard.V ol. 
21. 
[12]  Oore, S. 2005. Learning Advanced Skills on New Instruments. 
In Proceedings of the International Conference on New Inter-
faces for Musical Expression. 60–64. 
[13]  Roads, C. 1996. The computer music tutorial. MIT Press. 
[14]  Wessel, D., and Wright M. 2002. Problems and 
 p r o s p e c t s  f o r  i n t i m a t e  m u s i c a l  c o n t r o l  o f  c o m p u t e r s .  Computer 
Music Journal 26.3 11–22 
[15]  Wigdor, D., & Wixon, D. 2011. Brave NUI world: designing 
natural user interfaces for touch and gesture. Elsevier.  
Figure 8: word cloud of app store reviews
Proceedings of the International Conference on New Interfaces for Musical Expression
162