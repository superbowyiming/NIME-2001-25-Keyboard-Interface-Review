Distributed Control in a Mechatronic Musical Instrument
Michael Gurevich
University of Michigan
Department of Performing Arts Technology
School of Music, Theatre & Dance
Ann Arbor, Michigan
mdgurev@umich.edu
ABSTRACT
Drawing on concepts from systemics, cybernetics, and mu-
sical automata, this paper proposes a mechatronic, elec-
troacoustic instrument that allows for shared control be-
tween programmed, mechanized motion and a human in-
teractor. We suggest that such an instrument, situated
somewhere between a robotic musical instrument and a pas-
sive controller, will foster the emergence of new, complex,
and meaningful modes of musical interaction. Adopting a
practice-led research approach, the development and design
of one such instrument—Stringtrees—is described. The de-
sign process reﬂects the notion of ambiguity as a resource:
The instrument was endowed with a collection of sensors,
controls, and actuators without a highly speciﬁc or prescrip-
tive model for how a musician would interact with it.
Keywords
robot, cybernetics, automata, ambiguity, interpretation
1. INTRODUCTION
There has been substantial recent interest in mechatronic
music systems: instruments, devices, or assemblages that
integrate electronic controls, mechanical motion, and acous-
tic systems intended to create music. Most prominently,
these have taken the form of robotic instruments and en-
sembles thereof [12, 13, 16, 25, 26, 29]. Purely mechani-
cal automatic musical instruments, or musical automata—
instruments that play preprogrammed music on their own
with negligible human intervention—date back at least to
9th century [14], and became quite fashionable beginning in
17th century Europe [8]. Perhaps the most familiar musical
automata, player pianos were among the ﬁrst to successfully
integrate digital electronic control systems in the late 20th
century. Facilitated in part by the availability of accessi-
ble and aﬀordable rapid fabrication systems, programmable
embedded computers, sensors, and actuators, a 21st century
resurgence of musical automata is undoubtedly underway.
Yet for all the deserved attention they have received, mu-
sical automata represent only a subset of possible paradigms
of mechatronic music systems. The focus of this paper is
speciﬁcally mechatronic music systems that are not wholly
automatic, that is, instruments that feature electronically
controlled mechanized motion but aﬀord substantial human
involvement in the sound production process. Fundamental
to this investigation is the notion that the human performer
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
NIME’14,June 30 – July 03, 2014, Goldsmiths, University of London, UK.
Copyright remains with the author(s).
and mechatronic instrument are part of a dynamic system in
which they mutually inﬂuence each other’s behavior. This
paper proposes a class of instruments that occupy a middle
ground between digitally controlled musical automata on
one hand, and essentially passive “controllers” on the other.
2. HUMAN-INSTRUMENT RELATIONSHIPS
Our approach to a mechatronic instrument is situated through
a brief survey of perspectives on human-instrument relation-
ships in NIME and allied disciplines.
2.1 Cybernetics
Usually associated with Norbert Wiener, cybernetics is a
suite of concepts that initially framed the interaction be-
tween humans and machines in terms of communication
and exchange of information. These principles were sub-
sequently extended to other domains such as economics,
biology, ecology, and social science, and, especially due to
the contributions of Ashby, were simultaneously expanded
to broadly integrate the ideas of systemics [5]. The con-
cept of complex, highly interconnected systems, especially
on biological and planetary scales, has become rather com-
monplace these days, but has roots in cybernetics.
Later authors, most notably Maturana and Varela, shifted
attention toward the abilities of systems to organize them-
selves [18]. This so-called “new cybernetics” represents in
part a philosophical rejection of the notions of control and
design in favor of those of emergence and self-production
[5]. That is to say, systems, including living biological ones,
cannot be autonomous unless their behaviors are produced
spontaneously from their internal dynamics and interaction
with other systems. The repercussions for robotics and
artiﬁcial intelligence are signiﬁcant: it would be impossi-
ble to design an autonomous, intelligent system by exhaus-
tively specifying sets of input-output rules or comprehen-
sively enumerating all possible outcomes. Rather, a system
must be imbued with the possibility to dynamically gener-
ate its own knowledge, if not meanings.
A number of early (pre-NIME) authors considered the re-
lationship between human performers and music controllers
in terms of ﬁrst-generation (information processing) cyber-
netics, speciﬁcally examining the properties of controllers
that can facilitate eﬀective control given the constraints of
human abilities [19, 23, 28]. Mulder [20], however, high-
lights limitations of a strictly cybernetic model of the human-
instrument relationship, suggesting that other represen-
tations—semiotic models or those involving energetic ex-
change—may be simultaneously valid. He argues that in-
strument designers must therefore consider these multiple
models and be able to eﬀectively translate between them.
2.2 Haptics
Mulder’s “energetic exchange” model is consistent with
Cadoz’s concept of an “ergotic” human-machine relation-
Proceedings of the International Conference on New Interfaces for Musical Expression
487
ship, which he sees as a prerequisite for “instrumental” in-
teractions [3]. Cadoz argues that interactions with physical
devices having real-time inﬂuence over digital sound synthe-
sis (i.e., “music controllers” to which I have previously re-
ferred as“passive”) are frequently not instrumental, because
there is no physically meaningful exchange of energy be-
tween the performer and the sound-producing mechanism.
That is, by not mechanically transmitting energy back to
the human performer in response to their gestures (as, say,
a piano or a violin does), the interface and synthesis system
do not reveal their physical or acoustic properties.
Cadoz and others propose that one way to overcome this
problem without abandoning the whole enterprise of real-
time digital music is through active force-feedback or hap-
tics (a comprehensive list of citations would be too long
to list, but see, e.g. [1, 2, 3, 22, 27]). Haptic systems
are generally mechatronic, but on a continuum of mecha-
tronic music systems in terms of their degree of autonomy,
haptic systems would be at the opposite end as musical
automata. Haptics are seen as a way to promote tighter
and more meaningful coupling between a human performer
and a digital sound synthesis system, frequently—but not
always—by computationally modeling the forces exchanged
between real mechano-acoustic systems.
2.3 Semiotics
Mulder’s third representation of human-instrument relation-
ships—a semiotic model—points explicitly to the fact many
digital music systems aﬀord linguistic or symbolic inter-
faces. Signiﬁcantly, tangible or physical interfaces to dig-
ital music systems may still be essentially semiotic, espe-
cially when generic inputs are mapped directly to symbolic
properties of the system, e.g., a tempo knob or a trans-
position button. Based on qualitative studies of performers
and spectators, recent authors have pointed to the potential
for multiple modes of engagement or skill development with
interactive music systems, speciﬁcally highlighting the pre-
disposition of digital tools toward intellectual engagement
[7]. Magnusson takes a stronger position regarding semiotic
relationships, arguing that a digital musical instrument is
necessarily an epistemic tool —a device that encapsulates a
system of knowledge and thought in its own right [17].
2.3.1 Intelligent Systems
The impulse to endow computer-based music systems with
intelligence is as old as computer music itself [9]. A gen-
eration later, Lewis frames now-interactive and responsive
intelligent music systems explicitly in terms of “latter day
musical automata” [15]. Whereas Lewis’s work has been
conﬁned to synthetic sounds and digitally-controlled player
pianos, others, most notably Weinberg, have developed re-
sponsive musical robots [10, 29]. Although aspects of their
behavior are automatic, these systems represent another in-
teresting model of human-instrument relationship in that a
human can substantially aﬀect the system’s response in real-
time, but only indirectly and not entirely predictably. Fur-
thermore, the interaction is through an abstract, high-level,
symbolic (“musical”) language. This is to say that unlike
digital musical automata, a performer cannot control the
mechanical motions of these intelligent systems directly; to
cause a particular note to be played at a particular time,
for instance. What’s more, the interface to these systems is
generally acoustic: it is the sonic quality of another instru-
mentalist’s performance that inﬂuences their behavior.
2.4 Dynamic Systems
In one of the most interesting recent qualitative studies of
performer-instrument relationships, Johnston et al. iden-
tify three diﬀerent modes of interaction with a purely vir-
tual musical instrument—one that responds to acoustic in-
put from a performer with dynamic behavior according to
a physical model [11]. The authors identify what they call
instrumental, ornamental, and conversational modes of in-
teraction with the system, again suggesting a continuum
of possibly overlapping types of relationships. Although it
lacks a physical interface, Johnston’s system might be con-
sidered ergotic according to Cadoz’s criteria in that there
is a degree of proportional energetic exchange—acoustic in-
puts interact with a computational model of a physical dy-
namic system, which in turn provides multisensory (audio
and visual) feedback to the performer.
Perhaps the most signiﬁcant feature of this system is that
its input, like that of the intelligent robotic instruments de-
scribed above, is acoustic; but the virtual instrument in this
case does not model musical intelligence, it models a phys-
ical dynamic system. It is thus noteworthy that a model of
a virtual dynamic system could facilitate a conversational
interaction style, which would typically be associated with
symbolic communication. In one sense, we can consider this
an example of the transformations between representations
that Mulder describes [20].
3. DESIGN APPROACH
As designers, the team behind Stringtrees was struck by the
fact that in [11], a single dynamic system—even a virtual
one—with physically meaningful behaviors could engender
such rich, diverse, and ﬂuid modes of interaction. Other
authors, e.g., [4] have highlighted the utility of physically
meaningful metaphors in the design of musical interactions,
but we are interested speciﬁcally in systems the contain ex-
plicit, rather than metaphorical, representations of physical
dynamic systems. We are furthermore interested in systems
that “move at slower, ‘haptic’ rates (up to around 20 Hz)”
[11], as opposed to computational acoustic models used in
sound synthesis. However, instead of a virtual dynamic sys-
tem, we sought to integrate concepts of cybernetics by em-
ploying real, physical motion and an acoustic sound source.
Our interest is in examining the potential for a mecha-
tronic instrument to facilitate new modes of music making.
The underlying hypothesis is that bestowing the instrument
with dynamic behavior, while distributing real-time control
between a human performer and programmed automatic
motion, will allow for the emergence of rich and meaningful
musical interaction.
The concept of emergence is signiﬁcant here, reﬂecting
the notion of self-organization from cybernetics, but also
concepts from design theory, speciﬁcally those of designing
for ambiguity and facilitating interpretation advocated by
Sengers and Gaver [6, 24]. These ideas suggest that systems
can be designed to aﬀord multiple, heterogeneous interpre-
tations, styles or modes or interaction, which may in turn
engender more rewarding and meaningful experiences for
their users. In our case, the speciﬁc ways that a performer
would interact with the instrument were not prescribed in
advance; rather we sought to equip the instrument with use-
ful capabilities without excessively constraining a particular
way in which it would be used [24].
The approach in developing a hybrid mechatronic instru-
ment falls under the umbrella practice-as-research [21]. The
design process was theoretically motivated, but this was
seen to be an instance which demanded exploration through
reﬂective practice with a “real,” functional instrument, as
opposed to experimentation in a laboratory setting or user
studies. Furthermore, approaching the design as a creative
exercise allowed for what we consider appropriate freedom
to make artistic judgments, given that the ultimate appli-
cation of the design is a musical one.
Proceedings of the International Conference on New Interfaces for Musical Expression
488
4. STRINGTREES
Below we describe the general design concept of Stringtrees,
and document its development into its current form. In
the spirit of practice-as-research, at each major stage of
the process the developing design was holistically evaluated
with regard to the goals laid out above. Those reﬂections
are presented here alongside the account of the design.
Stringtrees was initially conceived as a plucked string in-
strument in which a motorized central rotating plectrum-
arm would pluck strings circularly arranged around it. Fol-
lowing the “tree” metaphor, the central shaft would be the
“trunk” and the strings branches surrounding it. The ini-
tial shape was also inspired by the old practice of plucking
the rotating spokes of a bicycle wheel with a card attached
to the frame; in this case, the plectrum rotates instead of
the spokes. The most obvious inspiration from NIME is the
rotating plectrum from LEMUR’s GuitarBot [25].
4.1 First Prototype
The ﬁrst prototype, developed in 2010, has an industrial
aesthetic. A 1” steel shaft supports a CNC-machined alu-
minum “crown,” from which guitar strings extend down to a
1m-diameter, circular Delrin base. The strings can be tuned
with standard guitar machine heads, which are mounted on
machined aluminum brackets that attach to the base with
a thumb screw. The crown supports up to 24 strings.
An industrial 12V motor drives a bearing-mounted arm
attached to the shaft via a v-belt and pulley. If the motor is
driven at a constant speed, the adjustable relative position
of the strings along the perimeter of the base allows for
continuously variable rhythmic pitch-sequence patterns as
the rotating arm plucks the strings.
The prototype was tested without a feedback-control sys-
tem. A potentiometer connected to an analog input of an
Arduino modiﬁed the duty cycle of a PWM output con-
nected to an H-bridge motor controller. Development of
this version of Stringtrees was suspended after initial test-
ing due primarily to its size and weight; the motor torque
involved to operate it required substantial power. It was
determined that a smaller, lighter version would be a more
eﬀective platform for investigation.
4.1.1 Reﬂections
Although development of this version was subsequently sus-
pended, initial testing of the ﬁrst prototype did oﬀer ben-
eﬁcial results that oﬀered some validation of our method
and informed the subsequent design. Among the design
evaluations, it became clear that spatially reconﬁguring the
strings “on-the-ﬂy” to achieve predictable rhythmic varia-
tion would be nearly impossible; even if it could be done,
the string tunings would be altered to a greater degree than
anticipated in the process of moving them.
The hub-and-spokes model didn’t appear to oﬀer feasi-
ble rhythmic variation by the human performer. It could
be achieved by programming the motion of the arm: A
solenoid at the end of the arm could be programmed to re-
tract or extend the plectrum to bypass or pluck strings as
desired. This of course would have deviated from our goal
of sharing control between human and automatic behaviors,
placing the instrument squarely in the realm of automata.
This would furthermore defeat the purpose of the tree-like
conﬁguration which presents an attractive spatial mapping
of rhythm to points on a circle.
With regard to the design method, it was encouraging
to witness spontaneous, unanticipated interactions with the
prototype. Upon switching on the power for the ﬁrst time
in the laboratory, a colleague who was uninvolved in the
project, and unaware of its aims or theoretical foundations,
almost instantly picked up a nearby wrench and began us-
ing it like a guitar slide along the strings to change their
pitch. It appeared that the open-ended design would in-
deed facilitate multiple interpretations.
4.2 Current Version
The current version of Stringtrees is smaller and lighter,
with a wooden, 18” square by 36” high frame and 1/4” shaft
(Figure 1a). It elaborates on the strictly tree-like shape by
replacing the array of individual strings around the base
with four equally-spaced rotating spindles supporting four
strings each. A spring-loaded mechanism locks each spindle
into place, with buttons on each of the 4 side panels to
release them (Figure 2a). This allows strings to be moved
into and out of the path of the arm easily, and without
altering their tuning as in the ﬁrst version. The machine-
head tuning attachments from the ﬁrst version were reused
from the ﬁrst prototype (Figure 1b).
Figure 1: Stringtrees January 2014. a) Full instru-
ment, b) Tuning mechanism, c) Multiple arms
This version uses a direct drive in which the shaft itself
rotates, with a 12V DC motor coupled directly to it. The
plectrum arm is made of threaded rod that screws into a
shaft collar. This simple and inexpensive mechanism allows
for the possibility of multiple plectrum arms (Figure 1c). At
the end of the arm, a laser-cut ﬁtting allows for plectra of
diﬀerent materials to be mounted and precisely positioned.
Figure 2: Inner detail. a) Spindle Lock, b) Motor
mount and magnetic speed sensing system
A shaft-mounted collar made of laser-cut acrylic holds 8
equally-spaced neodymium magnets that pass a linear hall-
eﬀect sensor as the shaft rotates (Figure 2b). This is cur-
rently used to calculate the rotation speed, shown on a nu-
merical display on the front panel, which provides a means
of feedback the performer can use to modulate their control.
The speed-control potentiometer system is retained from
the ﬁrst version. The magnetic rotation sensing system is
deliberately excessive for just displaying speed; in keeping
Proceedings of the International Conference on New Interfaces for Musical Expression
489
with the design philosophy, we left open the possibility of
further automating the motion of the arm to explore the
distribution of control.
4.2.1 Reﬂections
As with any instrument, our practice with Stringtrees will
evolve over time. Although we are only near the beginning
of our journey together, several important features are ap-
parent. Moving individual strings to spindles provided the
ability to easily change the tuning of a note at a particular
rhythmic position (or stop it from playing) by rotating the
spindle. This has enabled more eﬀective note-level control.
The spatial conﬁguration around the shaft suggests a collab-
orative performance. With one person at each spindle, we
are able to create coordinated harmonic progressions. This
suggests a new dimension for the distribution of control—
among several performers and an automated system.
The speed control system needs to be more reﬁned. This
is an instance where giving more control to the system will
be eﬀective. Instead of having the potentiometer control
the PWM duty cycle of the motor driver directly, we are
working toward programming it to set a desired speed, and
using the speed sensing mechanism to regulate the motor
drive to achieve that speed. In the current conﬁguration,
the dynamics of the motor drive require too much human
intervention to maintain a constant speed.
Perhaps the most signiﬁcant musical discovery has been
that varying the motor speed can put Stringtrees into per-
ceptually distinctive modes which suggest diﬀerent styles of
interaction. At low speeds, the eﬀect is that of looping pitch
sequences or arpeggios, which can be varied by rotating in
diﬀerent notes. At high speeds, the sustained string sounds
create a more of a harmonic texture than a note sequence.
One observer compared it to a hyper-tanpura. With multi-
ple plucking arms, the textural eﬀect is ampliﬁed.
As with the distribution of control between the instru-
ment and performer, we are ﬁnding the space in the middle—
where Stringtrees can be heard alternately as textural, har-
monic, or melodic—to be the richest area for further explo-
ration and musical development.
5. REFERENCES
[1] T. Beamish, K. Maclean, and S. Fels. Manipulating
music: Multimodal interaction for DJs. In Proceedings
of CHI, pages 327–334, 2004.
[2] E. Berdahl, G. Niemeyer, and J. O. Smith. Using
haptics to assist performers in making gestures to a
musical instrument. In Proceedings of NIME, pages
177–182, 2009.
[3] C. Cadoz. Supra-instrumental interactions and
gestures. Journal of New Music Research ,
38(3):215–230, 2009.
[4] L. Dahl and G. Wang. Sound bounce: Physical
metaphors in designing mobile music performance. In
Proceedings of NIME, pages 178–181, 2010.
[5] C. Fran¸ cois. Systemics and cybernetics in a historical
perspective. Systems Research and Behavioral
Science, 16(3):203–219, 1999.
[6] W. W. Gaver, J. Beaver, and S. Benford. Ambiguity
as a resource for design. In Proceedings of CHI, pages
233–240, 2003.
[7] M. Gurevich and A. Fyans. Digital musical
interactions: Performer-system relationships and their
perception by spectators. Organised Sound,
16(2):166–175, 2011.
[8] J. J. L. Haspels. Automatic Musical Instruments:
Their Mechanics and Their Music, 1580-1820 .
Drukkerij Tulp, Zwolle, 1987.
[9] L. A. Hiller. Computer music. Scientiﬁc American,
201(6):109–121, 1959.
[10] G. Hoﬀman and G. Weinberg. Interactive
improvisation with a robotic marimba player.
Autonomous Robots, 31(2-3):133–153, 2011.
[11] A. Johnston, L. Candy, and E. Edmonds. Designing
and evaluating virtual musical instruments:
facilitating conversational user interaction. Design
Studies, 29(6):556–571, 2008.
[12] A. Kapur. A history of robotic musical instruments.
In Proceedings of ICMC, pages 21–28, 2005.
[13] A. Kapur, M. Darling, D. Diakopoulos, J. W.
Murphy, J. Hochenbaum, O. Vallis, and C. Bahn. The
machine orchestra: An ensemble of human laptop
performers and robotic musical instruments.
Computer Music Journal , 35(4):49–63, 2011.
[14] T. Koetsier. On the prehistory of programmable
machines: Musical automata, looms, calculators.
Mechanism and Machine Theory, 36(5):589–603, 2001.
[15] G. E. Lewis. Interacting with latter-day musical
automata. Contemporary Music Review, 18(3):99–112,
1999.
[16] L. Maes, G.-W. Raes, and T. Rogers. The man and
machine robot orchestra at Logos. Computer Music
Journal, 35(4):28–48, 2011.
[17] T. Magnusson. Of epistemic tools: Musical
instruments as cognitive extensions. Organised Sound,
14(2):168–176, 2009.
[18] H. R. Maturana and F. J. Varela. Autopoiesis and
Cognition. Reidel, Boston, 1980.
[19] F. R. Moore. The dysfunctions of MIDI. Computer
Music Journal, 12(1):19–28, 1988.
[20] A. Mulder. Getting a GRIP on alternate controllers:
Addressing the variability of gestural expression in
musical instrument design.Leonardo Music Journal,
pages 33–40, 1996.
[21] R. Nelson. Practice as Research in the Arts . Palgrave
Macmillan, 2013.
[22] C. Nichols. The vBow: Development of a virtual
violin bow haptic human-computer interface. In
Proceedings of NIME, pages 133–136, 2002.
[23] J. Pressing. Cybernetic issues in interactive
performance systems. Computer Music Journal ,
14(1):12–25, 1990.
[24] P. Sengers and B. Gaver. Staying open to
interpretation: Engaging multiple meanings in design
and evaluation. InProceedings of the 6th Conference
on Designing Interactive Systems, pages 99–108, 2006.
[25] E. Singer, J. Feddersen, C. Redmon, and B. Bowen.
LEMUR’s musical robots. In Proceedings of NIME,
pages 181–184, 2004.
[26] J. Solis, K. Chida, K. Suefuji, and A. Takanishi. The
development of the anthropomorphic ﬂutist robot at
Waseda University.International Journal of
Humanoid Robotics, 3(2):127–151, 2006.
[27] B. Verplank, M. Gurevich, and M. Mathews. The
PLANK: Designing a simple haptic controller. In
Proceedings of NIME, pages 177–180, 2002.
[28] R. Vertegaal, T. Ungvary, and M. Kieslinger. Towards
a musician’s cockpit: Transducers, feedback and
musical function. In Proceedings of ICMC, pages
308–311, 1996.
[29] G. Weinberg and S. Driscoll. Toward robotic
musicianship. Computer Music Journal , 30(4):28–45,
2006.
Proceedings of the International Conference on New Interfaces for Musical Expression
490