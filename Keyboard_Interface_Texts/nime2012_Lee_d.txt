Real-time Modification of Music  
with Dancer’s Respiration Pattern 
 
 
Jeong-seob Lee and Woon Seung Yeo 
Audio & Interactive Media Lab 
Graduate School of Culture Technology, KAIST 
335 Gwahangno, Yuseong-gu, Daejeon, Korea 
jslee85@kaist.ac.kr, woony@kaist.edu 
 
 
ABSTRACT 
This research aims to improve the correspondence between  
music and dance , and explores the use of human respiration 
pattern for musical applications  with focus on the motional 
aspect of breathing. While respiration is frequently considered 
as an indicator of the metabolic state of human body that 
contains meaningful information for medicine or psychology, 
motional aspect of respiration has been relatively unnoticed in 
spite of its strong correlation with muscles and the brain.  
 This paper introduces an interactive system to control music 
playback for dance performance s based on the respiration 
pattern of the dancer. A wireless  wearable sensor device 
detects the dancer ’s respiration, which is then utilized to 
modify the dynamic  of music . Two different respiration -
dynamic mappings were designed and evaluated through 
public performances and  private tests by professional 
choreographers. Results from this research suggest a new 
conceptual approach to musical application s of respiration  
based on the technical characteristics of music and dance. 
 
Keywords 
Music, dance, respiration, correspondence, wireless interface, 
interactive performance 
1. INTRODUCTION 
Music and dance have existed from the  earliest beginning of 
the history of mankind as principal genres of performing arts. 
Based on time and rhythm, they have been closely connected 
to and influenced each other, and evolved together. However, 
their mutual c orrespondence has been an unsol ved problem 
with a long history : in spite of being similar to each  other, 
their characteristic differences restrained t he synergy  and 
sometimes made the ir relationship controversial, in which 
case one of them had to be subordinated to  the other  at the 
cost of its own artistic values. In spite of the efforts made by 
artists from both sides to overcome th is discrepancy, it still 
remains unsolved.  
 Focusing on structural aspect rather than emotional one, this 
constraint can be seen in various  elements such as  form, 
theatricality, sonority, tempo , etc. [21, 22]. Among these, 
inclusive d ynamic flow of music is of great importance for 
choreography: here the “dynamics” of music includes tempo, 
rhythm and emotional impression as well as the physical scale 
(e.g., amplitude gain) of music and its  sound [22]. The result 
of choreography is desired to be coherent with this dynamics 
of music. For example, m usical accents or beats may require 
corresponding reactions of the dancer: both the timing and the 
intensity of the accents of music need to be reflected in dance, 
so that agile motions with rotation or locomotion must be 
accompanied by the beats in music  [22] and faster motion s 
makes stronger beats. 
 In this paper, the issue of the relationship  between music 
and dance is dealt with a technical approach, and  a new 
method to improve their mutual correspondence based on the 
dancer’s respiration is introduc ed. This research was 
motivated by discussions with a number of  professional 
dancers and dance-majoring students on the role of respiration 
in dance : virtually every one of them emphasized the 
importance of respiration with motion and its relationship to 
music. Based on this fact, we focus on the motional aspect of 
respiration and developed a system to control selected 
features of music for dance by breathing . Compared with 
previous uses of respiration in music and dance, this is 
distinctive in that the main focus is not on the metabolic 
aspects of human body  but on biomechanics of motion. 
Specific mapping strategies  as well as  hardware 
implementations are also discussed and evaluated.  
2. RESPIRATION 
2.1 Respiration as an Interaction Modality 
Respiration is generally treated as one of the conventional 
biofeedback factors . These are closely related with the 
metabolic system and widely used in medicine [9, 13]. This 
approach developed and applied to  emotion [6, 10, 14], game 
[11, 17], Workload monitoring [20]. 
 Although these applications have different goals, they are 
commonly interested in the metabolic aspect of the respiration. 
Within such aspect, the most import ant thing of respiration is 
how much air is consumed  smoothly. Frequently used 
features are the average amplitude, frequency , and deviation 
of the respiration, which corresponds to spectral features. 
2.2 Respiration and Music 
There are some musical application cases of biofe edback 
including respiration, and the typical format of them is a bio -
music. Filatriau [7] introduced his works that used brainwave, 
respiration and heartbeat.  Main weakness of  his first work 
with EEG-driven so und synthesis was said to be its lack of 
playability.  Respiration and heartbeat signals were used in 
his second work. Two features of respiration, airflow and 
thoracic volume, were measured and used to control the 
center frequencies of different band-pass filters for subtractive 
synthesis: here  respiration events are directly reflected in 
sound, which is similar to the concept proposed in this paper . 
Tahiroglu used the skin conductance, electrocardiogram , and 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage  and that 
copies bear this notice and the full citation on the first page. To copy 
otherwise, to republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee. 
NIME’12, May 21-23, 2012, University of Michigan, Ann Arbor. 
Copyright remains with the author(s). 
 
respiration for sound synthesis  [15], in which respiration rate 
controlled the pitch, modulation points , and amplitude of the 
frequency modulation. In these two examples it is hard to find 
deep consideration on the meaning of  breathing. Meanwhile, 
Groux explored the utilization of the emotional aspect of the 
physiological data to control high -level musical attributes [8]. 
His research is inspiring for he focused on the higher -level 
features of the physiological data rather than simply dealing 
with raw signal. 
2.3 Mechanism and Control 
Mechanically, respiration process is operated with numerous 
thoracic and abdominal muscles. Functions of these muscles 
results in thorax deformation and the pressure gradient in the 
respiratory organs, and it causes the airflow for gas exchange 
[4]. 
 The respiratory center that controls ventilation is designed 
to alternate inspiration and expiration rhythmically. The rate 
and amplitude of these ventilator movements is under the 
direct control of the respiratory center , which are stimulated 
by the increase of CO2 increase in blood. 
 Meanwhile, neural input from the motor cortex stimulates 
the ventilation during the exercise. Also, it enables the 
voluntary control of breathing that allows an individual 
speaking, singing, or playing a wind instrum ent. The motor 
cortex also allows the motion and breathing to be integrated 
during exercise. It is the uniqueness of respiration comparing 
to other biofeedback factors, and we can expe ct different 
approach to utilize the respiration. 
2.4 Respiration and Muscular Activity 
Compared to metabolic correlation of breathing, r elation 
between the respiration and muscle activity has been a minor 
research interest [3]. Still, s ome researches show the 
meaningful correlation between the respiration a nd muscle 
activity. They focused on how breathing influences the 
instantaneous strength and flexibility of muscles [3, 12] and 
smoothness of motion [5]. These correlations  can be  
considered to be the result of structural ch ange of bones and 
muscles during the respiration process  rather than an 
influence of the oxygen and energy consumption , and it 
is supposed to be anatomically related to the performance of 
other skeletal muscles [12]. 
 The principle of the breathing is explored by dancers with 
their sense from early histo ry of dance, and their experiences 
are adopted and accumulated to the technique and education 
of dance. 
3. SYSTEM DESIGN 
3.1 Basic Concepts 
3.1.1 Why Respiration? 
For the homeostasis of the body, most biofeedback features 
are generally autonomous and not voluntarily controllable. 
Respiration is one of the exceptions in th is aspect: it can be 
controlled voluntarily and  instantly in some degree  (up to a 
certain degree) . Considering that  a number of  interactive 
musical pieces  with biofeedback s uffers from  the common 
problem of controllability [7, 16], this is of great importance . 
The fact that respiration mechanism is more closely 
connected to the inclusive mechanical state than other types 
of biofeedback is another benefit. 
 In terms of low - (or zero -) latency controllability, 
respiration is less advantageous than typical gesture detection 
methods using accelerometers, IR marker, computer vision, 
Kinect, etc., which generally provide faster, more responsive 
control features as well as more detail ed information on the 
movements of dancers. However, in the unique area of dance 
and performing arts, the y may expose their limitations: as the 
goal of this  research is to find  the correspondence between 
music and dance, the inclusive flow  or energy of entire body 
is more important than motion data of each body segments. In 
this context, respiration becomes a more direct and efficient 
approach with less restraint s on the dancer’s movement and 
more expressivity on the stage. 
3.1.2 Spectral vs. Temporal Approach 
In general, previous applications of respiration focused on its 
spectral feature only; this approach is advantageous for long -
term status of the bo dy which provides the metabolic 
information. Considering the uniqueness of respiration and its 
use in dance, however, we take a temporal approach to detect 
the instantaneous change s of breathing for the following 
reasons:  
 Respiration is a very slow activi ty compared to oth er 
physiological features , which makes system l atency too 
long with the spectral approach.  
 As dancers always control the ir respiration intentionally 
depending on his/her movement  (as mentioned before), the 
process is hardly periodic and spectral approach becomes 
less useful. 
3.1.3 Score-based Musical Interface 
The musical mapping s for this system are designed with the 
score-level control [18] in mind . In this structure, we can  
consider two dimensions of feature control – tempo and other 
instantaneous parameters  (e.g., pitch, loudness, and timbre). 
 While improvisatory variation of tempo gives more 
excitements to music [22], it can be confusing for dancers in a 
traditional paradigm because they are trained to dance to 
“regular” rhythms [2]. Therefore, we leave the control of 
tempo as  a future work  and focus on  dynamic features of 
music. 
3.2 Structure 
Basic structure of  the system is the real-time modification of 
pre-defined or randomly generated music s equence in 
progress by means of respiration of user. Respiration signal is 
measured with a  gauge pressure sensor on the mouth of the 
dancer (Figure 1), and it is amplified and transmitted to a 
computer wirelessly  in real -time. For sampling and 
transmission of the signal, Arduino FIO was used. Sampling 
and transmission rate was set to 200Hz , which would be big 
enough for respiration detection. 
 MAX/MSP is used as a main platform . The pressure signal 
is sent to a MAX/MSP patch and preprocessed with digital 
filters to eliminate DC -offset and reduce noise . The filtered 
signal is mapped to musical parameters considering the 
correlation between respiration, dance motion and musical 
parameter. The mapping strategy is the key point of this 
research. The interpreted mus ic parameters modulate given 
MIDI music sequence. The modified MIDI note is sent to the 
virtual instrument Ableton Live to synthesize the sound. 
 The goal of this research is the correspondence between the 
motion and music. Therefore, two correlations are needed to 
be considered  in mapping design : correlation between the 
motion and respiration, motion and music. Musical 
parameters are  designed considering these correlations . Two 
versions of mapping were attempted, and detail s of those 
mapping strategies and  evaluations will be discussed in the 
next chapter. 
 
 
Figure 1. Respiration sensor device 
 
4. MAPPING STRATEGIES AND 
EVALUTATIONS 
4.1 First Version 
Inhalation and exhalation is said to be related to the tension 
and relaxation of the body , which are dynamic characteristics 
of dance. As the pulmonary volume is  an accumulation of 
airflow and velocity of the airflow is proportional to the 
pressure [19], integration of the sensor pressure was used as  
an index of the pulmonary volume.  
 In fact, musical dynamics is a complicated term that is 
affected not only by loudness but also rhythm, pitc h and etc.  
[21] However, as the main goal of this research is to  improve 
the correspondence of given music , control feature is limited 
to the dynamic . The ventilation state is connected to the 
music loudness to raise it as the pulmonary volume increase 
(inhalation). In addition to the over -all loudness control, 
loudness of accompaniment part was controlled separately to 
change the affluence of music. It was easily implemented 
with use of multi-track MIDI file. 
 The first mapping system was demonstrated on stage at 
HANPAC Performing Art Center as a part of a new -media 
performance piece ‘ADC Project - Don’t Imagine’. A dancer 
was requested to choreograph with variety in motion with 
respect to the tempo and energy. Music was given with a pre-
defined piano MIDI score, and it was played and modulated 
with the aforementioned mapping strategy. And visual effect 
was displayed with proje ction and modulated with raw 
pressure signal. 
 After the performance, a brie f interview with some 
audiences was made. Audiences said they could not recognize 
the linkage between the music and dance. With the additional 
interview with the dancer, the proble ms of the first mapping 
strategy were discussed. First, loudness control with the 
pulmonary volume exposed conceptual error. Although the 
pulmonary volume is related to the tension and relaxation  of 
the body , the two states are static characteristic rather  than 
dynamic. H ence it came out to be  inappropriate to map the 
tension with the musical dynamics. It would be more 
appropriate to think the dynamic event of the body to occur 
with the transition between the tension and relaxation. 
 Another problem seen in  the dynamic control is latency. 
Inhalation or exhalation process is quite slow enough for 
human to recognize the time that pulmonary volume reach the 
peak with perceptible latency. It is critical to the 
correspondence of dance and music. 
4.2 Second Version 
4.2.1 Structure 
Another mapping strategy was designed after the evaluation 
of the first one and exposed problems were taken into account. 
First, basic concept of dynamic control changed. As 
aforementioned, a dynamic event of motion occurs with 
transition between t he tension and relaxation. It corresponds 
to the respiration event rather than pulmonary volume. It 
means that it is more appropriate to use pressure value that is 
proportional to the airflow [19] rather than the estimated 
pulmonary volume. 
 Another problem was latency. Use of pressure value instead 
of pulmonary volume  provides less latency.  Still, the 
respiration is so slow that perceptible latency happens while 
reaching the pressure peak. To reduce it even more , the 
concept of jerk is adopted. 
 Jerk is a physical term that represents the rate of change of 
acceleration, or force  [1]. As the jerk is the derivative of the 
force, physically corresponding dimension must be the 
derivate of the pressure assuming that the areal dimension is 
constant. Hence it was  decided to use this jerk as a basic 
factor for music loudness control. Simple peak detection 
algorithm is applied to detect  and figure out the height of the 
jerk peak. 
 Control parameter is designed like an ADSR envelope. 
Magnitude of a j erk peak decides attack level. Attack and 
release time is fixed to 0.4second. Release and decay part is 
made by adding raw pressure signal (Figure 2). 
 The biggest advantage of using the jerk is the minimized 
latency. Comparing to the estimated pulmonary volume and 
pressure, it has very short latency within 20ms. Another 
advantage is achieved by the physical meaning of  the jerk. 
Jerk is the rapidness of pressure, and it represents the 
rapidness of breathing. Breathing is not only categorized with 
deep and shallow, but also with rapid and smooth. Deep 
breath is mainly related to the big or relatively smooth 
motions while  the short breath is related to the more rapid 
movement. This short breath shows the bigger jerk value that 
we can achieve appropriate music accent for it. 
 As the dyna mic event of the motion happens with both 
direction of the transition, from relaxation to tension and vice 
versa, both of them were regarded as a positive factor for 
music dynamics. In other word, absolute value of the signal 
was connected to the music loudness. 
 
 
Figure 2. Signal flows of each step of the musical mapping 
 
3000 4000 5000 6000
Signals 
Time (ms) 
Pressure Jerk
Sawtooth Pulse Control Parameter
4.2.2 Evaluation 
The second mapping strategy was tested by a veteran 
contemporary choreographer who was thought to be well 
experienced in respiration control with improvised movement 
and musicality as a dancer, which are important abilities for 
this resea rch. Music sequence was replaced with a simple 
algorithmic random percussion rhythm to minimize bias of 
dynamic in original music. Recorded data includes video, 
filtered pressure signal, jerk, control parameter and modulated 
music data. Finally, through th e interview, he was  asked 
about his inclusive impression and opinion about the system. 
 Through the observation of those recorded data, we could 
see that, g enerally, respiration accent was corr esponding to 
the dynamic of motion  such as  rise and fall of bod y, 
contraction of torso, extension of torso and agility of the 
movement. Especially, such a pattern appeared remarkably 
during the dancer was doing athletic techniques like jump, 
kick and turn. The control parameter that derived from the 
pressure modulated  the loudness of the music. However, 
modulated accent was frequently not big enough to 
overwhelm bias of the initial accents of the rhythm sequence. 
Further adjustment of the mapping strategy might be required. 
 In addition to the data recording, we interv iewed the 
choreographer about the performance and expectation of the 
system. In conceptual aspect, as other many dancers, he 
emphasized the importance of the coupling between the 
motion and breathing. He agreed with that his movement had 
been generally well reflected to the music and the signal flow. 
 On the other hand, he claimed that the mask made him more 
breathless after he moved a lot, and it made him hard to 
control the respiration, which caused the respiration pattern 
more fluctuating and irregular. 
5. CONCLUSION 
In this research, musical application methodology of 
biomechanical aspect of the respiration to improve the 
correspondence between the music and dance has been 
explored. While the prior researches dealt with the respiration 
with spectral approach in metabolic aspect, motional aspect of 
the respiration can be more properly explored with temporal 
approach. Consequently, this research showed the potential of 
the new conceptual appro ach to utilize the respiration  for 
musical use. 
 There are still une xplored motional features of the 
respiration. While the test result of p ulmonary volume and 
difference between the inhalation and exhalation was 
undesirable, thos e are very important features that every 
dancer emphasizes. It has large potential  if proper 
corresponding musical features are found. Through the 
motional approach that takes the respiration technique and 
pattern of performer into account, more various and 
meaningful musical utilization of the respiration is expected. 
 
Supplemental materials for this paper can be found at: 
http://aimlab.kaist.ac.kr/~badclown/respiration 
6. REFERENCES 
[1] http://en.wikipedia.org/wiki/Jerk_(physics). 
[2] Bannerman, A. Connecting Spaces - Motion-capture, 
Dance, Sound. (formerly Dancing Sound - Sounding 
Dance). in Sound Moves: An International Conference 
on Music and Dance, 2005, London, England. 
[3] Boo, S.C., Study on the Muscular Strength, Power and 
Flexibility according to the Different States of Breathing 
(in Korean) , 1985, Graduate School of Education, 
Chosun University: Kwangju. 
[4] Brooks, G.A., T.D. Fahey, and K.M. Baldw in, Exercise 
Physiology: Human Bioenergetics and Its Applications . 
4th ed., 2005: William R. Glass. 
[5] Chung, K.I., The Influence that breathing has on the 
smoothness of dance movement (in Korean), 2008, Seoul 
National University: Seoul. 
[6] Cornelius, R. R., Theoretical approaches to emotion , in 
ISCA Tutorial and Research Workshop on Speech and 
Emotion-2000, 2000. p. 3-10. 
[7] Filatriau, J. -J. and L. Kessous, Visual and Sound 
Generation Driven By Brain, Heart and Respiration 
Signals, in Proceedings of the 2008 International 
Computer Music Conference, 2008. 
[8] Groux, S.L., et al., Implicit Physiological Interaction for 
The Generation of Affective Musical Sounds , in 
Proceedings of the 2008 International Computer Music 
Conference, 2008. 
[9] Imai, M., et al., Biological information sensing 
technologies for medical, health care, and wellness 
applications, in Proceedings of the 16th Asia and South 
Pacific Design Automation Conference , 2011, IEEE 
Press: Yokohama, Japan. p. 551-555. 
[10] James, W., What is an Emoti on? Mind, 1884. 9(34): p. 
188-205. 
[11] Kuikkaniemi, K., et al., The influence of implicit and 
explicit biofeedback in first -person shooter games , in 
Proceedings of the 28th international conference on 
Human factors in computing systems , 2010, ACM: 
Atlanta, Georgia, USA. p. 859-868. 
[12] Lee, C.S., A comparation analysis of strength according 
to the different states of breathing (in Korean) , 1979, 
Graduate School of Education, Chungnam National 
University: Daejeon. 
[13] Liolios, C., et al., An overview of b ody sensor networks 
in enabling pervasive healthcare and assistive 
environments, in Proceedings of the 3rd International 
Conference on PErvasive Technologies Related to 
Assistive Environments, 2010, ACM: Samos, Greece. p. 
1-10. 
[14] Rainville, P., et al., Basic emotions are associated with 
distinct patterns of cardiorespiratory activity.  
International Journal of Psychophysiology, 2006. 61(1): 
p. 5-18. 
[15] Tahiroglu, K., H. Drayson, and C. Erkut, An Interactive 
Bio-music Improvisation System , in Proceedings of the 
2008 International Computer Music Conference, 2008. 
[16] Takahashi, Y. and N. Okude, Dipa: play equipment with 
respiration-sensing interface, in ACM SIGGRAPH 2005 
Posters, 2005, ACM: Los Angeles, California. p. 100. 
[17] Tognetti, S., et al., Enjoyment recognition from 
physiological data in a car racing game , in Proceedings 
of the 3rd international workshop on Affective 
interaction in natural environments , 2010, ACM: 
Firenze, Italy. p. 3-8. 
[18] Wanderley, M.M. and N. Orio, Evaluation of Input 
Devices for Musical Expression: Borrowing Tools from 
HCI. Comput. Music J., 2002. 26(3): p. 62-76. 
[19] White, F.M., Fluid Mechanics . 5th ed., 2003, Boston: 
McGraw-Hill. 
[20] Wilson, G.F., Applied use of cardiac and respiration 
measures: Practical consideration s and precautions.  
Biological Psychology, 1992. 34(2-3): p. 163-178. 
[21] Woo, K.H., When Dance and Music Met (in Korean) , 
2000: Yesol. 
[22] Woo, K.H., Movement and Rhythm of Dance (in 
Korean), 2004: Yesol. 
 