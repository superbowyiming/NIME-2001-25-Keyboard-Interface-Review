A Survey and Thematic Analysis Approach as Input to 
the Design of Mobile Music GUIs 
 
 
Atau Tanaka 
Goldsmiths Digital Studios 
Goldsmiths, University of 
London 
SE14 6NW London UK 
a.tanaka@gold.ac.uk 
 
Adam Parkinson 
Culture Lab 
Newcastle University 
Newcastle upon Tyne 
NE1 7RU UK 
a.d.parkinson@gmail.com 
 
Zack Settel 
Music Faculty 
University of Montreal 
200, ave. Vincent-dʼIndy 
Montréal (QC) H2V 2T2 
zs@sympatico.ca 
 
Koray Tahiroğlu 
Department of Media 
Aalto University,  
School of Arts, Design and 
Architecture 
koray.tahiroglu@aalto.fi  
 
ABSTRACT 
Mobile devices represent a growing research field within 
NIME, and a growing area for commercial music software. 
They present unique design challenges and opportunities , 
which are yet to be fully explored and exploited. In this paper, 
we propose using a survey method combined with qualitative 
analysis to investigate the way in which people use mobiles 
musically. We subsequently present as an area of future 
research our own PDplayer, which provides a completely self 
contained end application in the mobile device, potentially 
making the mobile a more viable and expressive tool for 
musicians.  
 
Keywords 
NIME, Mobile Music, Pure Data  
1. INTRODUCTION 
As mobile phones have increased in processing power, there 
has been an explosion in mobile music research and 
performance, and the release of commercial apps [4], [18]. The 
mobile phone can be considered a computer, one that is 
sufficiently powerful enou gh to carry out signal processing in 
real time. The signal processing cores of interactive music 
platforms like Pure Data and Supercollider run on mobiles in 
the form of libraries [15]. These developments, in industry and 
in research, have taken place rapidly and organically. While 
many apps exploit new interface capabilities of the mobiles, 
few successfully address the specific limitations of the mobile 
and its form factor. In this light, the mobile is not just a small 
computer, but is a type of musical platform unto itself with 
specific sets of affordances and constraints. To design 
interfaces for these systems, it can be useful to understand the 
potential end user, and their expectations and experiences of 
mobile music making. 
 We propose a survey -based study-method to define the needs 
for screen interfaces to mobile music instruments. We draw 
upon user centered design (UCD) methodology from HCI 
practice, a family of qualitative and ethnomethodological 
methods that include the end user in the design proces s. 
Established UCD methods include ethnographic interviews, 
structured brainstorming, scenario building, participatory 
design workshops, and user studies. Surveys are one such 
method that is used at the outset of a design exercise to gauge 
user needs and understand existing usage. Thematic analysis 
can then be applied to extract emerging themes across the 
survey dataset, to structure and codify themes to inform the 
design of an interactive system. We report on a study that we 
conducted that includes an online survey and a resulting GUI 
framework for Pd on mobile devices. 
2. RELATED WORK 
HCI methods have been broadly applied as inputs to the design 
and as on evaluation of the outputs of NIME instruments. There 
has been a greater overall emphasis in the evaluation of NIME 
instruments and interfaces.  
 The importance but relative lack of evaluation of NIME 
instruments has been discussed by Stowell et al. [21]. They 
raise questions of how to evaluate the uses and affordances of 
new musical interfaces and compare the user experience of the 
designed system based between free and guided use of the 
interface. Johnston [14] proposes a broader study for the 
evaluation in order to understand the creative practice in a 
performer’s use of a NIME. Using techniques from grounded 
theory for data analysis and focusing on user experience 
studies, he proposes a theory of musician-interface interaction 
through experimental analysis. Beilharz et al. [5] approach user 
experience evaluation through task completion studies, 
interviews and questionnaires. Their findings indicate the 
necessity of user evaluation studies in order to fill the gap 
between user expectations and designers’ intentions especially 
in their context of wearable interfaces where the expression 
with the interface itself  is highly subjective. Fabiani et al. [9] 
look at the evaluation of a mobile system using a survey based 
questionnaire, across a diverse range of users followed by a 
controlled lab based experimental evaluation.  
 Evaluation methods from HCI research have been adapted to 
explore the creative affordances of NIME instruments. 
Gelineck and Serafin [11] apply questionnaire and usability 
tests with simple musical tasks and propose a musical task-
based method for investigating the comparative creative 
affordance of different basic control interfaces such as knobs 
and faders. Wanderley and Orio [23] present several methods 
for the evaluation of input devices and propose alternative 
musical tasks that are that demonstrate the usability of the 
controller; such as learnability, explorability, feature 
controllability and timing controllability. They aim to create 
simple guidelines for the performance evaluation of input 
devices. This evaluation methodology is not applied in a 
musical performance context but rather as a means to measure 
user intentions in the control of a musical interface. In the study 
of performances, Zappi et al. [24] used a questionnaire method 
to ask the audience evaluate a participatory audio- visual 
performance. 
 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that 
copies bear this notice and the full citation on the first page. To  copy 
otherwise, to republish, to post on servers or to redistribute to lists, 
requires prior specific permission and/or a fee.  
NIME’12, M ay 21 -23, 2012, University of Michigan, Ann Arbor.  
Copyright remains with the author(s).  
 
 User centered design and participato ry design are established 
methodologies in HCI that consult end-users and involve them 
in the design process of an interactive system. Bau et al. [3] 
used interview, structured brainstorming, and scenario building 
methods to inform the design of a novel au ditory display 
device. Essl [8] used design methodology to create an audio 
programming environment specific for the mobile. 
 NIME instruments are more typically created for specific 
musical projects or in a particular compositional context and 
tend not to consult a broad user base to gauge needs as an input 
to design. Whether the resulting interfaces are evaluated or not, 
this tendency risks to limit the usability and generalizability of 
NIME instruments. Through focusing on broad and general 
issues of mobile music practices in our own survey and using 
techniques of thematic analysis, we hoped to be able to distill 
some of the key design issues for contemporary mobile music 
practices. 
3. METHODS 
Thematic analysis is an approach that allows researchers to 
identify emergent topics not explicitly stated in survey 
questions. The theoretical framework is based on organizing 
key issues in data and grouped under themes reflecting 
important relations in the research questions. Thematic analysis 
should not conceptualize themes directly as answers for the 
overall research question but rather serve to frame key topics 
that involve specific descriptions in relation to the question [7].  
 We conducted an online survey for the period of three weeks 
using Survey Monkey [22]. Th e survey was publicized on 
mailing lists and forums geared towards music technology 
practitioners and institutions; such as Auditory, New Interfaces 
for Musical Expression (NIME) community, Sound and Music 
Computing (SMC) network etc. In this survey we aimed to find 
out the ways in which people have been using mobiles 
musically: for instance, as free-standing instruments, 
standalone portable studios, gestural controllers for laptops. We 
also wanted to understand the types of problems and challenges 
they mig ht encounter as they transposed their practices honed 
on desktop or laptop computers to mobile devices. 
Additionally, we wanted to know how they imagined mobiles 
being used musically in the future. 
 The survey was anonymous and was comprised of 19 
multiple choice questions that covered the following topics:  
• Musical experience 
• Computer programming experience  
• Types of mobile musical usage (e.g. composition, 
production, performance)  
• How usable and musical respondents found mobile 
music apps 
• Whether the mobile felt like an instrument and 
musically “expressive” 
 Alongside the multiple choice questions were a series of 
open-ended questions, requesting textual responses. These gave 
more room to respondents to refer to their personal experience. 
After gathering the results, the quantitative data was tabulated 
and the textual responses were collated for further qualitative 
analysis. This broad thematic analysis was intended to identify 
emerging themes and enable us to understand respondents 
concerns, in particular those that we hadn’t predicted or 
prompted by our own questions.  
4. RESULTS 
We gathered 226 surveys, 177 of which were completed (a 
completion rate of 70.5 %). The gender balance of respondents 
was 81.8% (180) male and 18.2% (40) female. 6.8% (15) 
participants w ere under the age of 24, 42.6% (94) were in the 
25-34 age group, 31.2% (69) in the 35 -44 age group and 19.5% 
(43) over the age of 45.  
 We asked the participants about their programming and 
musical expertise. When asked if they were a musician, 19.7% 
(42) responded 'no', 8.5% (18) 'beginner', 36.2% (77)'amateur' 
and 35.7% (76) 'professional'. When asked if they had any 
experience as programmers, 9.8% (20) replied 'not at all', 
29.8% (61) 'a little', 26.8% (55) 'quite a lot' and 33.7% (69) 
'very much'. 
 Our mu ltiple-choice questions asked respondents about the 
different ways in which they might use the phone musically. 
32.8% (64) used the smartphone in live performance, 32.8% 
(64), used music game apps and 24.1% (47) used a smartphone 
as a portable studio for composing music, whilst 43.1% (84) 
did not use their smartphones for making music.  
 18.4% (18) of those who had used instrument -like apps on 
the iPhone found they felt ‘not at all’ like an instrument, 55.1% 
(54) found they felt only 'a little' like an inst rument; 19.4% (19) 
found them 'quite a lot' like an instrument and 7.1% (7) found 
them ‘very much’ like an instrument. When asked whether the 
smartphone provided an interactive musical experience, 2.4% 
(2) replied ‘not at all’, 38.6% (32) replied ‘a little ’, 28.9% (24) 
replied ‘quite a lot’, and 30.1% (25) replied 'very much’ . 
 The smartphone was a regular part of the performance set up 
of 28.7% (27) of the users who had performed with it. Only 
8.3% (8) of participants who used portable studio type apps ha d 
actually finished a complete song on it.  
 56.5% (52) users used the smartphone in conjunction with a 
computer for music making. Nonetheless, 79.3% (73) 
respondents could imagine using a smartphone musically 
without a computer. We asked respondents how th ey used the 
sensor capabilities of the smartphones for musical purposes: 
91.9% (79) used the touchscreen, 59.3% (51) used the 
accelerometer, 51.2% (44) used the microphone, 19.8% (17) 
used the camera and 14% (12) used the proximity sensors. We 
asked about some of the collaborative and interactive aspects of 
mobile music making. 56.8% (46) used the smartphones 
musically in collaboration with others. When asked whether 
they felt like they were interacting with others through the 
smartphone, 11.8% (4) said ‘no t at all’, 23.5% (8) ‘only a 
little’, 52.9% (18) ‘some’ and 11.8% (3) ‘very much’. 
5. ANALYSIS 
The hybrid structure of the survey, with multiple choice and 
open-ended questions provided flexibility for us to apply a 
qualitative analytic method for analysis. Within the thematic 
analysis methodology, we looked the recurrence of certain 
issues in the answers, that included: limitation of the 
touchscreen, lack of consistency in sensor input, latency, 
networked possibilities, toy-like music applications, etc. 
Looking at how these issues mapped on to the practice of music 
making and by combining them in groups allowed us to 
identify high -level themes: “Frustration to Potential", 
"Workflow" and "Expressivity". At a higher level, the 
respondents were addressing the for ms of interaction afforded 
by the mobile devices intuitively without demonstrating 
knowledge of or directly citing the theory of affordances. These 
responses could be categorized broadly in two areas - 
interaction centered around the device and its form fa ctor, and 
interaction focused around the communicative, or social 
capabilities of the mobile phones. We then went back to the 
survey results and extracted related data with specific 
questions, through the lens of the main themes, allowing us to 
organize responses to different questions thematically, eliciting 
a potential narrative that was not prescribed by the design of the 
survey questions. Elemental units of study such as sensor 
interaction, usage paradigms, form factor, and unrealized 
potential, come to gether as related themes linked to musicality 
that become points of discussion within the context of a high 
level thematic analysis method.  
5.1 Modes of Musical Interaction 
5.1.1 Device Interaction  
Device interaction relies on the input capabilities of the 
embedded sensory systems of the mobile and enables multiple 
ways of using mobiles for making music. Sequencing with real -
time control of parameters is mentioned as one of the most 
common modes of musical interaction in our survey; both in 
the category of composing and gaming with music applications. 
This mode of musical interaction is linked to touchscreen -based 
control interfaces, and device interaction was often described as 
problematic in terms using of this touchscreen interface for 
editing within many mobile mu sic applications. Instrument -like 
applications were often referred to as being ‘just toys’ in the 
survey. Users reported serious limitations and lack of precision 
due mainly to latency issues and GUI problems and pointed to 
many interface design issues. Ho wever, for those who did use 
their smartphones as independent instrument, sensor 
capabilities, portability and mobility all emerged as positive 
aspects of the devices. 
 
 ‘remarkable: possible to make expressive gestures, advantage: 
small form factor, limitations: no haptic feedback’ (59) 
 
 Interaction with these instrument -like applications might 
result in developing new gestural libraries for mobile devices: it 
is mentioned in the survey that they produce new ways of 
interacting with the device. We were al so interested that one of 
the main demands of future design in mobile music applications 
was to enable more “creative ergonomy”, embracing what is 
unique and what comes naturally in interaction with these 
devices. Simply transplanting traditional conceptio ns of ‘real 
world’ instruments and emulating them in the design of musical 
applications did not fulfill the expectations for how mobiles 
could be used as musical instruments. 
 
 ‘I would prefer to use something that treats the devise as in 
interface in its own right and uses gestures/controls more 
natural to it than trying to play a tiny piano’ (31) 
 
'I think we want to get away from traditional interfaces like 
keys, strings, and even knobs and sliders as much as possible 
and be more abstract, while still maintaining a sense of some 
kind of intuitive system.' (8)  
 
 We found that for many the main interest in using 
smartphones musically was for exploring alternative options for 
gestural control in live performances. Sending sensor input data 
via wireless netwo rks to computers - generally running Max 
MSP or Ableton Live - was the most common way of using 
smartphones in live performance.  
 
 ‘Smartphones for us at this point are partly instruments but 
mostly controllers for Ableton’ (2) 
 
 However, reliability of th e wireless connection in such real -
time performances was questioned. In a programming context, 
device interaction was found to be highly limited in terms of 
input bandwidth, screen size, CPU speed, lack of pressure 
sensitivity and even suggestions of dynam ic screen texture. It 
was also mentioned that these type s of limitations could also be 
an advantage, creating focus on honing interaction. Mostly, rich 
library resources and quick iteration cycles were found by 
respondents to be advantages of programming o n smartphones. 
 
‘What an enormous pain. Has anyone heard of snippets? Give 
me back my keyboard!’(4) 
5.1.2 Social Interaction  
In a musical context, mobiles retain many of their social -
interaction aspects. This is not only through their embedded 
network features a nd their basic affordances as communication 
devices. Many music apps can become systems that allow 
designers to enable and promote various notions of social 
interaction in music making. As some respondents mentioned 
in the survey, the mobile opens opportunities for interaction in 
a collaborative context. Most of the respondents who replied to 
our question on participation and interaction mentioned that 
mobiles enabled the potential for networked interaction, as a 
possible platform for synchronized performan ces both locally 
and remotely. 
 
 ‘We have performed as a mobile phone orchestra to explore 
and research the smartphone as NIME's [...] advantages 
include these devices being close to their owners in their daily 
lives.’ (33) 
 
 ‘Networking possibilities pote ntially offer synchronized 
performance both locally and globally.’ (138) 
 
 Besides potentially making music creation more social, 
networked features also make it possible to share the created 
content and be part of online communities: social interaction 
can be integrated at many different layers in practice. A mobile 
application can enable a user to create music, connect that user 
to a network to collaborate musically or to receive online peer 
critique, and in the final stage it may allow the user to distribute 
the piece through social networks. This social experience also 
brings up a new forms of musical engagement that potentially 
allow for a democratizing of the multiple aspects of music 
production and distribution. The respondents also stressed how 
the interaction design of the applications affected the human -
human interaction in music collaboration. It is mentioned in the 
survey that much interaction requires the performer to look at 
the device in order to play it, affecting any musical interactions, 
which require eye contact between performers.  
 
 ‘difficult to keep eye contact without physical controllers 
(sense of touch)’ (25) 
 
Other respondents pointed to the social affordances of mobiles, 
resulting from the combination of mobility, commonality and 
network features, as they suggested:  
 
 ‘Probably the best use for mobile is in real -time audience 
participation’ (39) 
 
 ‘The network capabilities could enable [people coming] to a 
concert being able to download an app and build their own 
loops in synch with the concert.’ (127). 
6. Adaptive Interfaces 
Screen real estate and workflow issues combine to define 
limiting factors in musical expressivity of mobiles. We propose 
an app with a hybrid GUI system that uses an adaptive 
graphical display rendering a runtime gra phic interface on the 
premise that musical activity on the mobile is more focused on 
performance than on programming.  
 Mobile interface design provides unique design challenges, 
different from many of the challenges of computer -based 
interface design, and  has been the subject of previous CHI 
Workshops [17], and conferences in its own right (MobileHCI). 
One of the problems of designing for mobile is considering 
how to represent desktop and laptop user interfaces on the 
smaller mobile devices. Mori and Pater nò, [16] and Bandelloni 
et al [2] look at the problems with resizing user interfaces to 
function on mobiles, proposing a 'semantic redesign' which 
transplants the actual functionality of webpages to mobiles. 
Gupta et al [12] approach this problem through r epresenting 
webpages as multilevel hierarchies, and Hattori et al [13] 
propose a method of segmenting webpages for representation 
on mobile screens.  
 The small form factor, in particular the size of mobile screens 
(a consistent concern that emerges throug hout our own survey), 
is a key design a challenge. Some work looks at improving 
existing paradigms, such as Robbins, Lee and Fernandez [19], 
who examine different workflow and GUI integrations on 
mobile devices and present a novel GUI method. Similarly, 
Findlater, Wobbrock and Wigdor [10] look at the issues 
inherent to touchscreen typing and propose more ergonomic 
layouts for touchscreen keyboards. Roudaut, Lecolinet and 
Guiard [20] propose expanding input bandwidth through 
discriminating amongst subtly different thumb gestures. Benko, 
Wilson and Baudisch [6] look at two finger gestures techniques 
for pixel-accurate selection on larger touchscreens and tabletop 
displays, honing techniques for ‘pinch’ and other gestures. 
7. Conclusions and Future Work 
Since the mobile is not ideal for programming, and as the 
attraction of the mobile is for small, gestural touchscreen 
instruments to be used in performance situations, we propose a 
mobile application that divides the mobile music workflow into 
composition and perfor mance modes.  
 This mirrors the Edit and Playback modes of Max MSP or 
Pure Data. In our proposed solution, Edit mode takes place on 
the computer (GUI development) with Playback mode only on 
the mobile (GUI use). We demonstrate an implementation this 
proposed system using Pure Data, libPD, and Open 
Frameworks. 
 The proposed workflow allows the musician to develop 
custom patches in the way they are accustomed to using a 
graphical programming paradigm while authoring on the 
computer. The renderer allows the mu sician to deploy her patch 
on the mobile “automatically” with no additional development 
steps and no additional technical knowledge required. The 
result is a functional interface of sliders and buttons that recalls 
the original patch, running on the mobile  touchscreen interface. 
8. REFERENCES 
[1] Balch, C.V. Internet Survey Methodology . Cambridge, 
2010. 
[2] Bandelloni,R., Mori,G.,and Paternò,F. Dynamic 
Generation of Web Migratory Interfaces. In Proc. 
MobileHCI 2005, ACM Press (2005), 83 -90.  
[3] Bau, O., Tanaka, A., and M ackay, W. The A20: Musical 
Metaphors for Interface Design. In Proc NIME 2008, 
Genova (2008).  
[4] Beatmaker www.intua.net . 
[5] Beilharz, K., Moere, A., Stiel, B., Calo, C., Tomitsch, M. 
and Lombard, A., Expressive Wearable Sonification and 
Visualisation: Design and Evaluation of a Flexible 
Display. In Proc. NIME 2010, Syndey (2010). 
[6] Benko,H.,Wilson,A.,and  Baudisch,P.Precise Selection 
Techniques for Multi-Touch Screens. In Proc. CHI 2006, 
ACM Press (2006), 1263 -1272. 
[7] Braun, V., and    Clarke, V .  Using Thematic    Analysis 
in Psychology. In Qualitative Research in Psychology 3, 2  
(2006), 77-101. 
[8] Essl,G. Mobile Phones as Programming Platforms. 
Proceedings of the First International Workshop on 
Programming Methods for Mobile and Pervasive Systems  
(2010). 
[9] Fabiani, M., Dubus, G., and Bresin, R. MoodifierLive: 
Interactive and collaborative expressive music 
performance on mobile devices. In Proc. NIME 2011, 
University of Oslo and Norwegian Academy of Music 
(2011), 116-119. 
[10] Findlater,L.,Wobbrock,J.,andWigdor,D.Typingon Flat  
Glass: Examining Ten-Finger Expert Typing Patterns on 
Touch Surfaces. In Proc. CHI 2011, ACM Press (2011), 
2453-2462. 
[11] Gelineck, S., and Serafin, S. A Quantitative Evaluation of 
the Differences Between Knobs and Sliders. In Proc. 
NIME 2009, Pittsburgh (2009) 13-18. 
[12] Gupta, A., Kumar, A., Mayank, Tripathi, V., and Tapaswi, 
S. Mobile Web: Manipulation for Small Displays using 
Multi-level Hierarchy Page Segmentation. In Proc. 
Mobility 2007, ACM Press (2007), 599 -606. 
[13] Hattori, G., Hoashi, K., Matsumoto, K., and Sugaya, F. 
Robust Web Page Segmentation for Mobile Terminal 
Using Content-Distances and Page Layout Information. In 
Proc. WWW 2007, ACM Press (2007), 361 -370. 
[14] Johnston, A. Beyond Evaluation: Linking Practice and 
Theory in New Musical Interface Design. In Proc NIME 
2011, Oslo (2011), 280 -283. 
[15] Konrad, M. Analysis of audio synthesis possibilities on 
mobile devices using the Apple iPhone and iPad . Ph.D. 
Thesis, HTW Berlin, 2011.  
[16] Mori, G., and Paternò, F. Automatic Semantic Platform - 
dependent Redesign. In Proc. SOC-EUSAI 2005, ACM 
Press (2005), 177-182. 
[17] Nakhimovsky, Y., Eckles, D., and Riegelsberger, J. 
Mobile User Experience Research: Challenges, Methods 
& Tools. In Proc CHI 2009, ACM Press (2009), 4795 - 
4798. 
[18] Wang, G.Designing Smule's iPhone Ocarina. In Proc. 
NIME 2009, Pittsburgh (2009).   
[19] Robbins, D., Lee, B., and Fernandez, R. TapGlance: 
Desigining a Unified Smartphone Interface. In Proc. DIS 
2008, ACM Press (2008), 386 -394. 
[20] Roudaut,    A.,    Lecolinet,    E.,    and    Guiard,    Y .    
MicroRolls: Expanding Touch-Screen Input Vocabulary 
by Distinguishing Rolls vs. Slides of the Thumb.  In Proc. 
CHI 2009, ACM Press (2009), 927-936. 
[21] Stowell, D., Plumbley, M.D, and Bryan -Kinns, N. 
Discourse analysis evaluation method for expressive 
musical interfaces. In Proc. NIME 2008, Genoa (2008). 
[22] Survey Monkey http://www.surveymonkey.com/  
[23] Wanderley, M., and Orio, N. Evaluation of Input Devices 
for Musical Expression: Borrowing Tools from HCI. 
Computer Music Journal 26, 3  (2002), 62-76. 
[24] Zappi, V., Mazzanti, D., Brogni, A., and Caldwell, D. 
Design and Evaluation of a Hybrid Reality Performance. 
In Proc. NIME 2011, Oslo (2011), 355-360. 
 