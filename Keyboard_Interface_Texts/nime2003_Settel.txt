Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
Convolution Brother’s Instrument Design
Zack Settel
Zeep.com
4319 Esplanade, suite 1
Montral QC, CA
zack@zeep.com
Cort Lippe
Department of Music
Hiller Computer Music Studios
222 Baird Hall
Buffalo, NY , USA 14260
lippe@buffalo.edu
ABSTRACT
The subject of instrument design is quite broad. Much work
has been done at Ircam, MIT, CNMAT, Stanford1 and else-
where in the area. In this paper we will present our own
developed approach to designing and using instruments in
composition and performance for the authors’ “Convolution
Brothers” pieces. The presentation of this paper is accom-
panied by a live Convolution Brothers demonstration.
1. INTRODUCTION
To be sure, ins trument design has always been a rich
source of inspiration and di scovery for th ea u thors. We
continue to be fascinated by the relationship between in-
struments and the music written for them. The piano is
worth considering in this light. It was born from an idea: an
improvement to the harpsichord, which introduced the con-
cept of note-independent dynamic range to keyboard music.
Repertoire for the instrument only emerged once the piano
had been in the hands of performers and composers for a
certain time, after its appearance around 1700. In short,
the sound and nature of the piano inspired or induced both
pianistsand composers to discover new kinds of music for
the instrument: “piano music” (i.e. the kind of music writ-
ten by Mozart, Chopin or Debussy). One could say that the
instrument had a particular innate musical potential, based
on its design, just waiting to be tapped. The same appear-
ance of instrument-inspired music followed the introduction
of the saxophone, or electri cg u i t a r . T h eplaying and mu-
sic of Charlie Parker and JimiH endrix cannot be separated
from their respective instruments.
Harry Partch and John Cage are two excellent examples
of composers whose work deeply integrated instrument de-
sign in the compositional process. Harry Partch produced
compositions that integrated new scales, notation, and in-
struments (including playing techniques). The resulting mu-
sic remains quite distinctive and reﬁned; his music is easily
identiﬁed and consistent with his other works. Even more
impressive is Cage’s works for prepared pianos, where Cage
takes the piano as an instrumental point of departure, and
builds a completely new instrument with an extremely wide
expressive range (discussed later). Very little of the piano’s
original sound is retained. Rat her, the instrument is com-
pletely revisited, based on the concept of an ensemble of per-
cussion instruments under the control of a single musician.
Cage’s works for prepared pianos represent an unparalleled
example of creative expression, innovation and elegance in
1The following individuals are quite active in this area: B.
Rovan (IRCAM), T. Machover( M I T ) ,M .M a thews (Stan-
ford) and D. Wessel (CNMAT).
composition. While the “instrument” and resulting compo-
sitions are in many ways (starting with the timbre) unprece-
dented, much of the underlying compositional “implemen-
tation” (i.e. instrumental technique, and writing/scoring)
was squarely based on the tradition and practice of piano
music. From our point of view, in terms of compositional
approach, the prepared piano instrument serves as a vehicle
for discovery, a source of ideas, inspiration and composi-
tional curiosity. It is at the root of the inspiration of the
music composed for it. In o ur approach to composing, the
choice (or dev elopment) of instrument can be at the root
of compositional inspiration, and is a crucial stage in the
rendering of the piece. It is as if the music for a piece were
“reverse-engineered”, given the instrument it is composed
for. Otherwise said, in inve nting an instr ument, one in-
vents a piece. Thus, we attach a great deal of importance
to instrument design, and have developed an approach to
composing in this way.
2. DEVELOPING INSTRUMENTS
One of the most important considerations we have come to
recognize in designing instruments for composition is what
we would call “instrumental expressive range”; i.e. to what
extent the designed instrumenti sa b l et ot r ansmit the “mu-
sical message” of the performer, and to what extent the
instrument is able (versatile enough) to handle a wide range
of musical messages. The ideal instrument would be totally
responsive and completely transparent, consistently trans-
lating the musician’s playing actions instantly into sound,
arbitrarily without interference or distortion. Though not
ideal, it is worth referring to Cage’s prepared piano instru-
ment; sure, it lacks the stylistic versatility of the clarinet,
but it is remarkably transparent, capable of transmitting
even the ﬁnest playing gestures( b a s e do np i ano technique,
acquired over the years).
2.1 Instrumental expressive range
The expressiverange of a given instrument tends to deter-
mine its musical potential with respect to style (i.e. types of
musical expression that it lends well to), or compositional
application. While the piccolo is a ﬁne ensemble instru-
ment, it is rarely chosen by c omposers for solo works; to
imagine an evening of piccolo music is terrifying. The vio-
lin, on the other hand, lies at the other (complex) end of the
“instrumental complexity” continuum, and would be a ﬁne
instrument to be marooned on a deserted island with. The
number of music cultures around the world that include vi-
olin, or violin-like music is substantial. Based on its design,
the violin is capable of a vast range of musical expression.
The same can be said of other instruments of a similar de-
NIME03-197
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
gree of complexity, such as the saxophone or clarinet. Cage’s
prepared piano, mentioned above, would occupy a position
on the ins trumental complexity continuum (shown below)
much closer to the violin than to the claves.
claves piccolo violin
simple complex
Figure 1: Instrumental complexity
2.2 Instrument structure
In general, a complex instrument holds the greatest poten-
tial for musical (including, but not limited to compositional)
discovery-especially instruments that are unusual, since the
music they “embody” tends to emerge without being subject
to habits of hearing or musicalexpectation. What makes for
ac o m p l e xi n s t r u m e n t ?
1. High resolution and wide range with respect to dy-
namics, timbre and pitch (when applicable), though a
wide range is less important for pitch.
2. “Instrumental depth” or responsiveness: the degree to
which the instrument can consistently render a sonic
response speciﬁc to a particular instrumental manipu-
lation.
For example, the cl aves don’t qualify as a complex in-
strument. While they have ex cellent dynamic range and
resolution, the timbre never really changes. You can bang
on them any which way you please, but the resulting sound
is pretty much always the same.
The instruments we design for the “Convolution Broth-
ers” pieces tend to be complex, and typically involve acous-
tic instruments with electronic extensions for signal analysis,
signal processing, and sound generation. In each case, the
acoustic instrument is used as a sound source, and a con-
troller providing control signals derived via event detection.
Here’s how it looks on paper:
Figure 2: Electroacoustic instrument
The use of acoustic instruments in the design provides a
“built-in” degree of instrumental complexity and richness,
and a high-resolution “musical interface” for controlling the
instrument via event detection. It’s a good way to get
around the limitations of (usually low and) ﬁnite-resolution
controllers (i.e. all electronic controlling devices, and partic-
ularly those with 7-bit MIDI implementations). In this way,
the control resolution can approach that of the audio (e.g.
the envelope follower, that produces a 32-bit intensity pa-
rameter). Additionally, the acoustic instrument’s dynamic
spectrum (or fundamental aspects of it) is often present in
the instrument’s output, usually transformed. Thus, the
player’s technique and initial expression, as manifest in the
dynamic spectrum, are retained. An excellent simple exam-
ple of this is singing into a ring modulator; while the output
sound is completely transformed, all changes (no matter how
ﬁne) to the singer’s spectrum at the input of the ring mod-
ulator will produce corresponding degrees of change in the
modulator’s output spectrum. From this point of view, the
processing technique is highly transparent to the singer. Fi-
nally, the acoustic instrument’s spectrum can be combined
with additional sound sources, whose behavior is analogous
in one or more ways to the acoustic instrument’s behavior,
and a hybrid sound results. For example, an FM genera-
tor’s frequencies can be mappe df r o mt h eacoustic instru-
ment’s detected pitch, while the FM generator’s dynamic
spectrum is spectrally gated (asi nv o c o d i n g )b yt h ea c o u s -
tic instrument’s spectrum. The resulting sound’s behavior
is quite similar to that of the acoustic instrument. However
the spectral content can ber a d i cally diﬀerent.
2.3 The instrument and its context
The higher the degree of an instrument’s sophistication
(i.e. the instrument’s ability to produce a wide range of
timbral responses, based strictly on the musician’s input),
the less it needs to be updated via “external” (non-player
based) parameter or conﬁguration changes. Typically, these
kinds of “external” updates are based on the player’s po-
sition inthe score (or musical situation), and executed via
manual triggering, control tracks, or score followers. With
thea bility to design a sophisticated instrument and predict
how it will respond (sound) to a performer’s particular mu-
sicali nput, the performer’s score can be written with the
instrument’s response in mind, and material can be written
in the scoreto provoke certain resp onses from the instru-
ment when played by the performer. No score following is
required. Instead, the performer’s score serves as a sort of
control track, containing a sequence of events that will ulti-
mately determine (via event detection and parameter map-
ping) how the instrument is to sound . This relationship
between the instrument and the music intended for it is cen-
tral to our approach to instrument design and score crafting
(or improvisation applications).
3. IMPROVISATION
Designing instruments for use in speciﬁc compositions is
already a lot of work. However, the realm of possibilities
is limited by the demands of the given composition during
the course of its execution; the requirements of the instru-
ment are “deﬁned” as a single sequence specifying the in-
strument’s behavior and state at any given moment during
the piece. The sequence itself often consists of references to
patches to be activated at a particular time, with associated
context-speciﬁc data, such as harmonizer transpositions or
what have you. Score following is a well-known technique
which is employed for this kindof functional sequencing, and
can be eﬀective as long as the sequence of functionality for
the instrument is pre-deﬁned-and as long as there’s some-
one watching the score follower. Designing instruments for
use in compositions with “structured improvisation” is more
work; the instruments are not designed for use in a highly
circumscribed through composed musical situation. Rather,
they are designed to be “run away with”, in the “hands” of
NIME03-198
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
av i r t u o s op e r f o r m e r .
The amount of complexity required ofa ni n s t rument for
improvisation is signiﬁcant-especially if the player expects
to play for more than ﬁve minutes without getting bored.
The trouble with our ﬁnite electronic instruments is that
they usually only go as far as the imaginations of the de-
signers. Unlike an empty oil barrel, you can bang on a
synthesizer any number of ways, the result ing sound will
always be within the realm of its speciﬁed, “programmed”
behavior, intended or not. The oil barrel delivers an inﬁnite
number of variations for each “whack”. This brings us back
to the above discussion on instrumental depth: If you are
going to have to spend some timeo nad e s e r ti sland with an
instrument, or are planning to improvise, you better make
sure your instrument is not easily exhausted. Designing in-
struments for arbitrary style-independent improvisation sit-
uations is not obvious. Even a saxophone would have a hard
time living up to such an ideal. But let’s say that even when
the style is somewhat deﬁned, such as the “out there” exper-
imental electroacoustic free-jazz, like the kind of stuﬀ you
hear at festivals in Victoriaville, Quebec or in Vandoeuvre,
France, a “suitable” instrument’s potential range of expres-
sion is still enormous.
3.1 The instrument interface
The instruments described above, particularly the ones
used for virtuosop a s sages in the Convolution Brothers’ works,
serve as good points of de parture for improvisation instru-
ments. Rather than going into e ndless descriptions of vari-
ations on the coupling/combining/piloting of unit genera-
tors, we will emphasize an addi tional aspect of the impro-
visation instrument: the interface. Unlike the instruments
in “through composed” works, that resemble timelines more
than anything else, the interfacef o ran improvisation instru-
ment needs to be intuitive and allow for on-the-ﬂy enabling
of the instrument’s features (e.g. percussion sound trigger-
ing, reverse-gate reverb, triggered harmonization, sampler
source material choices, etc. ). Everything (all the DSP)
must be able to run a tt h es a m et ime! The interface also
needs to be modularized, so that subsets of it can be mixed
and matched. Below is the interface that the authors have
been developing over the past few years, and are currently
using for improvised performance:
Thei nterface provides two input meters, corresponding to
DSP sends A and B. The DSP sends feed their respective
unit generators. Many, but not all the types of unit gener-
ators in DSP A exist in DSP B. Using this “parallel” DSP
implementation, the same input signal can be routed to both
DSP A and DSP B, for extensive processing. Alternatively,
twoi ndependent inputs can be routed to either DSP send,
and thereby be processed independently of each other, as in
the case of a duo. The functional parts of the interface are
broken down into the following parts:
3.1.1 Recall via PRESET
Contains a preset object, which allows the state of all the
principal graphical parameter displays on the interface to
be captured and recalled, snapshot fashion. This feature is
invaluable, allowing for last-minute and/or in-concert mod-
iﬁcations/additions to the instrument.
3.1.2 “Sub States"
Consists of labeled switches (1A-16A) that represent en-
abled/disabled sub states (audio and control routing and
DSP states, deﬁned elsewhere, see ﬁg 4), in which arbitrary
control sources fort h e unit generators of DSP A are de-
ﬁned. These sources include parameter data, control al-
gorithms, and event detection control-stream mappings to
DSP parameters. For example,sub state “3A” activates a
sampler in DSP A, and routes the triggers and amplitude en-
velope (from the event detector) to the sampler. Sub states
are constructed add-hoc, as needed, addressing one or more
unit generators; there is no one-to-one correspondence be-
tween sub states and particular unit generators. Thus, any
combination of sub states can b ea c t i v e ,h o w ever, certain
enable/disable the same unit generators, so care must be
taken when cooking up combinations of them. An input
meter displaying the input level of the each of the two DSP
sends is included.
3.1.3 Event Tracking Assign
Routing of the computer’s three audio input signals to the
event detector, DSP A and DSP B is speciﬁed here. There
is only one tracking block to which any or all of the audio
inputs can be assigned.
3.1.4 Special Unit Generator Parameters
Particular unit generator parameters, including sample
names, are located here for quick access in performance,
or convenience during pre-concert preparation.
3.1.5 Output Mixer
Provides access to output gain levels for all the unit generators-
am i x e ro fs o r ts. The “trim” slider controls the gain of the
overall DSP output, and is quite indispensable since its value
often varies from preset to preset in order to maintain a uni-
form global “mix” level across them.
3.1.6 DSP States
Displays the state of the unit generators for both DSP
Aa n dB .F o rconvenience and rapid access to parameters,
external MIDI controllers can be used to control certain pa-
rameters of the interface such as feedback gain levels, trim,
and master gain. Typically those parameters are related to
mixing, not to the “instrument” per se.
The preset bank mentioned above provides instant recall
of anyc ombination of sub states. The fundamental behav-
ior and functionality of the improvisation instrument(s) is
deﬁned in the sub states, and combinations of them. New
sub states are added to the instrument from time to time,
as necessity or inspiration has it. But for the most part, de-
signing an instrument involves the combination of sub states
rather than the creation of new ones. Below, a code exam-
pleo fa sub state deﬁning the “gap-ﬁll” reverb mentioned
earlier. The performer’s amplitude gates his send level to
the reverb unit, and inversely gates the reverb proportion
(dry/wet mix) in the unit’s output.
4. USING THE INSTRUMENT
Normally, only a handful of presets are really used since
each preset represents a complex instrumental conﬁguration
that can be used for some time before “timbral exhaustion”
occurs. But mi nor changes to these basic presets are of-
ten made either b efore, or during, performance-mostly for
mixing balance purposes. Thus, the majority of the many
presets shown above are just modiﬁed copies of the basic
handful. On stage, the instrument spends most of its time
waiting for, responding to, and combining with the micro-
phone input. Some preset changes are recalled from time
to time when major musical “gear shifts” are required (such
as going to a speciﬁc “bell triggering” eﬀect for a moment).
NIME03-199
Proceedings of the 2003 Conference on New Interfaces for Musical Expression (NIME-03), Montreal, Canada
Figure 3: Code example of a “sub state”
However for the most part, it is the musician who evokes the
timbral changes in the instrument simply through his modes
de jeux, and not through major changes to the instrument’s
topology, signal routing or control mapping.
5. CONCLUSION
The strong em phasis on the “instrument” in this paper
reﬂects our longtime preoccupation with composing with
instruments for live performance. In our a pproach, the in-
strument is present in the composition process at its very
inception-as a sourceo fm u s i c a le xpression, wonderment,
curiosity, discovery, and inspiration. The approach to elec-
troacoustic instrument design presented in this text provides
for the invention and reinvention of new instruments, which
themselves can lead to new musical expressions, from which
compositions eventually emerge-which, in turn, inspire the
invention of still newer instruments. This iterative process
embodies composition and performance in a continuous cy-
cleo fc reation and expression, where the underlying tech-
niques serve simply as a vehiclef o rt h eimagination and as
as o u r c efor the musical spirit.
6. ACKNOW LEDGMENTS
Ourt hankst oM iller Puckette, Bennett Smith and David
Zicarelli.
7. REFERENCES
[1] C. Lippe. “Getting the A coustic Parameters from a
Live Performance” . In Proceedings of the 3rd
InternationalC o n f e r e n c efor Music Perception and
Cognition, pp. 328-333, Liege, 1994.
[2] C. Lippe. “Music for piano and computer: A
Description”. In Information Processing Society of
Japan SIG Notes,v ol. 97, no. 122, pp. 33-38, 1997.
[3] R. Rowe. Interactive music systems: machine listening
and composing.C ambridge, Mass.: MIT Press, 1993.
[4] D. Wessel. “Timbre Space as a Musical Control
Structure” Computer MusicJ o u r nal, vol. 3, no. 2 ,
1979.
[5] D. Wessel, D. Bristow, and Z. Settel “Control of
Phrasing and Articulation in Synthesis” In Proceedings
of the International Computer Music Conference,1987.
[6] D. Zicarelli. “Music Technology As A Form of
Parasite”. In Proceedings of the International Computer
Music Conference, pp. 69-72, 1992.
NIME03-200